id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/issues/106:1011,availability,replic,replicate,1011,"Best practice for handling replicates and associated statistics; I'm curious as to what would be the best practice for this situation... I have an np.array containing 18 expression values for gene y. There are 3 replicates, so 6 different conditions. . `adata.X[:,0] = [ 72. 92. 51. 93. 1. 46. 0. 33. 46. 75. 56. 28. 90. 100. 7. 25. 40. 81.]`. I need to calculate several values: replicate average, pvalue, FDR, standard error and standard deviation. Currently, I can calculate average for the replicates. The result for the above example is:. `adata.Xmean[:,0] = [71.6667 71.6667 71.6667 46.6667 46.6667 46.6667 26.3333 26.3333 26.3333 53. 53. 53. 65.6667 65.6667 65.6667 48.6667 48.6667 48.6667]`. This seems redundant as the average is listed for each replicate. It led me to think about separating the replicates into their own .X, like .X1 for replicate 1, .X2, etc. This would mean the .Xmean[0] would link to .X1[0], .X2[0], .X3[0]. . The averages may be the only one to benefit from this setup, as each replicate will have its' own p-value, FDR, standard error, and standard deviation. This makes me think the redundant .Xmean is the better approach. What are your thoughts? Thank you in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/106
https://github.com/scverse/scanpy/issues/106:1063,availability,error,error,1063,"Best practice for handling replicates and associated statistics; I'm curious as to what would be the best practice for this situation... I have an np.array containing 18 expression values for gene y. There are 3 replicates, so 6 different conditions. . `adata.X[:,0] = [ 72. 92. 51. 93. 1. 46. 0. 33. 46. 75. 56. 28. 90. 100. 7. 25. 40. 81.]`. I need to calculate several values: replicate average, pvalue, FDR, standard error and standard deviation. Currently, I can calculate average for the replicates. The result for the above example is:. `adata.Xmean[:,0] = [71.6667 71.6667 71.6667 46.6667 46.6667 46.6667 26.3333 26.3333 26.3333 53. 53. 53. 65.6667 65.6667 65.6667 48.6667 48.6667 48.6667]`. This seems redundant as the average is listed for each replicate. It led me to think about separating the replicates into their own .X, like .X1 for replicate 1, .X2, etc. This would mean the .Xmean[0] would link to .X1[0], .X2[0], .X3[0]. . The averages may be the only one to benefit from this setup, as each replicate will have its' own p-value, FDR, standard error, and standard deviation. This makes me think the redundant .Xmean is the better approach. What are your thoughts? Thank you in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/106
https://github.com/scverse/scanpy/issues/106:1118,availability,redund,redundant,1118,"Best practice for handling replicates and associated statistics; I'm curious as to what would be the best practice for this situation... I have an np.array containing 18 expression values for gene y. There are 3 replicates, so 6 different conditions. . `adata.X[:,0] = [ 72. 92. 51. 93. 1. 46. 0. 33. 46. 75. 56. 28. 90. 100. 7. 25. 40. 81.]`. I need to calculate several values: replicate average, pvalue, FDR, standard error and standard deviation. Currently, I can calculate average for the replicates. The result for the above example is:. `adata.Xmean[:,0] = [71.6667 71.6667 71.6667 46.6667 46.6667 46.6667 26.3333 26.3333 26.3333 53. 53. 53. 65.6667 65.6667 65.6667 48.6667 48.6667 48.6667]`. This seems redundant as the average is listed for each replicate. It led me to think about separating the replicates into their own .X, like .X1 for replicate 1, .X2, etc. This would mean the .Xmean[0] would link to .X1[0], .X2[0], .X3[0]. . The averages may be the only one to benefit from this setup, as each replicate will have its' own p-value, FDR, standard error, and standard deviation. This makes me think the redundant .Xmean is the better approach. What are your thoughts? Thank you in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/106
https://github.com/scverse/scanpy/issues/106:156,deployability,contain,containing,156,"Best practice for handling replicates and associated statistics; I'm curious as to what would be the best practice for this situation... I have an np.array containing 18 expression values for gene y. There are 3 replicates, so 6 different conditions. . `adata.X[:,0] = [ 72. 92. 51. 93. 1. 46. 0. 33. 46. 75. 56. 28. 90. 100. 7. 25. 40. 81.]`. I need to calculate several values: replicate average, pvalue, FDR, standard error and standard deviation. Currently, I can calculate average for the replicates. The result for the above example is:. `adata.Xmean[:,0] = [71.6667 71.6667 71.6667 46.6667 46.6667 46.6667 26.3333 26.3333 26.3333 53. 53. 53. 65.6667 65.6667 65.6667 48.6667 48.6667 48.6667]`. This seems redundant as the average is listed for each replicate. It led me to think about separating the replicates into their own .X, like .X1 for replicate 1, .X2, etc. This would mean the .Xmean[0] would link to .X1[0], .X2[0], .X3[0]. . The averages may be the only one to benefit from this setup, as each replicate will have its' own p-value, FDR, standard error, and standard deviation. This makes me think the redundant .Xmean is the better approach. What are your thoughts? Thank you in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/106
https://github.com/scverse/scanpy/issues/106:711,deployability,redundan,redundant,711,"Best practice for handling replicates and associated statistics; I'm curious as to what would be the best practice for this situation... I have an np.array containing 18 expression values for gene y. There are 3 replicates, so 6 different conditions. . `adata.X[:,0] = [ 72. 92. 51. 93. 1. 46. 0. 33. 46. 75. 56. 28. 90. 100. 7. 25. 40. 81.]`. I need to calculate several values: replicate average, pvalue, FDR, standard error and standard deviation. Currently, I can calculate average for the replicates. The result for the above example is:. `adata.Xmean[:,0] = [71.6667 71.6667 71.6667 46.6667 46.6667 46.6667 26.3333 26.3333 26.3333 53. 53. 53. 65.6667 65.6667 65.6667 48.6667 48.6667 48.6667]`. This seems redundant as the average is listed for each replicate. It led me to think about separating the replicates into their own .X, like .X1 for replicate 1, .X2, etc. This would mean the .Xmean[0] would link to .X1[0], .X2[0], .X3[0]. . The averages may be the only one to benefit from this setup, as each replicate will have its' own p-value, FDR, standard error, and standard deviation. This makes me think the redundant .Xmean is the better approach. What are your thoughts? Thank you in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/106
https://github.com/scverse/scanpy/issues/106:1118,deployability,redundan,redundant,1118,"Best practice for handling replicates and associated statistics; I'm curious as to what would be the best practice for this situation... I have an np.array containing 18 expression values for gene y. There are 3 replicates, so 6 different conditions. . `adata.X[:,0] = [ 72. 92. 51. 93. 1. 46. 0. 33. 46. 75. 56. 28. 90. 100. 7. 25. 40. 81.]`. I need to calculate several values: replicate average, pvalue, FDR, standard error and standard deviation. Currently, I can calculate average for the replicates. The result for the above example is:. `adata.Xmean[:,0] = [71.6667 71.6667 71.6667 46.6667 46.6667 46.6667 26.3333 26.3333 26.3333 53. 53. 53. 65.6667 65.6667 65.6667 48.6667 48.6667 48.6667]`. This seems redundant as the average is listed for each replicate. It led me to think about separating the replicates into their own .X, like .X1 for replicate 1, .X2, etc. This would mean the .Xmean[0] would link to .X1[0], .X2[0], .X3[0]. . The averages may be the only one to benefit from this setup, as each replicate will have its' own p-value, FDR, standard error, and standard deviation. This makes me think the redundant .Xmean is the better approach. What are your thoughts? Thank you in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/106
https://github.com/scverse/scanpy/issues/106:451,energy efficiency,Current,Currently,451,"Best practice for handling replicates and associated statistics; I'm curious as to what would be the best practice for this situation... I have an np.array containing 18 expression values for gene y. There are 3 replicates, so 6 different conditions. . `adata.X[:,0] = [ 72. 92. 51. 93. 1. 46. 0. 33. 46. 75. 56. 28. 90. 100. 7. 25. 40. 81.]`. I need to calculate several values: replicate average, pvalue, FDR, standard error and standard deviation. Currently, I can calculate average for the replicates. The result for the above example is:. `adata.Xmean[:,0] = [71.6667 71.6667 71.6667 46.6667 46.6667 46.6667 26.3333 26.3333 26.3333 53. 53. 53. 65.6667 65.6667 65.6667 48.6667 48.6667 48.6667]`. This seems redundant as the average is listed for each replicate. It led me to think about separating the replicates into their own .X, like .X1 for replicate 1, .X2, etc. This would mean the .Xmean[0] would link to .X1[0], .X2[0], .X3[0]. . The averages may be the only one to benefit from this setup, as each replicate will have its' own p-value, FDR, standard error, and standard deviation. This makes me think the redundant .Xmean is the better approach. What are your thoughts? Thank you in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/106
https://github.com/scverse/scanpy/issues/106:412,interoperability,standard,standard,412,"Best practice for handling replicates and associated statistics; I'm curious as to what would be the best practice for this situation... I have an np.array containing 18 expression values for gene y. There are 3 replicates, so 6 different conditions. . `adata.X[:,0] = [ 72. 92. 51. 93. 1. 46. 0. 33. 46. 75. 56. 28. 90. 100. 7. 25. 40. 81.]`. I need to calculate several values: replicate average, pvalue, FDR, standard error and standard deviation. Currently, I can calculate average for the replicates. The result for the above example is:. `adata.Xmean[:,0] = [71.6667 71.6667 71.6667 46.6667 46.6667 46.6667 26.3333 26.3333 26.3333 53. 53. 53. 65.6667 65.6667 65.6667 48.6667 48.6667 48.6667]`. This seems redundant as the average is listed for each replicate. It led me to think about separating the replicates into their own .X, like .X1 for replicate 1, .X2, etc. This would mean the .Xmean[0] would link to .X1[0], .X2[0], .X3[0]. . The averages may be the only one to benefit from this setup, as each replicate will have its' own p-value, FDR, standard error, and standard deviation. This makes me think the redundant .Xmean is the better approach. What are your thoughts? Thank you in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/106
https://github.com/scverse/scanpy/issues/106:431,interoperability,standard,standard,431,"Best practice for handling replicates and associated statistics; I'm curious as to what would be the best practice for this situation... I have an np.array containing 18 expression values for gene y. There are 3 replicates, so 6 different conditions. . `adata.X[:,0] = [ 72. 92. 51. 93. 1. 46. 0. 33. 46. 75. 56. 28. 90. 100. 7. 25. 40. 81.]`. I need to calculate several values: replicate average, pvalue, FDR, standard error and standard deviation. Currently, I can calculate average for the replicates. The result for the above example is:. `adata.Xmean[:,0] = [71.6667 71.6667 71.6667 46.6667 46.6667 46.6667 26.3333 26.3333 26.3333 53. 53. 53. 65.6667 65.6667 65.6667 48.6667 48.6667 48.6667]`. This seems redundant as the average is listed for each replicate. It led me to think about separating the replicates into their own .X, like .X1 for replicate 1, .X2, etc. This would mean the .Xmean[0] would link to .X1[0], .X2[0], .X3[0]. . The averages may be the only one to benefit from this setup, as each replicate will have its' own p-value, FDR, standard error, and standard deviation. This makes me think the redundant .Xmean is the better approach. What are your thoughts? Thank you in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/106
https://github.com/scverse/scanpy/issues/106:1054,interoperability,standard,standard,1054,"Best practice for handling replicates and associated statistics; I'm curious as to what would be the best practice for this situation... I have an np.array containing 18 expression values for gene y. There are 3 replicates, so 6 different conditions. . `adata.X[:,0] = [ 72. 92. 51. 93. 1. 46. 0. 33. 46. 75. 56. 28. 90. 100. 7. 25. 40. 81.]`. I need to calculate several values: replicate average, pvalue, FDR, standard error and standard deviation. Currently, I can calculate average for the replicates. The result for the above example is:. `adata.Xmean[:,0] = [71.6667 71.6667 71.6667 46.6667 46.6667 46.6667 26.3333 26.3333 26.3333 53. 53. 53. 65.6667 65.6667 65.6667 48.6667 48.6667 48.6667]`. This seems redundant as the average is listed for each replicate. It led me to think about separating the replicates into their own .X, like .X1 for replicate 1, .X2, etc. This would mean the .Xmean[0] would link to .X1[0], .X2[0], .X3[0]. . The averages may be the only one to benefit from this setup, as each replicate will have its' own p-value, FDR, standard error, and standard deviation. This makes me think the redundant .Xmean is the better approach. What are your thoughts? Thank you in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/106
https://github.com/scverse/scanpy/issues/106:1074,interoperability,standard,standard,1074,"Best practice for handling replicates and associated statistics; I'm curious as to what would be the best practice for this situation... I have an np.array containing 18 expression values for gene y. There are 3 replicates, so 6 different conditions. . `adata.X[:,0] = [ 72. 92. 51. 93. 1. 46. 0. 33. 46. 75. 56. 28. 90. 100. 7. 25. 40. 81.]`. I need to calculate several values: replicate average, pvalue, FDR, standard error and standard deviation. Currently, I can calculate average for the replicates. The result for the above example is:. `adata.Xmean[:,0] = [71.6667 71.6667 71.6667 46.6667 46.6667 46.6667 26.3333 26.3333 26.3333 53. 53. 53. 65.6667 65.6667 65.6667 48.6667 48.6667 48.6667]`. This seems redundant as the average is listed for each replicate. It led me to think about separating the replicates into their own .X, like .X1 for replicate 1, .X2, etc. This would mean the .Xmean[0] would link to .X1[0], .X2[0], .X3[0]. . The averages may be the only one to benefit from this setup, as each replicate will have its' own p-value, FDR, standard error, and standard deviation. This makes me think the redundant .Xmean is the better approach. What are your thoughts? Thank you in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/106
https://github.com/scverse/scanpy/issues/106:421,performance,error,error,421,"Best practice for handling replicates and associated statistics; I'm curious as to what would be the best practice for this situation... I have an np.array containing 18 expression values for gene y. There are 3 replicates, so 6 different conditions. . `adata.X[:,0] = [ 72. 92. 51. 93. 1. 46. 0. 33. 46. 75. 56. 28. 90. 100. 7. 25. 40. 81.]`. I need to calculate several values: replicate average, pvalue, FDR, standard error and standard deviation. Currently, I can calculate average for the replicates. The result for the above example is:. `adata.Xmean[:,0] = [71.6667 71.6667 71.6667 46.6667 46.6667 46.6667 26.3333 26.3333 26.3333 53. 53. 53. 65.6667 65.6667 65.6667 48.6667 48.6667 48.6667]`. This seems redundant as the average is listed for each replicate. It led me to think about separating the replicates into their own .X, like .X1 for replicate 1, .X2, etc. This would mean the .Xmean[0] would link to .X1[0], .X2[0], .X3[0]. . The averages may be the only one to benefit from this setup, as each replicate will have its' own p-value, FDR, standard error, and standard deviation. This makes me think the redundant .Xmean is the better approach. What are your thoughts? Thank you in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/106
https://github.com/scverse/scanpy/issues/106:1063,performance,error,error,1063,"Best practice for handling replicates and associated statistics; I'm curious as to what would be the best practice for this situation... I have an np.array containing 18 expression values for gene y. There are 3 replicates, so 6 different conditions. . `adata.X[:,0] = [ 72. 92. 51. 93. 1. 46. 0. 33. 46. 75. 56. 28. 90. 100. 7. 25. 40. 81.]`. I need to calculate several values: replicate average, pvalue, FDR, standard error and standard deviation. Currently, I can calculate average for the replicates. The result for the above example is:. `adata.Xmean[:,0] = [71.6667 71.6667 71.6667 46.6667 46.6667 46.6667 26.3333 26.3333 26.3333 53. 53. 53. 65.6667 65.6667 65.6667 48.6667 48.6667 48.6667]`. This seems redundant as the average is listed for each replicate. It led me to think about separating the replicates into their own .X, like .X1 for replicate 1, .X2, etc. This would mean the .Xmean[0] would link to .X1[0], .X2[0], .X3[0]. . The averages may be the only one to benefit from this setup, as each replicate will have its' own p-value, FDR, standard error, and standard deviation. This makes me think the redundant .Xmean is the better approach. What are your thoughts? Thank you in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/106
https://github.com/scverse/scanpy/issues/106:5,reliability,pra,practice,5,"Best practice for handling replicates and associated statistics; I'm curious as to what would be the best practice for this situation... I have an np.array containing 18 expression values for gene y. There are 3 replicates, so 6 different conditions. . `adata.X[:,0] = [ 72. 92. 51. 93. 1. 46. 0. 33. 46. 75. 56. 28. 90. 100. 7. 25. 40. 81.]`. I need to calculate several values: replicate average, pvalue, FDR, standard error and standard deviation. Currently, I can calculate average for the replicates. The result for the above example is:. `adata.Xmean[:,0] = [71.6667 71.6667 71.6667 46.6667 46.6667 46.6667 26.3333 26.3333 26.3333 53. 53. 53. 65.6667 65.6667 65.6667 48.6667 48.6667 48.6667]`. This seems redundant as the average is listed for each replicate. It led me to think about separating the replicates into their own .X, like .X1 for replicate 1, .X2, etc. This would mean the .Xmean[0] would link to .X1[0], .X2[0], .X3[0]. . The averages may be the only one to benefit from this setup, as each replicate will have its' own p-value, FDR, standard error, and standard deviation. This makes me think the redundant .Xmean is the better approach. What are your thoughts? Thank you in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/106
https://github.com/scverse/scanpy/issues/106:106,reliability,pra,practice,106,"Best practice for handling replicates and associated statistics; I'm curious as to what would be the best practice for this situation... I have an np.array containing 18 expression values for gene y. There are 3 replicates, so 6 different conditions. . `adata.X[:,0] = [ 72. 92. 51. 93. 1. 46. 0. 33. 46. 75. 56. 28. 90. 100. 7. 25. 40. 81.]`. I need to calculate several values: replicate average, pvalue, FDR, standard error and standard deviation. Currently, I can calculate average for the replicates. The result for the above example is:. `adata.Xmean[:,0] = [71.6667 71.6667 71.6667 46.6667 46.6667 46.6667 26.3333 26.3333 26.3333 53. 53. 53. 65.6667 65.6667 65.6667 48.6667 48.6667 48.6667]`. This seems redundant as the average is listed for each replicate. It led me to think about separating the replicates into their own .X, like .X1 for replicate 1, .X2, etc. This would mean the .Xmean[0] would link to .X1[0], .X2[0], .X3[0]. . The averages may be the only one to benefit from this setup, as each replicate will have its' own p-value, FDR, standard error, and standard deviation. This makes me think the redundant .Xmean is the better approach. What are your thoughts? Thank you in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/106
https://github.com/scverse/scanpy/issues/106:711,reliability,redundan,redundant,711,"Best practice for handling replicates and associated statistics; I'm curious as to what would be the best practice for this situation... I have an np.array containing 18 expression values for gene y. There are 3 replicates, so 6 different conditions. . `adata.X[:,0] = [ 72. 92. 51. 93. 1. 46. 0. 33. 46. 75. 56. 28. 90. 100. 7. 25. 40. 81.]`. I need to calculate several values: replicate average, pvalue, FDR, standard error and standard deviation. Currently, I can calculate average for the replicates. The result for the above example is:. `adata.Xmean[:,0] = [71.6667 71.6667 71.6667 46.6667 46.6667 46.6667 26.3333 26.3333 26.3333 53. 53. 53. 65.6667 65.6667 65.6667 48.6667 48.6667 48.6667]`. This seems redundant as the average is listed for each replicate. It led me to think about separating the replicates into their own .X, like .X1 for replicate 1, .X2, etc. This would mean the .Xmean[0] would link to .X1[0], .X2[0], .X3[0]. . The averages may be the only one to benefit from this setup, as each replicate will have its' own p-value, FDR, standard error, and standard deviation. This makes me think the redundant .Xmean is the better approach. What are your thoughts? Thank you in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/106
https://github.com/scverse/scanpy/issues/106:1118,reliability,redundan,redundant,1118,"Best practice for handling replicates and associated statistics; I'm curious as to what would be the best practice for this situation... I have an np.array containing 18 expression values for gene y. There are 3 replicates, so 6 different conditions. . `adata.X[:,0] = [ 72. 92. 51. 93. 1. 46. 0. 33. 46. 75. 56. 28. 90. 100. 7. 25. 40. 81.]`. I need to calculate several values: replicate average, pvalue, FDR, standard error and standard deviation. Currently, I can calculate average for the replicates. The result for the above example is:. `adata.Xmean[:,0] = [71.6667 71.6667 71.6667 46.6667 46.6667 46.6667 26.3333 26.3333 26.3333 53. 53. 53. 65.6667 65.6667 65.6667 48.6667 48.6667 48.6667]`. This seems redundant as the average is listed for each replicate. It led me to think about separating the replicates into their own .X, like .X1 for replicate 1, .X2, etc. This would mean the .Xmean[0] would link to .X1[0], .X2[0], .X3[0]. . The averages may be the only one to benefit from this setup, as each replicate will have its' own p-value, FDR, standard error, and standard deviation. This makes me think the redundant .Xmean is the better approach. What are your thoughts? Thank you in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/106
https://github.com/scverse/scanpy/issues/106:421,safety,error,error,421,"Best practice for handling replicates and associated statistics; I'm curious as to what would be the best practice for this situation... I have an np.array containing 18 expression values for gene y. There are 3 replicates, so 6 different conditions. . `adata.X[:,0] = [ 72. 92. 51. 93. 1. 46. 0. 33. 46. 75. 56. 28. 90. 100. 7. 25. 40. 81.]`. I need to calculate several values: replicate average, pvalue, FDR, standard error and standard deviation. Currently, I can calculate average for the replicates. The result for the above example is:. `adata.Xmean[:,0] = [71.6667 71.6667 71.6667 46.6667 46.6667 46.6667 26.3333 26.3333 26.3333 53. 53. 53. 65.6667 65.6667 65.6667 48.6667 48.6667 48.6667]`. This seems redundant as the average is listed for each replicate. It led me to think about separating the replicates into their own .X, like .X1 for replicate 1, .X2, etc. This would mean the .Xmean[0] would link to .X1[0], .X2[0], .X3[0]. . The averages may be the only one to benefit from this setup, as each replicate will have its' own p-value, FDR, standard error, and standard deviation. This makes me think the redundant .Xmean is the better approach. What are your thoughts? Thank you in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/106
https://github.com/scverse/scanpy/issues/106:711,safety,redund,redundant,711,"Best practice for handling replicates and associated statistics; I'm curious as to what would be the best practice for this situation... I have an np.array containing 18 expression values for gene y. There are 3 replicates, so 6 different conditions. . `adata.X[:,0] = [ 72. 92. 51. 93. 1. 46. 0. 33. 46. 75. 56. 28. 90. 100. 7. 25. 40. 81.]`. I need to calculate several values: replicate average, pvalue, FDR, standard error and standard deviation. Currently, I can calculate average for the replicates. The result for the above example is:. `adata.Xmean[:,0] = [71.6667 71.6667 71.6667 46.6667 46.6667 46.6667 26.3333 26.3333 26.3333 53. 53. 53. 65.6667 65.6667 65.6667 48.6667 48.6667 48.6667]`. This seems redundant as the average is listed for each replicate. It led me to think about separating the replicates into their own .X, like .X1 for replicate 1, .X2, etc. This would mean the .Xmean[0] would link to .X1[0], .X2[0], .X3[0]. . The averages may be the only one to benefit from this setup, as each replicate will have its' own p-value, FDR, standard error, and standard deviation. This makes me think the redundant .Xmean is the better approach. What are your thoughts? Thank you in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/106
https://github.com/scverse/scanpy/issues/106:1063,safety,error,error,1063,"Best practice for handling replicates and associated statistics; I'm curious as to what would be the best practice for this situation... I have an np.array containing 18 expression values for gene y. There are 3 replicates, so 6 different conditions. . `adata.X[:,0] = [ 72. 92. 51. 93. 1. 46. 0. 33. 46. 75. 56. 28. 90. 100. 7. 25. 40. 81.]`. I need to calculate several values: replicate average, pvalue, FDR, standard error and standard deviation. Currently, I can calculate average for the replicates. The result for the above example is:. `adata.Xmean[:,0] = [71.6667 71.6667 71.6667 46.6667 46.6667 46.6667 26.3333 26.3333 26.3333 53. 53. 53. 65.6667 65.6667 65.6667 48.6667 48.6667 48.6667]`. This seems redundant as the average is listed for each replicate. It led me to think about separating the replicates into their own .X, like .X1 for replicate 1, .X2, etc. This would mean the .Xmean[0] would link to .X1[0], .X2[0], .X3[0]. . The averages may be the only one to benefit from this setup, as each replicate will have its' own p-value, FDR, standard error, and standard deviation. This makes me think the redundant .Xmean is the better approach. What are your thoughts? Thank you in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/106
https://github.com/scverse/scanpy/issues/106:1118,safety,redund,redundant,1118,"Best practice for handling replicates and associated statistics; I'm curious as to what would be the best practice for this situation... I have an np.array containing 18 expression values for gene y. There are 3 replicates, so 6 different conditions. . `adata.X[:,0] = [ 72. 92. 51. 93. 1. 46. 0. 33. 46. 75. 56. 28. 90. 100. 7. 25. 40. 81.]`. I need to calculate several values: replicate average, pvalue, FDR, standard error and standard deviation. Currently, I can calculate average for the replicates. The result for the above example is:. `adata.Xmean[:,0] = [71.6667 71.6667 71.6667 46.6667 46.6667 46.6667 26.3333 26.3333 26.3333 53. 53. 53. 65.6667 65.6667 65.6667 48.6667 48.6667 48.6667]`. This seems redundant as the average is listed for each replicate. It led me to think about separating the replicates into their own .X, like .X1 for replicate 1, .X2, etc. This would mean the .Xmean[0] would link to .X1[0], .X2[0], .X3[0]. . The averages may be the only one to benefit from this setup, as each replicate will have its' own p-value, FDR, standard error, and standard deviation. This makes me think the redundant .Xmean is the better approach. What are your thoughts? Thank you in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/106
https://github.com/scverse/scanpy/issues/106:421,usability,error,error,421,"Best practice for handling replicates and associated statistics; I'm curious as to what would be the best practice for this situation... I have an np.array containing 18 expression values for gene y. There are 3 replicates, so 6 different conditions. . `adata.X[:,0] = [ 72. 92. 51. 93. 1. 46. 0. 33. 46. 75. 56. 28. 90. 100. 7. 25. 40. 81.]`. I need to calculate several values: replicate average, pvalue, FDR, standard error and standard deviation. Currently, I can calculate average for the replicates. The result for the above example is:. `adata.Xmean[:,0] = [71.6667 71.6667 71.6667 46.6667 46.6667 46.6667 26.3333 26.3333 26.3333 53. 53. 53. 65.6667 65.6667 65.6667 48.6667 48.6667 48.6667]`. This seems redundant as the average is listed for each replicate. It led me to think about separating the replicates into their own .X, like .X1 for replicate 1, .X2, etc. This would mean the .Xmean[0] would link to .X1[0], .X2[0], .X3[0]. . The averages may be the only one to benefit from this setup, as each replicate will have its' own p-value, FDR, standard error, and standard deviation. This makes me think the redundant .Xmean is the better approach. What are your thoughts? Thank you in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/106
https://github.com/scverse/scanpy/issues/106:1063,usability,error,error,1063,"Best practice for handling replicates and associated statistics; I'm curious as to what would be the best practice for this situation... I have an np.array containing 18 expression values for gene y. There are 3 replicates, so 6 different conditions. . `adata.X[:,0] = [ 72. 92. 51. 93. 1. 46. 0. 33. 46. 75. 56. 28. 90. 100. 7. 25. 40. 81.]`. I need to calculate several values: replicate average, pvalue, FDR, standard error and standard deviation. Currently, I can calculate average for the replicates. The result for the above example is:. `adata.Xmean[:,0] = [71.6667 71.6667 71.6667 46.6667 46.6667 46.6667 26.3333 26.3333 26.3333 53. 53. 53. 65.6667 65.6667 65.6667 48.6667 48.6667 48.6667]`. This seems redundant as the average is listed for each replicate. It led me to think about separating the replicates into their own .X, like .X1 for replicate 1, .X2, etc. This would mean the .Xmean[0] would link to .X1[0], .X2[0], .X3[0]. . The averages may be the only one to benefit from this setup, as each replicate will have its' own p-value, FDR, standard error, and standard deviation. This makes me think the redundant .Xmean is the better approach. What are your thoughts? Thank you in advance!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/106
https://github.com/scverse/scanpy/issues/107:348,usability,user,users,348,"Implementing more normalization options; Hey guys,. I was wondering what your thoughts were on implementing more-sophisticated normalization options (like [scran](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-0947-7), or [SCnorm](https://www.nature.com/articles/nmeth.4263)). Would you rather just keep this out of scanpy and users can bounce the expression matrix into R for it if they want it?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/107
https://github.com/scverse/scanpy/issues/108:86,deployability,api,api,86,"Do not change matplotlib style parameters; When loading scanpy through `import scanpy.api as sc` the plotting style is changed. This prevents my from using it in my general workflow because I have particular plotting styles I use. This used to be a issue with seaborn, but was changed in version 0.8, but scanpy still seems to restyle the entire plotting environment? If styles are applied locally in particular plotting functions, that is fine, but it shouldn't affect the users other plots.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/108
https://github.com/scverse/scanpy/issues/108:288,deployability,version,version,288,"Do not change matplotlib style parameters; When loading scanpy through `import scanpy.api as sc` the plotting style is changed. This prevents my from using it in my general workflow because I have particular plotting styles I use. This used to be a issue with seaborn, but was changed in version 0.8, but scanpy still seems to restyle the entire plotting environment? If styles are applied locally in particular plotting functions, that is fine, but it shouldn't affect the users other plots.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/108
https://github.com/scverse/scanpy/issues/108:48,energy efficiency,load,loading,48,"Do not change matplotlib style parameters; When loading scanpy through `import scanpy.api as sc` the plotting style is changed. This prevents my from using it in my general workflow because I have particular plotting styles I use. This used to be a issue with seaborn, but was changed in version 0.8, but scanpy still seems to restyle the entire plotting environment? If styles are applied locally in particular plotting functions, that is fine, but it shouldn't affect the users other plots.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/108
https://github.com/scverse/scanpy/issues/108:86,integrability,api,api,86,"Do not change matplotlib style parameters; When loading scanpy through `import scanpy.api as sc` the plotting style is changed. This prevents my from using it in my general workflow because I have particular plotting styles I use. This used to be a issue with seaborn, but was changed in version 0.8, but scanpy still seems to restyle the entire plotting environment? If styles are applied locally in particular plotting functions, that is fine, but it shouldn't affect the users other plots.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/108
https://github.com/scverse/scanpy/issues/108:288,integrability,version,version,288,"Do not change matplotlib style parameters; When loading scanpy through `import scanpy.api as sc` the plotting style is changed. This prevents my from using it in my general workflow because I have particular plotting styles I use. This used to be a issue with seaborn, but was changed in version 0.8, but scanpy still seems to restyle the entire plotting environment? If styles are applied locally in particular plotting functions, that is fine, but it shouldn't affect the users other plots.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/108
https://github.com/scverse/scanpy/issues/108:86,interoperability,api,api,86,"Do not change matplotlib style parameters; When loading scanpy through `import scanpy.api as sc` the plotting style is changed. This prevents my from using it in my general workflow because I have particular plotting styles I use. This used to be a issue with seaborn, but was changed in version 0.8, but scanpy still seems to restyle the entire plotting environment? If styles are applied locally in particular plotting functions, that is fine, but it shouldn't affect the users other plots.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/108
https://github.com/scverse/scanpy/issues/108:31,modifiability,paramet,parameters,31,"Do not change matplotlib style parameters; When loading scanpy through `import scanpy.api as sc` the plotting style is changed. This prevents my from using it in my general workflow because I have particular plotting styles I use. This used to be a issue with seaborn, but was changed in version 0.8, but scanpy still seems to restyle the entire plotting environment? If styles are applied locally in particular plotting functions, that is fine, but it shouldn't affect the users other plots.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/108
https://github.com/scverse/scanpy/issues/108:288,modifiability,version,version,288,"Do not change matplotlib style parameters; When loading scanpy through `import scanpy.api as sc` the plotting style is changed. This prevents my from using it in my general workflow because I have particular plotting styles I use. This used to be a issue with seaborn, but was changed in version 0.8, but scanpy still seems to restyle the entire plotting environment? If styles are applied locally in particular plotting functions, that is fine, but it shouldn't affect the users other plots.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/108
https://github.com/scverse/scanpy/issues/108:48,performance,load,loading,48,"Do not change matplotlib style parameters; When loading scanpy through `import scanpy.api as sc` the plotting style is changed. This prevents my from using it in my general workflow because I have particular plotting styles I use. This used to be a issue with seaborn, but was changed in version 0.8, but scanpy still seems to restyle the entire plotting environment? If styles are applied locally in particular plotting functions, that is fine, but it shouldn't affect the users other plots.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/108
https://github.com/scverse/scanpy/issues/108:133,safety,prevent,prevents,133,"Do not change matplotlib style parameters; When loading scanpy through `import scanpy.api as sc` the plotting style is changed. This prevents my from using it in my general workflow because I have particular plotting styles I use. This used to be a issue with seaborn, but was changed in version 0.8, but scanpy still seems to restyle the entire plotting environment? If styles are applied locally in particular plotting functions, that is fine, but it shouldn't affect the users other plots.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/108
https://github.com/scverse/scanpy/issues/108:133,security,preven,prevents,133,"Do not change matplotlib style parameters; When loading scanpy through `import scanpy.api as sc` the plotting style is changed. This prevents my from using it in my general workflow because I have particular plotting styles I use. This used to be a issue with seaborn, but was changed in version 0.8, but scanpy still seems to restyle the entire plotting environment? If styles are applied locally in particular plotting functions, that is fine, but it shouldn't affect the users other plots.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/108
https://github.com/scverse/scanpy/issues/108:173,usability,workflow,workflow,173,"Do not change matplotlib style parameters; When loading scanpy through `import scanpy.api as sc` the plotting style is changed. This prevents my from using it in my general workflow because I have particular plotting styles I use. This used to be a issue with seaborn, but was changed in version 0.8, but scanpy still seems to restyle the entire plotting environment? If styles are applied locally in particular plotting functions, that is fine, but it shouldn't affect the users other plots.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/108
https://github.com/scverse/scanpy/issues/108:474,usability,user,users,474,"Do not change matplotlib style parameters; When loading scanpy through `import scanpy.api as sc` the plotting style is changed. This prevents my from using it in my general workflow because I have particular plotting styles I use. This used to be a issue with seaborn, but was changed in version 0.8, but scanpy still seems to restyle the entire plotting environment? If styles are applied locally in particular plotting functions, that is fine, but it shouldn't affect the users other plots.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/108
https://github.com/scverse/scanpy/issues/109:6,availability,sli,slicing,6,"After slicing and normalizing index remains and PCA values remain(?); #**Here is an example:** . adata.var.ix['Wfdc18']. result: . gene_ids ENSMUSG00000000983. n_cells 2411. Name: Wfdc18, dtype: object. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). filter_result = sc.pp.filter_genes_dispersion(. adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.filter_genes_dispersion(filter_result). adata1 = adata[:, filter_result.gene_subset]. adata1.var.ix['Wfdc18']. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=ax",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:622,availability,toler,tolerance,622,"After slicing and normalizing index remains and PCA values remain(?); #**Here is an example:** . adata.var.ix['Wfdc18']. result: . gene_ids ENSMUSG00000000983. n_cells 2411. Name: Wfdc18, dtype: object. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). filter_result = sc.pp.filter_genes_dispersion(. adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.filter_genes_dispersion(filter_result). adata1 = adata[:, filter_result.gene_subset]. adata1.var.ix['Wfdc18']. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=ax",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:1919,availability,sli,slices,1919,"shTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc = self.index.get_loc(key). 2345 . 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:2379,availability,toler,tolerance,2379,"2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc = self.index.get_loc(key). 2345 . 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. **Moreover, it still plots it?:** . ax1 = sc.pl.pca_scatter(adata1, components='1,2', color=['Wfdc18'], right_margin=0.2). ![pca_adata1 001](https://user-images.githubusercontent.com/6422882/37835563-d56b07e6-2e86-11e8-8326-c730011de4d4.jpeg). **Any input I would be most grateful. Many thanks, . Olivia**.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:2582,availability,toler,tolerance,2582,"2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc = self.index.get_loc(key). 2345 . 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. **Moreover, it still plots it?:** . ax1 = sc.pl.pca_scatter(adata1, components='1,2', color=['Wfdc18'], right_margin=0.2). ![pca_adata1 001](https://user-images.githubusercontent.com/6422882/37835563-d56b07e6-2e86-11e8-8326-c730011de4d4.jpeg). **Any input I would be most grateful. Many thanks, . Olivia**.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:2592,availability,toler,tolerance,2592,"2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc = self.index.get_loc(key). 2345 . 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. **Moreover, it still plots it?:** . ax1 = sc.pl.pca_scatter(adata1, components='1,2', color=['Wfdc18'], right_margin=0.2). ![pca_adata1 001](https://user-images.githubusercontent.com/6422882/37835563-d56b07e6-2e86-11e8-8326-c730011de4d4.jpeg). **Any input I would be most grateful. Many thanks, . Olivia**.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:1207,deployability,modul,module,1207,"ormalize_per_cell(adata, counts_per_cell_after=1e4). filter_result = sc.pp.filter_genes_dispersion(. adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.filter_genes_dispersion(filter_result). adata1 = adata[:, filter_result.gene_subset]. adata1.var.ix['Wfdc18']. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:571,energy efficiency,core,core,571,"After slicing and normalizing index remains and PCA values remain(?); #**Here is an example:** . adata.var.ix['Wfdc18']. result: . gene_ids ENSMUSG00000000983. n_cells 2411. Name: Wfdc18, dtype: object. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). filter_result = sc.pp.filter_genes_dispersion(. adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.filter_genes_dispersion(filter_result). adata1 = adata[:, filter_result.gene_subset]. adata1.var.ix['Wfdc18']. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=ax",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:1339,energy efficiency,core,core,1339,"mean=3, min_disp=0.5). sc.pl.filter_genes_dispersion(filter_result). adata1 = adata[:, filter_result.gene_subset]. adata1.var.ix['Wfdc18']. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc = self.index.get_loc(key). 2345 . 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:1586,energy efficiency,core,core,1586,".py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc = self.index.get_loc(key). 2345 . 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolera",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:1840,energy efficiency,core,core,1840,"(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc = self.index.get_loc(key). 2345 . 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:2098,energy efficiency,core,core,2098,"other exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc = self.index.get_loc(key). 2345 . 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. **Moreover, it still plots it?:** . ax1 = sc.pl.pca_scatter(adata1, components='1,2', color=['Wfdc18'], right_margin=0.2). ![pca_adata1 001](https:/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:2328,energy efficiency,core,core,2328,"2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc = self.index.get_loc(key). 2345 . 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. **Moreover, it still plots it?:** . ax1 = sc.pl.pca_scatter(adata1, components='1,2', color=['Wfdc18'], right_margin=0.2). ![pca_adata1 001](https://user-images.githubusercontent.com/6422882/37835563-d56b07e6-2e86-11e8-8326-c730011de4d4.jpeg). **Any input I would be most grateful. Many thanks, . Olivia**.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:3020,integrability,compon,components,3020,"2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc = self.index.get_loc(key). 2345 . 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. **Moreover, it still plots it?:** . ax1 = sc.pl.pca_scatter(adata1, components='1,2', color=['Wfdc18'], right_margin=0.2). ![pca_adata1 001](https://user-images.githubusercontent.com/6422882/37835563-d56b07e6-2e86-11e8-8326-c730011de4d4.jpeg). **Any input I would be most grateful. Many thanks, . Olivia**.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:3020,interoperability,compon,components,3020,"2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc = self.index.get_loc(key). 2345 . 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. **Moreover, it still plots it?:** . ax1 = sc.pl.pca_scatter(adata1, components='1,2', color=['Wfdc18'], right_margin=0.2). ![pca_adata1 001](https://user-images.githubusercontent.com/6422882/37835563-d56b07e6-2e86-11e8-8326-c730011de4d4.jpeg). **Any input I would be most grateful. Many thanks, . Olivia**.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:555,modifiability,pac,packages,555,"After slicing and normalizing index remains and PCA values remain(?); #**Here is an example:** . adata.var.ix['Wfdc18']. result: . gene_ids ENSMUSG00000000983. n_cells 2411. Name: Wfdc18, dtype: object. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). filter_result = sc.pp.filter_genes_dispersion(. adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.filter_genes_dispersion(filter_result). adata1 = adata[:, filter_result.gene_subset]. adata1.var.ix['Wfdc18']. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=ax",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:1207,modifiability,modul,module,1207,"ormalize_per_cell(adata, counts_per_cell_after=1e4). filter_result = sc.pp.filter_genes_dispersion(. adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.filter_genes_dispersion(filter_result). adata1 = adata[:, filter_result.gene_subset]. adata1.var.ix['Wfdc18']. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:1323,modifiability,pac,packages,1323,"n=0.0125, max_mean=3, min_disp=0.5). sc.pl.filter_genes_dispersion(filter_result). adata1 = adata[:, filter_result.gene_subset]. adata1.var.ix['Wfdc18']. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc = self.index.get_loc(key). 2345 . 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:1570,modifiability,pac,packages,1570,"e/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc = self.index.get_loc(key). 2345 . 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:1824,modifiability,pac,packages,1824,"Engine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc = self.index.get_loc(key). 2345 . 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:2082,modifiability,pac,packages,2082," exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc = self.index.get_loc(key). 2345 . 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. **Moreover, it still plots it?:** . ax1 = sc.pl.pca_scatter(adata1, components='1,2', color=['Wfdc18'], right_margin=0.2). ![pca_adata",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:2312,modifiability,pac,packages,2312,"2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc = self.index.get_loc(key). 2345 . 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. **Moreover, it still plots it?:** . ax1 = sc.pl.pca_scatter(adata1, components='1,2', color=['Wfdc18'], right_margin=0.2). ![pca_adata1 001](https://user-images.githubusercontent.com/6422882/37835563-d56b07e6-2e86-11e8-8326-c730011de4d4.jpeg). **Any input I would be most grateful. Many thanks, . Olivia**.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:3020,modifiability,compon,components,3020,"2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc = self.index.get_loc(key). 2345 . 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. **Moreover, it still plots it?:** . ax1 = sc.pl.pca_scatter(adata1, components='1,2', color=['Wfdc18'], right_margin=0.2). ![pca_adata1 001](https://user-images.githubusercontent.com/6422882/37835563-d56b07e6-2e86-11e8-8326-c730011de4d4.jpeg). **Any input I would be most grateful. Many thanks, . Olivia**.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:6,reliability,sli,slicing,6,"After slicing and normalizing index remains and PCA values remain(?); #**Here is an example:** . adata.var.ix['Wfdc18']. result: . gene_ids ENSMUSG00000000983. n_cells 2411. Name: Wfdc18, dtype: object. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). filter_result = sc.pp.filter_genes_dispersion(. adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.filter_genes_dispersion(filter_result). adata1 = adata[:, filter_result.gene_subset]. adata1.var.ix['Wfdc18']. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=ax",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:622,reliability,toleran,tolerance,622,"After slicing and normalizing index remains and PCA values remain(?); #**Here is an example:** . adata.var.ix['Wfdc18']. result: . gene_ids ENSMUSG00000000983. n_cells 2411. Name: Wfdc18, dtype: object. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). filter_result = sc.pp.filter_genes_dispersion(. adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.filter_genes_dispersion(filter_result). adata1 = adata[:, filter_result.gene_subset]. adata1.var.ix['Wfdc18']. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=ax",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:1919,reliability,sli,slices,1919,"shTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc = self.index.get_loc(key). 2345 . 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.ge",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:2379,reliability,toleran,tolerance,2379,"2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc = self.index.get_loc(key). 2345 . 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. **Moreover, it still plots it?:** . ax1 = sc.pl.pca_scatter(adata1, components='1,2', color=['Wfdc18'], right_margin=0.2). ![pca_adata1 001](https://user-images.githubusercontent.com/6422882/37835563-d56b07e6-2e86-11e8-8326-c730011de4d4.jpeg). **Any input I would be most grateful. Many thanks, . Olivia**.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:2582,reliability,toleran,tolerance,2582,"2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc = self.index.get_loc(key). 2345 . 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. **Moreover, it still plots it?:** . ax1 = sc.pl.pca_scatter(adata1, components='1,2', color=['Wfdc18'], right_margin=0.2). ![pca_adata1 001](https://user-images.githubusercontent.com/6422882/37835563-d56b07e6-2e86-11e8-8326-c730011de4d4.jpeg). **Any input I would be most grateful. Many thanks, . Olivia**.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:2592,reliability,toleran,tolerance,2592,"2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc = self.index.get_loc(key). 2345 . 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. **Moreover, it still plots it?:** . ax1 = sc.pl.pca_scatter(adata1, components='1,2', color=['Wfdc18'], right_margin=0.2). ![pca_adata1 001](https://user-images.githubusercontent.com/6422882/37835563-d56b07e6-2e86-11e8-8326-c730011de4d4.jpeg). **Any input I would be most grateful. Many thanks, . Olivia**.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:692,safety,except,except,692,"After slicing and normalizing index remains and PCA values remain(?); #**Here is an example:** . adata.var.ix['Wfdc18']. result: . gene_ids ENSMUSG00000000983. n_cells 2411. Name: Wfdc18, dtype: object. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). filter_result = sc.pp.filter_genes_dispersion(. adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.filter_genes_dispersion(filter_result). adata1 = adata[:, filter_result.gene_subset]. adata1.var.ix['Wfdc18']. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=ax",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:1087,safety,except,exception,1087,"** . adata.var.ix['Wfdc18']. result: . gene_ids ENSMUSG00000000983. n_cells 2411. Name: Wfdc18, dtype: object. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). filter_result = sc.pp.filter_genes_dispersion(. adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.filter_genes_dispersion(filter_result). adata1 = adata[:, filter_result.gene_subset]. adata1.var.ix['Wfdc18']. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:1106,safety,except,exception,1106,"Wfdc18']. result: . gene_ids ENSMUSG00000000983. n_cells 2411. Name: Wfdc18, dtype: object. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). filter_result = sc.pp.filter_genes_dispersion(. adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.filter_genes_dispersion(filter_result). adata1 = adata[:, filter_result.gene_subset]. adata1.var.ix['Wfdc18']. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:1180,safety,input,input-,1180,"c18, dtype: object. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). filter_result = sc.pp.filter_genes_dispersion(. adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.filter_genes_dispersion(filter_result). adata1 = adata[:, filter_result.gene_subset]. adata1.var.ix['Wfdc18']. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:1207,safety,modul,module,1207,"ormalize_per_cell(adata, counts_per_cell_after=1e4). filter_result = sc.pp.filter_genes_dispersion(. adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.filter_genes_dispersion(filter_result). adata1 = adata[:, filter_result.gene_subset]. adata1.var.ix['Wfdc18']. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:2435,safety,except,except,2435,"2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc = self.index.get_loc(key). 2345 . 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. **Moreover, it still plots it?:** . ax1 = sc.pl.pca_scatter(adata1, components='1,2', color=['Wfdc18'], right_margin=0.2). ![pca_adata1 001](https://user-images.githubusercontent.com/6422882/37835563-d56b07e6-2e86-11e8-8326-c730011de4d4.jpeg). **Any input I would be most grateful. Many thanks, . Olivia**.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:3202,safety,input,input,3202,"2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc = self.index.get_loc(key). 2345 . 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. **Moreover, it still plots it?:** . ax1 = sc.pl.pca_scatter(adata1, components='1,2', color=['Wfdc18'], right_margin=0.2). ![pca_adata1 001](https://user-images.githubusercontent.com/6422882/37835563-d56b07e6-2e86-11e8-8326-c730011de4d4.jpeg). **Any input I would be most grateful. Many thanks, . Olivia**.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:902,security,hash,hashtable,902,"After slicing and normalizing index remains and PCA values remain(?); #**Here is an example:** . adata.var.ix['Wfdc18']. result: . gene_ids ENSMUSG00000000983. n_cells 2411. Name: Wfdc18, dtype: object. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). filter_result = sc.pp.filter_genes_dispersion(. adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.filter_genes_dispersion(filter_result). adata1 = adata[:, filter_result.gene_subset]. adata1.var.ix['Wfdc18']. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=ax",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:998,security,hash,hashtable,998,"er slicing and normalizing index remains and PCA values remain(?); #**Here is an example:** . adata.var.ix['Wfdc18']. result: . gene_ids ENSMUSG00000000983. n_cells 2411. Name: Wfdc18, dtype: object. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). filter_result = sc.pp.filter_genes_dispersion(. adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.filter_genes_dispersion(filter_result). adata1 = adata[:, filter_result.gene_subset]. adata1.var.ix['Wfdc18']. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:2796,security,hash,hashtable,2796,"2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc = self.index.get_loc(key). 2345 . 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. **Moreover, it still plots it?:** . ax1 = sc.pl.pca_scatter(adata1, components='1,2', color=['Wfdc18'], right_margin=0.2). ![pca_adata1 001](https://user-images.githubusercontent.com/6422882/37835563-d56b07e6-2e86-11e8-8326-c730011de4d4.jpeg). **Any input I would be most grateful. Many thanks, . Olivia**.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:2892,security,hash,hashtable,2892,"2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc = self.index.get_loc(key). 2345 . 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. **Moreover, it still plots it?:** . ax1 = sc.pl.pca_scatter(adata1, components='1,2', color=['Wfdc18'], right_margin=0.2). ![pca_adata1 001](https://user-images.githubusercontent.com/6422882/37835563-d56b07e6-2e86-11e8-8326-c730011de4d4.jpeg). **Any input I would be most grateful. Many thanks, . Olivia**.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:490,testability,Trace,Traceback,490,"After slicing and normalizing index remains and PCA values remain(?); #**Here is an example:** . adata.var.ix['Wfdc18']. result: . gene_ids ENSMUSG00000000983. n_cells 2411. Name: Wfdc18, dtype: object. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). filter_result = sc.pp.filter_genes_dispersion(. adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.filter_genes_dispersion(filter_result). adata1 = adata[:, filter_result.gene_subset]. adata1.var.ix['Wfdc18']. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=ax",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:1136,testability,Trace,Traceback,1136,"NSMUSG00000000983. n_cells 2411. Name: Wfdc18, dtype: object. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). filter_result = sc.pp.filter_genes_dispersion(. adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.filter_genes_dispersion(filter_result). adata1 = adata[:, filter_result.gene_subset]. adata1.var.ix['Wfdc18']. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, leve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:1180,usability,input,input-,1180,"c18, dtype: object. sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4). filter_result = sc.pp.filter_genes_dispersion(. adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). sc.pl.filter_genes_dispersion(filter_result). adata1 = adata[:, filter_result.gene_subset]. adata1.var.ix['Wfdc18']. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-53-fb4aad8315fd> in <module>(). 1 print (adata.var.ix['Wfdc18']). ----> 2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:3101,usability,user,user-images,3101,"2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc = self.index.get_loc(key). 2345 . 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. **Moreover, it still plots it?:** . ax1 = sc.pl.pca_scatter(adata1, components='1,2', color=['Wfdc18'], right_margin=0.2). ![pca_adata1 001](https://user-images.githubusercontent.com/6422882/37835563-d56b07e6-2e86-11e8-8326-c730011de4d4.jpeg). **Any input I would be most grateful. Many thanks, . Olivia**.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/109:3202,usability,input,input,3202,"2 print (adata1.var.ix['Wfdc18']). /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in __getitem__(self, key). 125 . 126 key = com._apply_if_callable(key, self.obj). --> 127 return self._getitem_axis(key, axis=axis). 128 . 129 def _get_label(self, label, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _getitem_axis(self, key, axis). 1106 return self._get_loc(key, axis=axis). 1107 . -> 1108 return self._get_label(key, axis=axis). 1109 . 1110 def _getitem_iterable(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/indexing.py in _get_label(self, label, axis). 143 raise IndexingError('no slices here, handle elsewhere'). 144 . --> 145 return self.obj._xs(label, axis=axis). 146 . 147 def _get_loc(self, key, axis=None):. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in xs(self, key, axis, level, drop_level). 2342 drop_level=drop_level). 2343 else:. -> 2344 loc = self.index.get_loc(key). 2345 . 2346 if isinstance(loc, np.ndarray):. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'Wfdc18'. **Moreover, it still plots it?:** . ax1 = sc.pl.pca_scatter(adata1, components='1,2', color=['Wfdc18'], right_margin=0.2). ![pca_adata1 001](https://user-images.githubusercontent.com/6422882/37835563-d56b07e6-2e86-11e8-8326-c730011de4d4.jpeg). **Any input I would be most grateful. Many thanks, . Olivia**.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/109
https://github.com/scverse/scanpy/issues/110:151,availability,error,errors,151,"aga_compare_paths: KeyError: 'aga_groups' and KeyError: 'aga_groups_order_original'; Hi, . I am following the example _robustness.ipynb_ and I get the errors . _KeyError: 'aga_groups'_ and _KeyError: 'aga_groups_order_original'_. when using the function _aga_compare_paths_ in scanpy 0.4.4. I read that _aga_groups_ disappeared in version 0.3, but looks like _aga_compare_paths_ is still using it? Many thanks,. Maria",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/110
https://github.com/scverse/scanpy/issues/110:331,deployability,version,version,331,"aga_compare_paths: KeyError: 'aga_groups' and KeyError: 'aga_groups_order_original'; Hi, . I am following the example _robustness.ipynb_ and I get the errors . _KeyError: 'aga_groups'_ and _KeyError: 'aga_groups_order_original'_. when using the function _aga_compare_paths_ in scanpy 0.4.4. I read that _aga_groups_ disappeared in version 0.3, but looks like _aga_compare_paths_ is still using it? Many thanks,. Maria",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/110
https://github.com/scverse/scanpy/issues/110:331,integrability,version,version,331,"aga_compare_paths: KeyError: 'aga_groups' and KeyError: 'aga_groups_order_original'; Hi, . I am following the example _robustness.ipynb_ and I get the errors . _KeyError: 'aga_groups'_ and _KeyError: 'aga_groups_order_original'_. when using the function _aga_compare_paths_ in scanpy 0.4.4. I read that _aga_groups_ disappeared in version 0.3, but looks like _aga_compare_paths_ is still using it? Many thanks,. Maria",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/110
https://github.com/scverse/scanpy/issues/110:331,modifiability,version,version,331,"aga_compare_paths: KeyError: 'aga_groups' and KeyError: 'aga_groups_order_original'; Hi, . I am following the example _robustness.ipynb_ and I get the errors . _KeyError: 'aga_groups'_ and _KeyError: 'aga_groups_order_original'_. when using the function _aga_compare_paths_ in scanpy 0.4.4. I read that _aga_groups_ disappeared in version 0.3, but looks like _aga_compare_paths_ is still using it? Many thanks,. Maria",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/110
https://github.com/scverse/scanpy/issues/110:151,performance,error,errors,151,"aga_compare_paths: KeyError: 'aga_groups' and KeyError: 'aga_groups_order_original'; Hi, . I am following the example _robustness.ipynb_ and I get the errors . _KeyError: 'aga_groups'_ and _KeyError: 'aga_groups_order_original'_. when using the function _aga_compare_paths_ in scanpy 0.4.4. I read that _aga_groups_ disappeared in version 0.3, but looks like _aga_compare_paths_ is still using it? Many thanks,. Maria",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/110
https://github.com/scverse/scanpy/issues/110:151,safety,error,errors,151,"aga_compare_paths: KeyError: 'aga_groups' and KeyError: 'aga_groups_order_original'; Hi, . I am following the example _robustness.ipynb_ and I get the errors . _KeyError: 'aga_groups'_ and _KeyError: 'aga_groups_order_original'_. when using the function _aga_compare_paths_ in scanpy 0.4.4. I read that _aga_groups_ disappeared in version 0.3, but looks like _aga_compare_paths_ is still using it? Many thanks,. Maria",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/110
https://github.com/scverse/scanpy/issues/110:151,usability,error,errors,151,"aga_compare_paths: KeyError: 'aga_groups' and KeyError: 'aga_groups_order_original'; Hi, . I am following the example _robustness.ipynb_ and I get the errors . _KeyError: 'aga_groups'_ and _KeyError: 'aga_groups_order_original'_. when using the function _aga_compare_paths_ in scanpy 0.4.4. I read that _aga_groups_ disappeared in version 0.3, but looks like _aga_compare_paths_ is still using it? Many thanks,. Maria",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/110
https://github.com/scverse/scanpy/pull/112:44,availability,cluster,clustermap,44,"Fix NoneType check in plotting/anndata.py; `clustermap` raises an exception when an `obs_keys` argument is not provided, because None is not a type.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/112
https://github.com/scverse/scanpy/pull/112:44,deployability,cluster,clustermap,44,"Fix NoneType check in plotting/anndata.py; `clustermap` raises an exception when an `obs_keys` argument is not provided, because None is not a type.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/112
https://github.com/scverse/scanpy/pull/112:66,safety,except,exception,66,"Fix NoneType check in plotting/anndata.py; `clustermap` raises an exception when an `obs_keys` argument is not provided, because None is not a type.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/112
https://github.com/scverse/scanpy/pull/114:20,interoperability,compatib,compatible,20,Make diffusion maps compatible with new Neighbors class; sc.tl.diffmap is not using new neighbors attributes.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/114
https://github.com/scverse/scanpy/issues/115:129,modifiability,variab,variable,129,"filter_genes_dispersion(adata, n_top_genes=x) retrieves fewer genes if zero-expression genes exist; I was trying to get top 1000 variable genes in 1.3M dataset, but every time I ended up with zero genes after the `sc.pp.filter_genes_dispersion(adata, n_top_genes=1000)` call. The reason is that `sc.pp.filter_genes_dispersion(adata, n_top_genes=x)` actually returns `x - num_zero_expression_genes` genes instead of x, where num_zero_expression_genes represents number of genes without any expression. . Here is a small reproducible example:. ![image](https://user-images.githubusercontent.com/1140359/38215015-9f3de66e-36c6-11e8-8c96-9c9a6458741d.png). It's easy to fix with a prior `sc.pp.filter_genes(adata, min_counts=1)` call, but I think filter_genes_dispersion should retrieve n_top_genes, regardless of presence of zero expression genes.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/115
https://github.com/scverse/scanpy/issues/115:171,performance,time,time,171,"filter_genes_dispersion(adata, n_top_genes=x) retrieves fewer genes if zero-expression genes exist; I was trying to get top 1000 variable genes in 1.3M dataset, but every time I ended up with zero genes after the `sc.pp.filter_genes_dispersion(adata, n_top_genes=1000)` call. The reason is that `sc.pp.filter_genes_dispersion(adata, n_top_genes=x)` actually returns `x - num_zero_expression_genes` genes instead of x, where num_zero_expression_genes represents number of genes without any expression. . Here is a small reproducible example:. ![image](https://user-images.githubusercontent.com/1140359/38215015-9f3de66e-36c6-11e8-8c96-9c9a6458741d.png). It's easy to fix with a prior `sc.pp.filter_genes(adata, min_counts=1)` call, but I think filter_genes_dispersion should retrieve n_top_genes, regardless of presence of zero expression genes.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/115
https://github.com/scverse/scanpy/issues/115:559,usability,user,user-images,559,"filter_genes_dispersion(adata, n_top_genes=x) retrieves fewer genes if zero-expression genes exist; I was trying to get top 1000 variable genes in 1.3M dataset, but every time I ended up with zero genes after the `sc.pp.filter_genes_dispersion(adata, n_top_genes=1000)` call. The reason is that `sc.pp.filter_genes_dispersion(adata, n_top_genes=x)` actually returns `x - num_zero_expression_genes` genes instead of x, where num_zero_expression_genes represents number of genes without any expression. . Here is a small reproducible example:. ![image](https://user-images.githubusercontent.com/1140359/38215015-9f3de66e-36c6-11e8-8c96-9c9a6458741d.png). It's easy to fix with a prior `sc.pp.filter_genes(adata, min_counts=1)` call, but I think filter_genes_dispersion should retrieve n_top_genes, regardless of presence of zero expression genes.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/115
https://github.com/scverse/scanpy/pull/116:0,deployability,Updat,Update,0,"Update PyPI badge; The new one is smaller, because it doesn’t say “package”. It’s also blue which shows it’s not a build status",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/116
https://github.com/scverse/scanpy/pull/116:115,deployability,build,build,115,"Update PyPI badge; The new one is smaller, because it doesn’t say “package”. It’s also blue which shows it’s not a build status",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/116
https://github.com/scverse/scanpy/pull/116:67,modifiability,pac,package,67,"Update PyPI badge; The new one is smaller, because it doesn’t say “package”. It’s also blue which shows it’s not a build status",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/116
https://github.com/scverse/scanpy/pull/116:54,reliability,doe,doesn,54,"Update PyPI badge; The new one is smaller, because it doesn’t say “package”. It’s also blue which shows it’s not a build status",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/116
https://github.com/scverse/scanpy/pull/116:0,safety,Updat,Update,0,"Update PyPI badge; The new one is smaller, because it doesn’t say “package”. It’s also blue which shows it’s not a build status",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/116
https://github.com/scverse/scanpy/pull/116:0,security,Updat,Update,0,"Update PyPI badge; The new one is smaller, because it doesn’t say “package”. It’s also blue which shows it’s not a build status",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/116
https://github.com/scverse/scanpy/pull/116:121,usability,statu,status,121,"Update PyPI badge; The new one is smaller, because it doesn’t say “package”. It’s also blue which shows it’s not a build status",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/116
https://github.com/scverse/scanpy/issues/117:30,deployability,api,api,30,"Write dir for export; `scanpy.api.pl.paga(adata, export_to_gexf=True)`. If 'write' dir does not exist, then export aborts. (Solution: manually create 'write' dir).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/117
https://github.com/scverse/scanpy/issues/117:30,integrability,api,api,30,"Write dir for export; `scanpy.api.pl.paga(adata, export_to_gexf=True)`. If 'write' dir does not exist, then export aborts. (Solution: manually create 'write' dir).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/117
https://github.com/scverse/scanpy/issues/117:30,interoperability,api,api,30,"Write dir for export; `scanpy.api.pl.paga(adata, export_to_gexf=True)`. If 'write' dir does not exist, then export aborts. (Solution: manually create 'write' dir).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/117
https://github.com/scverse/scanpy/issues/117:87,reliability,doe,does,87,"Write dir for export; `scanpy.api.pl.paga(adata, export_to_gexf=True)`. If 'write' dir does not exist, then export aborts. (Solution: manually create 'write' dir).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/117
https://github.com/scverse/scanpy/pull/118:36,energy efficiency,Current,Currently,36,savefig with bbox_inches = 'tight'; Currently output figures are often cut off at the edges. Adding bbox_inches = 'tight' to savefig no longer cuts off figure text at edges. As far as I've tested it this shouldn't cause any other problems and simply saves figures with proper padding.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/118
https://github.com/scverse/scanpy/pull/118:189,safety,test,tested,189,savefig with bbox_inches = 'tight'; Currently output figures are often cut off at the edges. Adding bbox_inches = 'tight' to savefig no longer cuts off figure text at edges. As far as I've tested it this shouldn't cause any other problems and simply saves figures with proper padding.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/118
https://github.com/scverse/scanpy/pull/118:189,testability,test,tested,189,savefig with bbox_inches = 'tight'; Currently output figures are often cut off at the edges. Adding bbox_inches = 'tight' to savefig no longer cuts off figure text at edges. As far as I've tested it this shouldn't cause any other problems and simply saves figures with proper padding.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/118
https://github.com/scverse/scanpy/pull/118:243,testability,simpl,simply,243,savefig with bbox_inches = 'tight'; Currently output figures are often cut off at the edges. Adding bbox_inches = 'tight' to savefig no longer cuts off figure text at edges. As far as I've tested it this shouldn't cause any other problems and simply saves figures with proper padding.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/118
https://github.com/scverse/scanpy/pull/118:243,usability,simpl,simply,243,savefig with bbox_inches = 'tight'; Currently output figures are often cut off at the edges. Adding bbox_inches = 'tight' to savefig no longer cuts off figure text at edges. As far as I've tested it this shouldn't cause any other problems and simply saves figures with proper padding.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/118
https://github.com/scverse/scanpy/pull/119:301,interoperability,format,format,301,"Added intersphinx, easier types in docs; As example for the change I [simplified scanpy.preprocessing.simple.filter_cells](https://github.com/theislab/scanpy/pull/119/commits/ae85520fcd16abbb1fb9748cf0b03fb35ce858b6#diff-1aa47c128676c77be1123acc601efd9eL19). Also I fixed a few docs problems. The new format is now custom, so if you dislike the grey headers, that’s easy. Before | After. ----------|----------. ![before](https://user-images.githubusercontent.com/291575/38499002-c6f9dda0-3bf5-11e8-8a76-07a423b366d3.png) | ![after](https://user-images.githubusercontent.com/291575/38512702-79d3ca24-3c1b-11e8-84af-87f033d5008e.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/119
https://github.com/scverse/scanpy/pull/119:70,testability,simpl,simplified,70,"Added intersphinx, easier types in docs; As example for the change I [simplified scanpy.preprocessing.simple.filter_cells](https://github.com/theislab/scanpy/pull/119/commits/ae85520fcd16abbb1fb9748cf0b03fb35ce858b6#diff-1aa47c128676c77be1123acc601efd9eL19). Also I fixed a few docs problems. The new format is now custom, so if you dislike the grey headers, that’s easy. Before | After. ----------|----------. ![before](https://user-images.githubusercontent.com/291575/38499002-c6f9dda0-3bf5-11e8-8a76-07a423b366d3.png) | ![after](https://user-images.githubusercontent.com/291575/38512702-79d3ca24-3c1b-11e8-84af-87f033d5008e.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/119
https://github.com/scverse/scanpy/pull/119:102,testability,simpl,simple,102,"Added intersphinx, easier types in docs; As example for the change I [simplified scanpy.preprocessing.simple.filter_cells](https://github.com/theislab/scanpy/pull/119/commits/ae85520fcd16abbb1fb9748cf0b03fb35ce858b6#diff-1aa47c128676c77be1123acc601efd9eL19). Also I fixed a few docs problems. The new format is now custom, so if you dislike the grey headers, that’s easy. Before | After. ----------|----------. ![before](https://user-images.githubusercontent.com/291575/38499002-c6f9dda0-3bf5-11e8-8a76-07a423b366d3.png) | ![after](https://user-images.githubusercontent.com/291575/38512702-79d3ca24-3c1b-11e8-84af-87f033d5008e.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/119
https://github.com/scverse/scanpy/pull/119:70,usability,simpl,simplified,70,"Added intersphinx, easier types in docs; As example for the change I [simplified scanpy.preprocessing.simple.filter_cells](https://github.com/theislab/scanpy/pull/119/commits/ae85520fcd16abbb1fb9748cf0b03fb35ce858b6#diff-1aa47c128676c77be1123acc601efd9eL19). Also I fixed a few docs problems. The new format is now custom, so if you dislike the grey headers, that’s easy. Before | After. ----------|----------. ![before](https://user-images.githubusercontent.com/291575/38499002-c6f9dda0-3bf5-11e8-8a76-07a423b366d3.png) | ![after](https://user-images.githubusercontent.com/291575/38512702-79d3ca24-3c1b-11e8-84af-87f033d5008e.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/119
https://github.com/scverse/scanpy/pull/119:102,usability,simpl,simple,102,"Added intersphinx, easier types in docs; As example for the change I [simplified scanpy.preprocessing.simple.filter_cells](https://github.com/theislab/scanpy/pull/119/commits/ae85520fcd16abbb1fb9748cf0b03fb35ce858b6#diff-1aa47c128676c77be1123acc601efd9eL19). Also I fixed a few docs problems. The new format is now custom, so if you dislike the grey headers, that’s easy. Before | After. ----------|----------. ![before](https://user-images.githubusercontent.com/291575/38499002-c6f9dda0-3bf5-11e8-8a76-07a423b366d3.png) | ![after](https://user-images.githubusercontent.com/291575/38512702-79d3ca24-3c1b-11e8-84af-87f033d5008e.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/119
https://github.com/scverse/scanpy/pull/119:315,usability,custom,custom,315,"Added intersphinx, easier types in docs; As example for the change I [simplified scanpy.preprocessing.simple.filter_cells](https://github.com/theislab/scanpy/pull/119/commits/ae85520fcd16abbb1fb9748cf0b03fb35ce858b6#diff-1aa47c128676c77be1123acc601efd9eL19). Also I fixed a few docs problems. The new format is now custom, so if you dislike the grey headers, that’s easy. Before | After. ----------|----------. ![before](https://user-images.githubusercontent.com/291575/38499002-c6f9dda0-3bf5-11e8-8a76-07a423b366d3.png) | ![after](https://user-images.githubusercontent.com/291575/38512702-79d3ca24-3c1b-11e8-84af-87f033d5008e.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/119
https://github.com/scverse/scanpy/pull/119:429,usability,user,user-images,429,"Added intersphinx, easier types in docs; As example for the change I [simplified scanpy.preprocessing.simple.filter_cells](https://github.com/theislab/scanpy/pull/119/commits/ae85520fcd16abbb1fb9748cf0b03fb35ce858b6#diff-1aa47c128676c77be1123acc601efd9eL19). Also I fixed a few docs problems. The new format is now custom, so if you dislike the grey headers, that’s easy. Before | After. ----------|----------. ![before](https://user-images.githubusercontent.com/291575/38499002-c6f9dda0-3bf5-11e8-8a76-07a423b366d3.png) | ![after](https://user-images.githubusercontent.com/291575/38512702-79d3ca24-3c1b-11e8-84af-87f033d5008e.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/119
https://github.com/scverse/scanpy/pull/119:540,usability,user,user-images,540,"Added intersphinx, easier types in docs; As example for the change I [simplified scanpy.preprocessing.simple.filter_cells](https://github.com/theislab/scanpy/pull/119/commits/ae85520fcd16abbb1fb9748cf0b03fb35ce858b6#diff-1aa47c128676c77be1123acc601efd9eL19). Also I fixed a few docs problems. The new format is now custom, so if you dislike the grey headers, that’s easy. Before | After. ----------|----------. ![before](https://user-images.githubusercontent.com/291575/38499002-c6f9dda0-3bf5-11e8-8a76-07a423b366d3.png) | ![after](https://user-images.githubusercontent.com/291575/38512702-79d3ca24-3c1b-11e8-84af-87f033d5008e.png)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/119
https://github.com/scverse/scanpy/issues/120:131,energy efficiency,estimat,estimates,131,"diffusion map ""sigma""; Is there documentation explaining how scanpy calculates diffusion maps? In particular, I'm wondering how it estimates ""sigma"" and whether it's possible to vary this parameter within scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/120
https://github.com/scverse/scanpy/issues/120:188,modifiability,paramet,parameter,188,"diffusion map ""sigma""; Is there documentation explaining how scanpy calculates diffusion maps? In particular, I'm wondering how it estimates ""sigma"" and whether it's possible to vary this parameter within scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/120
https://github.com/scverse/scanpy/issues/120:32,usability,document,documentation,32,"diffusion map ""sigma""; Is there documentation explaining how scanpy calculates diffusion maps? In particular, I'm wondering how it estimates ""sigma"" and whether it's possible to vary this parameter within scanpy?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/120
https://github.com/scverse/scanpy/issues/122:0,integrability,Filter,Filtering,0,"Filtering cells with a high % of reads mapping to genes in the mitochondrial genome; Hi,. I noticed that Scanpy doesn't have a ready function for filtering cells with a high percentage of reads mapping to genes in the mitochondrial genome. Is there still some easy way to do this? Apparently this type of cells can be bad. _In the absence of spike-in transcripts, the proportion of reads mapped to genes in the mitochondrial genome can also be used. High proportions are indicative of poor-quality cells (Islam et al. 2014; Ilicic et al. 2016), possibly because of loss of cytoplasmic RNA from perforated cells. The reasoning is that mitochondria are larger than individual transcript molecules and less likely to escape through tears in the cell membrane._. https://www.bioconductor.org/help/workflows/simpleSingleCell/#examining-gene-level-metrics.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/122
https://github.com/scverse/scanpy/issues/122:146,integrability,filter,filtering,146,"Filtering cells with a high % of reads mapping to genes in the mitochondrial genome; Hi,. I noticed that Scanpy doesn't have a ready function for filtering cells with a high percentage of reads mapping to genes in the mitochondrial genome. Is there still some easy way to do this? Apparently this type of cells can be bad. _In the absence of spike-in transcripts, the proportion of reads mapped to genes in the mitochondrial genome can also be used. High proportions are indicative of poor-quality cells (Islam et al. 2014; Ilicic et al. 2016), possibly because of loss of cytoplasmic RNA from perforated cells. The reasoning is that mitochondria are larger than individual transcript molecules and less likely to escape through tears in the cell membrane._. https://www.bioconductor.org/help/workflows/simpleSingleCell/#examining-gene-level-metrics.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/122
https://github.com/scverse/scanpy/issues/122:112,reliability,doe,doesn,112,"Filtering cells with a high % of reads mapping to genes in the mitochondrial genome; Hi,. I noticed that Scanpy doesn't have a ready function for filtering cells with a high percentage of reads mapping to genes in the mitochondrial genome. Is there still some easy way to do this? Apparently this type of cells can be bad. _In the absence of spike-in transcripts, the proportion of reads mapped to genes in the mitochondrial genome can also be used. High proportions are indicative of poor-quality cells (Islam et al. 2014; Ilicic et al. 2016), possibly because of loss of cytoplasmic RNA from perforated cells. The reasoning is that mitochondria are larger than individual transcript molecules and less likely to escape through tears in the cell membrane._. https://www.bioconductor.org/help/workflows/simpleSingleCell/#examining-gene-level-metrics.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/122
https://github.com/scverse/scanpy/issues/122:565,security,loss,loss,565,"Filtering cells with a high % of reads mapping to genes in the mitochondrial genome; Hi,. I noticed that Scanpy doesn't have a ready function for filtering cells with a high percentage of reads mapping to genes in the mitochondrial genome. Is there still some easy way to do this? Apparently this type of cells can be bad. _In the absence of spike-in transcripts, the proportion of reads mapped to genes in the mitochondrial genome can also be used. High proportions are indicative of poor-quality cells (Islam et al. 2014; Ilicic et al. 2016), possibly because of loss of cytoplasmic RNA from perforated cells. The reasoning is that mitochondria are larger than individual transcript molecules and less likely to escape through tears in the cell membrane._. https://www.bioconductor.org/help/workflows/simpleSingleCell/#examining-gene-level-metrics.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/122
https://github.com/scverse/scanpy/issues/122:803,testability,simpl,simpleSingleCell,803,"Filtering cells with a high % of reads mapping to genes in the mitochondrial genome; Hi,. I noticed that Scanpy doesn't have a ready function for filtering cells with a high percentage of reads mapping to genes in the mitochondrial genome. Is there still some easy way to do this? Apparently this type of cells can be bad. _In the absence of spike-in transcripts, the proportion of reads mapped to genes in the mitochondrial genome can also be used. High proportions are indicative of poor-quality cells (Islam et al. 2014; Ilicic et al. 2016), possibly because of loss of cytoplasmic RNA from perforated cells. The reasoning is that mitochondria are larger than individual transcript molecules and less likely to escape through tears in the cell membrane._. https://www.bioconductor.org/help/workflows/simpleSingleCell/#examining-gene-level-metrics.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/122
https://github.com/scverse/scanpy/issues/122:471,usability,indicat,indicative,471,"Filtering cells with a high % of reads mapping to genes in the mitochondrial genome; Hi,. I noticed that Scanpy doesn't have a ready function for filtering cells with a high percentage of reads mapping to genes in the mitochondrial genome. Is there still some easy way to do this? Apparently this type of cells can be bad. _In the absence of spike-in transcripts, the proportion of reads mapped to genes in the mitochondrial genome can also be used. High proportions are indicative of poor-quality cells (Islam et al. 2014; Ilicic et al. 2016), possibly because of loss of cytoplasmic RNA from perforated cells. The reasoning is that mitochondria are larger than individual transcript molecules and less likely to escape through tears in the cell membrane._. https://www.bioconductor.org/help/workflows/simpleSingleCell/#examining-gene-level-metrics.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/122
https://github.com/scverse/scanpy/issues/122:788,usability,help,help,788,"Filtering cells with a high % of reads mapping to genes in the mitochondrial genome; Hi,. I noticed that Scanpy doesn't have a ready function for filtering cells with a high percentage of reads mapping to genes in the mitochondrial genome. Is there still some easy way to do this? Apparently this type of cells can be bad. _In the absence of spike-in transcripts, the proportion of reads mapped to genes in the mitochondrial genome can also be used. High proportions are indicative of poor-quality cells (Islam et al. 2014; Ilicic et al. 2016), possibly because of loss of cytoplasmic RNA from perforated cells. The reasoning is that mitochondria are larger than individual transcript molecules and less likely to escape through tears in the cell membrane._. https://www.bioconductor.org/help/workflows/simpleSingleCell/#examining-gene-level-metrics.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/122
https://github.com/scverse/scanpy/issues/122:793,usability,workflow,workflows,793,"Filtering cells with a high % of reads mapping to genes in the mitochondrial genome; Hi,. I noticed that Scanpy doesn't have a ready function for filtering cells with a high percentage of reads mapping to genes in the mitochondrial genome. Is there still some easy way to do this? Apparently this type of cells can be bad. _In the absence of spike-in transcripts, the proportion of reads mapped to genes in the mitochondrial genome can also be used. High proportions are indicative of poor-quality cells (Islam et al. 2014; Ilicic et al. 2016), possibly because of loss of cytoplasmic RNA from perforated cells. The reasoning is that mitochondria are larger than individual transcript molecules and less likely to escape through tears in the cell membrane._. https://www.bioconductor.org/help/workflows/simpleSingleCell/#examining-gene-level-metrics.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/122
https://github.com/scverse/scanpy/issues/122:803,usability,simpl,simpleSingleCell,803,"Filtering cells with a high % of reads mapping to genes in the mitochondrial genome; Hi,. I noticed that Scanpy doesn't have a ready function for filtering cells with a high percentage of reads mapping to genes in the mitochondrial genome. Is there still some easy way to do this? Apparently this type of cells can be bad. _In the absence of spike-in transcripts, the proportion of reads mapped to genes in the mitochondrial genome can also be used. High proportions are indicative of poor-quality cells (Islam et al. 2014; Ilicic et al. 2016), possibly because of loss of cytoplasmic RNA from perforated cells. The reasoning is that mitochondria are larger than individual transcript molecules and less likely to escape through tears in the cell membrane._. https://www.bioconductor.org/help/workflows/simpleSingleCell/#examining-gene-level-metrics.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/122
https://github.com/scverse/scanpy/issues/123:799,deployability,modul,module,799,"[tl.diffmap] ValueError: Can only assign an array of same length (43570), not of length 2056.; Background: ~40k cells, umap, tsne, ... all had no problem. When running diffmap:. `sc.tl.diffmap(adata,n_comps=13)`. >/fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:793: RuntimeWarning: divide by zero encountered in true_divide. Q = scipy.sparse.spdiags(1.0/q, 0, W.shape[0], W.shape[0]). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:803: RuntimeWarning: divide by zero encountered in true_divide. self.Z = scipy.sparse.spdiags(1.0/z, 0, K.shape[0], K.shape[0]). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-6472f1ef45f7> in <module>(). ----> 1 sc.tl.diffmap(adata,n_comps=13). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/tools/diffmap.py in diffmap(adata, n_comps, copy). 49 dmap.compute_transitions(). 50 dmap.compute_eigen(n_comps=n_comps). ---> 51 adata.obsm['X_diffmap'] = dmap.eigen_basis. 52 adata.uns['diffmap_evals'] = dmap.eigen_values. 53 logg.info(' finished', time=True, end=' ' if settings.verbosity > 2 else '\n'). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/anndata/base.py in __setitem__(self, key, arr). 104 raise ValueError('Can only assign an array of same length ({}), '. 105 'not of length {}.'. --> 106 .format(self.shape[0], arr.shape[0])). 107 # the following always allocates a new array. 108 # even if the key already exists and dimensions match. ValueError: Can only assign an array of same length (43570), not of length 2056. What might be the problem here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/123
https://github.com/scverse/scanpy/issues/123:1144,deployability,log,logg,1144,"[tl.diffmap] ValueError: Can only assign an array of same length (43570), not of length 2056.; Background: ~40k cells, umap, tsne, ... all had no problem. When running diffmap:. `sc.tl.diffmap(adata,n_comps=13)`. >/fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:793: RuntimeWarning: divide by zero encountered in true_divide. Q = scipy.sparse.spdiags(1.0/q, 0, W.shape[0], W.shape[0]). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:803: RuntimeWarning: divide by zero encountered in true_divide. self.Z = scipy.sparse.spdiags(1.0/z, 0, K.shape[0], K.shape[0]). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-6472f1ef45f7> in <module>(). ----> 1 sc.tl.diffmap(adata,n_comps=13). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/tools/diffmap.py in diffmap(adata, n_comps, copy). 49 dmap.compute_transitions(). 50 dmap.compute_eigen(n_comps=n_comps). ---> 51 adata.obsm['X_diffmap'] = dmap.eigen_basis. 52 adata.uns['diffmap_evals'] = dmap.eigen_values. 53 logg.info(' finished', time=True, end=' ' if settings.verbosity > 2 else '\n'). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/anndata/base.py in __setitem__(self, key, arr). 104 raise ValueError('Can only assign an array of same length ({}), '. 105 'not of length {}.'. --> 106 .format(self.shape[0], arr.shape[0])). 107 # the following always allocates a new array. 108 # even if the key already exists and dimensions match. ValueError: Can only assign an array of same length (43570), not of length 2056. What might be the problem here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/123
https://github.com/scverse/scanpy/issues/123:1500,energy efficiency,alloc,allocates,1500,"[tl.diffmap] ValueError: Can only assign an array of same length (43570), not of length 2056.; Background: ~40k cells, umap, tsne, ... all had no problem. When running diffmap:. `sc.tl.diffmap(adata,n_comps=13)`. >/fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:793: RuntimeWarning: divide by zero encountered in true_divide. Q = scipy.sparse.spdiags(1.0/q, 0, W.shape[0], W.shape[0]). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:803: RuntimeWarning: divide by zero encountered in true_divide. self.Z = scipy.sparse.spdiags(1.0/z, 0, K.shape[0], K.shape[0]). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-6472f1ef45f7> in <module>(). ----> 1 sc.tl.diffmap(adata,n_comps=13). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/tools/diffmap.py in diffmap(adata, n_comps, copy). 49 dmap.compute_transitions(). 50 dmap.compute_eigen(n_comps=n_comps). ---> 51 adata.obsm['X_diffmap'] = dmap.eigen_basis. 52 adata.uns['diffmap_evals'] = dmap.eigen_values. 53 logg.info(' finished', time=True, end=' ' if settings.verbosity > 2 else '\n'). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/anndata/base.py in __setitem__(self, key, arr). 104 raise ValueError('Can only assign an array of same length ({}), '. 105 'not of length {}.'. --> 106 .format(self.shape[0], arr.shape[0])). 107 # the following always allocates a new array. 108 # even if the key already exists and dimensions match. ValueError: Can only assign an array of same length (43570), not of length 2056. What might be the problem here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/123
https://github.com/scverse/scanpy/issues/123:1435,interoperability,format,format,1435,"[tl.diffmap] ValueError: Can only assign an array of same length (43570), not of length 2056.; Background: ~40k cells, umap, tsne, ... all had no problem. When running diffmap:. `sc.tl.diffmap(adata,n_comps=13)`. >/fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:793: RuntimeWarning: divide by zero encountered in true_divide. Q = scipy.sparse.spdiags(1.0/q, 0, W.shape[0], W.shape[0]). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:803: RuntimeWarning: divide by zero encountered in true_divide. self.Z = scipy.sparse.spdiags(1.0/z, 0, K.shape[0], K.shape[0]). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-6472f1ef45f7> in <module>(). ----> 1 sc.tl.diffmap(adata,n_comps=13). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/tools/diffmap.py in diffmap(adata, n_comps, copy). 49 dmap.compute_transitions(). 50 dmap.compute_eigen(n_comps=n_comps). ---> 51 adata.obsm['X_diffmap'] = dmap.eigen_basis. 52 adata.uns['diffmap_evals'] = dmap.eigen_values. 53 logg.info(' finished', time=True, end=' ' if settings.verbosity > 2 else '\n'). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/anndata/base.py in __setitem__(self, key, arr). 104 raise ValueError('Can only assign an array of same length ({}), '. 105 'not of length {}.'. --> 106 .format(self.shape[0], arr.shape[0])). 107 # the following always allocates a new array. 108 # even if the key already exists and dimensions match. ValueError: Can only assign an array of same length (43570), not of length 2056. What might be the problem here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/123
https://github.com/scverse/scanpy/issues/123:263,modifiability,pac,packages,263,"[tl.diffmap] ValueError: Can only assign an array of same length (43570), not of length 2056.; Background: ~40k cells, umap, tsne, ... all had no problem. When running diffmap:. `sc.tl.diffmap(adata,n_comps=13)`. >/fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:793: RuntimeWarning: divide by zero encountered in true_divide. Q = scipy.sparse.spdiags(1.0/q, 0, W.shape[0], W.shape[0]). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:803: RuntimeWarning: divide by zero encountered in true_divide. self.Z = scipy.sparse.spdiags(1.0/z, 0, K.shape[0], K.shape[0]). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-6472f1ef45f7> in <module>(). ----> 1 sc.tl.diffmap(adata,n_comps=13). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/tools/diffmap.py in diffmap(adata, n_comps, copy). 49 dmap.compute_transitions(). 50 dmap.compute_eigen(n_comps=n_comps). ---> 51 adata.obsm['X_diffmap'] = dmap.eigen_basis. 52 adata.uns['diffmap_evals'] = dmap.eigen_values. 53 logg.info(' finished', time=True, end=' ' if settings.verbosity > 2 else '\n'). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/anndata/base.py in __setitem__(self, key, arr). 104 raise ValueError('Can only assign an array of same length ({}), '. 105 'not of length {}.'. --> 106 .format(self.shape[0], arr.shape[0])). 107 # the following always allocates a new array. 108 # even if the key already exists and dimensions match. ValueError: Can only assign an array of same length (43570), not of length 2056. What might be the problem here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/123
https://github.com/scverse/scanpy/issues/123:474,modifiability,pac,packages,474,"[tl.diffmap] ValueError: Can only assign an array of same length (43570), not of length 2056.; Background: ~40k cells, umap, tsne, ... all had no problem. When running diffmap:. `sc.tl.diffmap(adata,n_comps=13)`. >/fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:793: RuntimeWarning: divide by zero encountered in true_divide. Q = scipy.sparse.spdiags(1.0/q, 0, W.shape[0], W.shape[0]). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:803: RuntimeWarning: divide by zero encountered in true_divide. self.Z = scipy.sparse.spdiags(1.0/z, 0, K.shape[0], K.shape[0]). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-6472f1ef45f7> in <module>(). ----> 1 sc.tl.diffmap(adata,n_comps=13). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/tools/diffmap.py in diffmap(adata, n_comps, copy). 49 dmap.compute_transitions(). 50 dmap.compute_eigen(n_comps=n_comps). ---> 51 adata.obsm['X_diffmap'] = dmap.eigen_basis. 52 adata.uns['diffmap_evals'] = dmap.eigen_values. 53 logg.info(' finished', time=True, end=' ' if settings.verbosity > 2 else '\n'). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/anndata/base.py in __setitem__(self, key, arr). 104 raise ValueError('Can only assign an array of same length ({}), '. 105 'not of length {}.'. --> 106 .format(self.shape[0], arr.shape[0])). 107 # the following always allocates a new array. 108 # even if the key already exists and dimensions match. ValueError: Can only assign an array of same length (43570), not of length 2056. What might be the problem here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/123
https://github.com/scverse/scanpy/issues/123:799,modifiability,modul,module,799,"[tl.diffmap] ValueError: Can only assign an array of same length (43570), not of length 2056.; Background: ~40k cells, umap, tsne, ... all had no problem. When running diffmap:. `sc.tl.diffmap(adata,n_comps=13)`. >/fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:793: RuntimeWarning: divide by zero encountered in true_divide. Q = scipy.sparse.spdiags(1.0/q, 0, W.shape[0], W.shape[0]). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:803: RuntimeWarning: divide by zero encountered in true_divide. self.Z = scipy.sparse.spdiags(1.0/z, 0, K.shape[0], K.shape[0]). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-6472f1ef45f7> in <module>(). ----> 1 sc.tl.diffmap(adata,n_comps=13). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/tools/diffmap.py in diffmap(adata, n_comps, copy). 49 dmap.compute_transitions(). 50 dmap.compute_eigen(n_comps=n_comps). ---> 51 adata.obsm['X_diffmap'] = dmap.eigen_basis. 52 adata.uns['diffmap_evals'] = dmap.eigen_values. 53 logg.info(' finished', time=True, end=' ' if settings.verbosity > 2 else '\n'). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/anndata/base.py in __setitem__(self, key, arr). 104 raise ValueError('Can only assign an array of same length ({}), '. 105 'not of length {}.'. --> 106 .format(self.shape[0], arr.shape[0])). 107 # the following always allocates a new array. 108 # even if the key already exists and dimensions match. ValueError: Can only assign an array of same length (43570), not of length 2056. What might be the problem here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/123
https://github.com/scverse/scanpy/issues/123:900,modifiability,pac,packages,900,"[tl.diffmap] ValueError: Can only assign an array of same length (43570), not of length 2056.; Background: ~40k cells, umap, tsne, ... all had no problem. When running diffmap:. `sc.tl.diffmap(adata,n_comps=13)`. >/fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:793: RuntimeWarning: divide by zero encountered in true_divide. Q = scipy.sparse.spdiags(1.0/q, 0, W.shape[0], W.shape[0]). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:803: RuntimeWarning: divide by zero encountered in true_divide. self.Z = scipy.sparse.spdiags(1.0/z, 0, K.shape[0], K.shape[0]). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-6472f1ef45f7> in <module>(). ----> 1 sc.tl.diffmap(adata,n_comps=13). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/tools/diffmap.py in diffmap(adata, n_comps, copy). 49 dmap.compute_transitions(). 50 dmap.compute_eigen(n_comps=n_comps). ---> 51 adata.obsm['X_diffmap'] = dmap.eigen_basis. 52 adata.uns['diffmap_evals'] = dmap.eigen_values. 53 logg.info(' finished', time=True, end=' ' if settings.verbosity > 2 else '\n'). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/anndata/base.py in __setitem__(self, key, arr). 104 raise ValueError('Can only assign an array of same length ({}), '. 105 'not of length {}.'. --> 106 .format(self.shape[0], arr.shape[0])). 107 # the following always allocates a new array. 108 # even if the key already exists and dimensions match. ValueError: Can only assign an array of same length (43570), not of length 2056. What might be the problem here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/123
https://github.com/scverse/scanpy/issues/123:1273,modifiability,pac,packages,1273,"[tl.diffmap] ValueError: Can only assign an array of same length (43570), not of length 2056.; Background: ~40k cells, umap, tsne, ... all had no problem. When running diffmap:. `sc.tl.diffmap(adata,n_comps=13)`. >/fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:793: RuntimeWarning: divide by zero encountered in true_divide. Q = scipy.sparse.spdiags(1.0/q, 0, W.shape[0], W.shape[0]). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:803: RuntimeWarning: divide by zero encountered in true_divide. self.Z = scipy.sparse.spdiags(1.0/z, 0, K.shape[0], K.shape[0]). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-6472f1ef45f7> in <module>(). ----> 1 sc.tl.diffmap(adata,n_comps=13). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/tools/diffmap.py in diffmap(adata, n_comps, copy). 49 dmap.compute_transitions(). 50 dmap.compute_eigen(n_comps=n_comps). ---> 51 adata.obsm['X_diffmap'] = dmap.eigen_basis. 52 adata.uns['diffmap_evals'] = dmap.eigen_values. 53 logg.info(' finished', time=True, end=' ' if settings.verbosity > 2 else '\n'). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/anndata/base.py in __setitem__(self, key, arr). 104 raise ValueError('Can only assign an array of same length ({}), '. 105 'not of length {}.'. --> 106 .format(self.shape[0], arr.shape[0])). 107 # the following always allocates a new array. 108 # even if the key already exists and dimensions match. ValueError: Can only assign an array of same length (43570), not of length 2056. What might be the problem here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/123
https://github.com/scverse/scanpy/issues/123:1167,performance,time,time,1167,"[tl.diffmap] ValueError: Can only assign an array of same length (43570), not of length 2056.; Background: ~40k cells, umap, tsne, ... all had no problem. When running diffmap:. `sc.tl.diffmap(adata,n_comps=13)`. >/fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:793: RuntimeWarning: divide by zero encountered in true_divide. Q = scipy.sparse.spdiags(1.0/q, 0, W.shape[0], W.shape[0]). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:803: RuntimeWarning: divide by zero encountered in true_divide. self.Z = scipy.sparse.spdiags(1.0/z, 0, K.shape[0], K.shape[0]). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-6472f1ef45f7> in <module>(). ----> 1 sc.tl.diffmap(adata,n_comps=13). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/tools/diffmap.py in diffmap(adata, n_comps, copy). 49 dmap.compute_transitions(). 50 dmap.compute_eigen(n_comps=n_comps). ---> 51 adata.obsm['X_diffmap'] = dmap.eigen_basis. 52 adata.uns['diffmap_evals'] = dmap.eigen_values. 53 logg.info(' finished', time=True, end=' ' if settings.verbosity > 2 else '\n'). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/anndata/base.py in __setitem__(self, key, arr). 104 raise ValueError('Can only assign an array of same length ({}), '. 105 'not of length {}.'. --> 106 .format(self.shape[0], arr.shape[0])). 107 # the following always allocates a new array. 108 # even if the key already exists and dimensions match. ValueError: Can only assign an array of same length (43570), not of length 2056. What might be the problem here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/123
https://github.com/scverse/scanpy/issues/123:773,safety,input,input-,773,"[tl.diffmap] ValueError: Can only assign an array of same length (43570), not of length 2056.; Background: ~40k cells, umap, tsne, ... all had no problem. When running diffmap:. `sc.tl.diffmap(adata,n_comps=13)`. >/fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:793: RuntimeWarning: divide by zero encountered in true_divide. Q = scipy.sparse.spdiags(1.0/q, 0, W.shape[0], W.shape[0]). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:803: RuntimeWarning: divide by zero encountered in true_divide. self.Z = scipy.sparse.spdiags(1.0/z, 0, K.shape[0], K.shape[0]). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-6472f1ef45f7> in <module>(). ----> 1 sc.tl.diffmap(adata,n_comps=13). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/tools/diffmap.py in diffmap(adata, n_comps, copy). 49 dmap.compute_transitions(). 50 dmap.compute_eigen(n_comps=n_comps). ---> 51 adata.obsm['X_diffmap'] = dmap.eigen_basis. 52 adata.uns['diffmap_evals'] = dmap.eigen_values. 53 logg.info(' finished', time=True, end=' ' if settings.verbosity > 2 else '\n'). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/anndata/base.py in __setitem__(self, key, arr). 104 raise ValueError('Can only assign an array of same length ({}), '. 105 'not of length {}.'. --> 106 .format(self.shape[0], arr.shape[0])). 107 # the following always allocates a new array. 108 # even if the key already exists and dimensions match. ValueError: Can only assign an array of same length (43570), not of length 2056. What might be the problem here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/123
https://github.com/scverse/scanpy/issues/123:799,safety,modul,module,799,"[tl.diffmap] ValueError: Can only assign an array of same length (43570), not of length 2056.; Background: ~40k cells, umap, tsne, ... all had no problem. When running diffmap:. `sc.tl.diffmap(adata,n_comps=13)`. >/fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:793: RuntimeWarning: divide by zero encountered in true_divide. Q = scipy.sparse.spdiags(1.0/q, 0, W.shape[0], W.shape[0]). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:803: RuntimeWarning: divide by zero encountered in true_divide. self.Z = scipy.sparse.spdiags(1.0/z, 0, K.shape[0], K.shape[0]). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-6472f1ef45f7> in <module>(). ----> 1 sc.tl.diffmap(adata,n_comps=13). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/tools/diffmap.py in diffmap(adata, n_comps, copy). 49 dmap.compute_transitions(). 50 dmap.compute_eigen(n_comps=n_comps). ---> 51 adata.obsm['X_diffmap'] = dmap.eigen_basis. 52 adata.uns['diffmap_evals'] = dmap.eigen_values. 53 logg.info(' finished', time=True, end=' ' if settings.verbosity > 2 else '\n'). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/anndata/base.py in __setitem__(self, key, arr). 104 raise ValueError('Can only assign an array of same length ({}), '. 105 'not of length {}.'. --> 106 .format(self.shape[0], arr.shape[0])). 107 # the following always allocates a new array. 108 # even if the key already exists and dimensions match. ValueError: Can only assign an array of same length (43570), not of length 2056. What might be the problem here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/123
https://github.com/scverse/scanpy/issues/123:1144,safety,log,logg,1144,"[tl.diffmap] ValueError: Can only assign an array of same length (43570), not of length 2056.; Background: ~40k cells, umap, tsne, ... all had no problem. When running diffmap:. `sc.tl.diffmap(adata,n_comps=13)`. >/fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:793: RuntimeWarning: divide by zero encountered in true_divide. Q = scipy.sparse.spdiags(1.0/q, 0, W.shape[0], W.shape[0]). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:803: RuntimeWarning: divide by zero encountered in true_divide. self.Z = scipy.sparse.spdiags(1.0/z, 0, K.shape[0], K.shape[0]). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-6472f1ef45f7> in <module>(). ----> 1 sc.tl.diffmap(adata,n_comps=13). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/tools/diffmap.py in diffmap(adata, n_comps, copy). 49 dmap.compute_transitions(). 50 dmap.compute_eigen(n_comps=n_comps). ---> 51 adata.obsm['X_diffmap'] = dmap.eigen_basis. 52 adata.uns['diffmap_evals'] = dmap.eigen_values. 53 logg.info(' finished', time=True, end=' ' if settings.verbosity > 2 else '\n'). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/anndata/base.py in __setitem__(self, key, arr). 104 raise ValueError('Can only assign an array of same length ({}), '. 105 'not of length {}.'. --> 106 .format(self.shape[0], arr.shape[0])). 107 # the following always allocates a new array. 108 # even if the key already exists and dimensions match. ValueError: Can only assign an array of same length (43570), not of length 2056. What might be the problem here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/123
https://github.com/scverse/scanpy/issues/123:1144,security,log,logg,1144,"[tl.diffmap] ValueError: Can only assign an array of same length (43570), not of length 2056.; Background: ~40k cells, umap, tsne, ... all had no problem. When running diffmap:. `sc.tl.diffmap(adata,n_comps=13)`. >/fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:793: RuntimeWarning: divide by zero encountered in true_divide. Q = scipy.sparse.spdiags(1.0/q, 0, W.shape[0], W.shape[0]). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:803: RuntimeWarning: divide by zero encountered in true_divide. self.Z = scipy.sparse.spdiags(1.0/z, 0, K.shape[0], K.shape[0]). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-6472f1ef45f7> in <module>(). ----> 1 sc.tl.diffmap(adata,n_comps=13). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/tools/diffmap.py in diffmap(adata, n_comps, copy). 49 dmap.compute_transitions(). 50 dmap.compute_eigen(n_comps=n_comps). ---> 51 adata.obsm['X_diffmap'] = dmap.eigen_basis. 52 adata.uns['diffmap_evals'] = dmap.eigen_values. 53 logg.info(' finished', time=True, end=' ' if settings.verbosity > 2 else '\n'). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/anndata/base.py in __setitem__(self, key, arr). 104 raise ValueError('Can only assign an array of same length ({}), '. 105 'not of length {}.'. --> 106 .format(self.shape[0], arr.shape[0])). 107 # the following always allocates a new array. 108 # even if the key already exists and dimensions match. ValueError: Can only assign an array of same length (43570), not of length 2056. What might be the problem here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/123
https://github.com/scverse/scanpy/issues/123:729,testability,Trace,Traceback,729,"[tl.diffmap] ValueError: Can only assign an array of same length (43570), not of length 2056.; Background: ~40k cells, umap, tsne, ... all had no problem. When running diffmap:. `sc.tl.diffmap(adata,n_comps=13)`. >/fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:793: RuntimeWarning: divide by zero encountered in true_divide. Q = scipy.sparse.spdiags(1.0/q, 0, W.shape[0], W.shape[0]). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:803: RuntimeWarning: divide by zero encountered in true_divide. self.Z = scipy.sparse.spdiags(1.0/z, 0, K.shape[0], K.shape[0]). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-6472f1ef45f7> in <module>(). ----> 1 sc.tl.diffmap(adata,n_comps=13). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/tools/diffmap.py in diffmap(adata, n_comps, copy). 49 dmap.compute_transitions(). 50 dmap.compute_eigen(n_comps=n_comps). ---> 51 adata.obsm['X_diffmap'] = dmap.eigen_basis. 52 adata.uns['diffmap_evals'] = dmap.eigen_values. 53 logg.info(' finished', time=True, end=' ' if settings.verbosity > 2 else '\n'). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/anndata/base.py in __setitem__(self, key, arr). 104 raise ValueError('Can only assign an array of same length ({}), '. 105 'not of length {}.'. --> 106 .format(self.shape[0], arr.shape[0])). 107 # the following always allocates a new array. 108 # even if the key already exists and dimensions match. ValueError: Can only assign an array of same length (43570), not of length 2056. What might be the problem here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/123
https://github.com/scverse/scanpy/issues/123:1144,testability,log,logg,1144,"[tl.diffmap] ValueError: Can only assign an array of same length (43570), not of length 2056.; Background: ~40k cells, umap, tsne, ... all had no problem. When running diffmap:. `sc.tl.diffmap(adata,n_comps=13)`. >/fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:793: RuntimeWarning: divide by zero encountered in true_divide. Q = scipy.sparse.spdiags(1.0/q, 0, W.shape[0], W.shape[0]). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:803: RuntimeWarning: divide by zero encountered in true_divide. self.Z = scipy.sparse.spdiags(1.0/z, 0, K.shape[0], K.shape[0]). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-6472f1ef45f7> in <module>(). ----> 1 sc.tl.diffmap(adata,n_comps=13). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/tools/diffmap.py in diffmap(adata, n_comps, copy). 49 dmap.compute_transitions(). 50 dmap.compute_eigen(n_comps=n_comps). ---> 51 adata.obsm['X_diffmap'] = dmap.eigen_basis. 52 adata.uns['diffmap_evals'] = dmap.eigen_values. 53 logg.info(' finished', time=True, end=' ' if settings.verbosity > 2 else '\n'). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/anndata/base.py in __setitem__(self, key, arr). 104 raise ValueError('Can only assign an array of same length ({}), '. 105 'not of length {}.'. --> 106 .format(self.shape[0], arr.shape[0])). 107 # the following always allocates a new array. 108 # even if the key already exists and dimensions match. ValueError: Can only assign an array of same length (43570), not of length 2056. What might be the problem here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/123
https://github.com/scverse/scanpy/issues/123:773,usability,input,input-,773,"[tl.diffmap] ValueError: Can only assign an array of same length (43570), not of length 2056.; Background: ~40k cells, umap, tsne, ... all had no problem. When running diffmap:. `sc.tl.diffmap(adata,n_comps=13)`. >/fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:793: RuntimeWarning: divide by zero encountered in true_divide. Q = scipy.sparse.spdiags(1.0/q, 0, W.shape[0], W.shape[0]). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:803: RuntimeWarning: divide by zero encountered in true_divide. self.Z = scipy.sparse.spdiags(1.0/z, 0, K.shape[0], K.shape[0]). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-6472f1ef45f7> in <module>(). ----> 1 sc.tl.diffmap(adata,n_comps=13). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/tools/diffmap.py in diffmap(adata, n_comps, copy). 49 dmap.compute_transitions(). 50 dmap.compute_eigen(n_comps=n_comps). ---> 51 adata.obsm['X_diffmap'] = dmap.eigen_basis. 52 adata.uns['diffmap_evals'] = dmap.eigen_values. 53 logg.info(' finished', time=True, end=' ' if settings.verbosity > 2 else '\n'). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/anndata/base.py in __setitem__(self, key, arr). 104 raise ValueError('Can only assign an array of same length ({}), '. 105 'not of length {}.'. --> 106 .format(self.shape[0], arr.shape[0])). 107 # the following always allocates a new array. 108 # even if the key already exists and dimensions match. ValueError: Can only assign an array of same length (43570), not of length 2056. What might be the problem here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/123
https://github.com/scverse/scanpy/issues/123:916,usability,tool,tools,916,"[tl.diffmap] ValueError: Can only assign an array of same length (43570), not of length 2056.; Background: ~40k cells, umap, tsne, ... all had no problem. When running diffmap:. `sc.tl.diffmap(adata,n_comps=13)`. >/fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:793: RuntimeWarning: divide by zero encountered in true_divide. Q = scipy.sparse.spdiags(1.0/q, 0, W.shape[0], W.shape[0]). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/neighbors/__init__.py:803: RuntimeWarning: divide by zero encountered in true_divide. self.Z = scipy.sparse.spdiags(1.0/z, 0, K.shape[0], K.shape[0]). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-6472f1ef45f7> in <module>(). ----> 1 sc.tl.diffmap(adata,n_comps=13). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/scanpy/tools/diffmap.py in diffmap(adata, n_comps, copy). 49 dmap.compute_transitions(). 50 dmap.compute_eigen(n_comps=n_comps). ---> 51 adata.obsm['X_diffmap'] = dmap.eigen_basis. 52 adata.uns['diffmap_evals'] = dmap.eigen_values. 53 logg.info(' finished', time=True, end=' ' if settings.verbosity > 2 else '\n'). /fastdata/chris/bin/anaconda3/lib/python3.6/site-packages/anndata/base.py in __setitem__(self, key, arr). 104 raise ValueError('Can only assign an array of same length ({}), '. 105 'not of length {}.'. --> 106 .format(self.shape[0], arr.shape[0])). 107 # the following always allocates a new array. 108 # even if the key already exists and dimensions match. ValueError: Can only assign an array of same length (43570), not of length 2056. What might be the problem here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/123
https://github.com/scverse/scanpy/pull/124:310,availability,state,statement,310,"Do not use paga in draw_graph, if use_paga is False; This fixes the `UnboundLocalError: local variable 'ig_layout' referenced before assignment` exception that happens in following scenario:. ```. sc.tl.louvain(adata). sc.tl.paga(adata). sc.pl.paga(adata). sc.tl.draw_graph(adata). ```. Since there is no else statement for use_paga check, ig_layout is not defined.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/124
https://github.com/scverse/scanpy/pull/124:310,integrability,state,statement,310,"Do not use paga in draw_graph, if use_paga is False; This fixes the `UnboundLocalError: local variable 'ig_layout' referenced before assignment` exception that happens in following scenario:. ```. sc.tl.louvain(adata). sc.tl.paga(adata). sc.pl.paga(adata). sc.tl.draw_graph(adata). ```. Since there is no else statement for use_paga check, ig_layout is not defined.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/124
https://github.com/scverse/scanpy/pull/124:94,modifiability,variab,variable,94,"Do not use paga in draw_graph, if use_paga is False; This fixes the `UnboundLocalError: local variable 'ig_layout' referenced before assignment` exception that happens in following scenario:. ```. sc.tl.louvain(adata). sc.tl.paga(adata). sc.pl.paga(adata). sc.tl.draw_graph(adata). ```. Since there is no else statement for use_paga check, ig_layout is not defined.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/124
https://github.com/scverse/scanpy/pull/124:181,modifiability,scenario,scenario,181,"Do not use paga in draw_graph, if use_paga is False; This fixes the `UnboundLocalError: local variable 'ig_layout' referenced before assignment` exception that happens in following scenario:. ```. sc.tl.louvain(adata). sc.tl.paga(adata). sc.pl.paga(adata). sc.tl.draw_graph(adata). ```. Since there is no else statement for use_paga check, ig_layout is not defined.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/124
https://github.com/scverse/scanpy/pull/124:145,safety,except,exception,145,"Do not use paga in draw_graph, if use_paga is False; This fixes the `UnboundLocalError: local variable 'ig_layout' referenced before assignment` exception that happens in following scenario:. ```. sc.tl.louvain(adata). sc.tl.paga(adata). sc.pl.paga(adata). sc.tl.draw_graph(adata). ```. Since there is no else statement for use_paga check, ig_layout is not defined.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/124
https://github.com/scverse/scanpy/pull/125:99,deployability,modul,module,99,"Added MNN_correct support; Hi, I wrapped a R function from scran (mnnCorrect) in the preprocessing module. It's a new algorithm for batch effect removal ([Batch effects in single-cell RNA-sequencing data are corrected by matching mutual nearest neighbors](https://www.nature.com/articles/nbt.4091)) and has not been implemented in Python, so I thought it would be useful. (Extremely useful for myself 😁 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/125
https://github.com/scverse/scanpy/pull/125:33,integrability,wrap,wrapped,33,"Added MNN_correct support; Hi, I wrapped a R function from scran (mnnCorrect) in the preprocessing module. It's a new algorithm for batch effect removal ([Batch effects in single-cell RNA-sequencing data are corrected by matching mutual nearest neighbors](https://www.nature.com/articles/nbt.4091)) and has not been implemented in Python, so I thought it would be useful. (Extremely useful for myself 😁 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/125
https://github.com/scverse/scanpy/pull/125:132,integrability,batch,batch,132,"Added MNN_correct support; Hi, I wrapped a R function from scran (mnnCorrect) in the preprocessing module. It's a new algorithm for batch effect removal ([Batch effects in single-cell RNA-sequencing data are corrected by matching mutual nearest neighbors](https://www.nature.com/articles/nbt.4091)) and has not been implemented in Python, so I thought it would be useful. (Extremely useful for myself 😁 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/125
https://github.com/scverse/scanpy/pull/125:155,integrability,Batch,Batch,155,"Added MNN_correct support; Hi, I wrapped a R function from scran (mnnCorrect) in the preprocessing module. It's a new algorithm for batch effect removal ([Batch effects in single-cell RNA-sequencing data are corrected by matching mutual nearest neighbors](https://www.nature.com/articles/nbt.4091)) and has not been implemented in Python, so I thought it would be useful. (Extremely useful for myself 😁 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/125
https://github.com/scverse/scanpy/pull/125:99,modifiability,modul,module,99,"Added MNN_correct support; Hi, I wrapped a R function from scran (mnnCorrect) in the preprocessing module. It's a new algorithm for batch effect removal ([Batch effects in single-cell RNA-sequencing data are corrected by matching mutual nearest neighbors](https://www.nature.com/articles/nbt.4091)) and has not been implemented in Python, so I thought it would be useful. (Extremely useful for myself 😁 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/125
https://github.com/scverse/scanpy/pull/125:132,performance,batch,batch,132,"Added MNN_correct support; Hi, I wrapped a R function from scran (mnnCorrect) in the preprocessing module. It's a new algorithm for batch effect removal ([Batch effects in single-cell RNA-sequencing data are corrected by matching mutual nearest neighbors](https://www.nature.com/articles/nbt.4091)) and has not been implemented in Python, so I thought it would be useful. (Extremely useful for myself 😁 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/125
https://github.com/scverse/scanpy/pull/125:155,performance,Batch,Batch,155,"Added MNN_correct support; Hi, I wrapped a R function from scran (mnnCorrect) in the preprocessing module. It's a new algorithm for batch effect removal ([Batch effects in single-cell RNA-sequencing data are corrected by matching mutual nearest neighbors](https://www.nature.com/articles/nbt.4091)) and has not been implemented in Python, so I thought it would be useful. (Extremely useful for myself 😁 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/125
https://github.com/scverse/scanpy/pull/125:99,safety,modul,module,99,"Added MNN_correct support; Hi, I wrapped a R function from scran (mnnCorrect) in the preprocessing module. It's a new algorithm for batch effect removal ([Batch effects in single-cell RNA-sequencing data are corrected by matching mutual nearest neighbors](https://www.nature.com/articles/nbt.4091)) and has not been implemented in Python, so I thought it would be useful. (Extremely useful for myself 😁 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/125
https://github.com/scverse/scanpy/pull/125:18,usability,support,support,18,"Added MNN_correct support; Hi, I wrapped a R function from scran (mnnCorrect) in the preprocessing module. It's a new algorithm for batch effect removal ([Batch effects in single-cell RNA-sequencing data are corrected by matching mutual nearest neighbors](https://www.nature.com/articles/nbt.4091)) and has not been implemented in Python, so I thought it would be useful. (Extremely useful for myself 😁 )",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/125
https://github.com/scverse/scanpy/pull/126:17,deployability,Updat,Updated,17,Include pypairs; Updated /api and /tools to include sandbag and cyclone of the pypairs method. For more details see https://github.com/rfechtner/pypairs,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/126
https://github.com/scverse/scanpy/pull/126:26,deployability,api,api,26,Include pypairs; Updated /api and /tools to include sandbag and cyclone of the pypairs method. For more details see https://github.com/rfechtner/pypairs,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/126
https://github.com/scverse/scanpy/pull/126:26,integrability,api,api,26,Include pypairs; Updated /api and /tools to include sandbag and cyclone of the pypairs method. For more details see https://github.com/rfechtner/pypairs,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/126
https://github.com/scverse/scanpy/pull/126:26,interoperability,api,api,26,Include pypairs; Updated /api and /tools to include sandbag and cyclone of the pypairs method. For more details see https://github.com/rfechtner/pypairs,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/126
https://github.com/scverse/scanpy/pull/126:17,safety,Updat,Updated,17,Include pypairs; Updated /api and /tools to include sandbag and cyclone of the pypairs method. For more details see https://github.com/rfechtner/pypairs,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/126
https://github.com/scverse/scanpy/pull/126:17,security,Updat,Updated,17,Include pypairs; Updated /api and /tools to include sandbag and cyclone of the pypairs method. For more details see https://github.com/rfechtner/pypairs,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/126
https://github.com/scverse/scanpy/pull/126:35,usability,tool,tools,35,Include pypairs; Updated /api and /tools to include sandbag and cyclone of the pypairs method. For more details see https://github.com/rfechtner/pypairs,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/126
https://github.com/scverse/scanpy/issues/127:118,modifiability,paramet,parameter,118,sc.pl.violin ylabel and title; I think it would be usedul to allow for manual setting of ylabel and title through the parameter list of sc.pl.violin(),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/127
https://github.com/scverse/scanpy/issues/128:148,availability,error,error,148,"Set multiple roots in tree layout; Setting one root works well:. `sc.pl.paga(adata, layout='eq_tree', root=[9])`. Setting multiple roots returns an error: . `TypeError: unhashable type: 'list'`. Please give an example for using multiple roots, and also explain what does `rootlevel=` set?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/128
https://github.com/scverse/scanpy/issues/128:148,performance,error,error,148,"Set multiple roots in tree layout; Setting one root works well:. `sc.pl.paga(adata, layout='eq_tree', root=[9])`. Setting multiple roots returns an error: . `TypeError: unhashable type: 'list'`. Please give an example for using multiple roots, and also explain what does `rootlevel=` set?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/128
https://github.com/scverse/scanpy/issues/128:266,reliability,doe,does,266,"Set multiple roots in tree layout; Setting one root works well:. `sc.pl.paga(adata, layout='eq_tree', root=[9])`. Setting multiple roots returns an error: . `TypeError: unhashable type: 'list'`. Please give an example for using multiple roots, and also explain what does `rootlevel=` set?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/128
https://github.com/scverse/scanpy/issues/128:148,safety,error,error,148,"Set multiple roots in tree layout; Setting one root works well:. `sc.pl.paga(adata, layout='eq_tree', root=[9])`. Setting multiple roots returns an error: . `TypeError: unhashable type: 'list'`. Please give an example for using multiple roots, and also explain what does `rootlevel=` set?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/128
https://github.com/scverse/scanpy/issues/128:148,usability,error,error,148,"Set multiple roots in tree layout; Setting one root works well:. `sc.pl.paga(adata, layout='eq_tree', root=[9])`. Setting multiple roots returns an error: . `TypeError: unhashable type: 'list'`. Please give an example for using multiple roots, and also explain what does `rootlevel=` set?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/128
https://github.com/scverse/scanpy/issues/129:10,availability,error,error,10,"sc.pl.dpt error if n_branchings=0 in sc.tl.dpt; tl.dpt with no branching events works:. ```. sc.tl.dpt(adata, n_branchings=0, n_dcs=10, min_group_size=0.01, allow_kendall_tau_shift=True). yields. performing Diffusion Pseudotime analysis. initialized `.distances` `.connectivities` `.eigen_values` `.eigen_basis` `.distances_dpt`. eigenvalues of transition matrix. [1. 0.87799305 0.74851424 0.7235198 0.5982796 0.5652917. 0.45321003 0.35327435 0.33786523 0.29598442]. finished (0:01:09.57) --> added. 'dpt_pseudotime', the pseudotime (adata.obs). ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:595,availability,error,error,595,"sc.pl.dpt error if n_branchings=0 in sc.tl.dpt; tl.dpt with no branching events works:. ```. sc.tl.dpt(adata, n_branchings=0, n_dcs=10, min_group_size=0.01, allow_kendall_tau_shift=True). yields. performing Diffusion Pseudotime analysis. initialized `.distances` `.connectivities` `.eigen_values` `.eigen_basis` `.distances_dpt`. eigenvalues of transition matrix. [1. 0.87799305 0.74851424 0.7235198 0.5982796 0.5652917. 0.45321003 0.35327435 0.33786523 0.29598442]. finished (0:01:09.57) --> added. 'dpt_pseudotime', the pseudotime (adata.obs). ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:936,availability,toler,tolerance,936,"sc.pl.dpt error if n_branchings=0 in sc.tl.dpt; tl.dpt with no branching events works:. ```. sc.tl.dpt(adata, n_branchings=0, n_dcs=10, min_group_size=0.01, allow_kendall_tau_shift=True). yields. performing Diffusion Pseudotime analysis. initialized `.distances` `.connectivities` `.eigen_values` `.eigen_basis` `.distances_dpt`. eigenvalues of transition matrix. [1. 0.87799305 0.74851424 0.7235198 0.5982796 0.5652917. 0.45321003 0.35327435 0.33786523 0.29598442]. finished (0:01:09.57) --> added. 'dpt_pseudotime', the pseudotime (adata.obs). ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:3071,availability,toler,tolerance,3071,"78 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item). 1840 res = cache.get(item). 1841 if res is None:. -> 1842 values = self._data.get(item). 1843 res = self._box_item_values(item, values). 1844 cache[item] = res. /usr/local/lib/python3.6/site-packages/pandas/core/internals.py in get(self, item, fastpath). 3841 . 3842 if not isna(item):. -> 3843 loc = self.items.get_loc(item). 3844 else:. 3845 indexer = np.arange(len(self.items))[isna(self.items)]. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. ```. ---. scanpy==1.0.4+11.gc241098 anndata==0.5.10 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 python-igraph==0.7.1 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:3274,availability,toler,tolerance,3274,"78 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item). 1840 res = cache.get(item). 1841 if res is None:. -> 1842 values = self._data.get(item). 1843 res = self._box_item_values(item, values). 1844 cache[item] = res. /usr/local/lib/python3.6/site-packages/pandas/core/internals.py in get(self, item, fastpath). 3841 . 3842 if not isna(item):. -> 3843 loc = self.items.get_loc(item). 3844 else:. 3845 indexer = np.arange(len(self.items))[isna(self.items)]. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. ```. ---. scanpy==1.0.4+11.gc241098 anndata==0.5.10 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 python-igraph==0.7.1 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:3284,availability,toler,tolerance,3284,"78 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item). 1840 res = cache.get(item). 1841 if res is None:. -> 1842 values = self._data.get(item). 1843 res = self._box_item_values(item, values). 1844 cache[item] = res. /usr/local/lib/python3.6/site-packages/pandas/core/internals.py in get(self, item, fastpath). 3841 . 3842 if not isna(item):. -> 3843 loc = self.items.get_loc(item). 3844 else:. 3845 indexer = np.arange(len(self.items))[isna(self.items)]. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. ```. ---. scanpy==1.0.4+11.gc241098 anndata==0.5.10 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 python-igraph==0.7.1 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:1526,deployability,modul,module,1526,"ime (adata.obs). ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/cor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:885,energy efficiency,core,core,885,"sc.pl.dpt error if n_branchings=0 in sc.tl.dpt; tl.dpt with no branching events works:. ```. sc.tl.dpt(adata, n_branchings=0, n_dcs=10, min_group_size=0.01, allow_kendall_tau_shift=True). yields. performing Diffusion Pseudotime analysis. initialized `.distances` `.connectivities` `.eigen_values` `.eigen_basis` `.distances_dpt`. eigenvalues of transition matrix. [1. 0.87799305 0.74851424 0.7235198 0.5982796 0.5652917. 0.45321003 0.35327435 0.33786523 0.29598442]. finished (0:01:09.57) --> added. 'dpt_pseudotime', the pseudotime (adata.obs). ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:2046,energy efficiency,core,core,2046,"n pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item). 1840 res = cache.get(item). 1841 if res is None:. -> 1842 values = self._data.get(item). 1843 res = self._box_item_values(item, values). 1844 cache[item] = res. /usr/local/lib/python3.6/site-packages/pandas/core/internals.py in get(self, item, fastpath). 3841 . 3842 if not isna(item):. -> 3843 loc = self.items.get_loc(item). 3844 else:. 3845 indexer = np.arange(len(self.items))[isna(self.items)]. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:2275,energy efficiency,core,core,2275,"e_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item). 1840 res = cache.get(item). 1841 if res is None:. -> 1842 values = self._data.get(item). 1843 res = self._box_item_values(item, values). 1844 cache[item] = res. /usr/local/lib/python3.6/site-packages/pandas/core/internals.py in get(self, item, fastpath). 3841 . 3842 if not isna(item):. -> 3843 loc = self.items.get_loc(item). 3844 else:. 3845 indexer = np.arange(len(self.items))[isna(self.items)]. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tol",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:2457,energy efficiency,reduc,reduce,2457,"ack (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item). 1840 res = cache.get(item). 1841 if res is None:. -> 1842 values = self._data.get(item). 1843 res = self._box_item_values(item, values). 1844 cache[item] = res. /usr/local/lib/python3.6/site-packages/pandas/core/internals.py in get(self, item, fastpath). 3841 . 3842 if not isna(item):. -> 3843 loc = self.items.get_loc(item). 3844 else:. 3845 indexer = np.arange(len(self.items))[isna(self.items)]. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:2526,energy efficiency,core,core,2526,"dule>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item). 1840 res = cache.get(item). 1841 if res is None:. -> 1842 values = self._data.get(item). 1843 res = self._box_item_values(item, values). 1844 cache[item] = res. /usr/local/lib/python3.6/site-packages/pandas/core/internals.py in get(self, item, fastpath). 3841 . 3842 if not isna(item):. -> 3843 loc = self.items.get_loc(item). 3844 else:. 3845 indexer = np.arange(len(self.items))[isna(self.items)]. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:2781,energy efficiency,core,core,2781,"size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item). 1840 res = cache.get(item). 1841 if res is None:. -> 1842 values = self._data.get(item). 1843 res = self._box_item_values(item, values). 1844 cache[item] = res. /usr/local/lib/python3.6/site-packages/pandas/core/internals.py in get(self, item, fastpath). 3841 . 3842 if not isna(item):. -> 3843 loc = self.items.get_loc(item). 3844 else:. 3845 indexer = np.arange(len(self.items))[isna(self.items)]. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. ```. ---. scanpy==1.0.4+11.gc241098 anndata==0.5.10 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:3020,energy efficiency,core,core,3020,"78 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item). 1840 res = cache.get(item). 1841 if res is None:. -> 1842 values = self._data.get(item). 1843 res = self._box_item_values(item, values). 1844 cache[item] = res. /usr/local/lib/python3.6/site-packages/pandas/core/internals.py in get(self, item, fastpath). 3841 . 3842 if not isna(item):. -> 3843 loc = self.items.get_loc(item). 3844 else:. 3845 indexer = np.arange(len(self.items))[isna(self.items)]. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. ```. ---. scanpy==1.0.4+11.gc241098 anndata==0.5.10 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 python-igraph==0.7.1 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:73,integrability,event,events,73,"sc.pl.dpt error if n_branchings=0 in sc.tl.dpt; tl.dpt with no branching events works:. ```. sc.tl.dpt(adata, n_branchings=0, n_dcs=10, min_group_size=0.01, allow_kendall_tau_shift=True). yields. performing Diffusion Pseudotime analysis. initialized `.distances` `.connectivities` `.eigen_values` `.eigen_basis` `.distances_dpt`. eigenvalues of transition matrix. [1. 0.87799305 0.74851424 0.7235198 0.5982796 0.5652917. 0.45321003 0.35327435 0.33786523 0.29598442]. finished (0:01:09.57) --> added. 'dpt_pseudotime', the pseudotime (adata.obs). ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:1677,integrability,compon,components,1677,"n adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item). 1840 res = cache.get(item). 1841 if res is None:. -> 1842 values = self._data.get(item). 1843 res = self._bo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:1677,interoperability,compon,components,1677,"n adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item). 1840 res = cache.get(item). 1841 if res is None:. -> 1842 values = self._data.get(item). 1843 res = self._bo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:869,modifiability,pac,packages,869,"sc.pl.dpt error if n_branchings=0 in sc.tl.dpt; tl.dpt with no branching events works:. ```. sc.tl.dpt(adata, n_branchings=0, n_dcs=10, min_group_size=0.01, allow_kendall_tau_shift=True). yields. performing Diffusion Pseudotime analysis. initialized `.distances` `.connectivities` `.eigen_values` `.eigen_basis` `.distances_dpt`. eigenvalues of transition matrix. [1. 0.87799305 0.74851424 0.7235198 0.5982796 0.5652917. 0.45321003 0.35327435 0.33786523 0.29598442]. finished (0:01:09.57) --> added. 'dpt_pseudotime', the pseudotime (adata.obs). ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:1526,modifiability,modul,module,1526,"ime (adata.obs). ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/cor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:1677,modifiability,compon,components,1677,"n adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item). 1840 res = cache.get(item). 1841 if res is None:. -> 1842 values = self._data.get(item). 1843 res = self._bo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:2030,modifiability,pac,packages,2030,"bs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item). 1840 res = cache.get(item). 1841 if res is None:. -> 1842 values = self._data.get(item). 1843 res = self._box_item_values(item, values). 1844 cache[item] = res. /usr/local/lib/python3.6/site-packages/pandas/core/internals.py in get(self, item, fastpath). 3841 . 3842 if not isna(item):. -> 3843 loc = self.items.get_loc(item). 3844 else:. 3845 indexer = np.arange(len(self.items))[isna(self.items)]. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:2259,modifiability,pac,packages,2259,"_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item). 1840 res = cache.get(item). 1841 if res is None:. -> 1842 values = self._data.get(item). 1843 res = self._box_item_values(item, values). 1844 cache[item] = res. /usr/local/lib/python3.6/site-packages/pandas/core/internals.py in get(self, item, fastpath). 3841 . 3842 if not isna(item):. -> 3843 loc = self.items.get_loc(item). 3844 else:. 3845 indexer = np.arange(len(self.items))[isna(self.items)]. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], meth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:2510,modifiability,pac,packages,2510,"859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item). 1840 res = cache.get(item). 1841 if res is None:. -> 1842 values = self._data.get(item). 1843 res = self._box_item_values(item, values). 1844 cache[item] = res. /usr/local/lib/python3.6/site-packages/pandas/core/internals.py in get(self, item, fastpath). 3841 . 3842 if not isna(item):. -> 3843 loc = self.items.get_loc(item). 3844 else:. 3845 indexer = np.arange(len(self.items))[isna(self.items)]. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTabl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:2765,modifiability,pac,packages,2765,"right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item). 1840 res = cache.get(item). 1841 if res is None:. -> 1842 values = self._data.get(item). 1843 res = self._box_item_values(item, values). 1844 cache[item] = res. /usr/local/lib/python3.6/site-packages/pandas/core/internals.py in get(self, item, fastpath). 3841 . 3842 if not isna(item):. -> 3843 loc = self.items.get_loc(item). 3844 else:. 3845 indexer = np.arange(len(self.items))[isna(self.items)]. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. ```. ---. scanpy==1.0.4+11.gc241098 anndata==0.5.10 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:3004,modifiability,pac,packages,3004,"78 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item). 1840 res = cache.get(item). 1841 if res is None:. -> 1842 values = self._data.get(item). 1843 res = self._box_item_values(item, values). 1844 cache[item] = res. /usr/local/lib/python3.6/site-packages/pandas/core/internals.py in get(self, item, fastpath). 3841 . 3842 if not isna(item):. -> 3843 loc = self.items.get_loc(item). 3844 else:. 3845 indexer = np.arange(len(self.items))[isna(self.items)]. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. ```. ---. scanpy==1.0.4+11.gc241098 anndata==0.5.10 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 python-igraph==0.7.1 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:10,performance,error,error,10,"sc.pl.dpt error if n_branchings=0 in sc.tl.dpt; tl.dpt with no branching events works:. ```. sc.tl.dpt(adata, n_branchings=0, n_dcs=10, min_group_size=0.01, allow_kendall_tau_shift=True). yields. performing Diffusion Pseudotime analysis. initialized `.distances` `.connectivities` `.eigen_values` `.eigen_basis` `.distances_dpt`. eigenvalues of transition matrix. [1. 0.87799305 0.74851424 0.7235198 0.5982796 0.5652917. 0.45321003 0.35327435 0.33786523 0.29598442]. finished (0:01:09.57) --> added. 'dpt_pseudotime', the pseudotime (adata.obs). ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:196,performance,perform,performing,196,"sc.pl.dpt error if n_branchings=0 in sc.tl.dpt; tl.dpt with no branching events works:. ```. sc.tl.dpt(adata, n_branchings=0, n_dcs=10, min_group_size=0.01, allow_kendall_tau_shift=True). yields. performing Diffusion Pseudotime analysis. initialized `.distances` `.connectivities` `.eigen_values` `.eigen_basis` `.distances_dpt`. eigenvalues of transition matrix. [1. 0.87799305 0.74851424 0.7235198 0.5982796 0.5652917. 0.45321003 0.35327435 0.33786523 0.29598442]. finished (0:01:09.57) --> added. 'dpt_pseudotime', the pseudotime (adata.obs). ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:595,performance,error,error,595,"sc.pl.dpt error if n_branchings=0 in sc.tl.dpt; tl.dpt with no branching events works:. ```. sc.tl.dpt(adata, n_branchings=0, n_dcs=10, min_group_size=0.01, allow_kendall_tau_shift=True). yields. performing Diffusion Pseudotime analysis. initialized `.distances` `.connectivities` `.eigen_values` `.eigen_basis` `.distances_dpt`. eigenvalues of transition matrix. [1. 0.87799305 0.74851424 0.7235198 0.5982796 0.5652917. 0.45321003 0.35327435 0.33786523 0.29598442]. finished (0:01:09.57) --> added. 'dpt_pseudotime', the pseudotime (adata.obs). ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:2585,performance,cach,cache,2585,"ment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item). 1840 res = cache.get(item). 1841 if res is None:. -> 1842 values = self._data.get(item). 1843 res = self._box_item_values(item, values). 1844 cache[item] = res. /usr/local/lib/python3.6/site-packages/pandas/core/internals.py in get(self, item, fastpath). 3841 . 3842 if not isna(item):. -> 3843 loc = self.items.get_loc(item). 3844 else:. 3845 indexer = np.arange(len(self.items))[isna(self.items)]. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hash",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:2716,performance,cach,cache,2716,"_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item). 1840 res = cache.get(item). 1841 if res is None:. -> 1842 values = self._data.get(item). 1843 res = self._box_item_values(item, values). 1844 cache[item] = res. /usr/local/lib/python3.6/site-packages/pandas/core/internals.py in get(self, item, fastpath). 3841 . 3842 if not isna(item):. -> 3843 loc = self.items.get_loc(item). 3844 else:. 3845 indexer = np.arange(len(self.items))[isna(self.items)]. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. ```. ---. scanpy==1.0.4+11.gc241098 anndata==0.5.10 numpy==1.14.2 scipy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:936,reliability,toleran,tolerance,936,"sc.pl.dpt error if n_branchings=0 in sc.tl.dpt; tl.dpt with no branching events works:. ```. sc.tl.dpt(adata, n_branchings=0, n_dcs=10, min_group_size=0.01, allow_kendall_tau_shift=True). yields. performing Diffusion Pseudotime analysis. initialized `.distances` `.connectivities` `.eigen_values` `.eigen_basis` `.distances_dpt`. eigenvalues of transition matrix. [1. 0.87799305 0.74851424 0.7235198 0.5982796 0.5652917. 0.45321003 0.35327435 0.33786523 0.29598442]. finished (0:01:09.57) --> added. 'dpt_pseudotime', the pseudotime (adata.obs). ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:3071,reliability,toleran,tolerance,3071,"78 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item). 1840 res = cache.get(item). 1841 if res is None:. -> 1842 values = self._data.get(item). 1843 res = self._box_item_values(item, values). 1844 cache[item] = res. /usr/local/lib/python3.6/site-packages/pandas/core/internals.py in get(self, item, fastpath). 3841 . 3842 if not isna(item):. -> 3843 loc = self.items.get_loc(item). 3844 else:. 3845 indexer = np.arange(len(self.items))[isna(self.items)]. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. ```. ---. scanpy==1.0.4+11.gc241098 anndata==0.5.10 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 python-igraph==0.7.1 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:3274,reliability,toleran,tolerance,3274,"78 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item). 1840 res = cache.get(item). 1841 if res is None:. -> 1842 values = self._data.get(item). 1843 res = self._box_item_values(item, values). 1844 cache[item] = res. /usr/local/lib/python3.6/site-packages/pandas/core/internals.py in get(self, item, fastpath). 3841 . 3842 if not isna(item):. -> 3843 loc = self.items.get_loc(item). 3844 else:. 3845 indexer = np.arange(len(self.items))[isna(self.items)]. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. ```. ---. scanpy==1.0.4+11.gc241098 anndata==0.5.10 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 python-igraph==0.7.1 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:3284,reliability,toleran,tolerance,3284,"78 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item). 1840 res = cache.get(item). 1841 if res is None:. -> 1842 values = self._data.get(item). 1843 res = self._box_item_values(item, values). 1844 cache[item] = res. /usr/local/lib/python3.6/site-packages/pandas/core/internals.py in get(self, item, fastpath). 3841 . 3842 if not isna(item):. -> 3843 loc = self.items.get_loc(item). 3844 else:. 3845 indexer = np.arange(len(self.items))[isna(self.items)]. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. ```. ---. scanpy==1.0.4+11.gc241098 anndata==0.5.10 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 python-igraph==0.7.1 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:10,safety,error,error,10,"sc.pl.dpt error if n_branchings=0 in sc.tl.dpt; tl.dpt with no branching events works:. ```. sc.tl.dpt(adata, n_branchings=0, n_dcs=10, min_group_size=0.01, allow_kendall_tau_shift=True). yields. performing Diffusion Pseudotime analysis. initialized `.distances` `.connectivities` `.eigen_values` `.eigen_basis` `.distances_dpt`. eigenvalues of transition matrix. [1. 0.87799305 0.74851424 0.7235198 0.5982796 0.5652917. 0.45321003 0.35327435 0.33786523 0.29598442]. finished (0:01:09.57) --> added. 'dpt_pseudotime', the pseudotime (adata.obs). ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:595,safety,error,error,595,"sc.pl.dpt error if n_branchings=0 in sc.tl.dpt; tl.dpt with no branching events works:. ```. sc.tl.dpt(adata, n_branchings=0, n_dcs=10, min_group_size=0.01, allow_kendall_tau_shift=True). yields. performing Diffusion Pseudotime analysis. initialized `.distances` `.connectivities` `.eigen_values` `.eigen_basis` `.distances_dpt`. eigenvalues of transition matrix. [1. 0.87799305 0.74851424 0.7235198 0.5982796 0.5652917. 0.45321003 0.35327435 0.33786523 0.29598442]. finished (0:01:09.57) --> added. 'dpt_pseudotime', the pseudotime (adata.obs). ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:1006,safety,except,except,1006," error if n_branchings=0 in sc.tl.dpt; tl.dpt with no branching events works:. ```. sc.tl.dpt(adata, n_branchings=0, n_dcs=10, min_group_size=0.01, allow_kendall_tau_shift=True). yields. performing Diffusion Pseudotime analysis. initialized `.distances` `.connectivities` `.eigen_values` `.eigen_basis` `.distances_dpt`. eigenvalues of transition matrix. [1. 0.87799305 0.74851424 0.7235198 0.5982796 0.5652917. 0.45321003 0.35327435 0.33786523 0.29598442]. finished (0:01:09.57) --> added. 'dpt_pseudotime', the pseudotime (adata.obs). ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/loca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:1405,safety,except,exception,1405,"0.5652917. 0.45321003 0.35327435 0.33786523 0.29598442]. finished (0:01:09.57) --> added. 'dpt_pseudotime', the pseudotime (adata.obs). ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(ke",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:1424,safety,except,exception,1424,"03 0.35327435 0.33786523 0.29598442]. finished (0:01:09.57) --> added. 'dpt_pseudotime', the pseudotime (adata.obs). ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:1498,safety,input,input-,1498,"dpt_pseudotime', the pseudotime (adata.obs). ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:1526,safety,modul,module,1526,"ime (adata.obs). ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/cor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:3127,safety,except,except,3127,"78 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item). 1840 res = cache.get(item). 1841 if res is None:. -> 1842 values = self._data.get(item). 1843 res = self._box_item_values(item, values). 1844 cache[item] = res. /usr/local/lib/python3.6/site-packages/pandas/core/internals.py in get(self, item, fastpath). 3841 . 3842 if not isna(item):. -> 3843 loc = self.items.get_loc(item). 3844 else:. 3845 indexer = np.arange(len(self.items))[isna(self.items)]. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. ```. ---. scanpy==1.0.4+11.gc241098 anndata==0.5.10 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 python-igraph==0.7.1 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:1216,security,hash,hashtable,1216,"dotime analysis. initialized `.distances` `.connectivities` `.eigen_values` `.eigen_basis` `.distances_dpt`. eigenvalues of transition matrix. [1. 0.87799305 0.74851424 0.7235198 0.5982796 0.5652917. 0.45321003 0.35327435 0.33786523 0.29598442]. finished (0:01:09.57) --> added. 'dpt_pseudotime', the pseudotime (adata.obs). ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:1312,security,hash,hashtable,1312,"tances_dpt`. eigenvalues of transition matrix. [1. 0.87799305 0.74851424 0.7235198 0.5982796 0.5652917. 0.45321003 0.35327435 0.33786523 0.29598442]. finished (0:01:09.57) --> added. 'dpt_pseudotime', the pseudotime (adata.obs). ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:3488,security,hash,hashtable,3488,"78 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item). 1840 res = cache.get(item). 1841 if res is None:. -> 1842 values = self._data.get(item). 1843 res = self._box_item_values(item, values). 1844 cache[item] = res. /usr/local/lib/python3.6/site-packages/pandas/core/internals.py in get(self, item, fastpath). 3841 . 3842 if not isna(item):. -> 3843 loc = self.items.get_loc(item). 3844 else:. 3845 indexer = np.arange(len(self.items))[isna(self.items)]. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. ```. ---. scanpy==1.0.4+11.gc241098 anndata==0.5.10 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 python-igraph==0.7.1 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:3584,security,hash,hashtable,3584,"78 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item). 1840 res = cache.get(item). 1841 if res is None:. -> 1842 values = self._data.get(item). 1843 res = self._box_item_values(item, values). 1844 cache[item] = res. /usr/local/lib/python3.6/site-packages/pandas/core/internals.py in get(self, item, fastpath). 3841 . 3842 if not isna(item):. -> 3843 loc = self.items.get_loc(item). 3844 else:. 3845 indexer = np.arange(len(self.items))[isna(self.items)]. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. ```. ---. scanpy==1.0.4+11.gc241098 anndata==0.5.10 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 python-igraph==0.7.1 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:804,testability,Trace,Traceback,804,"sc.pl.dpt error if n_branchings=0 in sc.tl.dpt; tl.dpt with no branching events works:. ```. sc.tl.dpt(adata, n_branchings=0, n_dcs=10, min_group_size=0.01, allow_kendall_tau_shift=True). yields. performing Diffusion Pseudotime analysis. initialized `.distances` `.connectivities` `.eigen_values` `.eigen_basis` `.distances_dpt`. eigenvalues of transition matrix. [1. 0.87799305 0.74851424 0.7235198 0.5982796 0.5652917. 0.45321003 0.35327435 0.33786523 0.29598442]. finished (0:01:09.57) --> added. 'dpt_pseudotime', the pseudotime (adata.obs). ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:1454,testability,Trace,Traceback,1454,"98442]. finished (0:01:09.57) --> added. 'dpt_pseudotime', the pseudotime (adata.obs). ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:10,usability,error,error,10,"sc.pl.dpt error if n_branchings=0 in sc.tl.dpt; tl.dpt with no branching events works:. ```. sc.tl.dpt(adata, n_branchings=0, n_dcs=10, min_group_size=0.01, allow_kendall_tau_shift=True). yields. performing Diffusion Pseudotime analysis. initialized `.distances` `.connectivities` `.eigen_values` `.eigen_basis` `.distances_dpt`. eigenvalues of transition matrix. [1. 0.87799305 0.74851424 0.7235198 0.5982796 0.5652917. 0.45321003 0.35327435 0.33786523 0.29598442]. finished (0:01:09.57) --> added. 'dpt_pseudotime', the pseudotime (adata.obs). ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:196,usability,perform,performing,196,"sc.pl.dpt error if n_branchings=0 in sc.tl.dpt; tl.dpt with no branching events works:. ```. sc.tl.dpt(adata, n_branchings=0, n_dcs=10, min_group_size=0.01, allow_kendall_tau_shift=True). yields. performing Diffusion Pseudotime analysis. initialized `.distances` `.connectivities` `.eigen_values` `.eigen_basis` `.distances_dpt`. eigenvalues of transition matrix. [1. 0.87799305 0.74851424 0.7235198 0.5982796 0.5652917. 0.45321003 0.35327435 0.33786523 0.29598442]. finished (0:01:09.57) --> added. 'dpt_pseudotime', the pseudotime (adata.obs). ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:595,usability,error,error,595,"sc.pl.dpt error if n_branchings=0 in sc.tl.dpt; tl.dpt with no branching events works:. ```. sc.tl.dpt(adata, n_branchings=0, n_dcs=10, min_group_size=0.01, allow_kendall_tau_shift=True). yields. performing Diffusion Pseudotime analysis. initialized `.distances` `.connectivities` `.eigen_values` `.eigen_basis` `.distances_dpt`. eigenvalues of transition matrix. [1. 0.87799305 0.74851424 0.7235198 0.5982796 0.5652917. 0.45321003 0.35327435 0.33786523 0.29598442]. finished (0:01:09.57) --> added. 'dpt_pseudotime', the pseudotime (adata.obs). ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:1498,usability,input,input-,1498,"dpt_pseudotime', the pseudotime (adata.obs). ```. But calling pl.dpt on this object yields an error, looking at the above outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:1616,usability,tool,tools,1616,"ove outout of tl.dpt it seems that dpt_groups was not created in adata.obs if n_branchings=0? ```. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2524 try:. -> 2525 return self._engine.get_loc(key). 2526 except KeyError:. pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. During handling of the above exception, another exception occurred:. KeyError Traceback (most recent call last). <ipython-input-102-eb7d1d859c99> in <module>(). ----> 1 sc.pl.dpt(adata, groups=None). ~/gitDevelopment/scanpy/scanpy/plotting/tools/__init__.py in dpt(adata, basis, color, alpha, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, size, title, show, save). 677 """""". 678 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item). 1840 res = cache.get(item). 1841 if res is No",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/issues/129:3749,usability,learn,learn,3749,"78 colors = ['dpt_pseudotime']. --> 679 if len(np.unique(adata.obs['dpt_groups'].values)) > 1: colors += ['dpt_groups']. 680 if color is not None: colors = color. 681 dpt_scatter(. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in __getitem__(self, key). 2137 return self._getitem_multilevel(key). 2138 else:. -> 2139 return self._getitem_column(key). 2140 . 2141 def _getitem_column(self, key):. /usr/local/lib/python3.6/site-packages/pandas/core/frame.py in _getitem_column(self, key). 2144 # get column. 2145 if self.columns.is_unique:. -> 2146 return self._get_item_cache(key). 2147 . 2148 # duplicate columns & possible reduce dimensionality. /usr/local/lib/python3.6/site-packages/pandas/core/generic.py in _get_item_cache(self, item). 1840 res = cache.get(item). 1841 if res is None:. -> 1842 values = self._data.get(item). 1843 res = self._box_item_values(item, values). 1844 cache[item] = res. /usr/local/lib/python3.6/site-packages/pandas/core/internals.py in get(self, item, fastpath). 3841 . 3842 if not isna(item):. -> 3843 loc = self.items.get_loc(item). 3844 else:. 3845 indexer = np.arange(len(self.items))[isna(self.items)]. /usr/local/lib/python3.6/site-packages/pandas/core/indexes/base.py in get_loc(self, key, method, tolerance). 2525 return self._engine.get_loc(key). 2526 except KeyError:. -> 2527 return self._engine.get_loc(self._maybe_cast_indexer(key)). 2528 . 2529 indexer = self.get_indexer([key], method=method, tolerance=tolerance). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/index.pyx in pandas._libs.index.IndexEngine.get_loc(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.PyObjectHashTable.get_item(). KeyError: 'dpt_groups'. ```. ---. scanpy==1.0.4+11.gc241098 anndata==0.5.10 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 python-igraph==0.7.1 louvain==0.6.1 .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/129
https://github.com/scverse/scanpy/pull/131:6,integrability,wrap,wrapper,6,Added wrapper for mnnpy; Added wrapper for mnnpy in pp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/131
https://github.com/scverse/scanpy/pull/131:31,integrability,wrap,wrapper,31,Added wrapper for mnnpy; Added wrapper for mnnpy in pp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/131
https://github.com/scverse/scanpy/pull/131:6,interoperability,wrapper,wrapper,6,Added wrapper for mnnpy; Added wrapper for mnnpy in pp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/131
https://github.com/scverse/scanpy/pull/131:31,interoperability,wrapper,wrapper,31,Added wrapper for mnnpy; Added wrapper for mnnpy in pp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/131
https://github.com/scverse/scanpy/issues/132:12,availability,error,errors,12,"read_10x_h5 errors; Hi, . I can't manage to use the scanpy read_10x_h5 errors as it raises an exception for the genome I want to use : . `Exception: Genome GRCm38 does not exist in this file.`. But I'm sure it's this genome string in my file. . Reading the same file with . `mol_info = sc.read_hdf(""./molecule_info.h5"", key=""genome_ids"" )`. I obtain this error : `ValueError: could not convert string to float: 'GRCm38'`. Do you have any hint oin how to have it working ??? Thanks a lot !!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/132
https://github.com/scverse/scanpy/issues/132:71,availability,error,errors,71,"read_10x_h5 errors; Hi, . I can't manage to use the scanpy read_10x_h5 errors as it raises an exception for the genome I want to use : . `Exception: Genome GRCm38 does not exist in this file.`. But I'm sure it's this genome string in my file. . Reading the same file with . `mol_info = sc.read_hdf(""./molecule_info.h5"", key=""genome_ids"" )`. I obtain this error : `ValueError: could not convert string to float: 'GRCm38'`. Do you have any hint oin how to have it working ??? Thanks a lot !!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/132
https://github.com/scverse/scanpy/issues/132:355,availability,error,error,355,"read_10x_h5 errors; Hi, . I can't manage to use the scanpy read_10x_h5 errors as it raises an exception for the genome I want to use : . `Exception: Genome GRCm38 does not exist in this file.`. But I'm sure it's this genome string in my file. . Reading the same file with . `mol_info = sc.read_hdf(""./molecule_info.h5"", key=""genome_ids"" )`. I obtain this error : `ValueError: could not convert string to float: 'GRCm38'`. Do you have any hint oin how to have it working ??? Thanks a lot !!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/132
https://github.com/scverse/scanpy/issues/132:34,deployability,manag,manage,34,"read_10x_h5 errors; Hi, . I can't manage to use the scanpy read_10x_h5 errors as it raises an exception for the genome I want to use : . `Exception: Genome GRCm38 does not exist in this file.`. But I'm sure it's this genome string in my file. . Reading the same file with . `mol_info = sc.read_hdf(""./molecule_info.h5"", key=""genome_ids"" )`. I obtain this error : `ValueError: could not convert string to float: 'GRCm38'`. Do you have any hint oin how to have it working ??? Thanks a lot !!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/132
https://github.com/scverse/scanpy/issues/132:34,energy efficiency,manag,manage,34,"read_10x_h5 errors; Hi, . I can't manage to use the scanpy read_10x_h5 errors as it raises an exception for the genome I want to use : . `Exception: Genome GRCm38 does not exist in this file.`. But I'm sure it's this genome string in my file. . Reading the same file with . `mol_info = sc.read_hdf(""./molecule_info.h5"", key=""genome_ids"" )`. I obtain this error : `ValueError: could not convert string to float: 'GRCm38'`. Do you have any hint oin how to have it working ??? Thanks a lot !!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/132
https://github.com/scverse/scanpy/issues/132:12,performance,error,errors,12,"read_10x_h5 errors; Hi, . I can't manage to use the scanpy read_10x_h5 errors as it raises an exception for the genome I want to use : . `Exception: Genome GRCm38 does not exist in this file.`. But I'm sure it's this genome string in my file. . Reading the same file with . `mol_info = sc.read_hdf(""./molecule_info.h5"", key=""genome_ids"" )`. I obtain this error : `ValueError: could not convert string to float: 'GRCm38'`. Do you have any hint oin how to have it working ??? Thanks a lot !!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/132
https://github.com/scverse/scanpy/issues/132:71,performance,error,errors,71,"read_10x_h5 errors; Hi, . I can't manage to use the scanpy read_10x_h5 errors as it raises an exception for the genome I want to use : . `Exception: Genome GRCm38 does not exist in this file.`. But I'm sure it's this genome string in my file. . Reading the same file with . `mol_info = sc.read_hdf(""./molecule_info.h5"", key=""genome_ids"" )`. I obtain this error : `ValueError: could not convert string to float: 'GRCm38'`. Do you have any hint oin how to have it working ??? Thanks a lot !!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/132
https://github.com/scverse/scanpy/issues/132:355,performance,error,error,355,"read_10x_h5 errors; Hi, . I can't manage to use the scanpy read_10x_h5 errors as it raises an exception for the genome I want to use : . `Exception: Genome GRCm38 does not exist in this file.`. But I'm sure it's this genome string in my file. . Reading the same file with . `mol_info = sc.read_hdf(""./molecule_info.h5"", key=""genome_ids"" )`. I obtain this error : `ValueError: could not convert string to float: 'GRCm38'`. Do you have any hint oin how to have it working ??? Thanks a lot !!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/132
https://github.com/scverse/scanpy/issues/132:163,reliability,doe,does,163,"read_10x_h5 errors; Hi, . I can't manage to use the scanpy read_10x_h5 errors as it raises an exception for the genome I want to use : . `Exception: Genome GRCm38 does not exist in this file.`. But I'm sure it's this genome string in my file. . Reading the same file with . `mol_info = sc.read_hdf(""./molecule_info.h5"", key=""genome_ids"" )`. I obtain this error : `ValueError: could not convert string to float: 'GRCm38'`. Do you have any hint oin how to have it working ??? Thanks a lot !!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/132
https://github.com/scverse/scanpy/issues/132:12,safety,error,errors,12,"read_10x_h5 errors; Hi, . I can't manage to use the scanpy read_10x_h5 errors as it raises an exception for the genome I want to use : . `Exception: Genome GRCm38 does not exist in this file.`. But I'm sure it's this genome string in my file. . Reading the same file with . `mol_info = sc.read_hdf(""./molecule_info.h5"", key=""genome_ids"" )`. I obtain this error : `ValueError: could not convert string to float: 'GRCm38'`. Do you have any hint oin how to have it working ??? Thanks a lot !!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/132
https://github.com/scverse/scanpy/issues/132:34,safety,manag,manage,34,"read_10x_h5 errors; Hi, . I can't manage to use the scanpy read_10x_h5 errors as it raises an exception for the genome I want to use : . `Exception: Genome GRCm38 does not exist in this file.`. But I'm sure it's this genome string in my file. . Reading the same file with . `mol_info = sc.read_hdf(""./molecule_info.h5"", key=""genome_ids"" )`. I obtain this error : `ValueError: could not convert string to float: 'GRCm38'`. Do you have any hint oin how to have it working ??? Thanks a lot !!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/132
https://github.com/scverse/scanpy/issues/132:71,safety,error,errors,71,"read_10x_h5 errors; Hi, . I can't manage to use the scanpy read_10x_h5 errors as it raises an exception for the genome I want to use : . `Exception: Genome GRCm38 does not exist in this file.`. But I'm sure it's this genome string in my file. . Reading the same file with . `mol_info = sc.read_hdf(""./molecule_info.h5"", key=""genome_ids"" )`. I obtain this error : `ValueError: could not convert string to float: 'GRCm38'`. Do you have any hint oin how to have it working ??? Thanks a lot !!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/132
https://github.com/scverse/scanpy/issues/132:94,safety,except,exception,94,"read_10x_h5 errors; Hi, . I can't manage to use the scanpy read_10x_h5 errors as it raises an exception for the genome I want to use : . `Exception: Genome GRCm38 does not exist in this file.`. But I'm sure it's this genome string in my file. . Reading the same file with . `mol_info = sc.read_hdf(""./molecule_info.h5"", key=""genome_ids"" )`. I obtain this error : `ValueError: could not convert string to float: 'GRCm38'`. Do you have any hint oin how to have it working ??? Thanks a lot !!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/132
https://github.com/scverse/scanpy/issues/132:138,safety,Except,Exception,138,"read_10x_h5 errors; Hi, . I can't manage to use the scanpy read_10x_h5 errors as it raises an exception for the genome I want to use : . `Exception: Genome GRCm38 does not exist in this file.`. But I'm sure it's this genome string in my file. . Reading the same file with . `mol_info = sc.read_hdf(""./molecule_info.h5"", key=""genome_ids"" )`. I obtain this error : `ValueError: could not convert string to float: 'GRCm38'`. Do you have any hint oin how to have it working ??? Thanks a lot !!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/132
https://github.com/scverse/scanpy/issues/132:355,safety,error,error,355,"read_10x_h5 errors; Hi, . I can't manage to use the scanpy read_10x_h5 errors as it raises an exception for the genome I want to use : . `Exception: Genome GRCm38 does not exist in this file.`. But I'm sure it's this genome string in my file. . Reading the same file with . `mol_info = sc.read_hdf(""./molecule_info.h5"", key=""genome_ids"" )`. I obtain this error : `ValueError: could not convert string to float: 'GRCm38'`. Do you have any hint oin how to have it working ??? Thanks a lot !!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/132
https://github.com/scverse/scanpy/issues/132:12,usability,error,errors,12,"read_10x_h5 errors; Hi, . I can't manage to use the scanpy read_10x_h5 errors as it raises an exception for the genome I want to use : . `Exception: Genome GRCm38 does not exist in this file.`. But I'm sure it's this genome string in my file. . Reading the same file with . `mol_info = sc.read_hdf(""./molecule_info.h5"", key=""genome_ids"" )`. I obtain this error : `ValueError: could not convert string to float: 'GRCm38'`. Do you have any hint oin how to have it working ??? Thanks a lot !!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/132
https://github.com/scverse/scanpy/issues/132:71,usability,error,errors,71,"read_10x_h5 errors; Hi, . I can't manage to use the scanpy read_10x_h5 errors as it raises an exception for the genome I want to use : . `Exception: Genome GRCm38 does not exist in this file.`. But I'm sure it's this genome string in my file. . Reading the same file with . `mol_info = sc.read_hdf(""./molecule_info.h5"", key=""genome_ids"" )`. I obtain this error : `ValueError: could not convert string to float: 'GRCm38'`. Do you have any hint oin how to have it working ??? Thanks a lot !!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/132
https://github.com/scverse/scanpy/issues/132:355,usability,error,error,355,"read_10x_h5 errors; Hi, . I can't manage to use the scanpy read_10x_h5 errors as it raises an exception for the genome I want to use : . `Exception: Genome GRCm38 does not exist in this file.`. But I'm sure it's this genome string in my file. . Reading the same file with . `mol_info = sc.read_hdf(""./molecule_info.h5"", key=""genome_ids"" )`. I obtain this error : `ValueError: could not convert string to float: 'GRCm38'`. Do you have any hint oin how to have it working ??? Thanks a lot !!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/132
https://github.com/scverse/scanpy/issues/132:438,usability,hint,hint,438,"read_10x_h5 errors; Hi, . I can't manage to use the scanpy read_10x_h5 errors as it raises an exception for the genome I want to use : . `Exception: Genome GRCm38 does not exist in this file.`. But I'm sure it's this genome string in my file. . Reading the same file with . `mol_info = sc.read_hdf(""./molecule_info.h5"", key=""genome_ids"" )`. I obtain this error : `ValueError: could not convert string to float: 'GRCm38'`. Do you have any hint oin how to have it working ??? Thanks a lot !!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/132
https://github.com/scverse/scanpy/issues/135:257,modifiability,paramet,parameter,257,"Systematic chunk processing; Hi @Koncopd,. please - as discussed - go ahead and implement the method `chunks(self)` for `AnnData`, returning an iterator over chunks of the data matrix `.X`. Use this to implement `pp.log1p()` and `pp.pca()` with a `chunked` parameter. Use separate branches `chunks` for both. Some data with > 100K cells, which might be too much for a laptop:. https://github.com/czi-hca-comp-tools/easy-data/blob/master/datasets/developing_mouse_retina.md. https://github.com/falexwolf/fun-analyses/blob/master/mouse_retina_dev/mouse_retina_dev.ipynb. Looking forward to working on this with you! :smile:. Alex",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/135
https://github.com/scverse/scanpy/issues/135:409,usability,tool,tools,409,"Systematic chunk processing; Hi @Koncopd,. please - as discussed - go ahead and implement the method `chunks(self)` for `AnnData`, returning an iterator over chunks of the data matrix `.X`. Use this to implement `pp.log1p()` and `pp.pca()` with a `chunked` parameter. Use separate branches `chunks` for both. Some data with > 100K cells, which might be too much for a laptop:. https://github.com/czi-hca-comp-tools/easy-data/blob/master/datasets/developing_mouse_retina.md. https://github.com/falexwolf/fun-analyses/blob/master/mouse_retina_dev/mouse_retina_dev.ipynb. Looking forward to working on this with you! :smile:. Alex",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/135
https://github.com/scverse/scanpy/pull/136:456,availability,operat,operator,456,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:10,deployability,integr,integration,10,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:51,deployability,API,APIs,51,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:659,deployability,version,version,659,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:236,energy efficiency,estimat,estimator,236,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:394,energy efficiency,power,powerful,394,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:10,integrability,integr,integration,10,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:51,integrability,API,APIs,51,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:168,integrability,interfac,interface,168,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:280,integrability,interfac,interface,280,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:509,integrability,interfac,interface,509,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:659,integrability,version,version,659,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:10,interoperability,integr,integration,10,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:51,interoperability,API,APIs,51,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:168,interoperability,interfac,interface,168,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:280,interoperability,interfac,interface,280,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:509,interoperability,interfac,interface,509,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:10,modifiability,integr,integration,10,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:168,modifiability,interfac,interface,168,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:280,modifiability,interfac,interface,280,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:421,modifiability,paramet,parameters,421,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:509,modifiability,interfac,interface,509,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:659,modifiability,version,version,659,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:10,reliability,integr,integration,10,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:10,security,integr,integration,10,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:10,testability,integr,integration,10,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:377,testability,simpl,simple,377,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:377,usability,simpl,simple,377,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/pull/136:578,usability,prefer,prefer,578,"Add PHATE integration; Hi! I've added two possible APIs for PHATE: I imagine you'll only want to include one of them. . The first, `sc.tl.PHATE`, is an object-oriented interface that matches `phate.PHATE`, which looks like an `sklearn` estimator class. The second is a functional interface which is equivalent to running `phate.PHATE().fit_transform(data)`. The second is more simple, but less powerful as any changes in parameters will require the entire operator to be recomputed, where the object-oriented interface allows partial recomputation. Please let me know which you prefer (or if you would like to include both!) If we only include the functional version I would probably rename it to `phate` rather than `run_phate`.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/136
https://github.com/scverse/scanpy/issues/137:438,deployability,Build,Build,438,"How to create a panel of plots when using, for example, tsne; Hi,. Would it be possible to create a panel of plots using both rows and columns when plotting tsne? I did something similar to this:. ![tsne markers](https://user-images.githubusercontent.com/697622/39486721-19f44a02-4d4b-11e8-986e-d78079a06e0c.png). Basically the code calls the matplotlib subplots method based on the number of plots:. ```py. def _build_subplots(n):. '''. Build subplots grid. n: number of subplots. '''. nrow = int(np.sqrt(n)). ncol = int(np.ceil(n / nrow)). fig, axs = plt.subplots(nrow, ncol, dpi=100, figsize=(ncol*5, nrow*5)). return fig, axs, nrow, ncol. ```. Then the plots are drawn:. ```py. genes = [...list of gene symbols...]. fig, axs, nrow, ncol = _build_subplots(len(genes)). if type(axs) != np.ndarray:. axs = [axs]. else:. axs = axs.ravel(). for i in range(nrow*ncol):. if i < len(genes):. gene = genes[i]. # df is the numpy array containing tSNE. axs[i].scatter(df[:, 0], df[:, 1], ...). ```. Is it something that is already done, planned or that you don't want to integrate? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/137
https://github.com/scverse/scanpy/issues/137:929,deployability,contain,containing,929,"How to create a panel of plots when using, for example, tsne; Hi,. Would it be possible to create a panel of plots using both rows and columns when plotting tsne? I did something similar to this:. ![tsne markers](https://user-images.githubusercontent.com/697622/39486721-19f44a02-4d4b-11e8-986e-d78079a06e0c.png). Basically the code calls the matplotlib subplots method based on the number of plots:. ```py. def _build_subplots(n):. '''. Build subplots grid. n: number of subplots. '''. nrow = int(np.sqrt(n)). ncol = int(np.ceil(n / nrow)). fig, axs = plt.subplots(nrow, ncol, dpi=100, figsize=(ncol*5, nrow*5)). return fig, axs, nrow, ncol. ```. Then the plots are drawn:. ```py. genes = [...list of gene symbols...]. fig, axs, nrow, ncol = _build_subplots(len(genes)). if type(axs) != np.ndarray:. axs = [axs]. else:. axs = axs.ravel(). for i in range(nrow*ncol):. if i < len(genes):. gene = genes[i]. # df is the numpy array containing tSNE. axs[i].scatter(df[:, 0], df[:, 1], ...). ```. Is it something that is already done, planned or that you don't want to integrate? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/137
https://github.com/scverse/scanpy/issues/137:1064,deployability,integr,integrate,1064,"How to create a panel of plots when using, for example, tsne; Hi,. Would it be possible to create a panel of plots using both rows and columns when plotting tsne? I did something similar to this:. ![tsne markers](https://user-images.githubusercontent.com/697622/39486721-19f44a02-4d4b-11e8-986e-d78079a06e0c.png). Basically the code calls the matplotlib subplots method based on the number of plots:. ```py. def _build_subplots(n):. '''. Build subplots grid. n: number of subplots. '''. nrow = int(np.sqrt(n)). ncol = int(np.ceil(n / nrow)). fig, axs = plt.subplots(nrow, ncol, dpi=100, figsize=(ncol*5, nrow*5)). return fig, axs, nrow, ncol. ```. Then the plots are drawn:. ```py. genes = [...list of gene symbols...]. fig, axs, nrow, ncol = _build_subplots(len(genes)). if type(axs) != np.ndarray:. axs = [axs]. else:. axs = axs.ravel(). for i in range(nrow*ncol):. if i < len(genes):. gene = genes[i]. # df is the numpy array containing tSNE. axs[i].scatter(df[:, 0], df[:, 1], ...). ```. Is it something that is already done, planned or that you don't want to integrate? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/137
https://github.com/scverse/scanpy/issues/137:667,energy efficiency,draw,drawn,667,"How to create a panel of plots when using, for example, tsne; Hi,. Would it be possible to create a panel of plots using both rows and columns when plotting tsne? I did something similar to this:. ![tsne markers](https://user-images.githubusercontent.com/697622/39486721-19f44a02-4d4b-11e8-986e-d78079a06e0c.png). Basically the code calls the matplotlib subplots method based on the number of plots:. ```py. def _build_subplots(n):. '''. Build subplots grid. n: number of subplots. '''. nrow = int(np.sqrt(n)). ncol = int(np.ceil(n / nrow)). fig, axs = plt.subplots(nrow, ncol, dpi=100, figsize=(ncol*5, nrow*5)). return fig, axs, nrow, ncol. ```. Then the plots are drawn:. ```py. genes = [...list of gene symbols...]. fig, axs, nrow, ncol = _build_subplots(len(genes)). if type(axs) != np.ndarray:. axs = [axs]. else:. axs = axs.ravel(). for i in range(nrow*ncol):. if i < len(genes):. gene = genes[i]. # df is the numpy array containing tSNE. axs[i].scatter(df[:, 0], df[:, 1], ...). ```. Is it something that is already done, planned or that you don't want to integrate? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/137
https://github.com/scverse/scanpy/issues/137:354,integrability,sub,subplots,354,"How to create a panel of plots when using, for example, tsne; Hi,. Would it be possible to create a panel of plots using both rows and columns when plotting tsne? I did something similar to this:. ![tsne markers](https://user-images.githubusercontent.com/697622/39486721-19f44a02-4d4b-11e8-986e-d78079a06e0c.png). Basically the code calls the matplotlib subplots method based on the number of plots:. ```py. def _build_subplots(n):. '''. Build subplots grid. n: number of subplots. '''. nrow = int(np.sqrt(n)). ncol = int(np.ceil(n / nrow)). fig, axs = plt.subplots(nrow, ncol, dpi=100, figsize=(ncol*5, nrow*5)). return fig, axs, nrow, ncol. ```. Then the plots are drawn:. ```py. genes = [...list of gene symbols...]. fig, axs, nrow, ncol = _build_subplots(len(genes)). if type(axs) != np.ndarray:. axs = [axs]. else:. axs = axs.ravel(). for i in range(nrow*ncol):. if i < len(genes):. gene = genes[i]. # df is the numpy array containing tSNE. axs[i].scatter(df[:, 0], df[:, 1], ...). ```. Is it something that is already done, planned or that you don't want to integrate? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/137
https://github.com/scverse/scanpy/issues/137:444,integrability,sub,subplots,444,"How to create a panel of plots when using, for example, tsne; Hi,. Would it be possible to create a panel of plots using both rows and columns when plotting tsne? I did something similar to this:. ![tsne markers](https://user-images.githubusercontent.com/697622/39486721-19f44a02-4d4b-11e8-986e-d78079a06e0c.png). Basically the code calls the matplotlib subplots method based on the number of plots:. ```py. def _build_subplots(n):. '''. Build subplots grid. n: number of subplots. '''. nrow = int(np.sqrt(n)). ncol = int(np.ceil(n / nrow)). fig, axs = plt.subplots(nrow, ncol, dpi=100, figsize=(ncol*5, nrow*5)). return fig, axs, nrow, ncol. ```. Then the plots are drawn:. ```py. genes = [...list of gene symbols...]. fig, axs, nrow, ncol = _build_subplots(len(genes)). if type(axs) != np.ndarray:. axs = [axs]. else:. axs = axs.ravel(). for i in range(nrow*ncol):. if i < len(genes):. gene = genes[i]. # df is the numpy array containing tSNE. axs[i].scatter(df[:, 0], df[:, 1], ...). ```. Is it something that is already done, planned or that you don't want to integrate? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/137
https://github.com/scverse/scanpy/issues/137:472,integrability,sub,subplots,472,"How to create a panel of plots when using, for example, tsne; Hi,. Would it be possible to create a panel of plots using both rows and columns when plotting tsne? I did something similar to this:. ![tsne markers](https://user-images.githubusercontent.com/697622/39486721-19f44a02-4d4b-11e8-986e-d78079a06e0c.png). Basically the code calls the matplotlib subplots method based on the number of plots:. ```py. def _build_subplots(n):. '''. Build subplots grid. n: number of subplots. '''. nrow = int(np.sqrt(n)). ncol = int(np.ceil(n / nrow)). fig, axs = plt.subplots(nrow, ncol, dpi=100, figsize=(ncol*5, nrow*5)). return fig, axs, nrow, ncol. ```. Then the plots are drawn:. ```py. genes = [...list of gene symbols...]. fig, axs, nrow, ncol = _build_subplots(len(genes)). if type(axs) != np.ndarray:. axs = [axs]. else:. axs = axs.ravel(). for i in range(nrow*ncol):. if i < len(genes):. gene = genes[i]. # df is the numpy array containing tSNE. axs[i].scatter(df[:, 0], df[:, 1], ...). ```. Is it something that is already done, planned or that you don't want to integrate? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/137
https://github.com/scverse/scanpy/issues/137:557,integrability,sub,subplots,557,"How to create a panel of plots when using, for example, tsne; Hi,. Would it be possible to create a panel of plots using both rows and columns when plotting tsne? I did something similar to this:. ![tsne markers](https://user-images.githubusercontent.com/697622/39486721-19f44a02-4d4b-11e8-986e-d78079a06e0c.png). Basically the code calls the matplotlib subplots method based on the number of plots:. ```py. def _build_subplots(n):. '''. Build subplots grid. n: number of subplots. '''. nrow = int(np.sqrt(n)). ncol = int(np.ceil(n / nrow)). fig, axs = plt.subplots(nrow, ncol, dpi=100, figsize=(ncol*5, nrow*5)). return fig, axs, nrow, ncol. ```. Then the plots are drawn:. ```py. genes = [...list of gene symbols...]. fig, axs, nrow, ncol = _build_subplots(len(genes)). if type(axs) != np.ndarray:. axs = [axs]. else:. axs = axs.ravel(). for i in range(nrow*ncol):. if i < len(genes):. gene = genes[i]. # df is the numpy array containing tSNE. axs[i].scatter(df[:, 0], df[:, 1], ...). ```. Is it something that is already done, planned or that you don't want to integrate? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/137
https://github.com/scverse/scanpy/issues/137:1064,integrability,integr,integrate,1064,"How to create a panel of plots when using, for example, tsne; Hi,. Would it be possible to create a panel of plots using both rows and columns when plotting tsne? I did something similar to this:. ![tsne markers](https://user-images.githubusercontent.com/697622/39486721-19f44a02-4d4b-11e8-986e-d78079a06e0c.png). Basically the code calls the matplotlib subplots method based on the number of plots:. ```py. def _build_subplots(n):. '''. Build subplots grid. n: number of subplots. '''. nrow = int(np.sqrt(n)). ncol = int(np.ceil(n / nrow)). fig, axs = plt.subplots(nrow, ncol, dpi=100, figsize=(ncol*5, nrow*5)). return fig, axs, nrow, ncol. ```. Then the plots are drawn:. ```py. genes = [...list of gene symbols...]. fig, axs, nrow, ncol = _build_subplots(len(genes)). if type(axs) != np.ndarray:. axs = [axs]. else:. axs = axs.ravel(). for i in range(nrow*ncol):. if i < len(genes):. gene = genes[i]. # df is the numpy array containing tSNE. axs[i].scatter(df[:, 0], df[:, 1], ...). ```. Is it something that is already done, planned or that you don't want to integrate? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/137
https://github.com/scverse/scanpy/issues/137:1064,interoperability,integr,integrate,1064,"How to create a panel of plots when using, for example, tsne; Hi,. Would it be possible to create a panel of plots using both rows and columns when plotting tsne? I did something similar to this:. ![tsne markers](https://user-images.githubusercontent.com/697622/39486721-19f44a02-4d4b-11e8-986e-d78079a06e0c.png). Basically the code calls the matplotlib subplots method based on the number of plots:. ```py. def _build_subplots(n):. '''. Build subplots grid. n: number of subplots. '''. nrow = int(np.sqrt(n)). ncol = int(np.ceil(n / nrow)). fig, axs = plt.subplots(nrow, ncol, dpi=100, figsize=(ncol*5, nrow*5)). return fig, axs, nrow, ncol. ```. Then the plots are drawn:. ```py. genes = [...list of gene symbols...]. fig, axs, nrow, ncol = _build_subplots(len(genes)). if type(axs) != np.ndarray:. axs = [axs]. else:. axs = axs.ravel(). for i in range(nrow*ncol):. if i < len(genes):. gene = genes[i]. # df is the numpy array containing tSNE. axs[i].scatter(df[:, 0], df[:, 1], ...). ```. Is it something that is already done, planned or that you don't want to integrate? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/137
https://github.com/scverse/scanpy/issues/137:1064,modifiability,integr,integrate,1064,"How to create a panel of plots when using, for example, tsne; Hi,. Would it be possible to create a panel of plots using both rows and columns when plotting tsne? I did something similar to this:. ![tsne markers](https://user-images.githubusercontent.com/697622/39486721-19f44a02-4d4b-11e8-986e-d78079a06e0c.png). Basically the code calls the matplotlib subplots method based on the number of plots:. ```py. def _build_subplots(n):. '''. Build subplots grid. n: number of subplots. '''. nrow = int(np.sqrt(n)). ncol = int(np.ceil(n / nrow)). fig, axs = plt.subplots(nrow, ncol, dpi=100, figsize=(ncol*5, nrow*5)). return fig, axs, nrow, ncol. ```. Then the plots are drawn:. ```py. genes = [...list of gene symbols...]. fig, axs, nrow, ncol = _build_subplots(len(genes)). if type(axs) != np.ndarray:. axs = [axs]. else:. axs = axs.ravel(). for i in range(nrow*ncol):. if i < len(genes):. gene = genes[i]. # df is the numpy array containing tSNE. axs[i].scatter(df[:, 0], df[:, 1], ...). ```. Is it something that is already done, planned or that you don't want to integrate? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/137
https://github.com/scverse/scanpy/issues/137:1064,reliability,integr,integrate,1064,"How to create a panel of plots when using, for example, tsne; Hi,. Would it be possible to create a panel of plots using both rows and columns when plotting tsne? I did something similar to this:. ![tsne markers](https://user-images.githubusercontent.com/697622/39486721-19f44a02-4d4b-11e8-986e-d78079a06e0c.png). Basically the code calls the matplotlib subplots method based on the number of plots:. ```py. def _build_subplots(n):. '''. Build subplots grid. n: number of subplots. '''. nrow = int(np.sqrt(n)). ncol = int(np.ceil(n / nrow)). fig, axs = plt.subplots(nrow, ncol, dpi=100, figsize=(ncol*5, nrow*5)). return fig, axs, nrow, ncol. ```. Then the plots are drawn:. ```py. genes = [...list of gene symbols...]. fig, axs, nrow, ncol = _build_subplots(len(genes)). if type(axs) != np.ndarray:. axs = [axs]. else:. axs = axs.ravel(). for i in range(nrow*ncol):. if i < len(genes):. gene = genes[i]. # df is the numpy array containing tSNE. axs[i].scatter(df[:, 0], df[:, 1], ...). ```. Is it something that is already done, planned or that you don't want to integrate? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/137
https://github.com/scverse/scanpy/issues/137:1064,security,integr,integrate,1064,"How to create a panel of plots when using, for example, tsne; Hi,. Would it be possible to create a panel of plots using both rows and columns when plotting tsne? I did something similar to this:. ![tsne markers](https://user-images.githubusercontent.com/697622/39486721-19f44a02-4d4b-11e8-986e-d78079a06e0c.png). Basically the code calls the matplotlib subplots method based on the number of plots:. ```py. def _build_subplots(n):. '''. Build subplots grid. n: number of subplots. '''. nrow = int(np.sqrt(n)). ncol = int(np.ceil(n / nrow)). fig, axs = plt.subplots(nrow, ncol, dpi=100, figsize=(ncol*5, nrow*5)). return fig, axs, nrow, ncol. ```. Then the plots are drawn:. ```py. genes = [...list of gene symbols...]. fig, axs, nrow, ncol = _build_subplots(len(genes)). if type(axs) != np.ndarray:. axs = [axs]. else:. axs = axs.ravel(). for i in range(nrow*ncol):. if i < len(genes):. gene = genes[i]. # df is the numpy array containing tSNE. axs[i].scatter(df[:, 0], df[:, 1], ...). ```. Is it something that is already done, planned or that you don't want to integrate? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/137
https://github.com/scverse/scanpy/issues/137:1030,testability,plan,planned,1030,"How to create a panel of plots when using, for example, tsne; Hi,. Would it be possible to create a panel of plots using both rows and columns when plotting tsne? I did something similar to this:. ![tsne markers](https://user-images.githubusercontent.com/697622/39486721-19f44a02-4d4b-11e8-986e-d78079a06e0c.png). Basically the code calls the matplotlib subplots method based on the number of plots:. ```py. def _build_subplots(n):. '''. Build subplots grid. n: number of subplots. '''. nrow = int(np.sqrt(n)). ncol = int(np.ceil(n / nrow)). fig, axs = plt.subplots(nrow, ncol, dpi=100, figsize=(ncol*5, nrow*5)). return fig, axs, nrow, ncol. ```. Then the plots are drawn:. ```py. genes = [...list of gene symbols...]. fig, axs, nrow, ncol = _build_subplots(len(genes)). if type(axs) != np.ndarray:. axs = [axs]. else:. axs = axs.ravel(). for i in range(nrow*ncol):. if i < len(genes):. gene = genes[i]. # df is the numpy array containing tSNE. axs[i].scatter(df[:, 0], df[:, 1], ...). ```. Is it something that is already done, planned or that you don't want to integrate? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/137
https://github.com/scverse/scanpy/issues/137:1064,testability,integr,integrate,1064,"How to create a panel of plots when using, for example, tsne; Hi,. Would it be possible to create a panel of plots using both rows and columns when plotting tsne? I did something similar to this:. ![tsne markers](https://user-images.githubusercontent.com/697622/39486721-19f44a02-4d4b-11e8-986e-d78079a06e0c.png). Basically the code calls the matplotlib subplots method based on the number of plots:. ```py. def _build_subplots(n):. '''. Build subplots grid. n: number of subplots. '''. nrow = int(np.sqrt(n)). ncol = int(np.ceil(n / nrow)). fig, axs = plt.subplots(nrow, ncol, dpi=100, figsize=(ncol*5, nrow*5)). return fig, axs, nrow, ncol. ```. Then the plots are drawn:. ```py. genes = [...list of gene symbols...]. fig, axs, nrow, ncol = _build_subplots(len(genes)). if type(axs) != np.ndarray:. axs = [axs]. else:. axs = axs.ravel(). for i in range(nrow*ncol):. if i < len(genes):. gene = genes[i]. # df is the numpy array containing tSNE. axs[i].scatter(df[:, 0], df[:, 1], ...). ```. Is it something that is already done, planned or that you don't want to integrate? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/137
https://github.com/scverse/scanpy/issues/137:221,usability,user,user-images,221,"How to create a panel of plots when using, for example, tsne; Hi,. Would it be possible to create a panel of plots using both rows and columns when plotting tsne? I did something similar to this:. ![tsne markers](https://user-images.githubusercontent.com/697622/39486721-19f44a02-4d4b-11e8-986e-d78079a06e0c.png). Basically the code calls the matplotlib subplots method based on the number of plots:. ```py. def _build_subplots(n):. '''. Build subplots grid. n: number of subplots. '''. nrow = int(np.sqrt(n)). ncol = int(np.ceil(n / nrow)). fig, axs = plt.subplots(nrow, ncol, dpi=100, figsize=(ncol*5, nrow*5)). return fig, axs, nrow, ncol. ```. Then the plots are drawn:. ```py. genes = [...list of gene symbols...]. fig, axs, nrow, ncol = _build_subplots(len(genes)). if type(axs) != np.ndarray:. axs = [axs]. else:. axs = axs.ravel(). for i in range(nrow*ncol):. if i < len(genes):. gene = genes[i]. # df is the numpy array containing tSNE. axs[i].scatter(df[:, 0], df[:, 1], ...). ```. Is it something that is already done, planned or that you don't want to integrate? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/137
https://github.com/scverse/scanpy/issues/138:59,availability,cluster,clustering,59,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:245,availability,cluster,clustering,245,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:59,deployability,cluster,clustering,59,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:149,deployability,instal,installed,149,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:245,deployability,cluster,clustering,245,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:429,deployability,modul,module,429,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:479,deployability,version,versions,479,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:699,deployability,log,logg,699,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:873,deployability,version,versions,873,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:1217,deployability,version,versions,1217,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:1283,deployability,modul,module,1283,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:1481,deployability,upgrad,upgrade,1481,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:1642,deployability,upgrad,upgrade,1642,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:1839,deployability,depend,dependencies,1839,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:479,integrability,version,versions,479,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:873,integrability,version,versions,873,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:1217,integrability,version,versions,1217,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:1839,integrability,depend,dependencies,1839,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:429,modifiability,modul,module,429,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:479,modifiability,version,versions,479,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:513,modifiability,pac,packages,513,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:873,modifiability,version,versions,873,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:907,modifiability,pac,packages,907,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:1217,modifiability,version,versions,1217,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:1251,modifiability,pac,packages,1251,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:1283,modifiability,modul,module,1283,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:1481,modifiability,upgrad,upgrade,1481,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:1642,modifiability,upgrad,upgrade,1642,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:1839,modifiability,depend,dependencies,1839,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:81,performance,time,time,81,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:105,safety,compl,complains,105,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:402,safety,input,input-,402,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:429,safety,modul,module,429,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:699,safety,log,logg,699,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:1283,safety,modul,module,1283,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:1358,safety,avoid,avoid,1358,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:1532,safety,avoid,avoid,1532,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:1839,safety,depend,dependencies,1839,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:105,security,compl,complains,105,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:699,security,log,logg,699,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:358,testability,Trace,Traceback,358,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:699,testability,log,logg,699,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:1839,testability,depend,dependencies,1839,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:402,usability,input,input-,402,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:529,usability,tool,tools,529,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:1415,usability,visual,visualization,1415,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/issues/138:1583,usability,visual,visualization,1583,"igraph problems; Hi,. I have some problems running Louvain clustering. The first time I tried to run, it complains about missing library `igraph`. I installed `igraph` but now this same library throws a `DeprecationWarning` when calling Louvain clustering. ```. ---------------------------------------------------------------------------. DeprecationWarning Traceback (most recent call last). <ipython-input-17-329d7c2ac26c> in <module>(). ----> 1 sc.tl.louvain(adata). ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/tools/louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, n_jobs, copy). 79 directed = False. 80 if not directed: logg.m(' using the undirected graph', v=4). ---> 81 g = utils.get_igraph_from_adjacency(adjacency, directed=directed). 82 if flavor == 'vtraag':. 83 import louvain. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/utils.py in get_igraph_from_adjacency(adjacency, directed). 92 def get_igraph_from_adjacency(adjacency, directed=None):. 93 """"""Get igraph graph from adjacency matrix."""""". ---> 94 import igraph as ig. 95 sources, targets = adjacency.nonzero(). 96 weights = adjacency[sources, targets]. ~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/igraph/__init__.py in <module>(). 6 __license__ = ""MIT"". 7 . ----> 8 raise DeprecationWarning(""To avoid name collision with the igraph project, "". 9 ""this visualization library has been renamed to "". 10 ""'jgraph'. Please upgrade when convenient.""). DeprecationWarning: To avoid name collision with the igraph project, this visualization library has been renamed to 'jgraph'. Please upgrade when convenient. ```. I can work on a PR and change line 94 of `scanpy/utils.py` to:. ```. import jgraph as ig. ```. This should solve the issue afaik (and `jgraph` should be listed in the dependencies I think). Let me know if you accept PRs. Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/138
https://github.com/scverse/scanpy/pull/139:13,deployability,API,API,13,Add PHATE to API docs; Sorry for the noise - I didn't realise until after the last one merged that I had to add PHATE manually to the API docs. Thanks!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/139
https://github.com/scverse/scanpy/pull/139:134,deployability,API,API,134,Add PHATE to API docs; Sorry for the noise - I didn't realise until after the last one merged that I had to add PHATE manually to the API docs. Thanks!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/139
https://github.com/scverse/scanpy/pull/139:13,integrability,API,API,13,Add PHATE to API docs; Sorry for the noise - I didn't realise until after the last one merged that I had to add PHATE manually to the API docs. Thanks!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/139
https://github.com/scverse/scanpy/pull/139:134,integrability,API,API,134,Add PHATE to API docs; Sorry for the noise - I didn't realise until after the last one merged that I had to add PHATE manually to the API docs. Thanks!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/139
https://github.com/scverse/scanpy/pull/139:13,interoperability,API,API,13,Add PHATE to API docs; Sorry for the noise - I didn't realise until after the last one merged that I had to add PHATE manually to the API docs. Thanks!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/139
https://github.com/scverse/scanpy/pull/139:134,interoperability,API,API,134,Add PHATE to API docs; Sorry for the noise - I didn't realise until after the last one merged that I had to add PHATE manually to the API docs. Thanks!,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/139
https://github.com/scverse/scanpy/issues/140:370,availability,sli,slice,370,"SettingWithCopyWarning on rank_genes_groups_violin(); It is low-priority I think (the function should work anyway), but I get the following Warning when I execute `rank_genes_groups_violin()`:. ```. /Users/user/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py:1037: SettingWithCopyWarning: . A value is trying to be set on a copy of a slice from a DataFrame. See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy. df['hue'][df['hue'] != group_name] = 'rest'. ```. The interested line is the following:. https://github.com/theislab/scanpy/blob/639dcd4c2385a24271733a8f05d838dbf70175e6/scanpy/plotting/tools/__init__.py#L1159. If I remember correctly Pandas API, such line should be rewritten as:. ```python. df.loc[df['hue'] != group_name, 'hue'] = 'rest'. ```. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/140
https://github.com/scverse/scanpy/issues/140:218,deployability,version,versions,218,"SettingWithCopyWarning on rank_genes_groups_violin(); It is low-priority I think (the function should work anyway), but I get the following Warning when I execute `rank_genes_groups_violin()`:. ```. /Users/user/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py:1037: SettingWithCopyWarning: . A value is trying to be set on a copy of a slice from a DataFrame. See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy. df['hue'][df['hue'] != group_name] = 'rest'. ```. The interested line is the following:. https://github.com/theislab/scanpy/blob/639dcd4c2385a24271733a8f05d838dbf70175e6/scanpy/plotting/tools/__init__.py#L1159. If I remember correctly Pandas API, such line should be rewritten as:. ```python. df.loc[df['hue'] != group_name, 'hue'] = 'rest'. ```. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/140
https://github.com/scverse/scanpy/issues/140:759,deployability,API,API,759,"SettingWithCopyWarning on rank_genes_groups_violin(); It is low-priority I think (the function should work anyway), but I get the following Warning when I execute `rank_genes_groups_violin()`:. ```. /Users/user/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py:1037: SettingWithCopyWarning: . A value is trying to be set on a copy of a slice from a DataFrame. See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy. df['hue'][df['hue'] != group_name] = 'rest'. ```. The interested line is the following:. https://github.com/theislab/scanpy/blob/639dcd4c2385a24271733a8f05d838dbf70175e6/scanpy/plotting/tools/__init__.py#L1159. If I remember correctly Pandas API, such line should be rewritten as:. ```python. df.loc[df['hue'] != group_name, 'hue'] = 'rest'. ```. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/140
https://github.com/scverse/scanpy/issues/140:218,integrability,version,versions,218,"SettingWithCopyWarning on rank_genes_groups_violin(); It is low-priority I think (the function should work anyway), but I get the following Warning when I execute `rank_genes_groups_violin()`:. ```. /Users/user/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py:1037: SettingWithCopyWarning: . A value is trying to be set on a copy of a slice from a DataFrame. See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy. df['hue'][df['hue'] != group_name] = 'rest'. ```. The interested line is the following:. https://github.com/theislab/scanpy/blob/639dcd4c2385a24271733a8f05d838dbf70175e6/scanpy/plotting/tools/__init__.py#L1159. If I remember correctly Pandas API, such line should be rewritten as:. ```python. df.loc[df['hue'] != group_name, 'hue'] = 'rest'. ```. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/140
https://github.com/scverse/scanpy/issues/140:759,integrability,API,API,759,"SettingWithCopyWarning on rank_genes_groups_violin(); It is low-priority I think (the function should work anyway), but I get the following Warning when I execute `rank_genes_groups_violin()`:. ```. /Users/user/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py:1037: SettingWithCopyWarning: . A value is trying to be set on a copy of a slice from a DataFrame. See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy. df['hue'][df['hue'] != group_name] = 'rest'. ```. The interested line is the following:. https://github.com/theislab/scanpy/blob/639dcd4c2385a24271733a8f05d838dbf70175e6/scanpy/plotting/tools/__init__.py#L1159. If I remember correctly Pandas API, such line should be rewritten as:. ```python. df.loc[df['hue'] != group_name, 'hue'] = 'rest'. ```. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/140
https://github.com/scverse/scanpy/issues/140:759,interoperability,API,API,759,"SettingWithCopyWarning on rank_genes_groups_violin(); It is low-priority I think (the function should work anyway), but I get the following Warning when I execute `rank_genes_groups_violin()`:. ```. /Users/user/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py:1037: SettingWithCopyWarning: . A value is trying to be set on a copy of a slice from a DataFrame. See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy. df['hue'][df['hue'] != group_name] = 'rest'. ```. The interested line is the following:. https://github.com/theislab/scanpy/blob/639dcd4c2385a24271733a8f05d838dbf70175e6/scanpy/plotting/tools/__init__.py#L1159. If I remember correctly Pandas API, such line should be rewritten as:. ```python. df.loc[df['hue'] != group_name, 'hue'] = 'rest'. ```. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/140
https://github.com/scverse/scanpy/issues/140:218,modifiability,version,versions,218,"SettingWithCopyWarning on rank_genes_groups_violin(); It is low-priority I think (the function should work anyway), but I get the following Warning when I execute `rank_genes_groups_violin()`:. ```. /Users/user/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py:1037: SettingWithCopyWarning: . A value is trying to be set on a copy of a slice from a DataFrame. See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy. df['hue'][df['hue'] != group_name] = 'rest'. ```. The interested line is the following:. https://github.com/theislab/scanpy/blob/639dcd4c2385a24271733a8f05d838dbf70175e6/scanpy/plotting/tools/__init__.py#L1159. If I remember correctly Pandas API, such line should be rewritten as:. ```python. df.loc[df['hue'] != group_name, 'hue'] = 'rest'. ```. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/140
https://github.com/scverse/scanpy/issues/140:252,modifiability,pac,packages,252,"SettingWithCopyWarning on rank_genes_groups_violin(); It is low-priority I think (the function should work anyway), but I get the following Warning when I execute `rank_genes_groups_violin()`:. ```. /Users/user/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py:1037: SettingWithCopyWarning: . A value is trying to be set on a copy of a slice from a DataFrame. See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy. df['hue'][df['hue'] != group_name] = 'rest'. ```. The interested line is the following:. https://github.com/theislab/scanpy/blob/639dcd4c2385a24271733a8f05d838dbf70175e6/scanpy/plotting/tools/__init__.py#L1159. If I remember correctly Pandas API, such line should be rewritten as:. ```python. df.loc[df['hue'] != group_name, 'hue'] = 'rest'. ```. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/140
https://github.com/scverse/scanpy/issues/140:370,reliability,sli,slice,370,"SettingWithCopyWarning on rank_genes_groups_violin(); It is low-priority I think (the function should work anyway), but I get the following Warning when I execute `rank_genes_groups_violin()`:. ```. /Users/user/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py:1037: SettingWithCopyWarning: . A value is trying to be set on a copy of a slice from a DataFrame. See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy. df['hue'][df['hue'] != group_name] = 'rest'. ```. The interested line is the following:. https://github.com/theislab/scanpy/blob/639dcd4c2385a24271733a8f05d838dbf70175e6/scanpy/plotting/tools/__init__.py#L1159. If I remember correctly Pandas API, such line should be rewritten as:. ```python. df.loc[df['hue'] != group_name, 'hue'] = 'rest'. ```. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/140
https://github.com/scverse/scanpy/issues/140:733,safety,reme,remember,733,"SettingWithCopyWarning on rank_genes_groups_violin(); It is low-priority I think (the function should work anyway), but I get the following Warning when I execute `rank_genes_groups_violin()`:. ```. /Users/user/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py:1037: SettingWithCopyWarning: . A value is trying to be set on a copy of a slice from a DataFrame. See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy. df['hue'][df['hue'] != group_name] = 'rest'. ```. The interested line is the following:. https://github.com/theislab/scanpy/blob/639dcd4c2385a24271733a8f05d838dbf70175e6/scanpy/plotting/tools/__init__.py#L1159. If I remember correctly Pandas API, such line should be rewritten as:. ```python. df.loc[df['hue'] != group_name, 'hue'] = 'rest'. ```. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/140
https://github.com/scverse/scanpy/issues/140:200,usability,User,Users,200,"SettingWithCopyWarning on rank_genes_groups_violin(); It is low-priority I think (the function should work anyway), but I get the following Warning when I execute `rank_genes_groups_violin()`:. ```. /Users/user/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py:1037: SettingWithCopyWarning: . A value is trying to be set on a copy of a slice from a DataFrame. See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy. df['hue'][df['hue'] != group_name] = 'rest'. ```. The interested line is the following:. https://github.com/theislab/scanpy/blob/639dcd4c2385a24271733a8f05d838dbf70175e6/scanpy/plotting/tools/__init__.py#L1159. If I remember correctly Pandas API, such line should be rewritten as:. ```python. df.loc[df['hue'] != group_name, 'hue'] = 'rest'. ```. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/140
https://github.com/scverse/scanpy/issues/140:206,usability,user,user,206,"SettingWithCopyWarning on rank_genes_groups_violin(); It is low-priority I think (the function should work anyway), but I get the following Warning when I execute `rank_genes_groups_violin()`:. ```. /Users/user/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py:1037: SettingWithCopyWarning: . A value is trying to be set on a copy of a slice from a DataFrame. See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy. df['hue'][df['hue'] != group_name] = 'rest'. ```. The interested line is the following:. https://github.com/theislab/scanpy/blob/639dcd4c2385a24271733a8f05d838dbf70175e6/scanpy/plotting/tools/__init__.py#L1159. If I remember correctly Pandas API, such line should be rewritten as:. ```python. df.loc[df['hue'] != group_name, 'hue'] = 'rest'. ```. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/140
https://github.com/scverse/scanpy/issues/140:277,usability,tool,tools,277,"SettingWithCopyWarning on rank_genes_groups_violin(); It is low-priority I think (the function should work anyway), but I get the following Warning when I execute `rank_genes_groups_violin()`:. ```. /Users/user/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py:1037: SettingWithCopyWarning: . A value is trying to be set on a copy of a slice from a DataFrame. See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy. df['hue'][df['hue'] != group_name] = 'rest'. ```. The interested line is the following:. https://github.com/theislab/scanpy/blob/639dcd4c2385a24271733a8f05d838dbf70175e6/scanpy/plotting/tools/__init__.py#L1159. If I remember correctly Pandas API, such line should be rewritten as:. ```python. df.loc[df['hue'] != group_name, 'hue'] = 'rest'. ```. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/140
https://github.com/scverse/scanpy/issues/140:417,usability,document,documentation,417,"SettingWithCopyWarning on rank_genes_groups_violin(); It is low-priority I think (the function should work anyway), but I get the following Warning when I execute `rank_genes_groups_violin()`:. ```. /Users/user/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py:1037: SettingWithCopyWarning: . A value is trying to be set on a copy of a slice from a DataFrame. See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy. df['hue'][df['hue'] != group_name] = 'rest'. ```. The interested line is the following:. https://github.com/theislab/scanpy/blob/639dcd4c2385a24271733a8f05d838dbf70175e6/scanpy/plotting/tools/__init__.py#L1159. If I remember correctly Pandas API, such line should be rewritten as:. ```python. df.loc[df['hue'] != group_name, 'hue'] = 'rest'. ```. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/140
https://github.com/scverse/scanpy/issues/140:703,usability,tool,tools,703,"SettingWithCopyWarning on rank_genes_groups_violin(); It is low-priority I think (the function should work anyway), but I get the following Warning when I execute `rank_genes_groups_violin()`:. ```. /Users/user/.pyenv/versions/3.6.4/lib/python3.6/site-packages/scanpy/plotting/tools/__init__.py:1037: SettingWithCopyWarning: . A value is trying to be set on a copy of a slice from a DataFrame. See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy. df['hue'][df['hue'] != group_name] = 'rest'. ```. The interested line is the following:. https://github.com/theislab/scanpy/blob/639dcd4c2385a24271733a8f05d838dbf70175e6/scanpy/plotting/tools/__init__.py#L1159. If I remember correctly Pandas API, such line should be rewritten as:. ```python. df.loc[df['hue'] != group_name, 'hue'] = 'rest'. ```. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/140
https://github.com/scverse/scanpy/pull/141:198,availability,error,error-prone,198,"Programmatic mitochondrial gene symbols retrieval; I added a method for programmatic retrieval of mitochondrial gene symbols through BioMart (instead of using a regular expression, this may be less error-prone and constantly up-to-date). Let me know if you are interested in merging it, and if the code style is acceptable for this library. I was unsure on how to test it, in case do you have any suggestions? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/141
https://github.com/scverse/scanpy/pull/141:198,performance,error,error-prone,198,"Programmatic mitochondrial gene symbols retrieval; I added a method for programmatic retrieval of mitochondrial gene symbols through BioMart (instead of using a regular expression, this may be less error-prone and constantly up-to-date). Let me know if you are interested in merging it, and if the code style is acceptable for this library. I was unsure on how to test it, in case do you have any suggestions? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/141
https://github.com/scverse/scanpy/pull/141:198,safety,error,error-prone,198,"Programmatic mitochondrial gene symbols retrieval; I added a method for programmatic retrieval of mitochondrial gene symbols through BioMart (instead of using a regular expression, this may be less error-prone and constantly up-to-date). Let me know if you are interested in merging it, and if the code style is acceptable for this library. I was unsure on how to test it, in case do you have any suggestions? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/141
https://github.com/scverse/scanpy/pull/141:364,safety,test,test,364,"Programmatic mitochondrial gene symbols retrieval; I added a method for programmatic retrieval of mitochondrial gene symbols through BioMart (instead of using a regular expression, this may be less error-prone and constantly up-to-date). Let me know if you are interested in merging it, and if the code style is acceptable for this library. I was unsure on how to test it, in case do you have any suggestions? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/141
https://github.com/scverse/scanpy/pull/141:364,testability,test,test,364,"Programmatic mitochondrial gene symbols retrieval; I added a method for programmatic retrieval of mitochondrial gene symbols through BioMart (instead of using a regular expression, this may be less error-prone and constantly up-to-date). Let me know if you are interested in merging it, and if the code style is acceptable for this library. I was unsure on how to test it, in case do you have any suggestions? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/141
https://github.com/scverse/scanpy/pull/141:198,usability,error,error-prone,198,"Programmatic mitochondrial gene symbols retrieval; I added a method for programmatic retrieval of mitochondrial gene symbols through BioMart (instead of using a regular expression, this may be less error-prone and constantly up-to-date). Let me know if you are interested in merging it, and if the code style is acceptable for this library. I was unsure on how to test it, in case do you have any suggestions? Thanks,. Francesco",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/141
https://github.com/scverse/scanpy/issues/142:216,availability,down,downstream,216,"DCA integration; I'd like to integrate DCA with scanpy and I need to ask some questions regarding that. . There are two use cases for DCA so far. One is denoising as a preprocessing step and using denoised matrix in downstream analyses, especially in the ones that require original feature space such as differential expression. This seems to be a better fit for the `preprocessing` package i.e. `sc.pp.dca(adata)` which overwrites `adata.X` with the denoised matrix. Users can use `copy=True` to keep adata.X of original matrix unchanged. The other use case is the low dimensional representations of cells produced by the encoder. This can also be used for the downstream analyses that do not require original feature space e.g. clustering, and visualization. This is more like `sc.tl.dca(adata)` which stores the new representation into `adata.obsm['X_dca']`. Optionally it can store dropout probabilities (pi matrix) and the dispersion, as well. However, having both sc.tl.dca and sc.pp.dca might be confusing for the users. Any suggestions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/142
https://github.com/scverse/scanpy/issues/142:662,availability,down,downstream,662,"DCA integration; I'd like to integrate DCA with scanpy and I need to ask some questions regarding that. . There are two use cases for DCA so far. One is denoising as a preprocessing step and using denoised matrix in downstream analyses, especially in the ones that require original feature space such as differential expression. This seems to be a better fit for the `preprocessing` package i.e. `sc.pp.dca(adata)` which overwrites `adata.X` with the denoised matrix. Users can use `copy=True` to keep adata.X of original matrix unchanged. The other use case is the low dimensional representations of cells produced by the encoder. This can also be used for the downstream analyses that do not require original feature space e.g. clustering, and visualization. This is more like `sc.tl.dca(adata)` which stores the new representation into `adata.obsm['X_dca']`. Optionally it can store dropout probabilities (pi matrix) and the dispersion, as well. However, having both sc.tl.dca and sc.pp.dca might be confusing for the users. Any suggestions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/142
https://github.com/scverse/scanpy/issues/142:730,availability,cluster,clustering,730,"DCA integration; I'd like to integrate DCA with scanpy and I need to ask some questions regarding that. . There are two use cases for DCA so far. One is denoising as a preprocessing step and using denoised matrix in downstream analyses, especially in the ones that require original feature space such as differential expression. This seems to be a better fit for the `preprocessing` package i.e. `sc.pp.dca(adata)` which overwrites `adata.X` with the denoised matrix. Users can use `copy=True` to keep adata.X of original matrix unchanged. The other use case is the low dimensional representations of cells produced by the encoder. This can also be used for the downstream analyses that do not require original feature space e.g. clustering, and visualization. This is more like `sc.tl.dca(adata)` which stores the new representation into `adata.obsm['X_dca']`. Optionally it can store dropout probabilities (pi matrix) and the dispersion, as well. However, having both sc.tl.dca and sc.pp.dca might be confusing for the users. Any suggestions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/142
https://github.com/scverse/scanpy/issues/142:4,deployability,integr,integration,4,"DCA integration; I'd like to integrate DCA with scanpy and I need to ask some questions regarding that. . There are two use cases for DCA so far. One is denoising as a preprocessing step and using denoised matrix in downstream analyses, especially in the ones that require original feature space such as differential expression. This seems to be a better fit for the `preprocessing` package i.e. `sc.pp.dca(adata)` which overwrites `adata.X` with the denoised matrix. Users can use `copy=True` to keep adata.X of original matrix unchanged. The other use case is the low dimensional representations of cells produced by the encoder. This can also be used for the downstream analyses that do not require original feature space e.g. clustering, and visualization. This is more like `sc.tl.dca(adata)` which stores the new representation into `adata.obsm['X_dca']`. Optionally it can store dropout probabilities (pi matrix) and the dispersion, as well. However, having both sc.tl.dca and sc.pp.dca might be confusing for the users. Any suggestions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/142
https://github.com/scverse/scanpy/issues/142:29,deployability,integr,integrate,29,"DCA integration; I'd like to integrate DCA with scanpy and I need to ask some questions regarding that. . There are two use cases for DCA so far. One is denoising as a preprocessing step and using denoised matrix in downstream analyses, especially in the ones that require original feature space such as differential expression. This seems to be a better fit for the `preprocessing` package i.e. `sc.pp.dca(adata)` which overwrites `adata.X` with the denoised matrix. Users can use `copy=True` to keep adata.X of original matrix unchanged. The other use case is the low dimensional representations of cells produced by the encoder. This can also be used for the downstream analyses that do not require original feature space e.g. clustering, and visualization. This is more like `sc.tl.dca(adata)` which stores the new representation into `adata.obsm['X_dca']`. Optionally it can store dropout probabilities (pi matrix) and the dispersion, as well. However, having both sc.tl.dca and sc.pp.dca might be confusing for the users. Any suggestions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/142
https://github.com/scverse/scanpy/issues/142:730,deployability,cluster,clustering,730,"DCA integration; I'd like to integrate DCA with scanpy and I need to ask some questions regarding that. . There are two use cases for DCA so far. One is denoising as a preprocessing step and using denoised matrix in downstream analyses, especially in the ones that require original feature space such as differential expression. This seems to be a better fit for the `preprocessing` package i.e. `sc.pp.dca(adata)` which overwrites `adata.X` with the denoised matrix. Users can use `copy=True` to keep adata.X of original matrix unchanged. The other use case is the low dimensional representations of cells produced by the encoder. This can also be used for the downstream analyses that do not require original feature space e.g. clustering, and visualization. This is more like `sc.tl.dca(adata)` which stores the new representation into `adata.obsm['X_dca']`. Optionally it can store dropout probabilities (pi matrix) and the dispersion, as well. However, having both sc.tl.dca and sc.pp.dca might be confusing for the users. Any suggestions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/142
https://github.com/scverse/scanpy/issues/142:4,integrability,integr,integration,4,"DCA integration; I'd like to integrate DCA with scanpy and I need to ask some questions regarding that. . There are two use cases for DCA so far. One is denoising as a preprocessing step and using denoised matrix in downstream analyses, especially in the ones that require original feature space such as differential expression. This seems to be a better fit for the `preprocessing` package i.e. `sc.pp.dca(adata)` which overwrites `adata.X` with the denoised matrix. Users can use `copy=True` to keep adata.X of original matrix unchanged. The other use case is the low dimensional representations of cells produced by the encoder. This can also be used for the downstream analyses that do not require original feature space e.g. clustering, and visualization. This is more like `sc.tl.dca(adata)` which stores the new representation into `adata.obsm['X_dca']`. Optionally it can store dropout probabilities (pi matrix) and the dispersion, as well. However, having both sc.tl.dca and sc.pp.dca might be confusing for the users. Any suggestions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/142
https://github.com/scverse/scanpy/issues/142:29,integrability,integr,integrate,29,"DCA integration; I'd like to integrate DCA with scanpy and I need to ask some questions regarding that. . There are two use cases for DCA so far. One is denoising as a preprocessing step and using denoised matrix in downstream analyses, especially in the ones that require original feature space such as differential expression. This seems to be a better fit for the `preprocessing` package i.e. `sc.pp.dca(adata)` which overwrites `adata.X` with the denoised matrix. Users can use `copy=True` to keep adata.X of original matrix unchanged. The other use case is the low dimensional representations of cells produced by the encoder. This can also be used for the downstream analyses that do not require original feature space e.g. clustering, and visualization. This is more like `sc.tl.dca(adata)` which stores the new representation into `adata.obsm['X_dca']`. Optionally it can store dropout probabilities (pi matrix) and the dispersion, as well. However, having both sc.tl.dca and sc.pp.dca might be confusing for the users. Any suggestions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/142
https://github.com/scverse/scanpy/issues/142:4,interoperability,integr,integration,4,"DCA integration; I'd like to integrate DCA with scanpy and I need to ask some questions regarding that. . There are two use cases for DCA so far. One is denoising as a preprocessing step and using denoised matrix in downstream analyses, especially in the ones that require original feature space such as differential expression. This seems to be a better fit for the `preprocessing` package i.e. `sc.pp.dca(adata)` which overwrites `adata.X` with the denoised matrix. Users can use `copy=True` to keep adata.X of original matrix unchanged. The other use case is the low dimensional representations of cells produced by the encoder. This can also be used for the downstream analyses that do not require original feature space e.g. clustering, and visualization. This is more like `sc.tl.dca(adata)` which stores the new representation into `adata.obsm['X_dca']`. Optionally it can store dropout probabilities (pi matrix) and the dispersion, as well. However, having both sc.tl.dca and sc.pp.dca might be confusing for the users. Any suggestions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/142
https://github.com/scverse/scanpy/issues/142:29,interoperability,integr,integrate,29,"DCA integration; I'd like to integrate DCA with scanpy and I need to ask some questions regarding that. . There are two use cases for DCA so far. One is denoising as a preprocessing step and using denoised matrix in downstream analyses, especially in the ones that require original feature space such as differential expression. This seems to be a better fit for the `preprocessing` package i.e. `sc.pp.dca(adata)` which overwrites `adata.X` with the denoised matrix. Users can use `copy=True` to keep adata.X of original matrix unchanged. The other use case is the low dimensional representations of cells produced by the encoder. This can also be used for the downstream analyses that do not require original feature space e.g. clustering, and visualization. This is more like `sc.tl.dca(adata)` which stores the new representation into `adata.obsm['X_dca']`. Optionally it can store dropout probabilities (pi matrix) and the dispersion, as well. However, having both sc.tl.dca and sc.pp.dca might be confusing for the users. Any suggestions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/142
https://github.com/scverse/scanpy/issues/142:4,modifiability,integr,integration,4,"DCA integration; I'd like to integrate DCA with scanpy and I need to ask some questions regarding that. . There are two use cases for DCA so far. One is denoising as a preprocessing step and using denoised matrix in downstream analyses, especially in the ones that require original feature space such as differential expression. This seems to be a better fit for the `preprocessing` package i.e. `sc.pp.dca(adata)` which overwrites `adata.X` with the denoised matrix. Users can use `copy=True` to keep adata.X of original matrix unchanged. The other use case is the low dimensional representations of cells produced by the encoder. This can also be used for the downstream analyses that do not require original feature space e.g. clustering, and visualization. This is more like `sc.tl.dca(adata)` which stores the new representation into `adata.obsm['X_dca']`. Optionally it can store dropout probabilities (pi matrix) and the dispersion, as well. However, having both sc.tl.dca and sc.pp.dca might be confusing for the users. Any suggestions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/142
https://github.com/scverse/scanpy/issues/142:29,modifiability,integr,integrate,29,"DCA integration; I'd like to integrate DCA with scanpy and I need to ask some questions regarding that. . There are two use cases for DCA so far. One is denoising as a preprocessing step and using denoised matrix in downstream analyses, especially in the ones that require original feature space such as differential expression. This seems to be a better fit for the `preprocessing` package i.e. `sc.pp.dca(adata)` which overwrites `adata.X` with the denoised matrix. Users can use `copy=True` to keep adata.X of original matrix unchanged. The other use case is the low dimensional representations of cells produced by the encoder. This can also be used for the downstream analyses that do not require original feature space e.g. clustering, and visualization. This is more like `sc.tl.dca(adata)` which stores the new representation into `adata.obsm['X_dca']`. Optionally it can store dropout probabilities (pi matrix) and the dispersion, as well. However, having both sc.tl.dca and sc.pp.dca might be confusing for the users. Any suggestions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/142
https://github.com/scverse/scanpy/issues/142:383,modifiability,pac,package,383,"DCA integration; I'd like to integrate DCA with scanpy and I need to ask some questions regarding that. . There are two use cases for DCA so far. One is denoising as a preprocessing step and using denoised matrix in downstream analyses, especially in the ones that require original feature space such as differential expression. This seems to be a better fit for the `preprocessing` package i.e. `sc.pp.dca(adata)` which overwrites `adata.X` with the denoised matrix. Users can use `copy=True` to keep adata.X of original matrix unchanged. The other use case is the low dimensional representations of cells produced by the encoder. This can also be used for the downstream analyses that do not require original feature space e.g. clustering, and visualization. This is more like `sc.tl.dca(adata)` which stores the new representation into `adata.obsm['X_dca']`. Optionally it can store dropout probabilities (pi matrix) and the dispersion, as well. However, having both sc.tl.dca and sc.pp.dca might be confusing for the users. Any suggestions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/142
https://github.com/scverse/scanpy/issues/142:4,reliability,integr,integration,4,"DCA integration; I'd like to integrate DCA with scanpy and I need to ask some questions regarding that. . There are two use cases for DCA so far. One is denoising as a preprocessing step and using denoised matrix in downstream analyses, especially in the ones that require original feature space such as differential expression. This seems to be a better fit for the `preprocessing` package i.e. `sc.pp.dca(adata)` which overwrites `adata.X` with the denoised matrix. Users can use `copy=True` to keep adata.X of original matrix unchanged. The other use case is the low dimensional representations of cells produced by the encoder. This can also be used for the downstream analyses that do not require original feature space e.g. clustering, and visualization. This is more like `sc.tl.dca(adata)` which stores the new representation into `adata.obsm['X_dca']`. Optionally it can store dropout probabilities (pi matrix) and the dispersion, as well. However, having both sc.tl.dca and sc.pp.dca might be confusing for the users. Any suggestions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/142
https://github.com/scverse/scanpy/issues/142:29,reliability,integr,integrate,29,"DCA integration; I'd like to integrate DCA with scanpy and I need to ask some questions regarding that. . There are two use cases for DCA so far. One is denoising as a preprocessing step and using denoised matrix in downstream analyses, especially in the ones that require original feature space such as differential expression. This seems to be a better fit for the `preprocessing` package i.e. `sc.pp.dca(adata)` which overwrites `adata.X` with the denoised matrix. Users can use `copy=True` to keep adata.X of original matrix unchanged. The other use case is the low dimensional representations of cells produced by the encoder. This can also be used for the downstream analyses that do not require original feature space e.g. clustering, and visualization. This is more like `sc.tl.dca(adata)` which stores the new representation into `adata.obsm['X_dca']`. Optionally it can store dropout probabilities (pi matrix) and the dispersion, as well. However, having both sc.tl.dca and sc.pp.dca might be confusing for the users. Any suggestions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/142
https://github.com/scverse/scanpy/issues/142:4,security,integr,integration,4,"DCA integration; I'd like to integrate DCA with scanpy and I need to ask some questions regarding that. . There are two use cases for DCA so far. One is denoising as a preprocessing step and using denoised matrix in downstream analyses, especially in the ones that require original feature space such as differential expression. This seems to be a better fit for the `preprocessing` package i.e. `sc.pp.dca(adata)` which overwrites `adata.X` with the denoised matrix. Users can use `copy=True` to keep adata.X of original matrix unchanged. The other use case is the low dimensional representations of cells produced by the encoder. This can also be used for the downstream analyses that do not require original feature space e.g. clustering, and visualization. This is more like `sc.tl.dca(adata)` which stores the new representation into `adata.obsm['X_dca']`. Optionally it can store dropout probabilities (pi matrix) and the dispersion, as well. However, having both sc.tl.dca and sc.pp.dca might be confusing for the users. Any suggestions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/142
https://github.com/scverse/scanpy/issues/142:29,security,integr,integrate,29,"DCA integration; I'd like to integrate DCA with scanpy and I need to ask some questions regarding that. . There are two use cases for DCA so far. One is denoising as a preprocessing step and using denoised matrix in downstream analyses, especially in the ones that require original feature space such as differential expression. This seems to be a better fit for the `preprocessing` package i.e. `sc.pp.dca(adata)` which overwrites `adata.X` with the denoised matrix. Users can use `copy=True` to keep adata.X of original matrix unchanged. The other use case is the low dimensional representations of cells produced by the encoder. This can also be used for the downstream analyses that do not require original feature space e.g. clustering, and visualization. This is more like `sc.tl.dca(adata)` which stores the new representation into `adata.obsm['X_dca']`. Optionally it can store dropout probabilities (pi matrix) and the dispersion, as well. However, having both sc.tl.dca and sc.pp.dca might be confusing for the users. Any suggestions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/142
https://github.com/scverse/scanpy/issues/142:4,testability,integr,integration,4,"DCA integration; I'd like to integrate DCA with scanpy and I need to ask some questions regarding that. . There are two use cases for DCA so far. One is denoising as a preprocessing step and using denoised matrix in downstream analyses, especially in the ones that require original feature space such as differential expression. This seems to be a better fit for the `preprocessing` package i.e. `sc.pp.dca(adata)` which overwrites `adata.X` with the denoised matrix. Users can use `copy=True` to keep adata.X of original matrix unchanged. The other use case is the low dimensional representations of cells produced by the encoder. This can also be used for the downstream analyses that do not require original feature space e.g. clustering, and visualization. This is more like `sc.tl.dca(adata)` which stores the new representation into `adata.obsm['X_dca']`. Optionally it can store dropout probabilities (pi matrix) and the dispersion, as well. However, having both sc.tl.dca and sc.pp.dca might be confusing for the users. Any suggestions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/142
https://github.com/scverse/scanpy/issues/142:29,testability,integr,integrate,29,"DCA integration; I'd like to integrate DCA with scanpy and I need to ask some questions regarding that. . There are two use cases for DCA so far. One is denoising as a preprocessing step and using denoised matrix in downstream analyses, especially in the ones that require original feature space such as differential expression. This seems to be a better fit for the `preprocessing` package i.e. `sc.pp.dca(adata)` which overwrites `adata.X` with the denoised matrix. Users can use `copy=True` to keep adata.X of original matrix unchanged. The other use case is the low dimensional representations of cells produced by the encoder. This can also be used for the downstream analyses that do not require original feature space e.g. clustering, and visualization. This is more like `sc.tl.dca(adata)` which stores the new representation into `adata.obsm['X_dca']`. Optionally it can store dropout probabilities (pi matrix) and the dispersion, as well. However, having both sc.tl.dca and sc.pp.dca might be confusing for the users. Any suggestions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/142
https://github.com/scverse/scanpy/issues/142:468,usability,User,Users,468,"DCA integration; I'd like to integrate DCA with scanpy and I need to ask some questions regarding that. . There are two use cases for DCA so far. One is denoising as a preprocessing step and using denoised matrix in downstream analyses, especially in the ones that require original feature space such as differential expression. This seems to be a better fit for the `preprocessing` package i.e. `sc.pp.dca(adata)` which overwrites `adata.X` with the denoised matrix. Users can use `copy=True` to keep adata.X of original matrix unchanged. The other use case is the low dimensional representations of cells produced by the encoder. This can also be used for the downstream analyses that do not require original feature space e.g. clustering, and visualization. This is more like `sc.tl.dca(adata)` which stores the new representation into `adata.obsm['X_dca']`. Optionally it can store dropout probabilities (pi matrix) and the dispersion, as well. However, having both sc.tl.dca and sc.pp.dca might be confusing for the users. Any suggestions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/142
https://github.com/scverse/scanpy/issues/142:746,usability,visual,visualization,746,"DCA integration; I'd like to integrate DCA with scanpy and I need to ask some questions regarding that. . There are two use cases for DCA so far. One is denoising as a preprocessing step and using denoised matrix in downstream analyses, especially in the ones that require original feature space such as differential expression. This seems to be a better fit for the `preprocessing` package i.e. `sc.pp.dca(adata)` which overwrites `adata.X` with the denoised matrix. Users can use `copy=True` to keep adata.X of original matrix unchanged. The other use case is the low dimensional representations of cells produced by the encoder. This can also be used for the downstream analyses that do not require original feature space e.g. clustering, and visualization. This is more like `sc.tl.dca(adata)` which stores the new representation into `adata.obsm['X_dca']`. Optionally it can store dropout probabilities (pi matrix) and the dispersion, as well. However, having both sc.tl.dca and sc.pp.dca might be confusing for the users. Any suggestions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/142
https://github.com/scverse/scanpy/issues/142:1021,usability,user,users,1021,"DCA integration; I'd like to integrate DCA with scanpy and I need to ask some questions regarding that. . There are two use cases for DCA so far. One is denoising as a preprocessing step and using denoised matrix in downstream analyses, especially in the ones that require original feature space such as differential expression. This seems to be a better fit for the `preprocessing` package i.e. `sc.pp.dca(adata)` which overwrites `adata.X` with the denoised matrix. Users can use `copy=True` to keep adata.X of original matrix unchanged. The other use case is the low dimensional representations of cells produced by the encoder. This can also be used for the downstream analyses that do not require original feature space e.g. clustering, and visualization. This is more like `sc.tl.dca(adata)` which stores the new representation into `adata.obsm['X_dca']`. Optionally it can store dropout probabilities (pi matrix) and the dispersion, as well. However, having both sc.tl.dca and sc.pp.dca might be confusing for the users. Any suggestions?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/142
https://github.com/scverse/scanpy/issues/143:125,availability,error,error,125,could not install louvain via conda ; . I tried to install louvain through conda. `conda install -c vtraag louvain`. but got error message:. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. - python-igraph[version='>=0.7.1.0']. However I could install it by. `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks! [https://scanpy.readthedocs.io/en/latest/installation.html](url).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143
https://github.com/scverse/scanpy/issues/143:224,availability,avail,available,224,could not install louvain via conda ; . I tried to install louvain through conda. `conda install -c vtraag louvain`. but got error message:. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. - python-igraph[version='>=0.7.1.0']. However I could install it by. `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks! [https://scanpy.readthedocs.io/en/latest/installation.html](url).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143
https://github.com/scverse/scanpy/issues/143:10,deployability,instal,install,10,could not install louvain via conda ; . I tried to install louvain through conda. `conda install -c vtraag louvain`. but got error message:. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. - python-igraph[version='>=0.7.1.0']. However I could install it by. `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks! [https://scanpy.readthedocs.io/en/latest/installation.html](url).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143
https://github.com/scverse/scanpy/issues/143:51,deployability,instal,install,51,could not install louvain via conda ; . I tried to install louvain through conda. `conda install -c vtraag louvain`. but got error message:. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. - python-igraph[version='>=0.7.1.0']. However I could install it by. `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks! [https://scanpy.readthedocs.io/en/latest/installation.html](url).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143
https://github.com/scverse/scanpy/issues/143:89,deployability,instal,install,89,could not install louvain via conda ; . I tried to install louvain through conda. `conda install -c vtraag louvain`. but got error message:. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. - python-igraph[version='>=0.7.1.0']. However I could install it by. `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks! [https://scanpy.readthedocs.io/en/latest/installation.html](url).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143
https://github.com/scverse/scanpy/issues/143:162,deployability,fail,failed,162,could not install louvain via conda ; . I tried to install louvain through conda. `conda install -c vtraag louvain`. but got error message:. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. - python-igraph[version='>=0.7.1.0']. However I could install it by. `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks! [https://scanpy.readthedocs.io/en/latest/installation.html](url).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143
https://github.com/scverse/scanpy/issues/143:285,deployability,version,version,285,could not install louvain via conda ; . I tried to install louvain through conda. `conda install -c vtraag louvain`. but got error message:. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. - python-igraph[version='>=0.7.1.0']. However I could install it by. `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks! [https://scanpy.readthedocs.io/en/latest/installation.html](url).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143
https://github.com/scverse/scanpy/issues/143:323,deployability,instal,install,323,could not install louvain via conda ; . I tried to install louvain through conda. `conda install -c vtraag louvain`. but got error message:. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. - python-igraph[version='>=0.7.1.0']. However I could install it by. `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks! [https://scanpy.readthedocs.io/en/latest/installation.html](url).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143
https://github.com/scverse/scanpy/issues/143:345,deployability,instal,install,345,could not install louvain via conda ; . I tried to install louvain through conda. `conda install -c vtraag louvain`. but got error message:. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. - python-igraph[version='>=0.7.1.0']. However I could install it by. `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks! [https://scanpy.readthedocs.io/en/latest/installation.html](url).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143
https://github.com/scverse/scanpy/issues/143:393,deployability,updat,update,393,could not install louvain via conda ; . I tried to install louvain through conda. `conda install -c vtraag louvain`. but got error message:. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. - python-igraph[version='>=0.7.1.0']. However I could install it by. `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks! [https://scanpy.readthedocs.io/en/latest/installation.html](url).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143
https://github.com/scverse/scanpy/issues/143:468,deployability,instal,installation,468,could not install louvain via conda ; . I tried to install louvain through conda. `conda install -c vtraag louvain`. but got error message:. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. - python-igraph[version='>=0.7.1.0']. However I could install it by. `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks! [https://scanpy.readthedocs.io/en/latest/installation.html](url).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143
https://github.com/scverse/scanpy/issues/143:239,energy efficiency,current,current,239,could not install louvain via conda ; . I tried to install louvain through conda. `conda install -c vtraag louvain`. but got error message:. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. - python-igraph[version='>=0.7.1.0']. However I could install it by. `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks! [https://scanpy.readthedocs.io/en/latest/installation.html](url).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143
https://github.com/scverse/scanpy/issues/143:131,integrability,messag,message,131,could not install louvain via conda ; . I tried to install louvain through conda. `conda install -c vtraag louvain`. but got error message:. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. - python-igraph[version='>=0.7.1.0']. However I could install it by. `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks! [https://scanpy.readthedocs.io/en/latest/installation.html](url).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143
https://github.com/scverse/scanpy/issues/143:285,integrability,version,version,285,could not install louvain via conda ; . I tried to install louvain through conda. `conda install -c vtraag louvain`. but got error message:. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. - python-igraph[version='>=0.7.1.0']. However I could install it by. `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks! [https://scanpy.readthedocs.io/en/latest/installation.html](url).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143
https://github.com/scverse/scanpy/issues/143:131,interoperability,messag,message,131,could not install louvain via conda ; . I tried to install louvain through conda. `conda install -c vtraag louvain`. but got error message:. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. - python-igraph[version='>=0.7.1.0']. However I could install it by. `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks! [https://scanpy.readthedocs.io/en/latest/installation.html](url).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143
https://github.com/scverse/scanpy/issues/143:170,modifiability,Pac,PackagesNotFoundError,170,could not install louvain via conda ; . I tried to install louvain through conda. `conda install -c vtraag louvain`. but got error message:. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. - python-igraph[version='>=0.7.1.0']. However I could install it by. `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks! [https://scanpy.readthedocs.io/en/latest/installation.html](url).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143
https://github.com/scverse/scanpy/issues/143:207,modifiability,pac,packages,207,could not install louvain via conda ; . I tried to install louvain through conda. `conda install -c vtraag louvain`. but got error message:. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. - python-igraph[version='>=0.7.1.0']. However I could install it by. `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks! [https://scanpy.readthedocs.io/en/latest/installation.html](url).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143
https://github.com/scverse/scanpy/issues/143:285,modifiability,version,version,285,could not install louvain via conda ; . I tried to install louvain through conda. `conda install -c vtraag louvain`. but got error message:. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. - python-igraph[version='>=0.7.1.0']. However I could install it by. `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks! [https://scanpy.readthedocs.io/en/latest/installation.html](url).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143
https://github.com/scverse/scanpy/issues/143:125,performance,error,error,125,could not install louvain via conda ; . I tried to install louvain through conda. `conda install -c vtraag louvain`. but got error message:. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. - python-igraph[version='>=0.7.1.0']. However I could install it by. `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks! [https://scanpy.readthedocs.io/en/latest/installation.html](url).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143
https://github.com/scverse/scanpy/issues/143:162,reliability,fail,failed,162,could not install louvain via conda ; . I tried to install louvain through conda. `conda install -c vtraag louvain`. but got error message:. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. - python-igraph[version='>=0.7.1.0']. However I could install it by. `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks! [https://scanpy.readthedocs.io/en/latest/installation.html](url).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143
https://github.com/scverse/scanpy/issues/143:224,reliability,availab,available,224,could not install louvain via conda ; . I tried to install louvain through conda. `conda install -c vtraag louvain`. but got error message:. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. - python-igraph[version='>=0.7.1.0']. However I could install it by. `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks! [https://scanpy.readthedocs.io/en/latest/installation.html](url).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143
https://github.com/scverse/scanpy/issues/143:125,safety,error,error,125,could not install louvain via conda ; . I tried to install louvain through conda. `conda install -c vtraag louvain`. but got error message:. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. - python-igraph[version='>=0.7.1.0']. However I could install it by. `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks! [https://scanpy.readthedocs.io/en/latest/installation.html](url).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143
https://github.com/scverse/scanpy/issues/143:224,safety,avail,available,224,could not install louvain via conda ; . I tried to install louvain through conda. `conda install -c vtraag louvain`. but got error message:. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. - python-igraph[version='>=0.7.1.0']. However I could install it by. `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks! [https://scanpy.readthedocs.io/en/latest/installation.html](url).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143
https://github.com/scverse/scanpy/issues/143:393,safety,updat,update,393,could not install louvain via conda ; . I tried to install louvain through conda. `conda install -c vtraag louvain`. but got error message:. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. - python-igraph[version='>=0.7.1.0']. However I could install it by. `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks! [https://scanpy.readthedocs.io/en/latest/installation.html](url).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143
https://github.com/scverse/scanpy/issues/143:224,security,availab,available,224,could not install louvain via conda ; . I tried to install louvain through conda. `conda install -c vtraag louvain`. but got error message:. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. - python-igraph[version='>=0.7.1.0']. However I could install it by. `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks! [https://scanpy.readthedocs.io/en/latest/installation.html](url).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143
https://github.com/scverse/scanpy/issues/143:393,security,updat,update,393,could not install louvain via conda ; . I tried to install louvain through conda. `conda install -c vtraag louvain`. but got error message:. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. - python-igraph[version='>=0.7.1.0']. However I could install it by. `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks! [https://scanpy.readthedocs.io/en/latest/installation.html](url).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143
https://github.com/scverse/scanpy/issues/143:125,usability,error,error,125,could not install louvain via conda ; . I tried to install louvain through conda. `conda install -c vtraag louvain`. but got error message:. Solving environment: failed. PackagesNotFoundError: The following packages are not available from current channels:. - louvain. - python-igraph[version='>=0.7.1.0']. However I could install it by. `conda install -c conda-forge louvain`. Can you please update it on the webpage. Thanks! [https://scanpy.readthedocs.io/en/latest/installation.html](url).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/143
https://github.com/scverse/scanpy/issues/144:19,availability,cluster,clustering,19,"How to get Louvain clustering labels from adata/scanpy; I am trying to get clustering labels from Louvain. I followed the Seurat-like notebook (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I am able to run the clustering and visualize it on tSNE, with:. ```python. >>> sc.tl.louvain(adata). running Louvain clustering. using the ""louvain"" package of Traag (2017). finished (0:00:00.11) --> found 8 clusters and added. 'louvain', the cluster labels (adata.obs, categorical). >>> sc.pl.tsne(adata, color='louvain'). ```. However, I cannot find the clustering labels under adata:. ```. AnnData object with n_obs × n_vars = 1320 × 5014 . uns: 'pca'. obsm: 'X_pca', 'X_tsne'. varm: 'PCs'. ```. I tried looking directly into obs, obsm etc., but I didn't find any label. But the plots work out correctly. How is it possible? I have the default louvain parameters, so it should be updated in-place.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/144
https://github.com/scverse/scanpy/issues/144:75,availability,cluster,clustering,75,"How to get Louvain clustering labels from adata/scanpy; I am trying to get clustering labels from Louvain. I followed the Seurat-like notebook (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I am able to run the clustering and visualize it on tSNE, with:. ```python. >>> sc.tl.louvain(adata). running Louvain clustering. using the ""louvain"" package of Traag (2017). finished (0:00:00.11) --> found 8 clusters and added. 'louvain', the cluster labels (adata.obs, categorical). >>> sc.pl.tsne(adata, color='louvain'). ```. However, I cannot find the clustering labels under adata:. ```. AnnData object with n_obs × n_vars = 1320 × 5014 . uns: 'pca'. obsm: 'X_pca', 'X_tsne'. varm: 'PCs'. ```. I tried looking directly into obs, obsm etc., but I didn't find any label. But the plots work out correctly. How is it possible? I have the default louvain parameters, so it should be updated in-place.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/144
https://github.com/scverse/scanpy/issues/144:264,availability,cluster,clustering,264,"How to get Louvain clustering labels from adata/scanpy; I am trying to get clustering labels from Louvain. I followed the Seurat-like notebook (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I am able to run the clustering and visualize it on tSNE, with:. ```python. >>> sc.tl.louvain(adata). running Louvain clustering. using the ""louvain"" package of Traag (2017). finished (0:00:00.11) --> found 8 clusters and added. 'louvain', the cluster labels (adata.obs, categorical). >>> sc.pl.tsne(adata, color='louvain'). ```. However, I cannot find the clustering labels under adata:. ```. AnnData object with n_obs × n_vars = 1320 × 5014 . uns: 'pca'. obsm: 'X_pca', 'X_tsne'. varm: 'PCs'. ```. I tried looking directly into obs, obsm etc., but I didn't find any label. But the plots work out correctly. How is it possible? I have the default louvain parameters, so it should be updated in-place.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/144
https://github.com/scverse/scanpy/issues/144:361,availability,cluster,clustering,361,"How to get Louvain clustering labels from adata/scanpy; I am trying to get clustering labels from Louvain. I followed the Seurat-like notebook (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I am able to run the clustering and visualize it on tSNE, with:. ```python. >>> sc.tl.louvain(adata). running Louvain clustering. using the ""louvain"" package of Traag (2017). finished (0:00:00.11) --> found 8 clusters and added. 'louvain', the cluster labels (adata.obs, categorical). >>> sc.pl.tsne(adata, color='louvain'). ```. However, I cannot find the clustering labels under adata:. ```. AnnData object with n_obs × n_vars = 1320 × 5014 . uns: 'pca'. obsm: 'X_pca', 'X_tsne'. varm: 'PCs'. ```. I tried looking directly into obs, obsm etc., but I didn't find any label. But the plots work out correctly. How is it possible? I have the default louvain parameters, so it should be updated in-place.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/144
https://github.com/scverse/scanpy/issues/144:452,availability,cluster,clusters,452,"How to get Louvain clustering labels from adata/scanpy; I am trying to get clustering labels from Louvain. I followed the Seurat-like notebook (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I am able to run the clustering and visualize it on tSNE, with:. ```python. >>> sc.tl.louvain(adata). running Louvain clustering. using the ""louvain"" package of Traag (2017). finished (0:00:00.11) --> found 8 clusters and added. 'louvain', the cluster labels (adata.obs, categorical). >>> sc.pl.tsne(adata, color='louvain'). ```. However, I cannot find the clustering labels under adata:. ```. AnnData object with n_obs × n_vars = 1320 × 5014 . uns: 'pca'. obsm: 'X_pca', 'X_tsne'. varm: 'PCs'. ```. I tried looking directly into obs, obsm etc., but I didn't find any label. But the plots work out correctly. How is it possible? I have the default louvain parameters, so it should be updated in-place.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/144
https://github.com/scverse/scanpy/issues/144:487,availability,cluster,cluster,487,"How to get Louvain clustering labels from adata/scanpy; I am trying to get clustering labels from Louvain. I followed the Seurat-like notebook (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I am able to run the clustering and visualize it on tSNE, with:. ```python. >>> sc.tl.louvain(adata). running Louvain clustering. using the ""louvain"" package of Traag (2017). finished (0:00:00.11) --> found 8 clusters and added. 'louvain', the cluster labels (adata.obs, categorical). >>> sc.pl.tsne(adata, color='louvain'). ```. However, I cannot find the clustering labels under adata:. ```. AnnData object with n_obs × n_vars = 1320 × 5014 . uns: 'pca'. obsm: 'X_pca', 'X_tsne'. varm: 'PCs'. ```. I tried looking directly into obs, obsm etc., but I didn't find any label. But the plots work out correctly. How is it possible? I have the default louvain parameters, so it should be updated in-place.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/144
https://github.com/scverse/scanpy/issues/144:600,availability,cluster,clustering,600,"How to get Louvain clustering labels from adata/scanpy; I am trying to get clustering labels from Louvain. I followed the Seurat-like notebook (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I am able to run the clustering and visualize it on tSNE, with:. ```python. >>> sc.tl.louvain(adata). running Louvain clustering. using the ""louvain"" package of Traag (2017). finished (0:00:00.11) --> found 8 clusters and added. 'louvain', the cluster labels (adata.obs, categorical). >>> sc.pl.tsne(adata, color='louvain'). ```. However, I cannot find the clustering labels under adata:. ```. AnnData object with n_obs × n_vars = 1320 × 5014 . uns: 'pca'. obsm: 'X_pca', 'X_tsne'. varm: 'PCs'. ```. I tried looking directly into obs, obsm etc., but I didn't find any label. But the plots work out correctly. How is it possible? I have the default louvain parameters, so it should be updated in-place.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/144
https://github.com/scverse/scanpy/issues/144:19,deployability,cluster,clustering,19,"How to get Louvain clustering labels from adata/scanpy; I am trying to get clustering labels from Louvain. I followed the Seurat-like notebook (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I am able to run the clustering and visualize it on tSNE, with:. ```python. >>> sc.tl.louvain(adata). running Louvain clustering. using the ""louvain"" package of Traag (2017). finished (0:00:00.11) --> found 8 clusters and added. 'louvain', the cluster labels (adata.obs, categorical). >>> sc.pl.tsne(adata, color='louvain'). ```. However, I cannot find the clustering labels under adata:. ```. AnnData object with n_obs × n_vars = 1320 × 5014 . uns: 'pca'. obsm: 'X_pca', 'X_tsne'. varm: 'PCs'. ```. I tried looking directly into obs, obsm etc., but I didn't find any label. But the plots work out correctly. How is it possible? I have the default louvain parameters, so it should be updated in-place.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/144
https://github.com/scverse/scanpy/issues/144:75,deployability,cluster,clustering,75,"How to get Louvain clustering labels from adata/scanpy; I am trying to get clustering labels from Louvain. I followed the Seurat-like notebook (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I am able to run the clustering and visualize it on tSNE, with:. ```python. >>> sc.tl.louvain(adata). running Louvain clustering. using the ""louvain"" package of Traag (2017). finished (0:00:00.11) --> found 8 clusters and added. 'louvain', the cluster labels (adata.obs, categorical). >>> sc.pl.tsne(adata, color='louvain'). ```. However, I cannot find the clustering labels under adata:. ```. AnnData object with n_obs × n_vars = 1320 × 5014 . uns: 'pca'. obsm: 'X_pca', 'X_tsne'. varm: 'PCs'. ```. I tried looking directly into obs, obsm etc., but I didn't find any label. But the plots work out correctly. How is it possible? I have the default louvain parameters, so it should be updated in-place.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/144
https://github.com/scverse/scanpy/issues/144:264,deployability,cluster,clustering,264,"How to get Louvain clustering labels from adata/scanpy; I am trying to get clustering labels from Louvain. I followed the Seurat-like notebook (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I am able to run the clustering and visualize it on tSNE, with:. ```python. >>> sc.tl.louvain(adata). running Louvain clustering. using the ""louvain"" package of Traag (2017). finished (0:00:00.11) --> found 8 clusters and added. 'louvain', the cluster labels (adata.obs, categorical). >>> sc.pl.tsne(adata, color='louvain'). ```. However, I cannot find the clustering labels under adata:. ```. AnnData object with n_obs × n_vars = 1320 × 5014 . uns: 'pca'. obsm: 'X_pca', 'X_tsne'. varm: 'PCs'. ```. I tried looking directly into obs, obsm etc., but I didn't find any label. But the plots work out correctly. How is it possible? I have the default louvain parameters, so it should be updated in-place.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/144
https://github.com/scverse/scanpy/issues/144:361,deployability,cluster,clustering,361,"How to get Louvain clustering labels from adata/scanpy; I am trying to get clustering labels from Louvain. I followed the Seurat-like notebook (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I am able to run the clustering and visualize it on tSNE, with:. ```python. >>> sc.tl.louvain(adata). running Louvain clustering. using the ""louvain"" package of Traag (2017). finished (0:00:00.11) --> found 8 clusters and added. 'louvain', the cluster labels (adata.obs, categorical). >>> sc.pl.tsne(adata, color='louvain'). ```. However, I cannot find the clustering labels under adata:. ```. AnnData object with n_obs × n_vars = 1320 × 5014 . uns: 'pca'. obsm: 'X_pca', 'X_tsne'. varm: 'PCs'. ```. I tried looking directly into obs, obsm etc., but I didn't find any label. But the plots work out correctly. How is it possible? I have the default louvain parameters, so it should be updated in-place.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/144
https://github.com/scverse/scanpy/issues/144:452,deployability,cluster,clusters,452,"How to get Louvain clustering labels from adata/scanpy; I am trying to get clustering labels from Louvain. I followed the Seurat-like notebook (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I am able to run the clustering and visualize it on tSNE, with:. ```python. >>> sc.tl.louvain(adata). running Louvain clustering. using the ""louvain"" package of Traag (2017). finished (0:00:00.11) --> found 8 clusters and added. 'louvain', the cluster labels (adata.obs, categorical). >>> sc.pl.tsne(adata, color='louvain'). ```. However, I cannot find the clustering labels under adata:. ```. AnnData object with n_obs × n_vars = 1320 × 5014 . uns: 'pca'. obsm: 'X_pca', 'X_tsne'. varm: 'PCs'. ```. I tried looking directly into obs, obsm etc., but I didn't find any label. But the plots work out correctly. How is it possible? I have the default louvain parameters, so it should be updated in-place.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/144
https://github.com/scverse/scanpy/issues/144:487,deployability,cluster,cluster,487,"How to get Louvain clustering labels from adata/scanpy; I am trying to get clustering labels from Louvain. I followed the Seurat-like notebook (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I am able to run the clustering and visualize it on tSNE, with:. ```python. >>> sc.tl.louvain(adata). running Louvain clustering. using the ""louvain"" package of Traag (2017). finished (0:00:00.11) --> found 8 clusters and added. 'louvain', the cluster labels (adata.obs, categorical). >>> sc.pl.tsne(adata, color='louvain'). ```. However, I cannot find the clustering labels under adata:. ```. AnnData object with n_obs × n_vars = 1320 × 5014 . uns: 'pca'. obsm: 'X_pca', 'X_tsne'. varm: 'PCs'. ```. I tried looking directly into obs, obsm etc., but I didn't find any label. But the plots work out correctly. How is it possible? I have the default louvain parameters, so it should be updated in-place.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/144
https://github.com/scverse/scanpy/issues/144:600,deployability,cluster,clustering,600,"How to get Louvain clustering labels from adata/scanpy; I am trying to get clustering labels from Louvain. I followed the Seurat-like notebook (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I am able to run the clustering and visualize it on tSNE, with:. ```python. >>> sc.tl.louvain(adata). running Louvain clustering. using the ""louvain"" package of Traag (2017). finished (0:00:00.11) --> found 8 clusters and added. 'louvain', the cluster labels (adata.obs, categorical). >>> sc.pl.tsne(adata, color='louvain'). ```. However, I cannot find the clustering labels under adata:. ```. AnnData object with n_obs × n_vars = 1320 × 5014 . uns: 'pca'. obsm: 'X_pca', 'X_tsne'. varm: 'PCs'. ```. I tried looking directly into obs, obsm etc., but I didn't find any label. But the plots work out correctly. How is it possible? I have the default louvain parameters, so it should be updated in-place.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/144
https://github.com/scverse/scanpy/issues/144:927,deployability,updat,updated,927,"How to get Louvain clustering labels from adata/scanpy; I am trying to get clustering labels from Louvain. I followed the Seurat-like notebook (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I am able to run the clustering and visualize it on tSNE, with:. ```python. >>> sc.tl.louvain(adata). running Louvain clustering. using the ""louvain"" package of Traag (2017). finished (0:00:00.11) --> found 8 clusters and added. 'louvain', the cluster labels (adata.obs, categorical). >>> sc.pl.tsne(adata, color='louvain'). ```. However, I cannot find the clustering labels under adata:. ```. AnnData object with n_obs × n_vars = 1320 × 5014 . uns: 'pca'. obsm: 'X_pca', 'X_tsne'. varm: 'PCs'. ```. I tried looking directly into obs, obsm etc., but I didn't find any label. But the plots work out correctly. How is it possible? I have the default louvain parameters, so it should be updated in-place.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/144
https://github.com/scverse/scanpy/issues/144:393,modifiability,pac,package,393,"How to get Louvain clustering labels from adata/scanpy; I am trying to get clustering labels from Louvain. I followed the Seurat-like notebook (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I am able to run the clustering and visualize it on tSNE, with:. ```python. >>> sc.tl.louvain(adata). running Louvain clustering. using the ""louvain"" package of Traag (2017). finished (0:00:00.11) --> found 8 clusters and added. 'louvain', the cluster labels (adata.obs, categorical). >>> sc.pl.tsne(adata, color='louvain'). ```. However, I cannot find the clustering labels under adata:. ```. AnnData object with n_obs × n_vars = 1320 × 5014 . uns: 'pca'. obsm: 'X_pca', 'X_tsne'. varm: 'PCs'. ```. I tried looking directly into obs, obsm etc., but I didn't find any label. But the plots work out correctly. How is it possible? I have the default louvain parameters, so it should be updated in-place.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/144
https://github.com/scverse/scanpy/issues/144:899,modifiability,paramet,parameters,899,"How to get Louvain clustering labels from adata/scanpy; I am trying to get clustering labels from Louvain. I followed the Seurat-like notebook (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I am able to run the clustering and visualize it on tSNE, with:. ```python. >>> sc.tl.louvain(adata). running Louvain clustering. using the ""louvain"" package of Traag (2017). finished (0:00:00.11) --> found 8 clusters and added. 'louvain', the cluster labels (adata.obs, categorical). >>> sc.pl.tsne(adata, color='louvain'). ```. However, I cannot find the clustering labels under adata:. ```. AnnData object with n_obs × n_vars = 1320 × 5014 . uns: 'pca'. obsm: 'X_pca', 'X_tsne'. varm: 'PCs'. ```. I tried looking directly into obs, obsm etc., but I didn't find any label. But the plots work out correctly. How is it possible? I have the default louvain parameters, so it should be updated in-place.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/144
https://github.com/scverse/scanpy/issues/144:927,safety,updat,updated,927,"How to get Louvain clustering labels from adata/scanpy; I am trying to get clustering labels from Louvain. I followed the Seurat-like notebook (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I am able to run the clustering and visualize it on tSNE, with:. ```python. >>> sc.tl.louvain(adata). running Louvain clustering. using the ""louvain"" package of Traag (2017). finished (0:00:00.11) --> found 8 clusters and added. 'louvain', the cluster labels (adata.obs, categorical). >>> sc.pl.tsne(adata, color='louvain'). ```. However, I cannot find the clustering labels under adata:. ```. AnnData object with n_obs × n_vars = 1320 × 5014 . uns: 'pca'. obsm: 'X_pca', 'X_tsne'. varm: 'PCs'. ```. I tried looking directly into obs, obsm etc., but I didn't find any label. But the plots work out correctly. How is it possible? I have the default louvain parameters, so it should be updated in-place.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/144
https://github.com/scverse/scanpy/issues/144:927,security,updat,updated,927,"How to get Louvain clustering labels from adata/scanpy; I am trying to get clustering labels from Louvain. I followed the Seurat-like notebook (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I am able to run the clustering and visualize it on tSNE, with:. ```python. >>> sc.tl.louvain(adata). running Louvain clustering. using the ""louvain"" package of Traag (2017). finished (0:00:00.11) --> found 8 clusters and added. 'louvain', the cluster labels (adata.obs, categorical). >>> sc.pl.tsne(adata, color='louvain'). ```. However, I cannot find the clustering labels under adata:. ```. AnnData object with n_obs × n_vars = 1320 × 5014 . uns: 'pca'. obsm: 'X_pca', 'X_tsne'. varm: 'PCs'. ```. I tried looking directly into obs, obsm etc., but I didn't find any label. But the plots work out correctly. How is it possible? I have the default louvain parameters, so it should be updated in-place.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/144
https://github.com/scverse/scanpy/issues/144:279,usability,visual,visualize,279,"How to get Louvain clustering labels from adata/scanpy; I am trying to get clustering labels from Louvain. I followed the Seurat-like notebook (https://nbviewer.jupyter.org/github/theislab/scanpy_usage/blob/master/170505_seurat/seurat.ipynb). I am able to run the clustering and visualize it on tSNE, with:. ```python. >>> sc.tl.louvain(adata). running Louvain clustering. using the ""louvain"" package of Traag (2017). finished (0:00:00.11) --> found 8 clusters and added. 'louvain', the cluster labels (adata.obs, categorical). >>> sc.pl.tsne(adata, color='louvain'). ```. However, I cannot find the clustering labels under adata:. ```. AnnData object with n_obs × n_vars = 1320 × 5014 . uns: 'pca'. obsm: 'X_pca', 'X_tsne'. varm: 'PCs'. ```. I tried looking directly into obs, obsm etc., but I didn't find any label. But the plots work out correctly. How is it possible? I have the default louvain parameters, so it should be updated in-place.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/144
https://github.com/scverse/scanpy/issues/145:377,deployability,automat,automatically,377,"Filename prefix; When I use `pl.tsne` with autosave, the figure is saved with the same name `tsne.png`, independent of the data displayed (for example, it has the same name either if you are displaying the colors from louvain in one single suplots, or the expression of several marker genes in different subplots). Is there a way to define a prefix for the figure, in order to automatically execute `pl.tsne` without overwriting the last tsne result? Figure directory setting is not useful in this case, since I may want to display several tsne for the same project.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/145
https://github.com/scverse/scanpy/issues/145:304,integrability,sub,subplots,304,"Filename prefix; When I use `pl.tsne` with autosave, the figure is saved with the same name `tsne.png`, independent of the data displayed (for example, it has the same name either if you are displaying the colors from louvain in one single suplots, or the expression of several marker genes in different subplots). Is there a way to define a prefix for the figure, in order to automatically execute `pl.tsne` without overwriting the last tsne result? Figure directory setting is not useful in this case, since I may want to display several tsne for the same project.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/145
https://github.com/scverse/scanpy/issues/145:377,testability,automat,automatically,377,"Filename prefix; When I use `pl.tsne` with autosave, the figure is saved with the same name `tsne.png`, independent of the data displayed (for example, it has the same name either if you are displaying the colors from louvain in one single suplots, or the expression of several marker genes in different subplots). Is there a way to define a prefix for the figure, in order to automatically execute `pl.tsne` without overwriting the last tsne result? Figure directory setting is not useful in this case, since I may want to display several tsne for the same project.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/145
https://github.com/scverse/scanpy/issues/146:134,availability,cluster,clustering,134,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:134,deployability,cluster,clustering,134,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:857,deployability,api,api,857,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:1055,deployability,api,api,1055,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:1157,deployability,instal,installed,1157,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:1197,deployability,version,versions,1197,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:0,energy efficiency,Load,Loading,0,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:50,energy efficiency,load,loading,50,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:295,energy efficiency,load,loading,295,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:459,energy efficiency,load,load,459,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:857,integrability,api,api,857,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:1055,integrability,api,api,1055,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:1197,integrability,version,versions,1197,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:857,interoperability,api,api,857,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:1055,interoperability,api,api,1055,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:1197,modifiability,version,versions,1197,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:1349,modifiability,pac,package,1349,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:0,performance,Load,Loading,0,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:38,performance,memor,memory,38,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:50,performance,load,loading,50,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:295,performance,load,loading,295,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:422,performance,disk,disk,422,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:459,performance,load,load,459,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:514,performance,memor,memory,514,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:604,performance,memor,memory,604,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:647,performance,memor,memory,647,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:38,usability,memor,memory,38,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:280,usability,behavi,behavior,280,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:514,usability,memor,memory,514,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:604,usability,memor,memory,604,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:647,usability,memor,memory,647,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/issues/146:1289,usability,learn,learn,1289,"Loading from `.h5ad` taking much more memory than loading same dataset from 10x `.h5`; I was just trying to run the [1.3 million cell clustering example](https://github.com/theislab/scanpy_usage/tree/master/170522_visualizing_one_million_cells), but have come across some strange behavior. When loading in the `hdf5` file from 10x to an AnnData object, the whole process uses about 30gb. If I write that AnnData object to disk with `adata.write`, then try to load that file (with `sc.read`) I end up using all the memory on the machine (~60g) before segfault-ing. I'd think that any dataset I wrote from memory, I should be able to read back into memory. I've put the full scripts to reproduce on my system in [this gist](https://gist.github.com/ivirshup/42e70a745704b8c71d78e57dd43e3b0b), but essentially I've run:. ```python. # gen_h5ad.py. import scanpy.api as sc. adata = sc.read_10x_h5(""{DATAPTH}/1M_neurons_filtered_gene_bc_matrices_h5.h5"") # Uses about 30gb. adata.write(""./write/1M_neurons.h5ad""). ```. ```python. # load_anndata.py. import scanpy.api as sc. adata = sc.read(""./write/1M_neurons.h5ad"") # Ends with segfault. ```. I'm running `scanpy` installed with conda with the following versions:. ```. scanpy==1.0.4 anndata==0.6 numpy==1.14.2 scipy==1.0.1 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0. ```. Thanks for the great package! Let me know if you'd like any more details on my setup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/146
https://github.com/scverse/scanpy/pull/147:485,energy efficiency,current,currently,485,"Fixed Pandas .loc notation and added gene_names parameter to violin; With this PR, I tried to fix issue https://github.com/theislab/scanpy/issues/140. Needs to be tested still. Additionally, I found it useful to provide to scanpy directly the gene names when plotting violins. Use case: you have a different algorithm that is not implemented in scanpy for differential gene expression, and you want to plot its results with scanpy. Feel free to reject if there's a better way to do it currently in scanpy. I didn't find it though.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/147
https://github.com/scverse/scanpy/pull/147:48,modifiability,paramet,parameter,48,"Fixed Pandas .loc notation and added gene_names parameter to violin; With this PR, I tried to fix issue https://github.com/theislab/scanpy/issues/140. Needs to be tested still. Additionally, I found it useful to provide to scanpy directly the gene names when plotting violins. Use case: you have a different algorithm that is not implemented in scanpy for differential gene expression, and you want to plot its results with scanpy. Feel free to reject if there's a better way to do it currently in scanpy. I didn't find it though.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/147
https://github.com/scverse/scanpy/pull/147:163,safety,test,tested,163,"Fixed Pandas .loc notation and added gene_names parameter to violin; With this PR, I tried to fix issue https://github.com/theislab/scanpy/issues/140. Needs to be tested still. Additionally, I found it useful to provide to scanpy directly the gene names when plotting violins. Use case: you have a different algorithm that is not implemented in scanpy for differential gene expression, and you want to plot its results with scanpy. Feel free to reject if there's a better way to do it currently in scanpy. I didn't find it though.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/147
https://github.com/scverse/scanpy/pull/147:163,testability,test,tested,163,"Fixed Pandas .loc notation and added gene_names parameter to violin; With this PR, I tried to fix issue https://github.com/theislab/scanpy/issues/140. Needs to be tested still. Additionally, I found it useful to provide to scanpy directly the gene names when plotting violins. Use case: you have a different algorithm that is not implemented in scanpy for differential gene expression, and you want to plot its results with scanpy. Feel free to reject if there's a better way to do it currently in scanpy. I didn't find it though.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/147
https://github.com/scverse/scanpy/issues/148:92,availability,error,error,92,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:569,availability,error,error,569,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:8212,availability,error,error,8212,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:0,deployability,Fail,Fail,0,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:8,deployability,instal,install,8,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:64,deployability,instal,install,64,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:386,deployability,Fail,Failed,386,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:393,deployability,build,building,393,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:455,deployability,Fail,Failed,455,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:465,deployability,build,build,465,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:479,deployability,Instal,Installing,479,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:546,deployability,instal,install,546,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:738,deployability,instal,install-,738,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:901,deployability,instal,install,901,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:953,deployability,instal,install-record,953,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:981,deployability,version,version-externally-managed,981,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1045,deployability,instal,install,1045," using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1062,deployability,build,build,1062,"nstall scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1096,deployability,build,build,1096,"essage:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1112,deployability,build,build,1112,"s>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1132,deployability,build,build,1132,"global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1165,deployability,log,logging,1165,"MPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/to",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1179,deployability,build,build,1179,"hon/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1228,deployability,build,build,1228,"18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/too",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1276,deployability,build,build,1276,", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tool",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1321,deployability,build,build,1321,"t be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1369,deployability,build,build,1369,"------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1417,deployability,build,build,1417,"Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1466,deployability,build,build,1466,"d scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1493,deployability,build,build,1493,"ted packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1548,deployability,build,build,1548,"ll for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copyi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1604,deployability,build,build,1604,"lobal/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datas",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1663,deployability,build,build,1663,"/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> bui",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1721,deployability,build,build,1721,"xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1776,deployability,build,build,1776,"tr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1832,deployability,build,build,1832,"ce('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1887,deployability,build,build,1887," 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1943,deployability,build,build,1943,z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2003,deployability,build,build,2003,d --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/prepro,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2065,deployability,build,build,2065, running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creatin,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2128,deployability,build,build,2128, build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2189,deployability,build,build,2189,npy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2258,deployability,build,build,2258,_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py ->,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2317,deployability,build,build,2317, build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_gen,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2378,deployability,build,build,2378,anpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plo,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2411,deployability,build,build,2411,-> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/sc,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2481,deployability,build,build,2481,creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2519,deployability,build,build,2519,ng scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/prep,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2585,deployability,build,build,2585,ools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scan,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2663,deployability,build,build,2663,ld/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2699,deployability,build,build,2699,tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2767,deployability,build,build,2767,py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2804,deployability,build,build,2804, scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2879,deployability,build,build,2879,y -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/ap,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2953,deployability,build,build,2953,npy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3029,deployability,build,build,3029,ng scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3070,deployability,build,build,3070,b/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.p,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3133,deployability,build,build,3133,b/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3199,deployability,build,build,3199,npy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/n,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3262,deployability,build,build,3262,ib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. c,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3336,deployability,build,build,3336,. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3402,deployability,build,build,3402,ating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3467,deployability,build,build,3467,it__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3538,deployability,build,build,3538,ets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3574,deployability,build,build,3574,_.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/P,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3591,deployability,api,api,3591,b/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3611,deployability,api,api,3611,opying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3630,deployability,build,build,3630,ts/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dep,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3647,deployability,api,api,3647,atasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.tx,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3667,deployability,api,api,3667,lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requireme,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3680,deployability,build,build,3680,asets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3697,deployability,api,api,3697,build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/require,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3717,deployability,api,api,3717,ghbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-l,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3730,deployability,build,build,3730,g scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3747,deployability,api,api,3747,rs/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3767,deployability,api,api,3767,ild/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warni,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3787,deployability,build,build,3787,ors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: s,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3804,deployability,api,api,3804,ild/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3824,deployability,api,api,3824,ocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3843,deployability,build,build,3843,anpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scan,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3860,deployability,api,api,3860,ng/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOUR,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3880,deployability,api,api,3880,ld/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading ma,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3893,deployability,build,build,3893,preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest templat,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3910,deployability,api,api,3910,opying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3924,deployability,build,build,3924,reprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manife,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3999,deployability,build,build,3999,eprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:4078,deployability,build,build,4078,"canpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:4153,deployability,build,build,4153,"ng. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:4231,deployability,build,build,4231,"scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:4307,deployability,build,build,4307,"ng/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:4349,deployability,build,build,4349,"/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/O",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:4423,deployability,build,build,4423,"g. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:4501,deployability,build,build,4501,"anpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/global/software/MPI/GCC/4.9.2/OpenM",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:5031,deployability,modul,module,5031,"pying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/install.py"", line 61, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:5065,deployability,instal,install-,5065,"es.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/install.py"", line 61, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:5113,deployability,modul,module,5113,"ng scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/install.py"", line 61, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:5740,deployability,instal,install,5740,"info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/install.py"", line 61, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py""",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:5866,deployability,instal,install,5866,". reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/install.py"", line 61, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:5915,deployability,build,build,5915,"ng manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/install.py"", line 61, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:6322,deployability,build,build,6322,"al/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/install.py"", line 61, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:6706,deployability,instal,install-,6706,"-py3.6.egg/setuptools/command/install.py"", line 61, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, no",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:6730,deployability,version,versioneer,6730,"mand/install.py"", line 61, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. -----------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:7902,deployability,instal,install-,7902,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:8065,deployability,instal,install,8065,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:8117,deployability,instal,install-record,8117,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:8145,deployability,version,version-externally-managed,8145,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:8200,deployability,fail,failed,8200,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:8247,deployability,instal,install-,8247,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1000,energy efficiency,manag,managed,1000," to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:5263,energy efficiency,core,core,5263,"opying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/install.py"", line 61, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/Op",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:8164,energy efficiency,manag,managed,8164,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:98,integrability,messag,message,98,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:981,integrability,version,version-externally-managed,981,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3591,integrability,api,api,3591,b/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3611,integrability,api,api,3611,opying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3647,integrability,api,api,3647,atasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.tx,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3667,integrability,api,api,3667,lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requireme,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3697,integrability,api,api,3697,build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/require,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3717,integrability,api,api,3717,ghbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-l,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3747,integrability,api,api,3747,rs/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3767,integrability,api,api,3767,ild/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warni,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3804,integrability,api,api,3804,ild/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3824,integrability,api,api,3824,ocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3860,integrability,api,api,3860,ng/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOUR,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3880,integrability,api,api,3880,ld/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading ma,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3910,integrability,api,api,3910,opying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:5123,integrability,Topic,Topic,5123,"neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/install.py"", line 61, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/Op",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:6730,integrability,version,versioneer,6730,"mand/install.py"", line 61, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. -----------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:8145,integrability,version,version-externally-managed,8145,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:98,interoperability,messag,message,98,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3591,interoperability,api,api,3591,b/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3611,interoperability,api,api,3611,opying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3647,interoperability,api,api,3647,atasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.tx,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3667,interoperability,api,api,3667,lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requireme,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3697,interoperability,api,api,3697,build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/require,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3717,interoperability,api,api,3717,ghbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-l,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3747,interoperability,api,api,3747,rs/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3767,interoperability,api,api,3767,ild/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warni,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3804,interoperability,api,api,3804,ild/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3824,interoperability,api,api,3824,ocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3860,interoperability,api,api,3860,ng/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOUR,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3880,interoperability,api,api,3880,ld/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading ma,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:3910,interoperability,api,api,3910,opying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:4789,interoperability,standard,standard,4789,"lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/install.py"", line 61, in run. File ""/global/software/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:6052,interoperability,distribut,distribution,6052,"mp/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/install.py"", line 61, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:6507,interoperability,distribut,distribution,6507,"Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/install.py"", line 61, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/glob",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:211,modifiability,pac,packages,211,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:500,modifiability,pac,packages,500,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:518,modifiability,deco,decorator,518,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:981,modifiability,version,version-externally-managed,981,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:5031,modifiability,modul,module,5031,"pying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/install.py"", line 61, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:5113,modifiability,modul,module,5113,"ng scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/install.py"", line 61, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:5684,modifiability,pac,packages,5684,"nfo/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/install.py"", line 61, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:6730,modifiability,version,versioneer,6730,"mand/install.py"", line 61, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. -----------------",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:6869,modifiability,pac,packages,6869,".py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:7039,modifiability,pac,packages,7039,"nd. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:7225,modifiability,pac,packages,7225,"e ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:7403,modifiability,pac,packages,7403,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:7585,modifiability,pac,packages,7585,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:8145,modifiability,version,version-externally-managed,8145,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:92,performance,error,error,92,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:569,performance,error,error,569,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:8212,performance,error,error,8212,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:0,reliability,Fail,Fail,0,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:386,reliability,Fail,Failed,386,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:455,reliability,Fail,Failed,455,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:8200,reliability,fail,failed,8200,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:92,safety,error,error,92,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:569,safety,error,error,569,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:576,safety,Compl,Complete,576,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1000,safety,manag,managed,1000," to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> b",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1165,safety,log,logging,1165,"MPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/to",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:5031,safety,modul,module,5031,"pying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/install.py"", line 61, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:5113,safety,modul,module,5113,"ng scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/install.py"", line 61, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GC",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:8164,safety,manag,managed,8164,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:8212,safety,error,error,8212,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:576,security,Compl,Complete,576,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:700,security,token,tokenize,700,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:782,security,token,tokenize,782,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1165,security,log,logging,1165,"MPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/to",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:7864,security,token,tokenize,7864,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:7946,security,token,tokenize,7946,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1165,testability,log,logging,1165,"MPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/to",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2940,testability,simpl,simple,2940,build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/ne,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:4966,testability,Trace,Traceback,4966,"/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/install.py"", line 61, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:92,usability,error,error,92,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:259,usability,command,command,259,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:569,usability,error,error,569,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:597,usability,command,command,597,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:854,usability,close,close,854,"Fail to install scanpy by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1020,usability,user,user,1020," by pip; Hi everyone,. I am using pip3 to install scanpy, this is the error message:. <details>. ```pytb. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Failed building wheel for scanpy. Running setup.py clean for scanpy. Failed to build scanpy. Installing collected packages: scanpy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/to",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1510,usability,tool,tools,1510,"npy, decorator. Running setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. cre",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1532,usability,tool,tools,1532,"g setup.py install for scanpy ... error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1565,usability,tool,tools,1565," error. Complete output from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/dataset",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1587,usability,tool,tools,1587,"t from command /global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1621,usability,tool,tools,1621,"I/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1643,usability,tool,tools,1643,"8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_withou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1680,usability,tool,tools,1680,"port setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/dat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1702,usability,tool,tools,1702,"ize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1738,usability,tool,tools,1738,"tall-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1760,usability,tool,tools,1760,"etup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1793,usability,tool,tools,1793,"n', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1815,usability,tool,tools,1815,"de=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scan",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1849,usability,tool,tools,1849,"f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1871,usability,tool,tools,1871,"(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1904,usability,tool,tools,1904,l --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessi,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1926,usability,tool,tools,1926,ump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/pre,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1960,usability,tool,tools,1960,cord.txt --single-version-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:1982,usability,tool,tools,1982,ion-externally-managed --compile --user --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2020,usability,tool,tools,2020,r --prefix=:. running install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2042,usability,tool,tools,2042,install. running build. running build_py. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2082,usability,tool,tools,2082,. creating build. creating build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2104,usability,tool,tools,2104,ting build/lib. creating build/lib/scanpy. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying sc,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2145,usability,tool,tools,2145,. copying scanpy/logging.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanp,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2167,usability,tool,tools,2167,ng.py -> build/lib/scanpy. copying scanpy/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying sc,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2206,usability,tool,tools,2206,py/exporting.py -> build/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2228,usability,tool,tools,2228,ld/lib/scanpy. copying scanpy/_version.py -> build/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copyi,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2275,usability,tool,tools,2275,ild/lib/scanpy. copying scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2297,usability,tool,tools,2297,g scanpy/utils.py -> build/lib/scanpy. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying sca,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2334,usability,tool,tools,2334,. copying scanpy/__init__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> b,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2356,usability,tool,tools,2356,t__.py -> build/lib/scanpy. copying scanpy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotti,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2395,usability,tool,tools,2395,npy/settings.py -> build/lib/scanpy. copying scanpy/readwrite.py -> build/lib/scanpy. creating build/lib/scanpy/tools. copying scanpy/tools/dpt.py -> build/lib/scanpy/tools. copying scanpy/tools/paga.py -> build/lib/scanpy/tools. copying scanpy/tools/louvain.py -> build/lib/scanpy/tools. copying scanpy/tools/_utils.py -> build/lib/scanpy/tools. copying scanpy/tools/pca.py -> build/lib/scanpy/tools. copying scanpy/tools/umap.py -> build/lib/scanpy/tools. copying scanpy/tools/sim.py -> build/lib/scanpy/tools. copying scanpy/tools/tsne.py -> build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:2940,usability,simpl,simple,2940,build/lib/scanpy/tools. copying scanpy/tools/__init__.py -> build/lib/scanpy/tools. copying scanpy/tools/draw_graph.py -> build/lib/scanpy/tools. copying scanpy/tools/score_genes.py -> build/lib/scanpy/tools. copying scanpy/tools/_tsne_fix.py -> build/lib/scanpy/tools. copying scanpy/tools/rank_genes_groups.py -> build/lib/scanpy/tools. copying scanpy/tools/diffmap.py -> build/lib/scanpy/tools. copying scanpy/tools/top_genes.py -> build/lib/scanpy/tools. creating build/lib/scanpy/sim_models. copying scanpy/sim_models/__init__.py -> build/lib/scanpy/sim_models. creating build/lib/scanpy/datasets. copying scanpy/datasets/__init__.py -> build/lib/scanpy/datasets. copying scanpy/datasets/api_without_datasets.py -> build/lib/scanpy/datasets. creating build/lib/scanpy/neighbors. copying scanpy/neighbors/__init__.py -> build/lib/scanpy/neighbors. creating build/lib/scanpy/preprocessing. copying scanpy/preprocessing/recipes.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/simple.py -> build/lib/scanpy/preprocessing. copying scanpy/preprocessing/__init__.py -> build/lib/scanpy/preprocessing. creating build/lib/scanpy/plotting. copying scanpy/plotting/rcmod.py -> build/lib/scanpy/plotting. copying scanpy/plotting/palettes.py -> build/lib/scanpy/plotting. copying scanpy/plotting/utils.py -> build/lib/scanpy/plotting. copying scanpy/plotting/top_genes_visual.py -> build/lib/scanpy/plotting. copying scanpy/plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/ne,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:4375,usability,tool,tools,4375,"plotting/__init__.py -> build/lib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:4406,usability,tool,tools,4406,"ib/scanpy/plotting. copying scanpy/plotting/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:4449,usability,tool,tools,4449,"/anndata.py -> build/lib/scanpy/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in run_commands. self.run_comm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:4480,usability,tool,tools,4480,"/plotting. copying scanpy/plotting/preprocessing.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/global/softwar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:4527,usability,tool,tools,4527,"g.py -> build/lib/scanpy/plotting. creating build/lib/scanpy/api. copying scanpy/api/datasets.py -> build/lib/scanpy/api. copying scanpy/api/pl.py -> build/lib/scanpy/api. copying scanpy/api/pp.py -> build/lib/scanpy/api. copying scanpy/api/export_to.py -> build/lib/scanpy/api. copying scanpy/api/__init__.py -> build/lib/scanpy/api. copying scanpy/api/tl.py -> build/lib/scanpy/api. creating build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/utils.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/distances.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/umap_.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:5158,usability,Visual,Visualization,5158,"anpy/neighbors/umap. copying scanpy/neighbors/umap/__init__.py -> build/lib/scanpy/neighbors/umap. copying scanpy/neighbors/umap/sparse.py -> build/lib/scanpy/neighbors/umap. creating build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/paga.py -> build/lib/scanpy/plotting/tools. copying scanpy/plotting/tools/__init__.py -> build/lib/scanpy/plotting/tools. running egg_info. writing scanpy.egg-info/PKG-INFO. writing dependency_links to scanpy.egg-info/dependency_links.txt. writing requirements to scanpy.egg-info/requires.txt. writing top-level names to scanpy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/install.py"", line 61, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:5732,usability,command,command,5732,"npy.egg-info/top_level.txt. warning: manifest_maker: standard file '-c' not found. reading manifest file 'scanpy.egg-info/SOURCES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/install.py"", line 61, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versio",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:5858,usability,command,command,5858,"CES.txt'. reading manifest template 'MANIFEST.in'. writing manifest file 'scanpy.egg-info/SOURCES.txt'. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/install.py"", line 61, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:6077,usability,command,command,6077,"/scanpy/setup.py"", line 50, in <module>. 'Topic :: Scientific/Engineering :: Visualization',. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/core.py"", line 148, in setup. dist.run_commands(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/install.py"", line 61, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setup",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:6314,usability,command,command,6314," ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 955, in run_commands. self.run_command(cmd). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/install.py"", line 61, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:6532,usability,command,command,6532,"3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/install.py"", line 61, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/install.py"", line 545, in run. self.run_command('build'). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:6917,usability,command,command,6917,"). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:7087,usability,command,command,7087," ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:7273,usability,command,command,7273,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:7451,usability,command,command,7451,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:7633,usability,command,command,7633,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:7760,usability,Command,Command,7760,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:8018,usability,close,close,8018,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:8184,usability,user,user,8184,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/issues/148:8212,usability,error,error,8212,"/Python/3.6.0/lib/python3.6/distutils/command/build.py"", line 135, in run. self.run_command(cmd_name). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/cmd.py"", line 313, in run_command. self.distribution.run_command(command). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/distutils/dist.py"", line 974, in run_command. cmd_obj.run(). File ""/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/versioneer.py"", line 1555, in run. _build_py.run(self). File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 47, in run. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 103, in build_package_data. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 59, in __getattr__. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 86, in _get_data_files. File ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/lib/python3.6/site-packages/setuptools-18.3.2-py3.6.egg/setuptools/command/build_py.py"", line 94, in find_data_files. TypeError: must be str, not list. ----------------------------------------. Command ""/global/software/MPI/GCC/4.9.2/OpenMPI/1.8.5/Python/3.6.0/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/xs-ttgump/pip-record-v4z7bmhr/install-record.txt --single-version-externally-managed --compile --user --prefix="" failed with error code 1 in /tmp/xs-ttgump/pip-install-xpuhp0co/scanpy/. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/148
https://github.com/scverse/scanpy/pull/149:21,modifiability,paramet,parameter,21,"Fix UMAP metric_kwds parameter; Simple fix for sc.pp.neighbors(..., metric_kwds={...}).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/149
https://github.com/scverse/scanpy/pull/149:32,testability,Simpl,Simple,32,"Fix UMAP metric_kwds parameter; Simple fix for sc.pp.neighbors(..., metric_kwds={...}).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/149
https://github.com/scverse/scanpy/pull/149:32,usability,Simpl,Simple,32,"Fix UMAP metric_kwds parameter; Simple fix for sc.pp.neighbors(..., metric_kwds={...}).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/149
https://github.com/scverse/scanpy/issues/150:183,usability,user,user-images,183,"dpt didn't create a 'dpt_pseudotime' obs; Hey guys! always write funny markdown so I just pasted a screenshot. <img width=""1052"" alt=""screen shot 2018-05-08 at 00 54 02"" src=""https://user-images.githubusercontent.com/8361080/39713705-52a13720-525a-11e8-96f2-1a88e7a7b4c5.png"">. `sc.pl.dpt(mfdata)` yields same result. Could this be a bug? Or did I miss some step? Thanks++. Chris",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/150
https://github.com/scverse/scanpy/pull/152:37,interoperability,format,formats,37,Allow gz and bz2 extensions for text formats; Support for .gz and .bz2 compression. Uses https://github.com/theislab/anndata/pull/22 and fixes https://github.com/theislab/dca/issues/7.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/152
https://github.com/scverse/scanpy/pull/152:17,modifiability,extens,extensions,17,Allow gz and bz2 extensions for text formats; Support for .gz and .bz2 compression. Uses https://github.com/theislab/anndata/pull/22 and fixes https://github.com/theislab/dca/issues/7.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/152
https://github.com/scverse/scanpy/pull/152:46,usability,Support,Support,46,Allow gz and bz2 extensions for text formats; Support for .gz and .bz2 compression. Uses https://github.com/theislab/anndata/pull/22 and fixes https://github.com/theislab/dca/issues/7.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/152
https://github.com/scverse/scanpy/issues/153:42,availability,error,error,42,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:155,availability,error,error,155,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:470,availability,error,error,470,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:708,availability,error,errors,708,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:1452,availability,slo,slow,1452,"ion `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not import at the top of the file. --> 108 pl.filter_genes_dispersion(filter_result, log=True). 109 # actually filter the genes, the following is the inplace version of. 110 # adata = adata[:, filter_result.gene_subset]. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```. It looks like there's a pretty easy fix here, so I'd be up for making a pull request if you'd like.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:353,deployability,log,log,353,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:544,deployability,releas,release,544,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:646,deployability,api,api,646,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:861,deployability,log,logging,861,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:1776,deployability,modul,module,1776,"ion `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not import at the top of the file. --> 108 pl.filter_genes_dispersion(filter_result, log=True). 109 # actually filter the genes, the following is the inplace version of. 110 # adata = adata[:, filter_result.gene_subset]. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```. It looks like there's a pretty easy fix here, so I'd be up for making a pull request if you'd like.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:1921,deployability,log,log,1921,"ion `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not import at the top of the file. --> 108 pl.filter_genes_dispersion(filter_result, log=True). 109 # actually filter the genes, the following is the inplace version of. 110 # adata = adata[:, filter_result.gene_subset]. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```. It looks like there's a pretty easy fix here, so I'd be up for making a pull request if you'd like.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:2081,deployability,log,log,2081,"ion `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not import at the top of the file. --> 108 pl.filter_genes_dispersion(filter_result, log=True). 109 # actually filter the genes, the following is the inplace version of. 110 # adata = adata[:, filter_result.gene_subset]. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```. It looks like there's a pretty easy fix here, so I'd be up for making a pull request if you'd like.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:2154,deployability,version,version,2154,"ion `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not import at the top of the file. --> 108 pl.filter_genes_dispersion(filter_result, log=True). 109 # actually filter the genes, the following is the inplace version of. 110 # adata = adata[:, filter_result.gene_subset]. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```. It looks like there's a pretty easy fix here, so I'd be up for making a pull request if you'd like.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:2233,deployability,modul,module,2233,"ion `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not import at the top of the file. --> 108 pl.filter_genes_dispersion(filter_result, log=True). 109 # actually filter the genes, the following is the inplace version of. 110 # adata = adata[:, filter_result.gene_subset]. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```. It looks like there's a pretty easy fix here, so I'd be up for making a pull request if you'd like.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:646,integrability,api,api,646,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:2107,integrability,filter,filter,2107,"ion `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not import at the top of the file. --> 108 pl.filter_genes_dispersion(filter_result, log=True). 109 # actually filter the genes, the following is the inplace version of. 110 # adata = adata[:, filter_result.gene_subset]. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```. It looks like there's a pretty easy fix here, so I'd be up for making a pull request if you'd like.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:2154,integrability,version,version,2154,"ion `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not import at the top of the file. --> 108 pl.filter_genes_dispersion(filter_result, log=True). 109 # actually filter the genes, the following is the inplace version of. 110 # adata = adata[:, filter_result.gene_subset]. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```. It looks like there's a pretty easy fix here, so I'd be up for making a pull request if you'd like.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:646,interoperability,api,api,646,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:987,interoperability,Convers,Conversion,987,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:942,modifiability,pac,packages,942,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:1776,modifiability,modul,module,1776,"ion `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not import at the top of the file. --> 108 pl.filter_genes_dispersion(filter_result, log=True). 109 # actually filter the genes, the following is the inplace version of. 110 # adata = adata[:, filter_result.gene_subset]. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```. It looks like there's a pretty easy fix here, so I'd be up for making a pull request if you'd like.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:2154,modifiability,version,version,2154,"ion `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not import at the top of the file. --> 108 pl.filter_genes_dispersion(filter_result, log=True). 109 # actually filter the genes, the following is the inplace version of. 110 # adata = adata[:, filter_result.gene_subset]. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```. It looks like there's a pretty easy fix here, so I'd be up for making a pull request if you'd like.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:2233,modifiability,modul,module,2233,"ion `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not import at the top of the file. --> 108 pl.filter_genes_dispersion(filter_result, log=True). 109 # actually filter the genes, the following is the inplace version of. 110 # adata = adata[:, filter_result.gene_subset]. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```. It looks like there's a pretty easy fix here, so I'd be up for making a pull request if you'd like.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:42,performance,error,error,42,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:155,performance,error,error,155,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:470,performance,error,error,470,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:708,performance,error,errors,708,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:1476,performance,cach,cache,1476,"ion `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not import at the top of the file. --> 108 pl.filter_genes_dispersion(filter_result, log=True). 109 # actually filter the genes, the following is the inplace version of. 110 # adata = adata[:, filter_result.gene_subset]. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```. It looks like there's a pretty easy fix here, so I'd be up for making a pull request if you'd like.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:1530,performance,cach,cache,1530,"ion `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not import at the top of the file. --> 108 pl.filter_genes_dispersion(filter_result, log=True). 109 # actually filter the genes, the following is the inplace version of. 110 # adata = adata[:, filter_result.gene_subset]. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```. It looks like there's a pretty easy fix here, so I'd be up for making a pull request if you'd like.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:384,reliability,doe,doesn,384,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:1452,reliability,slo,slow,1452,"ion `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not import at the top of the file. --> 108 pl.filter_genes_dispersion(filter_result, log=True). 109 # actually filter the genes, the following is the inplace version of. 110 # adata = adata[:, filter_result.gene_subset]. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```. It looks like there's a pretty easy fix here, so I'd be up for making a pull request if you'd like.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:42,safety,error,error,42,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:155,safety,error,error,155,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:353,safety,log,log,353,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:470,safety,error,error,470,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:708,safety,error,errors,708,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:861,safety,log,logging,861,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:1750,safety,input,input-,1750,"ion `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not import at the top of the file. --> 108 pl.filter_genes_dispersion(filter_result, log=True). 109 # actually filter the genes, the following is the inplace version of. 110 # adata = adata[:, filter_result.gene_subset]. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```. It looks like there's a pretty easy fix here, so I'd be up for making a pull request if you'd like.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:1776,safety,modul,module,1776,"ion `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not import at the top of the file. --> 108 pl.filter_genes_dispersion(filter_result, log=True). 109 # actually filter the genes, the following is the inplace version of. 110 # adata = adata[:, filter_result.gene_subset]. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```. It looks like there's a pretty easy fix here, so I'd be up for making a pull request if you'd like.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:1921,safety,log,log,1921,"ion `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not import at the top of the file. --> 108 pl.filter_genes_dispersion(filter_result, log=True). 109 # actually filter the genes, the following is the inplace version of. 110 # adata = adata[:, filter_result.gene_subset]. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```. It looks like there's a pretty easy fix here, so I'd be up for making a pull request if you'd like.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:2081,safety,log,log,2081,"ion `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not import at the top of the file. --> 108 pl.filter_genes_dispersion(filter_result, log=True). 109 # actually filter the genes, the following is the inplace version of. 110 # adata = adata[:, filter_result.gene_subset]. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```. It looks like there's a pretty easy fix here, so I'd be up for making a pull request if you'd like.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:2233,safety,modul,module,2233,"ion `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not import at the top of the file. --> 108 pl.filter_genes_dispersion(filter_result, log=True). 109 # actually filter the genes, the following is the inplace version of. 110 # adata = adata[:, filter_result.gene_subset]. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```. It looks like there's a pretty easy fix here, so I'd be up for making a pull request if you'd like.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:353,security,log,log,353,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:436,security,expos,exposed,436,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:861,security,log,logging,861,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:1921,security,log,log,1921,"ion `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not import at the top of the file. --> 108 pl.filter_genes_dispersion(filter_result, log=True). 109 # actually filter the genes, the following is the inplace version of. 110 # adata = adata[:, filter_result.gene_subset]. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```. It looks like there's a pretty easy fix here, so I'd be up for making a pull request if you'd like.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:2081,security,log,log,2081,"ion `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not import at the top of the file. --> 108 pl.filter_genes_dispersion(filter_result, log=True). 109 # actually filter the genes, the following is the inplace version of. 110 # adata = adata[:, filter_result.gene_subset]. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```. It looks like there's a pretty easy fix here, so I'd be up for making a pull request if you'd like.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:353,testability,log,log,353,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:861,testability,log,logging,861,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:1706,testability,Trace,Traceback,1706,"ion `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not import at the top of the file. --> 108 pl.filter_genes_dispersion(filter_result, log=True). 109 # actually filter the genes, the following is the inplace version of. 110 # adata = adata[:, filter_result.gene_subset]. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```. It looks like there's a pretty easy fix here, so I'd be up for making a pull request if you'd like.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:1921,testability,log,log,1921,"ion `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not import at the top of the file. --> 108 pl.filter_genes_dispersion(filter_result, log=True). 109 # actually filter the genes, the following is the inplace version of. 110 # adata = adata[:, filter_result.gene_subset]. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```. It looks like there's a pretty easy fix here, so I'd be up for making a pull request if you'd like.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:2081,testability,log,log,2081,"ion `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not import at the top of the file. --> 108 pl.filter_genes_dispersion(filter_result, log=True). 109 # actually filter the genes, the following is the inplace version of. 110 # adata = adata[:, filter_result.gene_subset]. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```. It looks like there's a pretty easy fix here, so I'd be up for making a pull request if you'd like.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:42,usability,error,error,42,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:155,usability,error,error,155,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:470,usability,error,error,470,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:708,usability,error,errors,708,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:744,usability,hint,hints,744,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:888,usability,User,Users,888,"Recipes with plotting option throw import error; Some of the preprocessing recipes have a `plot` argument, but as far as I can tell, they'll only throw an error. `recipe_zheng17` and `recipe_seurat` have the lines:. ```python. if plot:. from .. import plotting as pl # should not import at the top of the file. pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:1308,usability,learn,learn,1308,"pl.filter_genes_dispersion(filter_result, log=True). ```. But `plotting` doesn't have the function `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not import at the top of the file. --> 108 pl.filter_genes_dispersion(filter_result, log=True). 109 # actually filter the genes, the following is the inplace version of. 110 # adata = adata[:, filter_result.gene_subset]. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```. It l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/153:1750,usability,input,input-,1750,"ion `filter_genes_dispersion` exposed. Here's an example of the error using `scanpy` pulled from github, but the same issue occurs on the release on pypi:. ```python. In [1]: import numpy as np. ...: import pandas as pd. ...: import scanpy.api as sc. ...: . ...: sc.settings.verbosity = 3 # verbosity: errors (0), warnings (1), info (2), hints (3). ...: sc.settings.set_figure_params(dpi=80) # low dpi (dots per inch) yields small inline figures. ...: sc.logging.print_versions(). /Users/isaac/miniconda3/envs/scanpy/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters. adatascanpy==1.0.4+91.ge9ae4ff anndata==0.6 numpy==1.14.3 scipy==1.1.0 pandas==0.22.0 scikit-learn==0.19.1 statsmodels==0.8.0 . In [2]: adata = sc.read(""./data/pbmc3k_filtered_gene_bc_matrices/hg19/matrix.mtx"").T. --> This might be very slow. Consider passing `cache=True`, which enables much faster reading from a cache file. In [3]: sc.pp.recipe_zheng17(adata, plot=True). running recipe zheng17. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-3-c19f237f1c6e> in <module>(). ----> 1 sc.pp.recipe_zheng17(adata, plot=True). ~/github/scanpy/scanpy/preprocessing/recipes.py in recipe_zheng17(adata, n_top_genes, log, plot, copy). 106 if plot:. 107 from .. import plotting as pl # should not import at the top of the file. --> 108 pl.filter_genes_dispersion(filter_result, log=True). 109 # actually filter the genes, the following is the inplace version of. 110 # adata = adata[:, filter_result.gene_subset]. AttributeError: module 'scanpy.plotting' has no attribute 'filter_genes_dispersion'. ```. It looks like there's a pretty easy fix here, so I'd be up for making a pull request if you'd like.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/153
https://github.com/scverse/scanpy/issues/154:10,deployability,modul,module,10,"writeread module does not write to loom format; Hi, . I am sort of confused as to why this function is not working. Any tip on to how resolve this? Thank you, . O. <img width=""577"" alt=""screen shot 2018-05-15 at 1 25 14 pm"" src=""https://user-images.githubusercontent.com/6422882/40072984-8bf0f22e-5843-11e8-9eaf-57bb018e0d7c.png"">. <img width=""733"" alt=""screen shot 2018-05-15 at 1 25 37 pm"" src=""https://user-images.githubusercontent.com/6422882/40072986-8e2a17b4-5843-11e8-9281-677631b32ef8.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/154
https://github.com/scverse/scanpy/issues/154:40,interoperability,format,format,40,"writeread module does not write to loom format; Hi, . I am sort of confused as to why this function is not working. Any tip on to how resolve this? Thank you, . O. <img width=""577"" alt=""screen shot 2018-05-15 at 1 25 14 pm"" src=""https://user-images.githubusercontent.com/6422882/40072984-8bf0f22e-5843-11e8-9eaf-57bb018e0d7c.png"">. <img width=""733"" alt=""screen shot 2018-05-15 at 1 25 37 pm"" src=""https://user-images.githubusercontent.com/6422882/40072986-8e2a17b4-5843-11e8-9281-677631b32ef8.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/154
https://github.com/scverse/scanpy/issues/154:10,modifiability,modul,module,10,"writeread module does not write to loom format; Hi, . I am sort of confused as to why this function is not working. Any tip on to how resolve this? Thank you, . O. <img width=""577"" alt=""screen shot 2018-05-15 at 1 25 14 pm"" src=""https://user-images.githubusercontent.com/6422882/40072984-8bf0f22e-5843-11e8-9eaf-57bb018e0d7c.png"">. <img width=""733"" alt=""screen shot 2018-05-15 at 1 25 37 pm"" src=""https://user-images.githubusercontent.com/6422882/40072986-8e2a17b4-5843-11e8-9281-677631b32ef8.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/154
https://github.com/scverse/scanpy/issues/154:17,reliability,doe,does,17,"writeread module does not write to loom format; Hi, . I am sort of confused as to why this function is not working. Any tip on to how resolve this? Thank you, . O. <img width=""577"" alt=""screen shot 2018-05-15 at 1 25 14 pm"" src=""https://user-images.githubusercontent.com/6422882/40072984-8bf0f22e-5843-11e8-9eaf-57bb018e0d7c.png"">. <img width=""733"" alt=""screen shot 2018-05-15 at 1 25 37 pm"" src=""https://user-images.githubusercontent.com/6422882/40072986-8e2a17b4-5843-11e8-9281-677631b32ef8.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/154
https://github.com/scverse/scanpy/issues/154:10,safety,modul,module,10,"writeread module does not write to loom format; Hi, . I am sort of confused as to why this function is not working. Any tip on to how resolve this? Thank you, . O. <img width=""577"" alt=""screen shot 2018-05-15 at 1 25 14 pm"" src=""https://user-images.githubusercontent.com/6422882/40072984-8bf0f22e-5843-11e8-9eaf-57bb018e0d7c.png"">. <img width=""733"" alt=""screen shot 2018-05-15 at 1 25 37 pm"" src=""https://user-images.githubusercontent.com/6422882/40072986-8e2a17b4-5843-11e8-9281-677631b32ef8.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/154
https://github.com/scverse/scanpy/issues/154:120,usability,tip,tip,120,"writeread module does not write to loom format; Hi, . I am sort of confused as to why this function is not working. Any tip on to how resolve this? Thank you, . O. <img width=""577"" alt=""screen shot 2018-05-15 at 1 25 14 pm"" src=""https://user-images.githubusercontent.com/6422882/40072984-8bf0f22e-5843-11e8-9eaf-57bb018e0d7c.png"">. <img width=""733"" alt=""screen shot 2018-05-15 at 1 25 37 pm"" src=""https://user-images.githubusercontent.com/6422882/40072986-8e2a17b4-5843-11e8-9281-677631b32ef8.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/154
https://github.com/scverse/scanpy/issues/154:237,usability,user,user-images,237,"writeread module does not write to loom format; Hi, . I am sort of confused as to why this function is not working. Any tip on to how resolve this? Thank you, . O. <img width=""577"" alt=""screen shot 2018-05-15 at 1 25 14 pm"" src=""https://user-images.githubusercontent.com/6422882/40072984-8bf0f22e-5843-11e8-9eaf-57bb018e0d7c.png"">. <img width=""733"" alt=""screen shot 2018-05-15 at 1 25 37 pm"" src=""https://user-images.githubusercontent.com/6422882/40072986-8e2a17b4-5843-11e8-9281-677631b32ef8.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/154
https://github.com/scverse/scanpy/issues/154:405,usability,user,user-images,405,"writeread module does not write to loom format; Hi, . I am sort of confused as to why this function is not working. Any tip on to how resolve this? Thank you, . O. <img width=""577"" alt=""screen shot 2018-05-15 at 1 25 14 pm"" src=""https://user-images.githubusercontent.com/6422882/40072984-8bf0f22e-5843-11e8-9eaf-57bb018e0d7c.png"">. <img width=""733"" alt=""screen shot 2018-05-15 at 1 25 37 pm"" src=""https://user-images.githubusercontent.com/6422882/40072986-8e2a17b4-5843-11e8-9281-677631b32ef8.png"">",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/154
https://github.com/scverse/scanpy/pull/155:193,availability,error,error,193,"Fix for `recipe_*(adata, plot=True)`; Fixes #153. Fixed usage of `plot=True` for `recipe_zheng17` and `recipe_seurat`. A test was added under `tests/preprocessing.py` which just checks that no error is thrown. Style wise, I just went with changing the fewest lines of code. The test isn't exactly stateless since I've got to deactivate interactive plotting, but I wasn't sure how you'd like to handle that. Lemme know if you'd like any changes.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/155
https://github.com/scverse/scanpy/pull/155:297,availability,state,stateless,297,"Fix for `recipe_*(adata, plot=True)`; Fixes #153. Fixed usage of `plot=True` for `recipe_zheng17` and `recipe_seurat`. A test was added under `tests/preprocessing.py` which just checks that no error is thrown. Style wise, I just went with changing the fewest lines of code. The test isn't exactly stateless since I've got to deactivate interactive plotting, but I wasn't sure how you'd like to handle that. Lemme know if you'd like any changes.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/155
https://github.com/scverse/scanpy/pull/155:297,integrability,state,stateless,297,"Fix for `recipe_*(adata, plot=True)`; Fixes #153. Fixed usage of `plot=True` for `recipe_zheng17` and `recipe_seurat`. A test was added under `tests/preprocessing.py` which just checks that no error is thrown. Style wise, I just went with changing the fewest lines of code. The test isn't exactly stateless since I've got to deactivate interactive plotting, but I wasn't sure how you'd like to handle that. Lemme know if you'd like any changes.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/155
https://github.com/scverse/scanpy/pull/155:193,performance,error,error,193,"Fix for `recipe_*(adata, plot=True)`; Fixes #153. Fixed usage of `plot=True` for `recipe_zheng17` and `recipe_seurat`. A test was added under `tests/preprocessing.py` which just checks that no error is thrown. Style wise, I just went with changing the fewest lines of code. The test isn't exactly stateless since I've got to deactivate interactive plotting, but I wasn't sure how you'd like to handle that. Lemme know if you'd like any changes.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/155
https://github.com/scverse/scanpy/pull/155:121,safety,test,test,121,"Fix for `recipe_*(adata, plot=True)`; Fixes #153. Fixed usage of `plot=True` for `recipe_zheng17` and `recipe_seurat`. A test was added under `tests/preprocessing.py` which just checks that no error is thrown. Style wise, I just went with changing the fewest lines of code. The test isn't exactly stateless since I've got to deactivate interactive plotting, but I wasn't sure how you'd like to handle that. Lemme know if you'd like any changes.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/155
https://github.com/scverse/scanpy/pull/155:143,safety,test,tests,143,"Fix for `recipe_*(adata, plot=True)`; Fixes #153. Fixed usage of `plot=True` for `recipe_zheng17` and `recipe_seurat`. A test was added under `tests/preprocessing.py` which just checks that no error is thrown. Style wise, I just went with changing the fewest lines of code. The test isn't exactly stateless since I've got to deactivate interactive plotting, but I wasn't sure how you'd like to handle that. Lemme know if you'd like any changes.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/155
https://github.com/scverse/scanpy/pull/155:193,safety,error,error,193,"Fix for `recipe_*(adata, plot=True)`; Fixes #153. Fixed usage of `plot=True` for `recipe_zheng17` and `recipe_seurat`. A test was added under `tests/preprocessing.py` which just checks that no error is thrown. Style wise, I just went with changing the fewest lines of code. The test isn't exactly stateless since I've got to deactivate interactive plotting, but I wasn't sure how you'd like to handle that. Lemme know if you'd like any changes.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/155
https://github.com/scverse/scanpy/pull/155:278,safety,test,test,278,"Fix for `recipe_*(adata, plot=True)`; Fixes #153. Fixed usage of `plot=True` for `recipe_zheng17` and `recipe_seurat`. A test was added under `tests/preprocessing.py` which just checks that no error is thrown. Style wise, I just went with changing the fewest lines of code. The test isn't exactly stateless since I've got to deactivate interactive plotting, but I wasn't sure how you'd like to handle that. Lemme know if you'd like any changes.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/155
https://github.com/scverse/scanpy/pull/155:121,testability,test,test,121,"Fix for `recipe_*(adata, plot=True)`; Fixes #153. Fixed usage of `plot=True` for `recipe_zheng17` and `recipe_seurat`. A test was added under `tests/preprocessing.py` which just checks that no error is thrown. Style wise, I just went with changing the fewest lines of code. The test isn't exactly stateless since I've got to deactivate interactive plotting, but I wasn't sure how you'd like to handle that. Lemme know if you'd like any changes.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/155
https://github.com/scverse/scanpy/pull/155:143,testability,test,tests,143,"Fix for `recipe_*(adata, plot=True)`; Fixes #153. Fixed usage of `plot=True` for `recipe_zheng17` and `recipe_seurat`. A test was added under `tests/preprocessing.py` which just checks that no error is thrown. Style wise, I just went with changing the fewest lines of code. The test isn't exactly stateless since I've got to deactivate interactive plotting, but I wasn't sure how you'd like to handle that. Lemme know if you'd like any changes.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/155
https://github.com/scverse/scanpy/pull/155:278,testability,test,test,278,"Fix for `recipe_*(adata, plot=True)`; Fixes #153. Fixed usage of `plot=True` for `recipe_zheng17` and `recipe_seurat`. A test was added under `tests/preprocessing.py` which just checks that no error is thrown. Style wise, I just went with changing the fewest lines of code. The test isn't exactly stateless since I've got to deactivate interactive plotting, but I wasn't sure how you'd like to handle that. Lemme know if you'd like any changes.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/155
https://github.com/scverse/scanpy/pull/155:193,usability,error,error,193,"Fix for `recipe_*(adata, plot=True)`; Fixes #153. Fixed usage of `plot=True` for `recipe_zheng17` and `recipe_seurat`. A test was added under `tests/preprocessing.py` which just checks that no error is thrown. Style wise, I just went with changing the fewest lines of code. The test isn't exactly stateless since I've got to deactivate interactive plotting, but I wasn't sure how you'd like to handle that. Lemme know if you'd like any changes.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/155
https://github.com/scverse/scanpy/pull/155:336,usability,interact,interactive,336,"Fix for `recipe_*(adata, plot=True)`; Fixes #153. Fixed usage of `plot=True` for `recipe_zheng17` and `recipe_seurat`. A test was added under `tests/preprocessing.py` which just checks that no error is thrown. Style wise, I just went with changing the fewest lines of code. The test isn't exactly stateless since I've got to deactivate interactive plotting, but I wasn't sure how you'd like to handle that. Lemme know if you'd like any changes.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/155
https://github.com/scverse/scanpy/issues/156:1034,availability,cluster,cluster,1034,"changing color palette for pl.tsne; Hello! I'm trying to recolor some categorical variables in the scanpy.api.pl.tsne function but am having some trouble. Specifically, with continuous data, I'm fine using the `color_map` key word to change between scales like ""viridis"" and ""Purples"" but when trying to pass the `palette` key word for categorical data (sample labels, louvain lables), it doesn't seem to update the colors in the plot. Perhaps I'm specifying the color palette incorrectly? Here are a few versions I've tried:. ```. sc.pl.tsne(adata, . color=['louvain'], . #palette=['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9'], . #palette=['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'],. #palette=""Set3"",. palette=sns.color_palette(""hls"", 15),. legend_fontsize=""20""). ```. ![image](https://user-images.githubusercontent.com/33738960/40148279-0b344502-5922-11e8-998c-4d5ece963253.png). But all of these attempts result in the same default cluster color scheme. Any suggestions? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/156
https://github.com/scverse/scanpy/issues/156:106,deployability,api,api,106,"changing color palette for pl.tsne; Hello! I'm trying to recolor some categorical variables in the scanpy.api.pl.tsne function but am having some trouble. Specifically, with continuous data, I'm fine using the `color_map` key word to change between scales like ""viridis"" and ""Purples"" but when trying to pass the `palette` key word for categorical data (sample labels, louvain lables), it doesn't seem to update the colors in the plot. Perhaps I'm specifying the color palette incorrectly? Here are a few versions I've tried:. ```. sc.pl.tsne(adata, . color=['louvain'], . #palette=['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9'], . #palette=['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'],. #palette=""Set3"",. palette=sns.color_palette(""hls"", 15),. legend_fontsize=""20""). ```. ![image](https://user-images.githubusercontent.com/33738960/40148279-0b344502-5922-11e8-998c-4d5ece963253.png). But all of these attempts result in the same default cluster color scheme. Any suggestions? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/156
https://github.com/scverse/scanpy/issues/156:174,deployability,continu,continuous,174,"changing color palette for pl.tsne; Hello! I'm trying to recolor some categorical variables in the scanpy.api.pl.tsne function but am having some trouble. Specifically, with continuous data, I'm fine using the `color_map` key word to change between scales like ""viridis"" and ""Purples"" but when trying to pass the `palette` key word for categorical data (sample labels, louvain lables), it doesn't seem to update the colors in the plot. Perhaps I'm specifying the color palette incorrectly? Here are a few versions I've tried:. ```. sc.pl.tsne(adata, . color=['louvain'], . #palette=['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9'], . #palette=['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'],. #palette=""Set3"",. palette=sns.color_palette(""hls"", 15),. legend_fontsize=""20""). ```. ![image](https://user-images.githubusercontent.com/33738960/40148279-0b344502-5922-11e8-998c-4d5ece963253.png). But all of these attempts result in the same default cluster color scheme. Any suggestions? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/156
https://github.com/scverse/scanpy/issues/156:249,deployability,scale,scales,249,"changing color palette for pl.tsne; Hello! I'm trying to recolor some categorical variables in the scanpy.api.pl.tsne function but am having some trouble. Specifically, with continuous data, I'm fine using the `color_map` key word to change between scales like ""viridis"" and ""Purples"" but when trying to pass the `palette` key word for categorical data (sample labels, louvain lables), it doesn't seem to update the colors in the plot. Perhaps I'm specifying the color palette incorrectly? Here are a few versions I've tried:. ```. sc.pl.tsne(adata, . color=['louvain'], . #palette=['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9'], . #palette=['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'],. #palette=""Set3"",. palette=sns.color_palette(""hls"", 15),. legend_fontsize=""20""). ```. ![image](https://user-images.githubusercontent.com/33738960/40148279-0b344502-5922-11e8-998c-4d5ece963253.png). But all of these attempts result in the same default cluster color scheme. Any suggestions? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/156
https://github.com/scverse/scanpy/issues/156:405,deployability,updat,update,405,"changing color palette for pl.tsne; Hello! I'm trying to recolor some categorical variables in the scanpy.api.pl.tsne function but am having some trouble. Specifically, with continuous data, I'm fine using the `color_map` key word to change between scales like ""viridis"" and ""Purples"" but when trying to pass the `palette` key word for categorical data (sample labels, louvain lables), it doesn't seem to update the colors in the plot. Perhaps I'm specifying the color palette incorrectly? Here are a few versions I've tried:. ```. sc.pl.tsne(adata, . color=['louvain'], . #palette=['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9'], . #palette=['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'],. #palette=""Set3"",. palette=sns.color_palette(""hls"", 15),. legend_fontsize=""20""). ```. ![image](https://user-images.githubusercontent.com/33738960/40148279-0b344502-5922-11e8-998c-4d5ece963253.png). But all of these attempts result in the same default cluster color scheme. Any suggestions? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/156
https://github.com/scverse/scanpy/issues/156:505,deployability,version,versions,505,"changing color palette for pl.tsne; Hello! I'm trying to recolor some categorical variables in the scanpy.api.pl.tsne function but am having some trouble. Specifically, with continuous data, I'm fine using the `color_map` key word to change between scales like ""viridis"" and ""Purples"" but when trying to pass the `palette` key word for categorical data (sample labels, louvain lables), it doesn't seem to update the colors in the plot. Perhaps I'm specifying the color palette incorrectly? Here are a few versions I've tried:. ```. sc.pl.tsne(adata, . color=['louvain'], . #palette=['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9'], . #palette=['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'],. #palette=""Set3"",. palette=sns.color_palette(""hls"", 15),. legend_fontsize=""20""). ```. ![image](https://user-images.githubusercontent.com/33738960/40148279-0b344502-5922-11e8-998c-4d5ece963253.png). But all of these attempts result in the same default cluster color scheme. Any suggestions? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/156
https://github.com/scverse/scanpy/issues/156:1034,deployability,cluster,cluster,1034,"changing color palette for pl.tsne; Hello! I'm trying to recolor some categorical variables in the scanpy.api.pl.tsne function but am having some trouble. Specifically, with continuous data, I'm fine using the `color_map` key word to change between scales like ""viridis"" and ""Purples"" but when trying to pass the `palette` key word for categorical data (sample labels, louvain lables), it doesn't seem to update the colors in the plot. Perhaps I'm specifying the color palette incorrectly? Here are a few versions I've tried:. ```. sc.pl.tsne(adata, . color=['louvain'], . #palette=['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9'], . #palette=['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'],. #palette=""Set3"",. palette=sns.color_palette(""hls"", 15),. legend_fontsize=""20""). ```. ![image](https://user-images.githubusercontent.com/33738960/40148279-0b344502-5922-11e8-998c-4d5ece963253.png). But all of these attempts result in the same default cluster color scheme. Any suggestions? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/156
https://github.com/scverse/scanpy/issues/156:249,energy efficiency,scale,scales,249,"changing color palette for pl.tsne; Hello! I'm trying to recolor some categorical variables in the scanpy.api.pl.tsne function but am having some trouble. Specifically, with continuous data, I'm fine using the `color_map` key word to change between scales like ""viridis"" and ""Purples"" but when trying to pass the `palette` key word for categorical data (sample labels, louvain lables), it doesn't seem to update the colors in the plot. Perhaps I'm specifying the color palette incorrectly? Here are a few versions I've tried:. ```. sc.pl.tsne(adata, . color=['louvain'], . #palette=['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9'], . #palette=['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'],. #palette=""Set3"",. palette=sns.color_palette(""hls"", 15),. legend_fontsize=""20""). ```. ![image](https://user-images.githubusercontent.com/33738960/40148279-0b344502-5922-11e8-998c-4d5ece963253.png). But all of these attempts result in the same default cluster color scheme. Any suggestions? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/156
https://github.com/scverse/scanpy/issues/156:687,energy efficiency,green,green,687,"changing color palette for pl.tsne; Hello! I'm trying to recolor some categorical variables in the scanpy.api.pl.tsne function but am having some trouble. Specifically, with continuous data, I'm fine using the `color_map` key word to change between scales like ""viridis"" and ""Purples"" but when trying to pass the `palette` key word for categorical data (sample labels, louvain lables), it doesn't seem to update the colors in the plot. Perhaps I'm specifying the color palette incorrectly? Here are a few versions I've tried:. ```. sc.pl.tsne(adata, . color=['louvain'], . #palette=['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9'], . #palette=['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'],. #palette=""Set3"",. palette=sns.color_palette(""hls"", 15),. legend_fontsize=""20""). ```. ![image](https://user-images.githubusercontent.com/33738960/40148279-0b344502-5922-11e8-998c-4d5ece963253.png). But all of these attempts result in the same default cluster color scheme. Any suggestions? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/156
https://github.com/scverse/scanpy/issues/156:106,integrability,api,api,106,"changing color palette for pl.tsne; Hello! I'm trying to recolor some categorical variables in the scanpy.api.pl.tsne function but am having some trouble. Specifically, with continuous data, I'm fine using the `color_map` key word to change between scales like ""viridis"" and ""Purples"" but when trying to pass the `palette` key word for categorical data (sample labels, louvain lables), it doesn't seem to update the colors in the plot. Perhaps I'm specifying the color palette incorrectly? Here are a few versions I've tried:. ```. sc.pl.tsne(adata, . color=['louvain'], . #palette=['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9'], . #palette=['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'],. #palette=""Set3"",. palette=sns.color_palette(""hls"", 15),. legend_fontsize=""20""). ```. ![image](https://user-images.githubusercontent.com/33738960/40148279-0b344502-5922-11e8-998c-4d5ece963253.png). But all of these attempts result in the same default cluster color scheme. Any suggestions? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/156
https://github.com/scverse/scanpy/issues/156:505,integrability,version,versions,505,"changing color palette for pl.tsne; Hello! I'm trying to recolor some categorical variables in the scanpy.api.pl.tsne function but am having some trouble. Specifically, with continuous data, I'm fine using the `color_map` key word to change between scales like ""viridis"" and ""Purples"" but when trying to pass the `palette` key word for categorical data (sample labels, louvain lables), it doesn't seem to update the colors in the plot. Perhaps I'm specifying the color palette incorrectly? Here are a few versions I've tried:. ```. sc.pl.tsne(adata, . color=['louvain'], . #palette=['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9'], . #palette=['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'],. #palette=""Set3"",. palette=sns.color_palette(""hls"", 15),. legend_fontsize=""20""). ```. ![image](https://user-images.githubusercontent.com/33738960/40148279-0b344502-5922-11e8-998c-4d5ece963253.png). But all of these attempts result in the same default cluster color scheme. Any suggestions? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/156
https://github.com/scverse/scanpy/issues/156:106,interoperability,api,api,106,"changing color palette for pl.tsne; Hello! I'm trying to recolor some categorical variables in the scanpy.api.pl.tsne function but am having some trouble. Specifically, with continuous data, I'm fine using the `color_map` key word to change between scales like ""viridis"" and ""Purples"" but when trying to pass the `palette` key word for categorical data (sample labels, louvain lables), it doesn't seem to update the colors in the plot. Perhaps I'm specifying the color palette incorrectly? Here are a few versions I've tried:. ```. sc.pl.tsne(adata, . color=['louvain'], . #palette=['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9'], . #palette=['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'],. #palette=""Set3"",. palette=sns.color_palette(""hls"", 15),. legend_fontsize=""20""). ```. ![image](https://user-images.githubusercontent.com/33738960/40148279-0b344502-5922-11e8-998c-4d5ece963253.png). But all of these attempts result in the same default cluster color scheme. Any suggestions? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/156
https://github.com/scverse/scanpy/issues/156:155,interoperability,Specif,Specifically,155,"changing color palette for pl.tsne; Hello! I'm trying to recolor some categorical variables in the scanpy.api.pl.tsne function but am having some trouble. Specifically, with continuous data, I'm fine using the `color_map` key word to change between scales like ""viridis"" and ""Purples"" but when trying to pass the `palette` key word for categorical data (sample labels, louvain lables), it doesn't seem to update the colors in the plot. Perhaps I'm specifying the color palette incorrectly? Here are a few versions I've tried:. ```. sc.pl.tsne(adata, . color=['louvain'], . #palette=['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9'], . #palette=['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'],. #palette=""Set3"",. palette=sns.color_palette(""hls"", 15),. legend_fontsize=""20""). ```. ![image](https://user-images.githubusercontent.com/33738960/40148279-0b344502-5922-11e8-998c-4d5ece963253.png). But all of these attempts result in the same default cluster color scheme. Any suggestions? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/156
https://github.com/scverse/scanpy/issues/156:448,interoperability,specif,specifying,448,"changing color palette for pl.tsne; Hello! I'm trying to recolor some categorical variables in the scanpy.api.pl.tsne function but am having some trouble. Specifically, with continuous data, I'm fine using the `color_map` key word to change between scales like ""viridis"" and ""Purples"" but when trying to pass the `palette` key word for categorical data (sample labels, louvain lables), it doesn't seem to update the colors in the plot. Perhaps I'm specifying the color palette incorrectly? Here are a few versions I've tried:. ```. sc.pl.tsne(adata, . color=['louvain'], . #palette=['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9'], . #palette=['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'],. #palette=""Set3"",. palette=sns.color_palette(""hls"", 15),. legend_fontsize=""20""). ```. ![image](https://user-images.githubusercontent.com/33738960/40148279-0b344502-5922-11e8-998c-4d5ece963253.png). But all of these attempts result in the same default cluster color scheme. Any suggestions? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/156
https://github.com/scverse/scanpy/issues/156:82,modifiability,variab,variables,82,"changing color palette for pl.tsne; Hello! I'm trying to recolor some categorical variables in the scanpy.api.pl.tsne function but am having some trouble. Specifically, with continuous data, I'm fine using the `color_map` key word to change between scales like ""viridis"" and ""Purples"" but when trying to pass the `palette` key word for categorical data (sample labels, louvain lables), it doesn't seem to update the colors in the plot. Perhaps I'm specifying the color palette incorrectly? Here are a few versions I've tried:. ```. sc.pl.tsne(adata, . color=['louvain'], . #palette=['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9'], . #palette=['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'],. #palette=""Set3"",. palette=sns.color_palette(""hls"", 15),. legend_fontsize=""20""). ```. ![image](https://user-images.githubusercontent.com/33738960/40148279-0b344502-5922-11e8-998c-4d5ece963253.png). But all of these attempts result in the same default cluster color scheme. Any suggestions? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/156
https://github.com/scverse/scanpy/issues/156:249,modifiability,scal,scales,249,"changing color palette for pl.tsne; Hello! I'm trying to recolor some categorical variables in the scanpy.api.pl.tsne function but am having some trouble. Specifically, with continuous data, I'm fine using the `color_map` key word to change between scales like ""viridis"" and ""Purples"" but when trying to pass the `palette` key word for categorical data (sample labels, louvain lables), it doesn't seem to update the colors in the plot. Perhaps I'm specifying the color palette incorrectly? Here are a few versions I've tried:. ```. sc.pl.tsne(adata, . color=['louvain'], . #palette=['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9'], . #palette=['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'],. #palette=""Set3"",. palette=sns.color_palette(""hls"", 15),. legend_fontsize=""20""). ```. ![image](https://user-images.githubusercontent.com/33738960/40148279-0b344502-5922-11e8-998c-4d5ece963253.png). But all of these attempts result in the same default cluster color scheme. Any suggestions? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/156
https://github.com/scverse/scanpy/issues/156:505,modifiability,version,versions,505,"changing color palette for pl.tsne; Hello! I'm trying to recolor some categorical variables in the scanpy.api.pl.tsne function but am having some trouble. Specifically, with continuous data, I'm fine using the `color_map` key word to change between scales like ""viridis"" and ""Purples"" but when trying to pass the `palette` key word for categorical data (sample labels, louvain lables), it doesn't seem to update the colors in the plot. Perhaps I'm specifying the color palette incorrectly? Here are a few versions I've tried:. ```. sc.pl.tsne(adata, . color=['louvain'], . #palette=['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9'], . #palette=['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'],. #palette=""Set3"",. palette=sns.color_palette(""hls"", 15),. legend_fontsize=""20""). ```. ![image](https://user-images.githubusercontent.com/33738960/40148279-0b344502-5922-11e8-998c-4d5ece963253.png). But all of these attempts result in the same default cluster color scheme. Any suggestions? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/156
https://github.com/scverse/scanpy/issues/156:249,performance,scale,scales,249,"changing color palette for pl.tsne; Hello! I'm trying to recolor some categorical variables in the scanpy.api.pl.tsne function but am having some trouble. Specifically, with continuous data, I'm fine using the `color_map` key word to change between scales like ""viridis"" and ""Purples"" but when trying to pass the `palette` key word for categorical data (sample labels, louvain lables), it doesn't seem to update the colors in the plot. Perhaps I'm specifying the color palette incorrectly? Here are a few versions I've tried:. ```. sc.pl.tsne(adata, . color=['louvain'], . #palette=['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9'], . #palette=['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'],. #palette=""Set3"",. palette=sns.color_palette(""hls"", 15),. legend_fontsize=""20""). ```. ![image](https://user-images.githubusercontent.com/33738960/40148279-0b344502-5922-11e8-998c-4d5ece963253.png). But all of these attempts result in the same default cluster color scheme. Any suggestions? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/156
https://github.com/scverse/scanpy/issues/156:389,reliability,doe,doesn,389,"changing color palette for pl.tsne; Hello! I'm trying to recolor some categorical variables in the scanpy.api.pl.tsne function but am having some trouble. Specifically, with continuous data, I'm fine using the `color_map` key word to change between scales like ""viridis"" and ""Purples"" but when trying to pass the `palette` key word for categorical data (sample labels, louvain lables), it doesn't seem to update the colors in the plot. Perhaps I'm specifying the color palette incorrectly? Here are a few versions I've tried:. ```. sc.pl.tsne(adata, . color=['louvain'], . #palette=['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9'], . #palette=['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'],. #palette=""Set3"",. palette=sns.color_palette(""hls"", 15),. legend_fontsize=""20""). ```. ![image](https://user-images.githubusercontent.com/33738960/40148279-0b344502-5922-11e8-998c-4d5ece963253.png). But all of these attempts result in the same default cluster color scheme. Any suggestions? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/156
https://github.com/scverse/scanpy/issues/156:405,safety,updat,update,405,"changing color palette for pl.tsne; Hello! I'm trying to recolor some categorical variables in the scanpy.api.pl.tsne function but am having some trouble. Specifically, with continuous data, I'm fine using the `color_map` key word to change between scales like ""viridis"" and ""Purples"" but when trying to pass the `palette` key word for categorical data (sample labels, louvain lables), it doesn't seem to update the colors in the plot. Perhaps I'm specifying the color palette incorrectly? Here are a few versions I've tried:. ```. sc.pl.tsne(adata, . color=['louvain'], . #palette=['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9'], . #palette=['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'],. #palette=""Set3"",. palette=sns.color_palette(""hls"", 15),. legend_fontsize=""20""). ```. ![image](https://user-images.githubusercontent.com/33738960/40148279-0b344502-5922-11e8-998c-4d5ece963253.png). But all of these attempts result in the same default cluster color scheme. Any suggestions? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/156
https://github.com/scverse/scanpy/issues/156:405,security,updat,update,405,"changing color palette for pl.tsne; Hello! I'm trying to recolor some categorical variables in the scanpy.api.pl.tsne function but am having some trouble. Specifically, with continuous data, I'm fine using the `color_map` key word to change between scales like ""viridis"" and ""Purples"" but when trying to pass the `palette` key word for categorical data (sample labels, louvain lables), it doesn't seem to update the colors in the plot. Perhaps I'm specifying the color palette incorrectly? Here are a few versions I've tried:. ```. sc.pl.tsne(adata, . color=['louvain'], . #palette=['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9'], . #palette=['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'],. #palette=""Set3"",. palette=sns.color_palette(""hls"", 15),. legend_fontsize=""20""). ```. ![image](https://user-images.githubusercontent.com/33738960/40148279-0b344502-5922-11e8-998c-4d5ece963253.png). But all of these attempts result in the same default cluster color scheme. Any suggestions? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/156
https://github.com/scverse/scanpy/issues/156:886,usability,user,user-images,886,"changing color palette for pl.tsne; Hello! I'm trying to recolor some categorical variables in the scanpy.api.pl.tsne function but am having some trouble. Specifically, with continuous data, I'm fine using the `color_map` key word to change between scales like ""viridis"" and ""Purples"" but when trying to pass the `palette` key word for categorical data (sample labels, louvain lables), it doesn't seem to update the colors in the plot. Perhaps I'm specifying the color palette incorrectly? Here are a few versions I've tried:. ```. sc.pl.tsne(adata, . color=['louvain'], . #palette=['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9'], . #palette=['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan'],. #palette=""Set3"",. palette=sns.color_palette(""hls"", 15),. legend_fontsize=""20""). ```. ![image](https://user-images.githubusercontent.com/33738960/40148279-0b344502-5922-11e8-998c-4d5ece963253.png). But all of these attempts result in the same default cluster color scheme. Any suggestions? Thanks!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/156
https://github.com/scverse/scanpy/pull/157:20,deployability,updat,updated,20,SPRING v2 export; I updated the export function `sc.export_to.spring_project` to work with our new version of SPRING (currently at https://github.com/allonkleinlab/spring_dev). .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/157
https://github.com/scverse/scanpy/pull/157:99,deployability,version,version,99,SPRING v2 export; I updated the export function `sc.export_to.spring_project` to work with our new version of SPRING (currently at https://github.com/allonkleinlab/spring_dev). .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/157
https://github.com/scverse/scanpy/pull/157:118,energy efficiency,current,currently,118,SPRING v2 export; I updated the export function `sc.export_to.spring_project` to work with our new version of SPRING (currently at https://github.com/allonkleinlab/spring_dev). .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/157
https://github.com/scverse/scanpy/pull/157:99,integrability,version,version,99,SPRING v2 export; I updated the export function `sc.export_to.spring_project` to work with our new version of SPRING (currently at https://github.com/allonkleinlab/spring_dev). .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/157
https://github.com/scverse/scanpy/pull/157:99,modifiability,version,version,99,SPRING v2 export; I updated the export function `sc.export_to.spring_project` to work with our new version of SPRING (currently at https://github.com/allonkleinlab/spring_dev). .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/157
https://github.com/scverse/scanpy/pull/157:20,safety,updat,updated,20,SPRING v2 export; I updated the export function `sc.export_to.spring_project` to work with our new version of SPRING (currently at https://github.com/allonkleinlab/spring_dev). .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/157
https://github.com/scverse/scanpy/pull/157:20,security,updat,updated,20,SPRING v2 export; I updated the export function `sc.export_to.spring_project` to work with our new version of SPRING (currently at https://github.com/allonkleinlab/spring_dev). .,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/157
https://github.com/scverse/scanpy/issues/158:0,availability,error,error,0,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:117,availability,error,error,117,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:343,deployability,modul,module,343,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:616,energy efficiency,core,core,616,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:747,energy efficiency,core,core,747,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:893,energy efficiency,core,core,893,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:1033,energy efficiency,core,core,1033,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:1170,energy efficiency,core,core,1170,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:1298,energy efficiency,core,core,1298,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:1435,energy efficiency,core,core,1435,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:1579,energy efficiency,core,core,1579,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:1788,integrability,Buffer,Buffer,1788,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:1801,interoperability,mismatch,mismatch,1801,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:343,modifiability,modul,module,343,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:403,modifiability,pac,packages,403,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:600,modifiability,pac,packages,600,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:731,modifiability,pac,packages,731,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:877,modifiability,pac,packages,877,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:1017,modifiability,pac,packages,1017,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:1154,modifiability,pac,packages,1154,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:1282,modifiability,pac,packages,1282,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:1419,modifiability,pac,packages,1419,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:1563,modifiability,pac,packages,1563,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:0,performance,error,error,0,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:68,performance,time,time,68,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:117,performance,error,error,117,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:0,safety,error,error,0,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:117,safety,error,error,117,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:343,safety,modul,module,343,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:1845,security,sign,signed,1845,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:279,testability,Trace,Traceback,279,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:433,testability,simpl,simple,433,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:0,usability,error,error,0,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:117,usability,error,error,117,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/158:433,usability,simpl,simple,433,"error in scanpy first tutorial; Hi, I'm trying scanpy for the first time, but following the first tutorial I got the error below. Any idea of what is happening? ```pytb. >>> filter_result = sc.pp.filter_genes_dispersion(. ... adata.X, min_mean=0.0125, max_mean=3, min_disp=0.5). Traceback (most recent call last):. File ""<stdin>"", line 2, in <module>. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/scanpy/preprocessing/simple.py"", line 328, in filter_genes_dispersion. disp_std_bin[one_gene_per_bin] = disp_mean_bin[one_gene_per_bin]. File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 938, in __setitem__. setitem(key, value). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 929, in setitem. self._where(~key, value, inplace=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7539, in _where. level=level, fill_value=np.nan). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/series.py"", line 3248, in align. broadcast_axis=broadcast_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7366, in align. fill_axis=fill_axis). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/generic.py"", line 7435, in _align_series. return_indexers=True). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 3772, in join. return_indexers=return_indexers). File ""/opt/anaconda3/envs/tiget/lib/python3.6/site-packages/pandas/core/indexes/base.py"", line 4012, in _join_monotonic. ridx = self._left_indexer_unique(sv, ov). File ""pandas/_libs/join_helper.pxi"", line 774, in pandas._libs.join.left_join_indexer_unique_object. ValueError: Buffer dtype mismatch, expected 'Python object' but got 'signed char'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/158
https://github.com/scverse/scanpy/issues/159:17,deployability,log,log-fold,17,"Where can I find log-fold change in gene expression for the markers; Does scanpy store log fold change, p-value and marker type flag (negative vs positive) somewhere? It looked at scObj.uns[""rank_genes_groups""] but found only 3 fields: params, scores and names.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/159
https://github.com/scverse/scanpy/issues/159:87,deployability,log,log,87,"Where can I find log-fold change in gene expression for the markers; Does scanpy store log fold change, p-value and marker type flag (negative vs positive) somewhere? It looked at scObj.uns[""rank_genes_groups""] but found only 3 fields: params, scores and names.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/159
https://github.com/scverse/scanpy/issues/159:69,reliability,Doe,Does,69,"Where can I find log-fold change in gene expression for the markers; Does scanpy store log fold change, p-value and marker type flag (negative vs positive) somewhere? It looked at scObj.uns[""rank_genes_groups""] but found only 3 fields: params, scores and names.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/159
https://github.com/scverse/scanpy/issues/159:17,safety,log,log-fold,17,"Where can I find log-fold change in gene expression for the markers; Does scanpy store log fold change, p-value and marker type flag (negative vs positive) somewhere? It looked at scObj.uns[""rank_genes_groups""] but found only 3 fields: params, scores and names.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/159
https://github.com/scverse/scanpy/issues/159:87,safety,log,log,87,"Where can I find log-fold change in gene expression for the markers; Does scanpy store log fold change, p-value and marker type flag (negative vs positive) somewhere? It looked at scObj.uns[""rank_genes_groups""] but found only 3 fields: params, scores and names.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/159
https://github.com/scverse/scanpy/issues/159:17,security,log,log-fold,17,"Where can I find log-fold change in gene expression for the markers; Does scanpy store log fold change, p-value and marker type flag (negative vs positive) somewhere? It looked at scObj.uns[""rank_genes_groups""] but found only 3 fields: params, scores and names.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/159
https://github.com/scverse/scanpy/issues/159:87,security,log,log,87,"Where can I find log-fold change in gene expression for the markers; Does scanpy store log fold change, p-value and marker type flag (negative vs positive) somewhere? It looked at scObj.uns[""rank_genes_groups""] but found only 3 fields: params, scores and names.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/159
https://github.com/scverse/scanpy/issues/159:17,testability,log,log-fold,17,"Where can I find log-fold change in gene expression for the markers; Does scanpy store log fold change, p-value and marker type flag (negative vs positive) somewhere? It looked at scObj.uns[""rank_genes_groups""] but found only 3 fields: params, scores and names.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/159
https://github.com/scverse/scanpy/issues/159:87,testability,log,log,87,"Where can I find log-fold change in gene expression for the markers; Does scanpy store log fold change, p-value and marker type flag (negative vs positive) somewhere? It looked at scObj.uns[""rank_genes_groups""] but found only 3 fields: params, scores and names.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/159
https://github.com/scverse/scanpy/issues/160:262,availability,error,error,262,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1063,availability,error,error,1063,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:31,deployability,api,api,31,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:75,deployability,instal,install,75,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:165,deployability,instal,installation,165,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:450,deployability,api,api,450,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:525,deployability,modul,module,525,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:648,deployability,modul,module,648,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:787,deployability,modul,module,787,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:970,deployability,manag,manager,970,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1133,deployability,api,api,1133,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1421,deployability,modul,module,1421,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1444,deployability,api,api,1444,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1569,deployability,modul,module,1569,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1708,deployability,modul,module,1708,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1891,deployability,manag,manager,1891,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:970,energy efficiency,manag,manager,970,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1268,energy efficiency,core,core,1268,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1891,energy efficiency,manag,manager,1891,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:31,integrability,api,api,31,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:450,integrability,api,api,450,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1133,integrability,api,api,1133,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1444,integrability,api,api,1444,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:31,interoperability,api,api,31,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:450,interoperability,api,api,450,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1133,interoperability,api,api,1133,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1444,interoperability,api,api,1444,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:525,modifiability,modul,module,525,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:605,modifiability,pac,packages,605,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:648,modifiability,modul,module,648,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:744,modifiability,pac,packages,744,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:787,modifiability,modul,module,787,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:911,modifiability,pac,packages,911,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1251,modifiability,pac,packages,1251,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1421,modifiability,modul,module,1421,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1526,modifiability,pac,packages,1526,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1569,modifiability,modul,module,1569,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1665,modifiability,pac,packages,1665,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1708,modifiability,modul,module,1708,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1832,modifiability,pac,packages,1832,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:262,performance,error,error,262,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1063,performance,error,error,1063,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:262,safety,error,error,262,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:525,safety,modul,module,525,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:648,safety,modul,module,648,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:787,safety,modul,module,787,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:970,safety,manag,manager,970,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1063,safety,error,error,1063,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1385,safety,input,input-,1385,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1421,safety,modul,module,1421,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1569,safety,modul,module,1569,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1708,safety,modul,module,1708,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1891,safety,manag,manager,1891,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:461,testability,Trace,Traceback,461,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1144,testability,Trace,Traceback,1144,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:262,usability,error,error,262,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:367,usability,help,help,367,"Jupyter notebook import scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get ove",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1063,usability,error,error,1063,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1273,usability,interact,interactiveshell,1273,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/issues/160:1385,usability,input,input-,1385,"ort scanpy.api ; I have followed these instructions to install scanpy into my miniconda environment:. [](https://scanpy.readthedocs.io/en/latest/installation.html). Whether I try to import scanpy straight from terminal, it keeps giving me an error:. ```. Python 3.5.5 |Anaconda, Inc.| (default, Mar 12 2018, 23:12:44). [GCC 7.2.0] on linux. Type ""help"", ""copyright"", ""credits"" or ""license"" for more information. >>> import scanpy.api as sc. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. >>>. ```. I also get the error when I try to use it with jupyter notebook:. ```. import scanpy.api as sc. Traceback (most recent call last):. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2910, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-1-4a13c503728c>"", line 1, in <module>. import scanpy.api as sc. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/scanpy/__init__.py"", line 24, in <module>. import anndata. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/__init__.py"", line 1, in <module>. from .base import AnnData, _MAIN_NARRATIVE. File ""/home/unix/tamarao/miniconda3/envs/tamara_env/lib/python3.5/site-packages/anndata/base.py"", line 287. return f'Backing file manager of file {self._filename}.'. ^. SyntaxError: invalid syntax. ```. What is the issue? How can I get over this? . Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/160
https://github.com/scverse/scanpy/pull/161:37,deployability,fail,fails,37,Test on 3.5; I expect unrelated test fails; see #162,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/161
https://github.com/scverse/scanpy/pull/161:37,reliability,fail,fails,37,Test on 3.5; I expect unrelated test fails; see #162,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/161
https://github.com/scverse/scanpy/pull/161:0,safety,Test,Test,0,Test on 3.5; I expect unrelated test fails; see #162,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/161
https://github.com/scverse/scanpy/pull/161:32,safety,test,test,32,Test on 3.5; I expect unrelated test fails; see #162,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/161
https://github.com/scverse/scanpy/pull/161:0,testability,Test,Test,0,Test on 3.5; I expect unrelated test fails; see #162,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/161
https://github.com/scverse/scanpy/pull/161:32,testability,test,test,32,Test on 3.5; I expect unrelated test fails; see #162,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/161
https://github.com/scverse/scanpy/issues/162:29,deployability,fail,failing,29,"Fix tests; The tests started failing with 4499d9460b8fe6e08fffb3c4cae0948849d40586, which obviously changed nothing that could make tests fail. So I’m sure some dependency updating is responsible (Travis started installing the newwer versions and the tests fail). We need to investigate why that is and how to fix it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162
https://github.com/scverse/scanpy/issues/162:138,deployability,fail,fail,138,"Fix tests; The tests started failing with 4499d9460b8fe6e08fffb3c4cae0948849d40586, which obviously changed nothing that could make tests fail. So I’m sure some dependency updating is responsible (Travis started installing the newwer versions and the tests fail). We need to investigate why that is and how to fix it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162
https://github.com/scverse/scanpy/issues/162:161,deployability,depend,dependency,161,"Fix tests; The tests started failing with 4499d9460b8fe6e08fffb3c4cae0948849d40586, which obviously changed nothing that could make tests fail. So I’m sure some dependency updating is responsible (Travis started installing the newwer versions and the tests fail). We need to investigate why that is and how to fix it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162
https://github.com/scverse/scanpy/issues/162:172,deployability,updat,updating,172,"Fix tests; The tests started failing with 4499d9460b8fe6e08fffb3c4cae0948849d40586, which obviously changed nothing that could make tests fail. So I’m sure some dependency updating is responsible (Travis started installing the newwer versions and the tests fail). We need to investigate why that is and how to fix it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162
https://github.com/scverse/scanpy/issues/162:212,deployability,instal,installing,212,"Fix tests; The tests started failing with 4499d9460b8fe6e08fffb3c4cae0948849d40586, which obviously changed nothing that could make tests fail. So I’m sure some dependency updating is responsible (Travis started installing the newwer versions and the tests fail). We need to investigate why that is and how to fix it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162
https://github.com/scverse/scanpy/issues/162:234,deployability,version,versions,234,"Fix tests; The tests started failing with 4499d9460b8fe6e08fffb3c4cae0948849d40586, which obviously changed nothing that could make tests fail. So I’m sure some dependency updating is responsible (Travis started installing the newwer versions and the tests fail). We need to investigate why that is and how to fix it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162
https://github.com/scverse/scanpy/issues/162:257,deployability,fail,fail,257,"Fix tests; The tests started failing with 4499d9460b8fe6e08fffb3c4cae0948849d40586, which obviously changed nothing that could make tests fail. So I’m sure some dependency updating is responsible (Travis started installing the newwer versions and the tests fail). We need to investigate why that is and how to fix it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162
https://github.com/scverse/scanpy/issues/162:161,integrability,depend,dependency,161,"Fix tests; The tests started failing with 4499d9460b8fe6e08fffb3c4cae0948849d40586, which obviously changed nothing that could make tests fail. So I’m sure some dependency updating is responsible (Travis started installing the newwer versions and the tests fail). We need to investigate why that is and how to fix it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162
https://github.com/scverse/scanpy/issues/162:234,integrability,version,versions,234,"Fix tests; The tests started failing with 4499d9460b8fe6e08fffb3c4cae0948849d40586, which obviously changed nothing that could make tests fail. So I’m sure some dependency updating is responsible (Travis started installing the newwer versions and the tests fail). We need to investigate why that is and how to fix it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162
https://github.com/scverse/scanpy/issues/162:161,modifiability,depend,dependency,161,"Fix tests; The tests started failing with 4499d9460b8fe6e08fffb3c4cae0948849d40586, which obviously changed nothing that could make tests fail. So I’m sure some dependency updating is responsible (Travis started installing the newwer versions and the tests fail). We need to investigate why that is and how to fix it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162
https://github.com/scverse/scanpy/issues/162:234,modifiability,version,versions,234,"Fix tests; The tests started failing with 4499d9460b8fe6e08fffb3c4cae0948849d40586, which obviously changed nothing that could make tests fail. So I’m sure some dependency updating is responsible (Travis started installing the newwer versions and the tests fail). We need to investigate why that is and how to fix it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162
https://github.com/scverse/scanpy/issues/162:29,reliability,fail,failing,29,"Fix tests; The tests started failing with 4499d9460b8fe6e08fffb3c4cae0948849d40586, which obviously changed nothing that could make tests fail. So I’m sure some dependency updating is responsible (Travis started installing the newwer versions and the tests fail). We need to investigate why that is and how to fix it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162
https://github.com/scverse/scanpy/issues/162:138,reliability,fail,fail,138,"Fix tests; The tests started failing with 4499d9460b8fe6e08fffb3c4cae0948849d40586, which obviously changed nothing that could make tests fail. So I’m sure some dependency updating is responsible (Travis started installing the newwer versions and the tests fail). We need to investigate why that is and how to fix it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162
https://github.com/scverse/scanpy/issues/162:257,reliability,fail,fail,257,"Fix tests; The tests started failing with 4499d9460b8fe6e08fffb3c4cae0948849d40586, which obviously changed nothing that could make tests fail. So I’m sure some dependency updating is responsible (Travis started installing the newwer versions and the tests fail). We need to investigate why that is and how to fix it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162
https://github.com/scverse/scanpy/issues/162:4,safety,test,tests,4,"Fix tests; The tests started failing with 4499d9460b8fe6e08fffb3c4cae0948849d40586, which obviously changed nothing that could make tests fail. So I’m sure some dependency updating is responsible (Travis started installing the newwer versions and the tests fail). We need to investigate why that is and how to fix it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162
https://github.com/scverse/scanpy/issues/162:15,safety,test,tests,15,"Fix tests; The tests started failing with 4499d9460b8fe6e08fffb3c4cae0948849d40586, which obviously changed nothing that could make tests fail. So I’m sure some dependency updating is responsible (Travis started installing the newwer versions and the tests fail). We need to investigate why that is and how to fix it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162
https://github.com/scverse/scanpy/issues/162:132,safety,test,tests,132,"Fix tests; The tests started failing with 4499d9460b8fe6e08fffb3c4cae0948849d40586, which obviously changed nothing that could make tests fail. So I’m sure some dependency updating is responsible (Travis started installing the newwer versions and the tests fail). We need to investigate why that is and how to fix it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162
https://github.com/scverse/scanpy/issues/162:161,safety,depend,dependency,161,"Fix tests; The tests started failing with 4499d9460b8fe6e08fffb3c4cae0948849d40586, which obviously changed nothing that could make tests fail. So I’m sure some dependency updating is responsible (Travis started installing the newwer versions and the tests fail). We need to investigate why that is and how to fix it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162
https://github.com/scverse/scanpy/issues/162:172,safety,updat,updating,172,"Fix tests; The tests started failing with 4499d9460b8fe6e08fffb3c4cae0948849d40586, which obviously changed nothing that could make tests fail. So I’m sure some dependency updating is responsible (Travis started installing the newwer versions and the tests fail). We need to investigate why that is and how to fix it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162
https://github.com/scverse/scanpy/issues/162:251,safety,test,tests,251,"Fix tests; The tests started failing with 4499d9460b8fe6e08fffb3c4cae0948849d40586, which obviously changed nothing that could make tests fail. So I’m sure some dependency updating is responsible (Travis started installing the newwer versions and the tests fail). We need to investigate why that is and how to fix it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162
https://github.com/scverse/scanpy/issues/162:172,security,updat,updating,172,"Fix tests; The tests started failing with 4499d9460b8fe6e08fffb3c4cae0948849d40586, which obviously changed nothing that could make tests fail. So I’m sure some dependency updating is responsible (Travis started installing the newwer versions and the tests fail). We need to investigate why that is and how to fix it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162
https://github.com/scverse/scanpy/issues/162:4,testability,test,tests,4,"Fix tests; The tests started failing with 4499d9460b8fe6e08fffb3c4cae0948849d40586, which obviously changed nothing that could make tests fail. So I’m sure some dependency updating is responsible (Travis started installing the newwer versions and the tests fail). We need to investigate why that is and how to fix it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162
https://github.com/scverse/scanpy/issues/162:15,testability,test,tests,15,"Fix tests; The tests started failing with 4499d9460b8fe6e08fffb3c4cae0948849d40586, which obviously changed nothing that could make tests fail. So I’m sure some dependency updating is responsible (Travis started installing the newwer versions and the tests fail). We need to investigate why that is and how to fix it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162
https://github.com/scverse/scanpy/issues/162:132,testability,test,tests,132,"Fix tests; The tests started failing with 4499d9460b8fe6e08fffb3c4cae0948849d40586, which obviously changed nothing that could make tests fail. So I’m sure some dependency updating is responsible (Travis started installing the newwer versions and the tests fail). We need to investigate why that is and how to fix it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162
https://github.com/scverse/scanpy/issues/162:161,testability,depend,dependency,161,"Fix tests; The tests started failing with 4499d9460b8fe6e08fffb3c4cae0948849d40586, which obviously changed nothing that could make tests fail. So I’m sure some dependency updating is responsible (Travis started installing the newwer versions and the tests fail). We need to investigate why that is and how to fix it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162
https://github.com/scverse/scanpy/issues/162:251,testability,test,tests,251,"Fix tests; The tests started failing with 4499d9460b8fe6e08fffb3c4cae0948849d40586, which obviously changed nothing that could make tests fail. So I’m sure some dependency updating is responsible (Travis started installing the newwer versions and the tests fail). We need to investigate why that is and how to fix it.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/162
https://github.com/scverse/scanpy/issues/163:407,energy efficiency,current,current,407,"faster mean, variance for computing dispersion; I did a time comparison on the scanpy function to compute mean and variance and the sklearn function that does the same. Here some results with a very large matrix (84.7 million values,):. ```python. adata.X. ```. > <8847360x58051 sparse matrix of type '<class 'numpy.float32'>'. > 	with 84702299 stored elements in Compressed Sparse Row format>. > . **Using current implementation**:. ```python. import scanpy.preprocessing.simple as simple. %timeit simple._get_mean_var(adata.X). ```. 2.3 s ± 114 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). **Using sklearn sparse functions**:. ```python. import sklearn.utils.sparsefuncs as sparsefuncs. def unbiased_estimator(X):. mean, var =sparsefuncs.mean_variance_axis(X, 0). # enforce R convention (unbiased estimator) for variance. var *= (X.shape[0]/(X.shape[0]-1)). return mean, var. %timeit unbiased_estimator(adata.X). ```. > 141 ms ± 6.95 ms per loop (mean ± std. dev. of 7 runs, 10 loops each). >. The results returned by both methods are different only in the precision:. ```python. # the variance of both methods. simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1]. ```. > (array([0.0073651 , 0.00061313, 0.005346 , ..., 0.05514137, 0.01749513,. > 0.05664281], dtype=float32),. > array([0.0073651 , 0.00061313, 0.00534599, ..., 0.05514137, 0.01749513,. > 0.05664282], dtype=float32)). > . ```python. np.allclose(simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1], rtol=1e-4,). ```. > True. This comparison is for the variance, but for the mean, the same results are obtained. I suggest to replace the `_get_mean_var` function for the sklearn function. **Note** the sklearn function only works with a sparse matrix.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/163
https://github.com/scverse/scanpy/issues/163:809,energy efficiency,estimat,estimator,809,"faster mean, variance for computing dispersion; I did a time comparison on the scanpy function to compute mean and variance and the sklearn function that does the same. Here some results with a very large matrix (84.7 million values,):. ```python. adata.X. ```. > <8847360x58051 sparse matrix of type '<class 'numpy.float32'>'. > 	with 84702299 stored elements in Compressed Sparse Row format>. > . **Using current implementation**:. ```python. import scanpy.preprocessing.simple as simple. %timeit simple._get_mean_var(adata.X). ```. 2.3 s ± 114 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). **Using sklearn sparse functions**:. ```python. import sklearn.utils.sparsefuncs as sparsefuncs. def unbiased_estimator(X):. mean, var =sparsefuncs.mean_variance_axis(X, 0). # enforce R convention (unbiased estimator) for variance. var *= (X.shape[0]/(X.shape[0]-1)). return mean, var. %timeit unbiased_estimator(adata.X). ```. > 141 ms ± 6.95 ms per loop (mean ± std. dev. of 7 runs, 10 loops each). >. The results returned by both methods are different only in the precision:. ```python. # the variance of both methods. simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1]. ```. > (array([0.0073651 , 0.00061313, 0.005346 , ..., 0.05514137, 0.01749513,. > 0.05664281], dtype=float32),. > array([0.0073651 , 0.00061313, 0.00534599, ..., 0.05514137, 0.01749513,. > 0.05664282], dtype=float32)). > . ```python. np.allclose(simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1], rtol=1e-4,). ```. > True. This comparison is for the variance, but for the mean, the same results are obtained. I suggest to replace the `_get_mean_var` function for the sklearn function. **Note** the sklearn function only works with a sparse matrix.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/163
https://github.com/scverse/scanpy/issues/163:386,interoperability,format,format,386,"faster mean, variance for computing dispersion; I did a time comparison on the scanpy function to compute mean and variance and the sklearn function that does the same. Here some results with a very large matrix (84.7 million values,):. ```python. adata.X. ```. > <8847360x58051 sparse matrix of type '<class 'numpy.float32'>'. > 	with 84702299 stored elements in Compressed Sparse Row format>. > . **Using current implementation**:. ```python. import scanpy.preprocessing.simple as simple. %timeit simple._get_mean_var(adata.X). ```. 2.3 s ± 114 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). **Using sklearn sparse functions**:. ```python. import sklearn.utils.sparsefuncs as sparsefuncs. def unbiased_estimator(X):. mean, var =sparsefuncs.mean_variance_axis(X, 0). # enforce R convention (unbiased estimator) for variance. var *= (X.shape[0]/(X.shape[0]-1)). return mean, var. %timeit unbiased_estimator(adata.X). ```. > 141 ms ± 6.95 ms per loop (mean ± std. dev. of 7 runs, 10 loops each). >. The results returned by both methods are different only in the precision:. ```python. # the variance of both methods. simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1]. ```. > (array([0.0073651 , 0.00061313, 0.005346 , ..., 0.05514137, 0.01749513,. > 0.05664281], dtype=float32),. > array([0.0073651 , 0.00061313, 0.00534599, ..., 0.05514137, 0.01749513,. > 0.05664282], dtype=float32)). > . ```python. np.allclose(simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1], rtol=1e-4,). ```. > True. This comparison is for the variance, but for the mean, the same results are obtained. I suggest to replace the `_get_mean_var` function for the sklearn function. **Note** the sklearn function only works with a sparse matrix.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/163
https://github.com/scverse/scanpy/issues/163:56,performance,time,time,56,"faster mean, variance for computing dispersion; I did a time comparison on the scanpy function to compute mean and variance and the sklearn function that does the same. Here some results with a very large matrix (84.7 million values,):. ```python. adata.X. ```. > <8847360x58051 sparse matrix of type '<class 'numpy.float32'>'. > 	with 84702299 stored elements in Compressed Sparse Row format>. > . **Using current implementation**:. ```python. import scanpy.preprocessing.simple as simple. %timeit simple._get_mean_var(adata.X). ```. 2.3 s ± 114 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). **Using sklearn sparse functions**:. ```python. import sklearn.utils.sparsefuncs as sparsefuncs. def unbiased_estimator(X):. mean, var =sparsefuncs.mean_variance_axis(X, 0). # enforce R convention (unbiased estimator) for variance. var *= (X.shape[0]/(X.shape[0]-1)). return mean, var. %timeit unbiased_estimator(adata.X). ```. > 141 ms ± 6.95 ms per loop (mean ± std. dev. of 7 runs, 10 loops each). >. The results returned by both methods are different only in the precision:. ```python. # the variance of both methods. simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1]. ```. > (array([0.0073651 , 0.00061313, 0.005346 , ..., 0.05514137, 0.01749513,. > 0.05664281], dtype=float32),. > array([0.0073651 , 0.00061313, 0.00534599, ..., 0.05514137, 0.01749513,. > 0.05664282], dtype=float32)). > . ```python. np.allclose(simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1], rtol=1e-4,). ```. > True. This comparison is for the variance, but for the mean, the same results are obtained. I suggest to replace the `_get_mean_var` function for the sklearn function. **Note** the sklearn function only works with a sparse matrix.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/163
https://github.com/scverse/scanpy/issues/163:492,performance,time,timeit,492,"faster mean, variance for computing dispersion; I did a time comparison on the scanpy function to compute mean and variance and the sklearn function that does the same. Here some results with a very large matrix (84.7 million values,):. ```python. adata.X. ```. > <8847360x58051 sparse matrix of type '<class 'numpy.float32'>'. > 	with 84702299 stored elements in Compressed Sparse Row format>. > . **Using current implementation**:. ```python. import scanpy.preprocessing.simple as simple. %timeit simple._get_mean_var(adata.X). ```. 2.3 s ± 114 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). **Using sklearn sparse functions**:. ```python. import sklearn.utils.sparsefuncs as sparsefuncs. def unbiased_estimator(X):. mean, var =sparsefuncs.mean_variance_axis(X, 0). # enforce R convention (unbiased estimator) for variance. var *= (X.shape[0]/(X.shape[0]-1)). return mean, var. %timeit unbiased_estimator(adata.X). ```. > 141 ms ± 6.95 ms per loop (mean ± std. dev. of 7 runs, 10 loops each). >. The results returned by both methods are different only in the precision:. ```python. # the variance of both methods. simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1]. ```. > (array([0.0073651 , 0.00061313, 0.005346 , ..., 0.05514137, 0.01749513,. > 0.05664281], dtype=float32),. > array([0.0073651 , 0.00061313, 0.00534599, ..., 0.05514137, 0.01749513,. > 0.05664282], dtype=float32)). > . ```python. np.allclose(simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1], rtol=1e-4,). ```. > True. This comparison is for the variance, but for the mean, the same results are obtained. I suggest to replace the `_get_mean_var` function for the sklearn function. **Note** the sklearn function only works with a sparse matrix.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/163
https://github.com/scverse/scanpy/issues/163:889,performance,time,timeit,889,"faster mean, variance for computing dispersion; I did a time comparison on the scanpy function to compute mean and variance and the sklearn function that does the same. Here some results with a very large matrix (84.7 million values,):. ```python. adata.X. ```. > <8847360x58051 sparse matrix of type '<class 'numpy.float32'>'. > 	with 84702299 stored elements in Compressed Sparse Row format>. > . **Using current implementation**:. ```python. import scanpy.preprocessing.simple as simple. %timeit simple._get_mean_var(adata.X). ```. 2.3 s ± 114 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). **Using sklearn sparse functions**:. ```python. import sklearn.utils.sparsefuncs as sparsefuncs. def unbiased_estimator(X):. mean, var =sparsefuncs.mean_variance_axis(X, 0). # enforce R convention (unbiased estimator) for variance. var *= (X.shape[0]/(X.shape[0]-1)). return mean, var. %timeit unbiased_estimator(adata.X). ```. > 141 ms ± 6.95 ms per loop (mean ± std. dev. of 7 runs, 10 loops each). >. The results returned by both methods are different only in the precision:. ```python. # the variance of both methods. simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1]. ```. > (array([0.0073651 , 0.00061313, 0.005346 , ..., 0.05514137, 0.01749513,. > 0.05664281], dtype=float32),. > array([0.0073651 , 0.00061313, 0.00534599, ..., 0.05514137, 0.01749513,. > 0.05664282], dtype=float32)). > . ```python. np.allclose(simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1], rtol=1e-4,). ```. > True. This comparison is for the variance, but for the mean, the same results are obtained. I suggest to replace the `_get_mean_var` function for the sklearn function. **Note** the sklearn function only works with a sparse matrix.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/163
https://github.com/scverse/scanpy/issues/163:154,reliability,doe,does,154,"faster mean, variance for computing dispersion; I did a time comparison on the scanpy function to compute mean and variance and the sklearn function that does the same. Here some results with a very large matrix (84.7 million values,):. ```python. adata.X. ```. > <8847360x58051 sparse matrix of type '<class 'numpy.float32'>'. > 	with 84702299 stored elements in Compressed Sparse Row format>. > . **Using current implementation**:. ```python. import scanpy.preprocessing.simple as simple. %timeit simple._get_mean_var(adata.X). ```. 2.3 s ± 114 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). **Using sklearn sparse functions**:. ```python. import sklearn.utils.sparsefuncs as sparsefuncs. def unbiased_estimator(X):. mean, var =sparsefuncs.mean_variance_axis(X, 0). # enforce R convention (unbiased estimator) for variance. var *= (X.shape[0]/(X.shape[0]-1)). return mean, var. %timeit unbiased_estimator(adata.X). ```. > 141 ms ± 6.95 ms per loop (mean ± std. dev. of 7 runs, 10 loops each). >. The results returned by both methods are different only in the precision:. ```python. # the variance of both methods. simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1]. ```. > (array([0.0073651 , 0.00061313, 0.005346 , ..., 0.05514137, 0.01749513,. > 0.05664281], dtype=float32),. > array([0.0073651 , 0.00061313, 0.00534599, ..., 0.05514137, 0.01749513,. > 0.05664282], dtype=float32)). > . ```python. np.allclose(simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1], rtol=1e-4,). ```. > True. This comparison is for the variance, but for the mean, the same results are obtained. I suggest to replace the `_get_mean_var` function for the sklearn function. **Note** the sklearn function only works with a sparse matrix.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/163
https://github.com/scverse/scanpy/issues/163:1502,reliability,rto,rtol,1502,"faster mean, variance for computing dispersion; I did a time comparison on the scanpy function to compute mean and variance and the sklearn function that does the same. Here some results with a very large matrix (84.7 million values,):. ```python. adata.X. ```. > <8847360x58051 sparse matrix of type '<class 'numpy.float32'>'. > 	with 84702299 stored elements in Compressed Sparse Row format>. > . **Using current implementation**:. ```python. import scanpy.preprocessing.simple as simple. %timeit simple._get_mean_var(adata.X). ```. 2.3 s ± 114 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). **Using sklearn sparse functions**:. ```python. import sklearn.utils.sparsefuncs as sparsefuncs. def unbiased_estimator(X):. mean, var =sparsefuncs.mean_variance_axis(X, 0). # enforce R convention (unbiased estimator) for variance. var *= (X.shape[0]/(X.shape[0]-1)). return mean, var. %timeit unbiased_estimator(adata.X). ```. > 141 ms ± 6.95 ms per loop (mean ± std. dev. of 7 runs, 10 loops each). >. The results returned by both methods are different only in the precision:. ```python. # the variance of both methods. simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1]. ```. > (array([0.0073651 , 0.00061313, 0.005346 , ..., 0.05514137, 0.01749513,. > 0.05664281], dtype=float32),. > array([0.0073651 , 0.00061313, 0.00534599, ..., 0.05514137, 0.01749513,. > 0.05664282], dtype=float32)). > . ```python. np.allclose(simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1], rtol=1e-4,). ```. > True. This comparison is for the variance, but for the mean, the same results are obtained. I suggest to replace the `_get_mean_var` function for the sklearn function. **Note** the sklearn function only works with a sparse matrix.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/163
https://github.com/scverse/scanpy/issues/163:473,testability,simpl,simple,473,"faster mean, variance for computing dispersion; I did a time comparison on the scanpy function to compute mean and variance and the sklearn function that does the same. Here some results with a very large matrix (84.7 million values,):. ```python. adata.X. ```. > <8847360x58051 sparse matrix of type '<class 'numpy.float32'>'. > 	with 84702299 stored elements in Compressed Sparse Row format>. > . **Using current implementation**:. ```python. import scanpy.preprocessing.simple as simple. %timeit simple._get_mean_var(adata.X). ```. 2.3 s ± 114 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). **Using sklearn sparse functions**:. ```python. import sklearn.utils.sparsefuncs as sparsefuncs. def unbiased_estimator(X):. mean, var =sparsefuncs.mean_variance_axis(X, 0). # enforce R convention (unbiased estimator) for variance. var *= (X.shape[0]/(X.shape[0]-1)). return mean, var. %timeit unbiased_estimator(adata.X). ```. > 141 ms ± 6.95 ms per loop (mean ± std. dev. of 7 runs, 10 loops each). >. The results returned by both methods are different only in the precision:. ```python. # the variance of both methods. simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1]. ```. > (array([0.0073651 , 0.00061313, 0.005346 , ..., 0.05514137, 0.01749513,. > 0.05664281], dtype=float32),. > array([0.0073651 , 0.00061313, 0.00534599, ..., 0.05514137, 0.01749513,. > 0.05664282], dtype=float32)). > . ```python. np.allclose(simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1], rtol=1e-4,). ```. > True. This comparison is for the variance, but for the mean, the same results are obtained. I suggest to replace the `_get_mean_var` function for the sklearn function. **Note** the sklearn function only works with a sparse matrix.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/163
https://github.com/scverse/scanpy/issues/163:483,testability,simpl,simple,483,"faster mean, variance for computing dispersion; I did a time comparison on the scanpy function to compute mean and variance and the sklearn function that does the same. Here some results with a very large matrix (84.7 million values,):. ```python. adata.X. ```. > <8847360x58051 sparse matrix of type '<class 'numpy.float32'>'. > 	with 84702299 stored elements in Compressed Sparse Row format>. > . **Using current implementation**:. ```python. import scanpy.preprocessing.simple as simple. %timeit simple._get_mean_var(adata.X). ```. 2.3 s ± 114 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). **Using sklearn sparse functions**:. ```python. import sklearn.utils.sparsefuncs as sparsefuncs. def unbiased_estimator(X):. mean, var =sparsefuncs.mean_variance_axis(X, 0). # enforce R convention (unbiased estimator) for variance. var *= (X.shape[0]/(X.shape[0]-1)). return mean, var. %timeit unbiased_estimator(adata.X). ```. > 141 ms ± 6.95 ms per loop (mean ± std. dev. of 7 runs, 10 loops each). >. The results returned by both methods are different only in the precision:. ```python. # the variance of both methods. simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1]. ```. > (array([0.0073651 , 0.00061313, 0.005346 , ..., 0.05514137, 0.01749513,. > 0.05664281], dtype=float32),. > array([0.0073651 , 0.00061313, 0.00534599, ..., 0.05514137, 0.01749513,. > 0.05664282], dtype=float32)). > . ```python. np.allclose(simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1], rtol=1e-4,). ```. > True. This comparison is for the variance, but for the mean, the same results are obtained. I suggest to replace the `_get_mean_var` function for the sklearn function. **Note** the sklearn function only works with a sparse matrix.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/163
https://github.com/scverse/scanpy/issues/163:499,testability,simpl,simple,499,"faster mean, variance for computing dispersion; I did a time comparison on the scanpy function to compute mean and variance and the sklearn function that does the same. Here some results with a very large matrix (84.7 million values,):. ```python. adata.X. ```. > <8847360x58051 sparse matrix of type '<class 'numpy.float32'>'. > 	with 84702299 stored elements in Compressed Sparse Row format>. > . **Using current implementation**:. ```python. import scanpy.preprocessing.simple as simple. %timeit simple._get_mean_var(adata.X). ```. 2.3 s ± 114 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). **Using sklearn sparse functions**:. ```python. import sklearn.utils.sparsefuncs as sparsefuncs. def unbiased_estimator(X):. mean, var =sparsefuncs.mean_variance_axis(X, 0). # enforce R convention (unbiased estimator) for variance. var *= (X.shape[0]/(X.shape[0]-1)). return mean, var. %timeit unbiased_estimator(adata.X). ```. > 141 ms ± 6.95 ms per loop (mean ± std. dev. of 7 runs, 10 loops each). >. The results returned by both methods are different only in the precision:. ```python. # the variance of both methods. simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1]. ```. > (array([0.0073651 , 0.00061313, 0.005346 , ..., 0.05514137, 0.01749513,. > 0.05664281], dtype=float32),. > array([0.0073651 , 0.00061313, 0.00534599, ..., 0.05514137, 0.01749513,. > 0.05664282], dtype=float32)). > . ```python. np.allclose(simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1], rtol=1e-4,). ```. > True. This comparison is for the variance, but for the mean, the same results are obtained. I suggest to replace the `_get_mean_var` function for the sklearn function. **Note** the sklearn function only works with a sparse matrix.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/163
https://github.com/scverse/scanpy/issues/163:1124,testability,simpl,simple,1124,"faster mean, variance for computing dispersion; I did a time comparison on the scanpy function to compute mean and variance and the sklearn function that does the same. Here some results with a very large matrix (84.7 million values,):. ```python. adata.X. ```. > <8847360x58051 sparse matrix of type '<class 'numpy.float32'>'. > 	with 84702299 stored elements in Compressed Sparse Row format>. > . **Using current implementation**:. ```python. import scanpy.preprocessing.simple as simple. %timeit simple._get_mean_var(adata.X). ```. 2.3 s ± 114 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). **Using sklearn sparse functions**:. ```python. import sklearn.utils.sparsefuncs as sparsefuncs. def unbiased_estimator(X):. mean, var =sparsefuncs.mean_variance_axis(X, 0). # enforce R convention (unbiased estimator) for variance. var *= (X.shape[0]/(X.shape[0]-1)). return mean, var. %timeit unbiased_estimator(adata.X). ```. > 141 ms ± 6.95 ms per loop (mean ± std. dev. of 7 runs, 10 loops each). >. The results returned by both methods are different only in the precision:. ```python. # the variance of both methods. simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1]. ```. > (array([0.0073651 , 0.00061313, 0.005346 , ..., 0.05514137, 0.01749513,. > 0.05664281], dtype=float32),. > array([0.0073651 , 0.00061313, 0.00534599, ..., 0.05514137, 0.01749513,. > 0.05664282], dtype=float32)). > . ```python. np.allclose(simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1], rtol=1e-4,). ```. > True. This comparison is for the variance, but for the mean, the same results are obtained. I suggest to replace the `_get_mean_var` function for the sklearn function. **Note** the sklearn function only works with a sparse matrix.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/163
https://github.com/scverse/scanpy/issues/163:1436,testability,simpl,simple,1436,"faster mean, variance for computing dispersion; I did a time comparison on the scanpy function to compute mean and variance and the sklearn function that does the same. Here some results with a very large matrix (84.7 million values,):. ```python. adata.X. ```. > <8847360x58051 sparse matrix of type '<class 'numpy.float32'>'. > 	with 84702299 stored elements in Compressed Sparse Row format>. > . **Using current implementation**:. ```python. import scanpy.preprocessing.simple as simple. %timeit simple._get_mean_var(adata.X). ```. 2.3 s ± 114 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). **Using sklearn sparse functions**:. ```python. import sklearn.utils.sparsefuncs as sparsefuncs. def unbiased_estimator(X):. mean, var =sparsefuncs.mean_variance_axis(X, 0). # enforce R convention (unbiased estimator) for variance. var *= (X.shape[0]/(X.shape[0]-1)). return mean, var. %timeit unbiased_estimator(adata.X). ```. > 141 ms ± 6.95 ms per loop (mean ± std. dev. of 7 runs, 10 loops each). >. The results returned by both methods are different only in the precision:. ```python. # the variance of both methods. simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1]. ```. > (array([0.0073651 , 0.00061313, 0.005346 , ..., 0.05514137, 0.01749513,. > 0.05664281], dtype=float32),. > array([0.0073651 , 0.00061313, 0.00534599, ..., 0.05514137, 0.01749513,. > 0.05664282], dtype=float32)). > . ```python. np.allclose(simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1], rtol=1e-4,). ```. > True. This comparison is for the variance, but for the mean, the same results are obtained. I suggest to replace the `_get_mean_var` function for the sklearn function. **Note** the sklearn function only works with a sparse matrix.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/163
https://github.com/scverse/scanpy/issues/163:473,usability,simpl,simple,473,"faster mean, variance for computing dispersion; I did a time comparison on the scanpy function to compute mean and variance and the sklearn function that does the same. Here some results with a very large matrix (84.7 million values,):. ```python. adata.X. ```. > <8847360x58051 sparse matrix of type '<class 'numpy.float32'>'. > 	with 84702299 stored elements in Compressed Sparse Row format>. > . **Using current implementation**:. ```python. import scanpy.preprocessing.simple as simple. %timeit simple._get_mean_var(adata.X). ```. 2.3 s ± 114 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). **Using sklearn sparse functions**:. ```python. import sklearn.utils.sparsefuncs as sparsefuncs. def unbiased_estimator(X):. mean, var =sparsefuncs.mean_variance_axis(X, 0). # enforce R convention (unbiased estimator) for variance. var *= (X.shape[0]/(X.shape[0]-1)). return mean, var. %timeit unbiased_estimator(adata.X). ```. > 141 ms ± 6.95 ms per loop (mean ± std. dev. of 7 runs, 10 loops each). >. The results returned by both methods are different only in the precision:. ```python. # the variance of both methods. simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1]. ```. > (array([0.0073651 , 0.00061313, 0.005346 , ..., 0.05514137, 0.01749513,. > 0.05664281], dtype=float32),. > array([0.0073651 , 0.00061313, 0.00534599, ..., 0.05514137, 0.01749513,. > 0.05664282], dtype=float32)). > . ```python. np.allclose(simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1], rtol=1e-4,). ```. > True. This comparison is for the variance, but for the mean, the same results are obtained. I suggest to replace the `_get_mean_var` function for the sklearn function. **Note** the sklearn function only works with a sparse matrix.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/163
https://github.com/scverse/scanpy/issues/163:483,usability,simpl,simple,483,"faster mean, variance for computing dispersion; I did a time comparison on the scanpy function to compute mean and variance and the sklearn function that does the same. Here some results with a very large matrix (84.7 million values,):. ```python. adata.X. ```. > <8847360x58051 sparse matrix of type '<class 'numpy.float32'>'. > 	with 84702299 stored elements in Compressed Sparse Row format>. > . **Using current implementation**:. ```python. import scanpy.preprocessing.simple as simple. %timeit simple._get_mean_var(adata.X). ```. 2.3 s ± 114 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). **Using sklearn sparse functions**:. ```python. import sklearn.utils.sparsefuncs as sparsefuncs. def unbiased_estimator(X):. mean, var =sparsefuncs.mean_variance_axis(X, 0). # enforce R convention (unbiased estimator) for variance. var *= (X.shape[0]/(X.shape[0]-1)). return mean, var. %timeit unbiased_estimator(adata.X). ```. > 141 ms ± 6.95 ms per loop (mean ± std. dev. of 7 runs, 10 loops each). >. The results returned by both methods are different only in the precision:. ```python. # the variance of both methods. simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1]. ```. > (array([0.0073651 , 0.00061313, 0.005346 , ..., 0.05514137, 0.01749513,. > 0.05664281], dtype=float32),. > array([0.0073651 , 0.00061313, 0.00534599, ..., 0.05514137, 0.01749513,. > 0.05664282], dtype=float32)). > . ```python. np.allclose(simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1], rtol=1e-4,). ```. > True. This comparison is for the variance, but for the mean, the same results are obtained. I suggest to replace the `_get_mean_var` function for the sklearn function. **Note** the sklearn function only works with a sparse matrix.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/163
https://github.com/scverse/scanpy/issues/163:499,usability,simpl,simple,499,"faster mean, variance for computing dispersion; I did a time comparison on the scanpy function to compute mean and variance and the sklearn function that does the same. Here some results with a very large matrix (84.7 million values,):. ```python. adata.X. ```. > <8847360x58051 sparse matrix of type '<class 'numpy.float32'>'. > 	with 84702299 stored elements in Compressed Sparse Row format>. > . **Using current implementation**:. ```python. import scanpy.preprocessing.simple as simple. %timeit simple._get_mean_var(adata.X). ```. 2.3 s ± 114 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). **Using sklearn sparse functions**:. ```python. import sklearn.utils.sparsefuncs as sparsefuncs. def unbiased_estimator(X):. mean, var =sparsefuncs.mean_variance_axis(X, 0). # enforce R convention (unbiased estimator) for variance. var *= (X.shape[0]/(X.shape[0]-1)). return mean, var. %timeit unbiased_estimator(adata.X). ```. > 141 ms ± 6.95 ms per loop (mean ± std. dev. of 7 runs, 10 loops each). >. The results returned by both methods are different only in the precision:. ```python. # the variance of both methods. simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1]. ```. > (array([0.0073651 , 0.00061313, 0.005346 , ..., 0.05514137, 0.01749513,. > 0.05664281], dtype=float32),. > array([0.0073651 , 0.00061313, 0.00534599, ..., 0.05514137, 0.01749513,. > 0.05664282], dtype=float32)). > . ```python. np.allclose(simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1], rtol=1e-4,). ```. > True. This comparison is for the variance, but for the mean, the same results are obtained. I suggest to replace the `_get_mean_var` function for the sklearn function. **Note** the sklearn function only works with a sparse matrix.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/163
https://github.com/scverse/scanpy/issues/163:1124,usability,simpl,simple,1124,"faster mean, variance for computing dispersion; I did a time comparison on the scanpy function to compute mean and variance and the sklearn function that does the same. Here some results with a very large matrix (84.7 million values,):. ```python. adata.X. ```. > <8847360x58051 sparse matrix of type '<class 'numpy.float32'>'. > 	with 84702299 stored elements in Compressed Sparse Row format>. > . **Using current implementation**:. ```python. import scanpy.preprocessing.simple as simple. %timeit simple._get_mean_var(adata.X). ```. 2.3 s ± 114 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). **Using sklearn sparse functions**:. ```python. import sklearn.utils.sparsefuncs as sparsefuncs. def unbiased_estimator(X):. mean, var =sparsefuncs.mean_variance_axis(X, 0). # enforce R convention (unbiased estimator) for variance. var *= (X.shape[0]/(X.shape[0]-1)). return mean, var. %timeit unbiased_estimator(adata.X). ```. > 141 ms ± 6.95 ms per loop (mean ± std. dev. of 7 runs, 10 loops each). >. The results returned by both methods are different only in the precision:. ```python. # the variance of both methods. simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1]. ```. > (array([0.0073651 , 0.00061313, 0.005346 , ..., 0.05514137, 0.01749513,. > 0.05664281], dtype=float32),. > array([0.0073651 , 0.00061313, 0.00534599, ..., 0.05514137, 0.01749513,. > 0.05664282], dtype=float32)). > . ```python. np.allclose(simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1], rtol=1e-4,). ```. > True. This comparison is for the variance, but for the mean, the same results are obtained. I suggest to replace the `_get_mean_var` function for the sklearn function. **Note** the sklearn function only works with a sparse matrix.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/163
https://github.com/scverse/scanpy/issues/163:1436,usability,simpl,simple,1436,"faster mean, variance for computing dispersion; I did a time comparison on the scanpy function to compute mean and variance and the sklearn function that does the same. Here some results with a very large matrix (84.7 million values,):. ```python. adata.X. ```. > <8847360x58051 sparse matrix of type '<class 'numpy.float32'>'. > 	with 84702299 stored elements in Compressed Sparse Row format>. > . **Using current implementation**:. ```python. import scanpy.preprocessing.simple as simple. %timeit simple._get_mean_var(adata.X). ```. 2.3 s ± 114 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). **Using sklearn sparse functions**:. ```python. import sklearn.utils.sparsefuncs as sparsefuncs. def unbiased_estimator(X):. mean, var =sparsefuncs.mean_variance_axis(X, 0). # enforce R convention (unbiased estimator) for variance. var *= (X.shape[0]/(X.shape[0]-1)). return mean, var. %timeit unbiased_estimator(adata.X). ```. > 141 ms ± 6.95 ms per loop (mean ± std. dev. of 7 runs, 10 loops each). >. The results returned by both methods are different only in the precision:. ```python. # the variance of both methods. simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1]. ```. > (array([0.0073651 , 0.00061313, 0.005346 , ..., 0.05514137, 0.01749513,. > 0.05664281], dtype=float32),. > array([0.0073651 , 0.00061313, 0.00534599, ..., 0.05514137, 0.01749513,. > 0.05664282], dtype=float32)). > . ```python. np.allclose(simple._get_mean_var(adata.X)[1], unbiased_estimator(adata.X)[1], rtol=1e-4,). ```. > True. This comparison is for the variance, but for the mean, the same results are obtained. I suggest to replace the `_get_mean_var` function for the sklearn function. **Note** the sklearn function only works with a sparse matrix.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/163
https://github.com/scverse/scanpy/pull/164:181,deployability,api,api,181,"regress_out multiprocessing; This PR adds multiprocessing to the pp.regress_out function. . Here some benchmarks:. ```python. import numpy as np. import pandas as pd. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. # create a matrix with 20.000 cells with 3000 genes. adata = AnnData(random(20000, 3000, density=0.6, format='csr')). ```. **Benchmark using ordinal variables**. ```python. # create a categorical column and run regress out using . # the categorical column. adata.obs['batch'] = pd.Categorical(np.random.randint(1, 4, size=adata.X.shape[0])). %timeit res = sc.pp.regress_out(adata, keys='batch', n_jobs=20, copy=True). ```. > 8.44 s ± 292 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. # import previous version of the function (which I saved in the file simple_old.py). from scanpy.preprocessing.simple_old import regress_out_old. %timeit res_old = regress_out_old(adata, keys='batch', n_jobs=1, copy=True). ```. > 1min 5s ± 4.45 s per loop (mean ± std. dev. of 7 runs, 1 loop each). **Compare that the previous and the new output are the same**. ```python. np.array_equal(res.X, res_old.X). ```. > True. **Benchmark using ordinal variables**. ```python. adata.obs['percent_mito'] = np.random.rand(adata.X.shape[0]). adata.obs['n_counts'] = adata.X.sum(axis=1). %timeit res2 = sc.pp.regress_out(adata, keys=['n_counts', 'percent_mito'], n_jobs=32, copy=True). ```. > 4.99 s ± 501 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. %timeit res2_old = regress_out_old(adata, keys=['n_counts', 'percent_mito'], n_jobs=1, copy=True). ```. > 41.2 s ± 7.79 s per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. np.array_equal(res2.X, res2_old.X). ```. > True.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/164
https://github.com/scverse/scanpy/pull/164:776,deployability,version,version,776,"regress_out multiprocessing; This PR adds multiprocessing to the pp.regress_out function. . Here some benchmarks:. ```python. import numpy as np. import pandas as pd. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. # create a matrix with 20.000 cells with 3000 genes. adata = AnnData(random(20000, 3000, density=0.6, format='csr')). ```. **Benchmark using ordinal variables**. ```python. # create a categorical column and run regress out using . # the categorical column. adata.obs['batch'] = pd.Categorical(np.random.randint(1, 4, size=adata.X.shape[0])). %timeit res = sc.pp.regress_out(adata, keys='batch', n_jobs=20, copy=True). ```. > 8.44 s ± 292 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. # import previous version of the function (which I saved in the file simple_old.py). from scanpy.preprocessing.simple_old import regress_out_old. %timeit res_old = regress_out_old(adata, keys='batch', n_jobs=1, copy=True). ```. > 1min 5s ± 4.45 s per loop (mean ± std. dev. of 7 runs, 1 loop each). **Compare that the previous and the new output are the same**. ```python. np.array_equal(res.X, res_old.X). ```. > True. **Benchmark using ordinal variables**. ```python. adata.obs['percent_mito'] = np.random.rand(adata.X.shape[0]). adata.obs['n_counts'] = adata.X.sum(axis=1). %timeit res2 = sc.pp.regress_out(adata, keys=['n_counts', 'percent_mito'], n_jobs=32, copy=True). ```. > 4.99 s ± 501 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. %timeit res2_old = regress_out_old(adata, keys=['n_counts', 'percent_mito'], n_jobs=1, copy=True). ```. > 41.2 s ± 7.79 s per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. np.array_equal(res2.X, res2_old.X). ```. > True.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/164
https://github.com/scverse/scanpy/pull/164:181,integrability,api,api,181,"regress_out multiprocessing; This PR adds multiprocessing to the pp.regress_out function. . Here some benchmarks:. ```python. import numpy as np. import pandas as pd. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. # create a matrix with 20.000 cells with 3000 genes. adata = AnnData(random(20000, 3000, density=0.6, format='csr')). ```. **Benchmark using ordinal variables**. ```python. # create a categorical column and run regress out using . # the categorical column. adata.obs['batch'] = pd.Categorical(np.random.randint(1, 4, size=adata.X.shape[0])). %timeit res = sc.pp.regress_out(adata, keys='batch', n_jobs=20, copy=True). ```. > 8.44 s ± 292 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. # import previous version of the function (which I saved in the file simple_old.py). from scanpy.preprocessing.simple_old import regress_out_old. %timeit res_old = regress_out_old(adata, keys='batch', n_jobs=1, copy=True). ```. > 1min 5s ± 4.45 s per loop (mean ± std. dev. of 7 runs, 1 loop each). **Compare that the previous and the new output are the same**. ```python. np.array_equal(res.X, res_old.X). ```. > True. **Benchmark using ordinal variables**. ```python. adata.obs['percent_mito'] = np.random.rand(adata.X.shape[0]). adata.obs['n_counts'] = adata.X.sum(axis=1). %timeit res2 = sc.pp.regress_out(adata, keys=['n_counts', 'percent_mito'], n_jobs=32, copy=True). ```. > 4.99 s ± 501 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. %timeit res2_old = regress_out_old(adata, keys=['n_counts', 'percent_mito'], n_jobs=1, copy=True). ```. > 41.2 s ± 7.79 s per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. np.array_equal(res2.X, res2_old.X). ```. > True.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/164
https://github.com/scverse/scanpy/pull/164:522,integrability,batch,batch,522,"regress_out multiprocessing; This PR adds multiprocessing to the pp.regress_out function. . Here some benchmarks:. ```python. import numpy as np. import pandas as pd. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. # create a matrix with 20.000 cells with 3000 genes. adata = AnnData(random(20000, 3000, density=0.6, format='csr')). ```. **Benchmark using ordinal variables**. ```python. # create a categorical column and run regress out using . # the categorical column. adata.obs['batch'] = pd.Categorical(np.random.randint(1, 4, size=adata.X.shape[0])). %timeit res = sc.pp.regress_out(adata, keys='batch', n_jobs=20, copy=True). ```. > 8.44 s ± 292 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. # import previous version of the function (which I saved in the file simple_old.py). from scanpy.preprocessing.simple_old import regress_out_old. %timeit res_old = regress_out_old(adata, keys='batch', n_jobs=1, copy=True). ```. > 1min 5s ± 4.45 s per loop (mean ± std. dev. of 7 runs, 1 loop each). **Compare that the previous and the new output are the same**. ```python. np.array_equal(res.X, res_old.X). ```. > True. **Benchmark using ordinal variables**. ```python. adata.obs['percent_mito'] = np.random.rand(adata.X.shape[0]). adata.obs['n_counts'] = adata.X.sum(axis=1). %timeit res2 = sc.pp.regress_out(adata, keys=['n_counts', 'percent_mito'], n_jobs=32, copy=True). ```. > 4.99 s ± 501 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. %timeit res2_old = regress_out_old(adata, keys=['n_counts', 'percent_mito'], n_jobs=1, copy=True). ```. > 41.2 s ± 7.79 s per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. np.array_equal(res2.X, res2_old.X). ```. > True.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/164
https://github.com/scverse/scanpy/pull/164:641,integrability,batch,batch,641,"regress_out multiprocessing; This PR adds multiprocessing to the pp.regress_out function. . Here some benchmarks:. ```python. import numpy as np. import pandas as pd. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. # create a matrix with 20.000 cells with 3000 genes. adata = AnnData(random(20000, 3000, density=0.6, format='csr')). ```. **Benchmark using ordinal variables**. ```python. # create a categorical column and run regress out using . # the categorical column. adata.obs['batch'] = pd.Categorical(np.random.randint(1, 4, size=adata.X.shape[0])). %timeit res = sc.pp.regress_out(adata, keys='batch', n_jobs=20, copy=True). ```. > 8.44 s ± 292 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. # import previous version of the function (which I saved in the file simple_old.py). from scanpy.preprocessing.simple_old import regress_out_old. %timeit res_old = regress_out_old(adata, keys='batch', n_jobs=1, copy=True). ```. > 1min 5s ± 4.45 s per loop (mean ± std. dev. of 7 runs, 1 loop each). **Compare that the previous and the new output are the same**. ```python. np.array_equal(res.X, res_old.X). ```. > True. **Benchmark using ordinal variables**. ```python. adata.obs['percent_mito'] = np.random.rand(adata.X.shape[0]). adata.obs['n_counts'] = adata.X.sum(axis=1). %timeit res2 = sc.pp.regress_out(adata, keys=['n_counts', 'percent_mito'], n_jobs=32, copy=True). ```. > 4.99 s ± 501 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. %timeit res2_old = regress_out_old(adata, keys=['n_counts', 'percent_mito'], n_jobs=1, copy=True). ```. > 41.2 s ± 7.79 s per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. np.array_equal(res2.X, res2_old.X). ```. > True.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/164
https://github.com/scverse/scanpy/pull/164:776,integrability,version,version,776,"regress_out multiprocessing; This PR adds multiprocessing to the pp.regress_out function. . Here some benchmarks:. ```python. import numpy as np. import pandas as pd. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. # create a matrix with 20.000 cells with 3000 genes. adata = AnnData(random(20000, 3000, density=0.6, format='csr')). ```. **Benchmark using ordinal variables**. ```python. # create a categorical column and run regress out using . # the categorical column. adata.obs['batch'] = pd.Categorical(np.random.randint(1, 4, size=adata.X.shape[0])). %timeit res = sc.pp.regress_out(adata, keys='batch', n_jobs=20, copy=True). ```. > 8.44 s ± 292 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. # import previous version of the function (which I saved in the file simple_old.py). from scanpy.preprocessing.simple_old import regress_out_old. %timeit res_old = regress_out_old(adata, keys='batch', n_jobs=1, copy=True). ```. > 1min 5s ± 4.45 s per loop (mean ± std. dev. of 7 runs, 1 loop each). **Compare that the previous and the new output are the same**. ```python. np.array_equal(res.X, res_old.X). ```. > True. **Benchmark using ordinal variables**. ```python. adata.obs['percent_mito'] = np.random.rand(adata.X.shape[0]). adata.obs['n_counts'] = adata.X.sum(axis=1). %timeit res2 = sc.pp.regress_out(adata, keys=['n_counts', 'percent_mito'], n_jobs=32, copy=True). ```. > 4.99 s ± 501 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. %timeit res2_old = regress_out_old(adata, keys=['n_counts', 'percent_mito'], n_jobs=1, copy=True). ```. > 41.2 s ± 7.79 s per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. np.array_equal(res2.X, res2_old.X). ```. > True.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/164
https://github.com/scverse/scanpy/pull/164:951,integrability,batch,batch,951,"regress_out multiprocessing; This PR adds multiprocessing to the pp.regress_out function. . Here some benchmarks:. ```python. import numpy as np. import pandas as pd. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. # create a matrix with 20.000 cells with 3000 genes. adata = AnnData(random(20000, 3000, density=0.6, format='csr')). ```. **Benchmark using ordinal variables**. ```python. # create a categorical column and run regress out using . # the categorical column. adata.obs['batch'] = pd.Categorical(np.random.randint(1, 4, size=adata.X.shape[0])). %timeit res = sc.pp.regress_out(adata, keys='batch', n_jobs=20, copy=True). ```. > 8.44 s ± 292 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. # import previous version of the function (which I saved in the file simple_old.py). from scanpy.preprocessing.simple_old import regress_out_old. %timeit res_old = regress_out_old(adata, keys='batch', n_jobs=1, copy=True). ```. > 1min 5s ± 4.45 s per loop (mean ± std. dev. of 7 runs, 1 loop each). **Compare that the previous and the new output are the same**. ```python. np.array_equal(res.X, res_old.X). ```. > True. **Benchmark using ordinal variables**. ```python. adata.obs['percent_mito'] = np.random.rand(adata.X.shape[0]). adata.obs['n_counts'] = adata.X.sum(axis=1). %timeit res2 = sc.pp.regress_out(adata, keys=['n_counts', 'percent_mito'], n_jobs=32, copy=True). ```. > 4.99 s ± 501 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. %timeit res2_old = regress_out_old(adata, keys=['n_counts', 'percent_mito'], n_jobs=1, copy=True). ```. > 41.2 s ± 7.79 s per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. np.array_equal(res2.X, res2_old.X). ```. > True.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/164
https://github.com/scverse/scanpy/pull/164:181,interoperability,api,api,181,"regress_out multiprocessing; This PR adds multiprocessing to the pp.regress_out function. . Here some benchmarks:. ```python. import numpy as np. import pandas as pd. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. # create a matrix with 20.000 cells with 3000 genes. adata = AnnData(random(20000, 3000, density=0.6, format='csr')). ```. **Benchmark using ordinal variables**. ```python. # create a categorical column and run regress out using . # the categorical column. adata.obs['batch'] = pd.Categorical(np.random.randint(1, 4, size=adata.X.shape[0])). %timeit res = sc.pp.regress_out(adata, keys='batch', n_jobs=20, copy=True). ```. > 8.44 s ± 292 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. # import previous version of the function (which I saved in the file simple_old.py). from scanpy.preprocessing.simple_old import regress_out_old. %timeit res_old = regress_out_old(adata, keys='batch', n_jobs=1, copy=True). ```. > 1min 5s ± 4.45 s per loop (mean ± std. dev. of 7 runs, 1 loop each). **Compare that the previous and the new output are the same**. ```python. np.array_equal(res.X, res_old.X). ```. > True. **Benchmark using ordinal variables**. ```python. adata.obs['percent_mito'] = np.random.rand(adata.X.shape[0]). adata.obs['n_counts'] = adata.X.sum(axis=1). %timeit res2 = sc.pp.regress_out(adata, keys=['n_counts', 'percent_mito'], n_jobs=32, copy=True). ```. > 4.99 s ± 501 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. %timeit res2_old = regress_out_old(adata, keys=['n_counts', 'percent_mito'], n_jobs=1, copy=True). ```. > 41.2 s ± 7.79 s per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. np.array_equal(res2.X, res2_old.X). ```. > True.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/164
https://github.com/scverse/scanpy/pull/164:356,interoperability,format,format,356,"regress_out multiprocessing; This PR adds multiprocessing to the pp.regress_out function. . Here some benchmarks:. ```python. import numpy as np. import pandas as pd. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. # create a matrix with 20.000 cells with 3000 genes. adata = AnnData(random(20000, 3000, density=0.6, format='csr')). ```. **Benchmark using ordinal variables**. ```python. # create a categorical column and run regress out using . # the categorical column. adata.obs['batch'] = pd.Categorical(np.random.randint(1, 4, size=adata.X.shape[0])). %timeit res = sc.pp.regress_out(adata, keys='batch', n_jobs=20, copy=True). ```. > 8.44 s ± 292 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. # import previous version of the function (which I saved in the file simple_old.py). from scanpy.preprocessing.simple_old import regress_out_old. %timeit res_old = regress_out_old(adata, keys='batch', n_jobs=1, copy=True). ```. > 1min 5s ± 4.45 s per loop (mean ± std. dev. of 7 runs, 1 loop each). **Compare that the previous and the new output are the same**. ```python. np.array_equal(res.X, res_old.X). ```. > True. **Benchmark using ordinal variables**. ```python. adata.obs['percent_mito'] = np.random.rand(adata.X.shape[0]). adata.obs['n_counts'] = adata.X.sum(axis=1). %timeit res2 = sc.pp.regress_out(adata, keys=['n_counts', 'percent_mito'], n_jobs=32, copy=True). ```. > 4.99 s ± 501 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. %timeit res2_old = regress_out_old(adata, keys=['n_counts', 'percent_mito'], n_jobs=1, copy=True). ```. > 41.2 s ± 7.79 s per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. np.array_equal(res2.X, res2_old.X). ```. > True.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/164
https://github.com/scverse/scanpy/pull/164:403,modifiability,variab,variables,403,"regress_out multiprocessing; This PR adds multiprocessing to the pp.regress_out function. . Here some benchmarks:. ```python. import numpy as np. import pandas as pd. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. # create a matrix with 20.000 cells with 3000 genes. adata = AnnData(random(20000, 3000, density=0.6, format='csr')). ```. **Benchmark using ordinal variables**. ```python. # create a categorical column and run regress out using . # the categorical column. adata.obs['batch'] = pd.Categorical(np.random.randint(1, 4, size=adata.X.shape[0])). %timeit res = sc.pp.regress_out(adata, keys='batch', n_jobs=20, copy=True). ```. > 8.44 s ± 292 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. # import previous version of the function (which I saved in the file simple_old.py). from scanpy.preprocessing.simple_old import regress_out_old. %timeit res_old = regress_out_old(adata, keys='batch', n_jobs=1, copy=True). ```. > 1min 5s ± 4.45 s per loop (mean ± std. dev. of 7 runs, 1 loop each). **Compare that the previous and the new output are the same**. ```python. np.array_equal(res.X, res_old.X). ```. > True. **Benchmark using ordinal variables**. ```python. adata.obs['percent_mito'] = np.random.rand(adata.X.shape[0]). adata.obs['n_counts'] = adata.X.sum(axis=1). %timeit res2 = sc.pp.regress_out(adata, keys=['n_counts', 'percent_mito'], n_jobs=32, copy=True). ```. > 4.99 s ± 501 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. %timeit res2_old = regress_out_old(adata, keys=['n_counts', 'percent_mito'], n_jobs=1, copy=True). ```. > 41.2 s ± 7.79 s per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. np.array_equal(res2.X, res2_old.X). ```. > True.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/164
https://github.com/scverse/scanpy/pull/164:776,modifiability,version,version,776,"regress_out multiprocessing; This PR adds multiprocessing to the pp.regress_out function. . Here some benchmarks:. ```python. import numpy as np. import pandas as pd. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. # create a matrix with 20.000 cells with 3000 genes. adata = AnnData(random(20000, 3000, density=0.6, format='csr')). ```. **Benchmark using ordinal variables**. ```python. # create a categorical column and run regress out using . # the categorical column. adata.obs['batch'] = pd.Categorical(np.random.randint(1, 4, size=adata.X.shape[0])). %timeit res = sc.pp.regress_out(adata, keys='batch', n_jobs=20, copy=True). ```. > 8.44 s ± 292 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. # import previous version of the function (which I saved in the file simple_old.py). from scanpy.preprocessing.simple_old import regress_out_old. %timeit res_old = regress_out_old(adata, keys='batch', n_jobs=1, copy=True). ```. > 1min 5s ± 4.45 s per loop (mean ± std. dev. of 7 runs, 1 loop each). **Compare that the previous and the new output are the same**. ```python. np.array_equal(res.X, res_old.X). ```. > True. **Benchmark using ordinal variables**. ```python. adata.obs['percent_mito'] = np.random.rand(adata.X.shape[0]). adata.obs['n_counts'] = adata.X.sum(axis=1). %timeit res2 = sc.pp.regress_out(adata, keys=['n_counts', 'percent_mito'], n_jobs=32, copy=True). ```. > 4.99 s ± 501 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. %timeit res2_old = regress_out_old(adata, keys=['n_counts', 'percent_mito'], n_jobs=1, copy=True). ```. > 41.2 s ± 7.79 s per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. np.array_equal(res2.X, res2_old.X). ```. > True.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/164
https://github.com/scverse/scanpy/pull/164:1204,modifiability,variab,variables,1204,"regress_out multiprocessing; This PR adds multiprocessing to the pp.regress_out function. . Here some benchmarks:. ```python. import numpy as np. import pandas as pd. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. # create a matrix with 20.000 cells with 3000 genes. adata = AnnData(random(20000, 3000, density=0.6, format='csr')). ```. **Benchmark using ordinal variables**. ```python. # create a categorical column and run regress out using . # the categorical column. adata.obs['batch'] = pd.Categorical(np.random.randint(1, 4, size=adata.X.shape[0])). %timeit res = sc.pp.regress_out(adata, keys='batch', n_jobs=20, copy=True). ```. > 8.44 s ± 292 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. # import previous version of the function (which I saved in the file simple_old.py). from scanpy.preprocessing.simple_old import regress_out_old. %timeit res_old = regress_out_old(adata, keys='batch', n_jobs=1, copy=True). ```. > 1min 5s ± 4.45 s per loop (mean ± std. dev. of 7 runs, 1 loop each). **Compare that the previous and the new output are the same**. ```python. np.array_equal(res.X, res_old.X). ```. > True. **Benchmark using ordinal variables**. ```python. adata.obs['percent_mito'] = np.random.rand(adata.X.shape[0]). adata.obs['n_counts'] = adata.X.sum(axis=1). %timeit res2 = sc.pp.regress_out(adata, keys=['n_counts', 'percent_mito'], n_jobs=32, copy=True). ```. > 4.99 s ± 501 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. %timeit res2_old = regress_out_old(adata, keys=['n_counts', 'percent_mito'], n_jobs=1, copy=True). ```. > 41.2 s ± 7.79 s per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. np.array_equal(res2.X, res2_old.X). ```. > True.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/164
https://github.com/scverse/scanpy/pull/164:522,performance,batch,batch,522,"regress_out multiprocessing; This PR adds multiprocessing to the pp.regress_out function. . Here some benchmarks:. ```python. import numpy as np. import pandas as pd. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. # create a matrix with 20.000 cells with 3000 genes. adata = AnnData(random(20000, 3000, density=0.6, format='csr')). ```. **Benchmark using ordinal variables**. ```python. # create a categorical column and run regress out using . # the categorical column. adata.obs['batch'] = pd.Categorical(np.random.randint(1, 4, size=adata.X.shape[0])). %timeit res = sc.pp.regress_out(adata, keys='batch', n_jobs=20, copy=True). ```. > 8.44 s ± 292 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. # import previous version of the function (which I saved in the file simple_old.py). from scanpy.preprocessing.simple_old import regress_out_old. %timeit res_old = regress_out_old(adata, keys='batch', n_jobs=1, copy=True). ```. > 1min 5s ± 4.45 s per loop (mean ± std. dev. of 7 runs, 1 loop each). **Compare that the previous and the new output are the same**. ```python. np.array_equal(res.X, res_old.X). ```. > True. **Benchmark using ordinal variables**. ```python. adata.obs['percent_mito'] = np.random.rand(adata.X.shape[0]). adata.obs['n_counts'] = adata.X.sum(axis=1). %timeit res2 = sc.pp.regress_out(adata, keys=['n_counts', 'percent_mito'], n_jobs=32, copy=True). ```. > 4.99 s ± 501 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. %timeit res2_old = regress_out_old(adata, keys=['n_counts', 'percent_mito'], n_jobs=1, copy=True). ```. > 41.2 s ± 7.79 s per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. np.array_equal(res2.X, res2_old.X). ```. > True.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/164
https://github.com/scverse/scanpy/pull/164:597,performance,time,timeit,597,"regress_out multiprocessing; This PR adds multiprocessing to the pp.regress_out function. . Here some benchmarks:. ```python. import numpy as np. import pandas as pd. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. # create a matrix with 20.000 cells with 3000 genes. adata = AnnData(random(20000, 3000, density=0.6, format='csr')). ```. **Benchmark using ordinal variables**. ```python. # create a categorical column and run regress out using . # the categorical column. adata.obs['batch'] = pd.Categorical(np.random.randint(1, 4, size=adata.X.shape[0])). %timeit res = sc.pp.regress_out(adata, keys='batch', n_jobs=20, copy=True). ```. > 8.44 s ± 292 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. # import previous version of the function (which I saved in the file simple_old.py). from scanpy.preprocessing.simple_old import regress_out_old. %timeit res_old = regress_out_old(adata, keys='batch', n_jobs=1, copy=True). ```. > 1min 5s ± 4.45 s per loop (mean ± std. dev. of 7 runs, 1 loop each). **Compare that the previous and the new output are the same**. ```python. np.array_equal(res.X, res_old.X). ```. > True. **Benchmark using ordinal variables**. ```python. adata.obs['percent_mito'] = np.random.rand(adata.X.shape[0]). adata.obs['n_counts'] = adata.X.sum(axis=1). %timeit res2 = sc.pp.regress_out(adata, keys=['n_counts', 'percent_mito'], n_jobs=32, copy=True). ```. > 4.99 s ± 501 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. %timeit res2_old = regress_out_old(adata, keys=['n_counts', 'percent_mito'], n_jobs=1, copy=True). ```. > 41.2 s ± 7.79 s per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. np.array_equal(res2.X, res2_old.X). ```. > True.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/164
https://github.com/scverse/scanpy/pull/164:641,performance,batch,batch,641,"regress_out multiprocessing; This PR adds multiprocessing to the pp.regress_out function. . Here some benchmarks:. ```python. import numpy as np. import pandas as pd. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. # create a matrix with 20.000 cells with 3000 genes. adata = AnnData(random(20000, 3000, density=0.6, format='csr')). ```. **Benchmark using ordinal variables**. ```python. # create a categorical column and run regress out using . # the categorical column. adata.obs['batch'] = pd.Categorical(np.random.randint(1, 4, size=adata.X.shape[0])). %timeit res = sc.pp.regress_out(adata, keys='batch', n_jobs=20, copy=True). ```. > 8.44 s ± 292 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. # import previous version of the function (which I saved in the file simple_old.py). from scanpy.preprocessing.simple_old import regress_out_old. %timeit res_old = regress_out_old(adata, keys='batch', n_jobs=1, copy=True). ```. > 1min 5s ± 4.45 s per loop (mean ± std. dev. of 7 runs, 1 loop each). **Compare that the previous and the new output are the same**. ```python. np.array_equal(res.X, res_old.X). ```. > True. **Benchmark using ordinal variables**. ```python. adata.obs['percent_mito'] = np.random.rand(adata.X.shape[0]). adata.obs['n_counts'] = adata.X.sum(axis=1). %timeit res2 = sc.pp.regress_out(adata, keys=['n_counts', 'percent_mito'], n_jobs=32, copy=True). ```. > 4.99 s ± 501 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. %timeit res2_old = regress_out_old(adata, keys=['n_counts', 'percent_mito'], n_jobs=1, copy=True). ```. > 41.2 s ± 7.79 s per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. np.array_equal(res2.X, res2_old.X). ```. > True.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/164
https://github.com/scverse/scanpy/pull/164:905,performance,time,timeit,905,"regress_out multiprocessing; This PR adds multiprocessing to the pp.regress_out function. . Here some benchmarks:. ```python. import numpy as np. import pandas as pd. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. # create a matrix with 20.000 cells with 3000 genes. adata = AnnData(random(20000, 3000, density=0.6, format='csr')). ```. **Benchmark using ordinal variables**. ```python. # create a categorical column and run regress out using . # the categorical column. adata.obs['batch'] = pd.Categorical(np.random.randint(1, 4, size=adata.X.shape[0])). %timeit res = sc.pp.regress_out(adata, keys='batch', n_jobs=20, copy=True). ```. > 8.44 s ± 292 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. # import previous version of the function (which I saved in the file simple_old.py). from scanpy.preprocessing.simple_old import regress_out_old. %timeit res_old = regress_out_old(adata, keys='batch', n_jobs=1, copy=True). ```. > 1min 5s ± 4.45 s per loop (mean ± std. dev. of 7 runs, 1 loop each). **Compare that the previous and the new output are the same**. ```python. np.array_equal(res.X, res_old.X). ```. > True. **Benchmark using ordinal variables**. ```python. adata.obs['percent_mito'] = np.random.rand(adata.X.shape[0]). adata.obs['n_counts'] = adata.X.sum(axis=1). %timeit res2 = sc.pp.regress_out(adata, keys=['n_counts', 'percent_mito'], n_jobs=32, copy=True). ```. > 4.99 s ± 501 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. %timeit res2_old = regress_out_old(adata, keys=['n_counts', 'percent_mito'], n_jobs=1, copy=True). ```. > 41.2 s ± 7.79 s per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. np.array_equal(res2.X, res2_old.X). ```. > True.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/164
https://github.com/scverse/scanpy/pull/164:951,performance,batch,batch,951,"regress_out multiprocessing; This PR adds multiprocessing to the pp.regress_out function. . Here some benchmarks:. ```python. import numpy as np. import pandas as pd. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. # create a matrix with 20.000 cells with 3000 genes. adata = AnnData(random(20000, 3000, density=0.6, format='csr')). ```. **Benchmark using ordinal variables**. ```python. # create a categorical column and run regress out using . # the categorical column. adata.obs['batch'] = pd.Categorical(np.random.randint(1, 4, size=adata.X.shape[0])). %timeit res = sc.pp.regress_out(adata, keys='batch', n_jobs=20, copy=True). ```. > 8.44 s ± 292 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. # import previous version of the function (which I saved in the file simple_old.py). from scanpy.preprocessing.simple_old import regress_out_old. %timeit res_old = regress_out_old(adata, keys='batch', n_jobs=1, copy=True). ```. > 1min 5s ± 4.45 s per loop (mean ± std. dev. of 7 runs, 1 loop each). **Compare that the previous and the new output are the same**. ```python. np.array_equal(res.X, res_old.X). ```. > True. **Benchmark using ordinal variables**. ```python. adata.obs['percent_mito'] = np.random.rand(adata.X.shape[0]). adata.obs['n_counts'] = adata.X.sum(axis=1). %timeit res2 = sc.pp.regress_out(adata, keys=['n_counts', 'percent_mito'], n_jobs=32, copy=True). ```. > 4.99 s ± 501 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. %timeit res2_old = regress_out_old(adata, keys=['n_counts', 'percent_mito'], n_jobs=1, copy=True). ```. > 41.2 s ± 7.79 s per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. np.array_equal(res2.X, res2_old.X). ```. > True.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/164
https://github.com/scverse/scanpy/pull/164:1336,performance,time,timeit,1336,"regress_out multiprocessing; This PR adds multiprocessing to the pp.regress_out function. . Here some benchmarks:. ```python. import numpy as np. import pandas as pd. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. # create a matrix with 20.000 cells with 3000 genes. adata = AnnData(random(20000, 3000, density=0.6, format='csr')). ```. **Benchmark using ordinal variables**. ```python. # create a categorical column and run regress out using . # the categorical column. adata.obs['batch'] = pd.Categorical(np.random.randint(1, 4, size=adata.X.shape[0])). %timeit res = sc.pp.regress_out(adata, keys='batch', n_jobs=20, copy=True). ```. > 8.44 s ± 292 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. # import previous version of the function (which I saved in the file simple_old.py). from scanpy.preprocessing.simple_old import regress_out_old. %timeit res_old = regress_out_old(adata, keys='batch', n_jobs=1, copy=True). ```. > 1min 5s ± 4.45 s per loop (mean ± std. dev. of 7 runs, 1 loop each). **Compare that the previous and the new output are the same**. ```python. np.array_equal(res.X, res_old.X). ```. > True. **Benchmark using ordinal variables**. ```python. adata.obs['percent_mito'] = np.random.rand(adata.X.shape[0]). adata.obs['n_counts'] = adata.X.sum(axis=1). %timeit res2 = sc.pp.regress_out(adata, keys=['n_counts', 'percent_mito'], n_jobs=32, copy=True). ```. > 4.99 s ± 501 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. %timeit res2_old = regress_out_old(adata, keys=['n_counts', 'percent_mito'], n_jobs=1, copy=True). ```. > 41.2 s ± 7.79 s per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. np.array_equal(res2.X, res2_old.X). ```. > True.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/164
https://github.com/scverse/scanpy/pull/164:1520,performance,time,timeit,1520,"regress_out multiprocessing; This PR adds multiprocessing to the pp.regress_out function. . Here some benchmarks:. ```python. import numpy as np. import pandas as pd. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. # create a matrix with 20.000 cells with 3000 genes. adata = AnnData(random(20000, 3000, density=0.6, format='csr')). ```. **Benchmark using ordinal variables**. ```python. # create a categorical column and run regress out using . # the categorical column. adata.obs['batch'] = pd.Categorical(np.random.randint(1, 4, size=adata.X.shape[0])). %timeit res = sc.pp.regress_out(adata, keys='batch', n_jobs=20, copy=True). ```. > 8.44 s ± 292 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. # import previous version of the function (which I saved in the file simple_old.py). from scanpy.preprocessing.simple_old import regress_out_old. %timeit res_old = regress_out_old(adata, keys='batch', n_jobs=1, copy=True). ```. > 1min 5s ± 4.45 s per loop (mean ± std. dev. of 7 runs, 1 loop each). **Compare that the previous and the new output are the same**. ```python. np.array_equal(res.X, res_old.X). ```. > True. **Benchmark using ordinal variables**. ```python. adata.obs['percent_mito'] = np.random.rand(adata.X.shape[0]). adata.obs['n_counts'] = adata.X.sum(axis=1). %timeit res2 = sc.pp.regress_out(adata, keys=['n_counts', 'percent_mito'], n_jobs=32, copy=True). ```. > 4.99 s ± 501 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. %timeit res2_old = regress_out_old(adata, keys=['n_counts', 'percent_mito'], n_jobs=1, copy=True). ```. > 41.2 s ± 7.79 s per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. np.array_equal(res2.X, res2_old.X). ```. > True.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/164
https://github.com/scverse/scanpy/pull/164:465,testability,regress,regress,465,"regress_out multiprocessing; This PR adds multiprocessing to the pp.regress_out function. . Here some benchmarks:. ```python. import numpy as np. import pandas as pd. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. # create a matrix with 20.000 cells with 3000 genes. adata = AnnData(random(20000, 3000, density=0.6, format='csr')). ```. **Benchmark using ordinal variables**. ```python. # create a categorical column and run regress out using . # the categorical column. adata.obs['batch'] = pd.Categorical(np.random.randint(1, 4, size=adata.X.shape[0])). %timeit res = sc.pp.regress_out(adata, keys='batch', n_jobs=20, copy=True). ```. > 8.44 s ± 292 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. # import previous version of the function (which I saved in the file simple_old.py). from scanpy.preprocessing.simple_old import regress_out_old. %timeit res_old = regress_out_old(adata, keys='batch', n_jobs=1, copy=True). ```. > 1min 5s ± 4.45 s per loop (mean ± std. dev. of 7 runs, 1 loop each). **Compare that the previous and the new output are the same**. ```python. np.array_equal(res.X, res_old.X). ```. > True. **Benchmark using ordinal variables**. ```python. adata.obs['percent_mito'] = np.random.rand(adata.X.shape[0]). adata.obs['n_counts'] = adata.X.sum(axis=1). %timeit res2 = sc.pp.regress_out(adata, keys=['n_counts', 'percent_mito'], n_jobs=32, copy=True). ```. > 4.99 s ± 501 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. %timeit res2_old = regress_out_old(adata, keys=['n_counts', 'percent_mito'], n_jobs=1, copy=True). ```. > 41.2 s ± 7.79 s per loop (mean ± std. dev. of 7 runs, 1 loop each). ```python. np.array_equal(res2.X, res2_old.X). ```. > True.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/164
https://github.com/scverse/scanpy/issues/165:583,availability,consist,consistent,583,"Adding further annotation to subset; Hi, Alex, . Fantastic package! As a python guy, I have become such a huge fan of Scanpy. . I'm encountering an issue when trying to add further annotation to a subset, what I'm doing is basically:. ```. adata = sc.read(filename). adata.var_names = pd.read_csv('genes.tsv'). adata.obs_names = pd.read_csv('barcodes.tsv'). adata_subset = adata[ list_of_barcodes,:]. anno = pd.read_csv(filename_sample_annotation). adata_subset.obs = anno. ```. But unfortunately _**adata_subset.obs**_ didn't get updated (I checked the index of _**anno**_ and it's consistent with _**adata_subset.obs_names**_). . It works only if I add the annotation column by column (In my case there are too many columns so it won't be ideal), e.g. `adata_subset.obs['cell_groups'] = anno['cell_groups']`. Could you please help me figure it out? Many thanks! Huidong.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/165
https://github.com/scverse/scanpy/issues/165:531,deployability,updat,updated,531,"Adding further annotation to subset; Hi, Alex, . Fantastic package! As a python guy, I have become such a huge fan of Scanpy. . I'm encountering an issue when trying to add further annotation to a subset, what I'm doing is basically:. ```. adata = sc.read(filename). adata.var_names = pd.read_csv('genes.tsv'). adata.obs_names = pd.read_csv('barcodes.tsv'). adata_subset = adata[ list_of_barcodes,:]. anno = pd.read_csv(filename_sample_annotation). adata_subset.obs = anno. ```. But unfortunately _**adata_subset.obs**_ didn't get updated (I checked the index of _**anno**_ and it's consistent with _**adata_subset.obs_names**_). . It works only if I add the annotation column by column (In my case there are too many columns so it won't be ideal), e.g. `adata_subset.obs['cell_groups'] = anno['cell_groups']`. Could you please help me figure it out? Many thanks! Huidong.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/165
https://github.com/scverse/scanpy/issues/165:29,integrability,sub,subset,29,"Adding further annotation to subset; Hi, Alex, . Fantastic package! As a python guy, I have become such a huge fan of Scanpy. . I'm encountering an issue when trying to add further annotation to a subset, what I'm doing is basically:. ```. adata = sc.read(filename). adata.var_names = pd.read_csv('genes.tsv'). adata.obs_names = pd.read_csv('barcodes.tsv'). adata_subset = adata[ list_of_barcodes,:]. anno = pd.read_csv(filename_sample_annotation). adata_subset.obs = anno. ```. But unfortunately _**adata_subset.obs**_ didn't get updated (I checked the index of _**anno**_ and it's consistent with _**adata_subset.obs_names**_). . It works only if I add the annotation column by column (In my case there are too many columns so it won't be ideal), e.g. `adata_subset.obs['cell_groups'] = anno['cell_groups']`. Could you please help me figure it out? Many thanks! Huidong.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/165
https://github.com/scverse/scanpy/issues/165:197,integrability,sub,subset,197,"Adding further annotation to subset; Hi, Alex, . Fantastic package! As a python guy, I have become such a huge fan of Scanpy. . I'm encountering an issue when trying to add further annotation to a subset, what I'm doing is basically:. ```. adata = sc.read(filename). adata.var_names = pd.read_csv('genes.tsv'). adata.obs_names = pd.read_csv('barcodes.tsv'). adata_subset = adata[ list_of_barcodes,:]. anno = pd.read_csv(filename_sample_annotation). adata_subset.obs = anno. ```. But unfortunately _**adata_subset.obs**_ didn't get updated (I checked the index of _**anno**_ and it's consistent with _**adata_subset.obs_names**_). . It works only if I add the annotation column by column (In my case there are too many columns so it won't be ideal), e.g. `adata_subset.obs['cell_groups'] = anno['cell_groups']`. Could you please help me figure it out? Many thanks! Huidong.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/165
https://github.com/scverse/scanpy/issues/165:59,modifiability,pac,package,59,"Adding further annotation to subset; Hi, Alex, . Fantastic package! As a python guy, I have become such a huge fan of Scanpy. . I'm encountering an issue when trying to add further annotation to a subset, what I'm doing is basically:. ```. adata = sc.read(filename). adata.var_names = pd.read_csv('genes.tsv'). adata.obs_names = pd.read_csv('barcodes.tsv'). adata_subset = adata[ list_of_barcodes,:]. anno = pd.read_csv(filename_sample_annotation). adata_subset.obs = anno. ```. But unfortunately _**adata_subset.obs**_ didn't get updated (I checked the index of _**anno**_ and it's consistent with _**adata_subset.obs_names**_). . It works only if I add the annotation column by column (In my case there are too many columns so it won't be ideal), e.g. `adata_subset.obs['cell_groups'] = anno['cell_groups']`. Could you please help me figure it out? Many thanks! Huidong.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/165
https://github.com/scverse/scanpy/issues/165:531,safety,updat,updated,531,"Adding further annotation to subset; Hi, Alex, . Fantastic package! As a python guy, I have become such a huge fan of Scanpy. . I'm encountering an issue when trying to add further annotation to a subset, what I'm doing is basically:. ```. adata = sc.read(filename). adata.var_names = pd.read_csv('genes.tsv'). adata.obs_names = pd.read_csv('barcodes.tsv'). adata_subset = adata[ list_of_barcodes,:]. anno = pd.read_csv(filename_sample_annotation). adata_subset.obs = anno. ```. But unfortunately _**adata_subset.obs**_ didn't get updated (I checked the index of _**anno**_ and it's consistent with _**adata_subset.obs_names**_). . It works only if I add the annotation column by column (In my case there are too many columns so it won't be ideal), e.g. `adata_subset.obs['cell_groups'] = anno['cell_groups']`. Could you please help me figure it out? Many thanks! Huidong.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/165
https://github.com/scverse/scanpy/issues/165:531,security,updat,updated,531,"Adding further annotation to subset; Hi, Alex, . Fantastic package! As a python guy, I have become such a huge fan of Scanpy. . I'm encountering an issue when trying to add further annotation to a subset, what I'm doing is basically:. ```. adata = sc.read(filename). adata.var_names = pd.read_csv('genes.tsv'). adata.obs_names = pd.read_csv('barcodes.tsv'). adata_subset = adata[ list_of_barcodes,:]. anno = pd.read_csv(filename_sample_annotation). adata_subset.obs = anno. ```. But unfortunately _**adata_subset.obs**_ didn't get updated (I checked the index of _**anno**_ and it's consistent with _**adata_subset.obs_names**_). . It works only if I add the annotation column by column (In my case there are too many columns so it won't be ideal), e.g. `adata_subset.obs['cell_groups'] = anno['cell_groups']`. Could you please help me figure it out? Many thanks! Huidong.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/165
https://github.com/scverse/scanpy/issues/165:583,usability,consist,consistent,583,"Adding further annotation to subset; Hi, Alex, . Fantastic package! As a python guy, I have become such a huge fan of Scanpy. . I'm encountering an issue when trying to add further annotation to a subset, what I'm doing is basically:. ```. adata = sc.read(filename). adata.var_names = pd.read_csv('genes.tsv'). adata.obs_names = pd.read_csv('barcodes.tsv'). adata_subset = adata[ list_of_barcodes,:]. anno = pd.read_csv(filename_sample_annotation). adata_subset.obs = anno. ```. But unfortunately _**adata_subset.obs**_ didn't get updated (I checked the index of _**anno**_ and it's consistent with _**adata_subset.obs_names**_). . It works only if I add the annotation column by column (In my case there are too many columns so it won't be ideal), e.g. `adata_subset.obs['cell_groups'] = anno['cell_groups']`. Could you please help me figure it out? Many thanks! Huidong.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/165
https://github.com/scverse/scanpy/issues/165:828,usability,help,help,828,"Adding further annotation to subset; Hi, Alex, . Fantastic package! As a python guy, I have become such a huge fan of Scanpy. . I'm encountering an issue when trying to add further annotation to a subset, what I'm doing is basically:. ```. adata = sc.read(filename). adata.var_names = pd.read_csv('genes.tsv'). adata.obs_names = pd.read_csv('barcodes.tsv'). adata_subset = adata[ list_of_barcodes,:]. anno = pd.read_csv(filename_sample_annotation). adata_subset.obs = anno. ```. But unfortunately _**adata_subset.obs**_ didn't get updated (I checked the index of _**anno**_ and it's consistent with _**adata_subset.obs_names**_). . It works only if I add the annotation column by column (In my case there are too many columns so it won't be ideal), e.g. `adata_subset.obs['cell_groups'] = anno['cell_groups']`. Could you please help me figure it out? Many thanks! Huidong.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/165
https://github.com/scverse/scanpy/issues/166:126,availability,error,error,126,"Issue with sanitize_anndata() in plotting functions with subsets of anndata objects are passed.; I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:. `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:448,availability,error,error,448,"Issue with sanitize_anndata() in plotting functions with subsets of anndata objects are passed.; I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:. `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:210,deployability,version,version,210,"Issue with sanitize_anndata() in plotting functions with subsets of anndata objects are passed.; I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:. `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:725,deployability,modul,module,725,"Issue with sanitize_anndata() in plotting functions with subsets of anndata objects are passed.; I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:. `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:2113,deployability,log,logg,2113,"ht, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.categories) < len(c):. 1285 df[key] = c. -> 1286 df[key].cat.categories = df[key].cat.categories.astype('U'). 1287 logg.info(. 1288 '... storing \'{}\' as categorical'. ~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in __getattr__(self, name). 3608 if (name in self._internal_names_set or name in self._metadata or. 3609 name in self._accessors):. -> 3610 return object.__getattribute__(self, name). 3611 else:. 3612 if name in self._info_axis:. ~/anaconda3/lib/python3.6/site-packages/pandas/core/accessor.py in __get__(self, instance, owner). 52 # this ensures that Series.str.<method> is well defined. 53 return self.accessor_cls. ---> 54 return self.construct_accessor(instance). 55 . 56 def __set__(self, instance, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat access",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:2214,energy efficiency,core,core,2214,"save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.categories) < len(c):. 1285 df[key] = c. -> 1286 df[key].cat.categories = df[key].cat.categories.astype('U'). 1287 logg.info(. 1288 '... storing \'{}\' as categorical'. ~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in __getattr__(self, name). 3608 if (name in self._internal_names_set or name in self._metadata or. 3609 name in self._accessors):. -> 3610 return object.__getattribute__(self, name). 3611 else:. 3612 if name in self._info_axis:. ~/anaconda3/lib/python3.6/site-packages/pandas/core/accessor.py in __get__(self, instance, owner). 52 # this ensures that Series.str.<method> is well defined. 53 return self.accessor_cls. ---> 54 return self.construct_accessor(instance). 55 . 56 def __set__(self, instance, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:2507,energy efficiency,core,core,2507,", legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.categories) < len(c):. 1285 df[key] = c. -> 1286 df[key].cat.categories = df[key].cat.categories.astype('U'). 1287 logg.info(. 1288 '... storing \'{}\' as categorical'. ~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in __getattr__(self, name). 3608 if (name in self._internal_names_set or name in self._metadata or. 3609 name in self._accessors):. -> 3610 return object.__getattribute__(self, name). 3611 else:. 3612 if name in self._info_axis:. ~/anaconda3/lib/python3.6/site-packages/pandas/core/accessor.py in __get__(self, instance, owner). 52 # this ensures that Series.str.<method> is well defined. 53 return self.accessor_cls. ---> 54 return self.construct_accessor(instance). 55 . 56 def __set__(self, instance, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:2790,energy efficiency,core,core,2790,"ize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.categories) < len(c):. 1285 df[key] = c. -> 1286 df[key].cat.categories = df[key].cat.categories.astype('U'). 1287 logg.info(. 1288 '... storing \'{}\' as categorical'. ~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in __getattr__(self, name). 3608 if (name in self._internal_names_set or name in self._metadata or. 3609 name in self._accessors):. -> 3610 return object.__getattribute__(self, name). 3611 else:. 3612 if name in self._info_axis:. ~/anaconda3/lib/python3.6/site-packages/pandas/core/accessor.py in __get__(self, instance, owner). 52 # this ensures that Series.str.<method> is well defined. 53 return self.accessor_cls. ---> 54 return self.construct_accessor(instance). 55 . 56 def __set__(self, instance, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:57,integrability,sub,subsets,57,"Issue with sanitize_anndata() in plotting functions with subsets of anndata objects are passed.; I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:. `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:210,integrability,version,version,210,"Issue with sanitize_anndata() in plotting functions with subsets of anndata objects are passed.; I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:. `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:262,integrability,sub,subsetted,262,"Issue with sanitize_anndata() in plotting functions with subsets of anndata objects are passed.; I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:. `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:454,integrability,messag,message,454,"Issue with sanitize_anndata() in plotting functions with subsets of anndata objects are passed.; I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:. `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:1047,integrability,compon,components,1047,"with subsets of anndata objects are passed.; I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:. `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.categories) < len(c):. 1285 df[key] = c. -> 1286 df[ke",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:1458,integrability,compon,components,1458,"bout categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.categories) < len(c):. 1285 df[key] = c. -> 1286 df[key].cat.categories = df[key].cat.categories.astype('U'). 1287 logg.info(. 1288 '... storing \'{}\' as categorical'. ~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in __getattr__(self, name). 3608 if (name in self._internal_names_set or name in self._metadata or. 3609 name in self._accessors):. -> 3610 return object.__getattribute__(self, name). 3611 else:. 3612 if name in self._info_axis:. ~/a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:3341,integrability,coupl,couple,3341,"elf._accessors):. -> 3610 return object.__getattribute__(self, name). 3611 else:. 3612 if name in self._info_axis:. ~/anaconda3/lib/python3.6/site-packages/pandas/core/accessor.py in __get__(self, instance, owner). 52 # this ensures that Series.str.<method> is well defined. 53 return self.accessor_cls. ---> 54 return self.construct_accessor(instance). 55 . 56 def __set__(self, instance, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the pl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:3885,integrability,sub,subsetted,3885,"e, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the plotting functions should have a parameter to plot only a subset of the data. That way sanitize_anndata can be called on the whole anndata object every time as there is no longer a reason to pass a view of the object. You could then test if a view is being passed to sanitize anndata, and then say ""please don't pass subsetted anndata objects to plotting functions"" or something like that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:3986,integrability,sub,subsetted,3986,"e, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the plotting functions should have a parameter to plot only a subset of the data. That way sanitize_anndata can be called on the whole anndata object every time as there is no longer a reason to pass a view of the object. You could then test if a view is being passed to sanitize anndata, and then say ""please don't pass subsetted anndata objects to plotting functions"" or something like that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:4057,integrability,sub,subsequently,4057,"e, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the plotting functions should have a parameter to plot only a subset of the data. That way sanitize_anndata can be called on the whole anndata object every time as there is no longer a reason to pass a view of the object. You could then test if a view is being passed to sanitize anndata, and then say ""please don't pass subsetted anndata objects to plotting functions"" or something like that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:4099,integrability,sub,subsetted,4099,"e, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the plotting functions should have a parameter to plot only a subset of the data. That way sanitize_anndata can be called on the whole anndata object every time as there is no longer a reason to pass a view of the object. You could then test if a view is being passed to sanitize anndata, and then say ""please don't pass subsetted anndata objects to plotting functions"" or something like that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:4400,integrability,sub,subset,4400,"e, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the plotting functions should have a parameter to plot only a subset of the data. That way sanitize_anndata can be called on the whole anndata object every time as there is no longer a reason to pass a view of the object. You could then test if a view is being passed to sanitize anndata, and then say ""please don't pass subsetted anndata objects to plotting functions"" or something like that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:4659,integrability,sub,subsetted,4659,"e, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the plotting functions should have a parameter to plot only a subset of the data. That way sanitize_anndata can be called on the whole anndata object every time as there is no longer a reason to pass a view of the object. You could then test if a view is being passed to sanitize anndata, and then say ""please don't pass subsetted anndata objects to plotting functions"" or something like that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:454,interoperability,messag,message,454,"Issue with sanitize_anndata() in plotting functions with subsets of anndata objects are passed.; I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:. `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:1047,interoperability,compon,components,1047,"with subsets of anndata objects are passed.; I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:. `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.categories) < len(c):. 1285 df[key] = c. -> 1286 df[ke",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:1458,interoperability,compon,components,1458,"bout categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.categories) < len(c):. 1285 df[key] = c. -> 1286 df[key].cat.categories = df[key].cat.categories.astype('U'). 1287 logg.info(. 1288 '... storing \'{}\' as categorical'. ~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in __getattr__(self, name). 3608 if (name in self._internal_names_set or name in self._metadata or. 3609 name in self._accessors):. -> 3610 return object.__getattribute__(self, name). 3611 else:. 3612 if name in self._info_axis:. ~/a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:3809,interoperability,convers,conversion,3809,"e, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the plotting functions should have a parameter to plot only a subset of the data. That way sanitize_anndata can be called on the whole anndata object every time as there is no longer a reason to pass a view of the object. You could then test if a view is being passed to sanitize anndata, and then say ""please don't pass subsetted anndata objects to plotting functions"" or something like that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:3939,interoperability,convers,conversion,3939,"e, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the plotting functions should have a parameter to plot only a subset of the data. That way sanitize_anndata can be called on the whole anndata object every time as there is no longer a reason to pass a view of the object. You could then test if a view is being passed to sanitize anndata, and then say ""please don't pass subsetted anndata objects to plotting functions"" or something like that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:4021,interoperability,convers,conversion,4021,"e, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the plotting functions should have a parameter to plot only a subset of the data. That way sanitize_anndata can be called on the whole anndata object every time as there is no longer a reason to pass a view of the object. You could then test if a view is being passed to sanitize anndata, and then say ""please don't pass subsetted anndata objects to plotting functions"" or something like that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:210,modifiability,version,version,210,"Issue with sanitize_anndata() in plotting functions with subsets of anndata objects are passed.; I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:. `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:480,modifiability,variab,variables,480,"Issue with sanitize_anndata() in plotting functions with subsets of anndata objects are passed.; I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:. `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:725,modifiability,modul,module,725,"Issue with sanitize_anndata() in plotting functions with subsets of anndata objects are passed.; I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:. `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:1047,modifiability,compon,components,1047,"with subsets of anndata objects are passed.; I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:. `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.categories) < len(c):. 1285 df[key] = c. -> 1286 df[ke",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:1458,modifiability,compon,components,1458,"bout categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.categories) < len(c):. 1285 df[key] = c. -> 1286 df[key].cat.categories = df[key].cat.categories.astype('U'). 1287 logg.info(. 1288 '... storing \'{}\' as categorical'. ~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in __getattr__(self, name). 3608 if (name in self._internal_names_set or name in self._metadata or. 3609 name in self._accessors):. -> 3610 return object.__getattribute__(self, name). 3611 else:. 3612 if name in self._info_axis:. ~/a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:2198,modifiability,pac,packages,2198,"ow=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.categories) < len(c):. 1285 df[key] = c. -> 1286 df[key].cat.categories = df[key].cat.categories.astype('U'). 1287 logg.info(. 1288 '... storing \'{}\' as categorical'. ~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in __getattr__(self, name). 3608 if (name in self._internal_names_set or name in self._metadata or. 3609 name in self._accessors):. -> 3610 return object.__getattribute__(self, name). 3611 else:. 3612 if name in self._info_axis:. ~/anaconda3/lib/python3.6/site-packages/pandas/core/accessor.py in __get__(self, instance, owner). 52 # this ensures that Series.str.<method> is well defined. 53 return self.accessor_cls. ---> 54 return self.construct_accessor(instance). 55 . 56 def __set__(self, instance, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:2491,modifiability,pac,packages,2491,"egend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.categories) < len(c):. 1285 df[key] = c. -> 1286 df[key].cat.categories = df[key].cat.categories.astype('U'). 1287 logg.info(. 1288 '... storing \'{}\' as categorical'. ~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in __getattr__(self, name). 3608 if (name in self._internal_names_set or name in self._metadata or. 3609 name in self._accessors):. -> 3610 return object.__getattribute__(self, name). 3611 else:. 3612 if name in self._info_axis:. ~/anaconda3/lib/python3.6/site-packages/pandas/core/accessor.py in __get__(self, instance, owner). 52 # this ensures that Series.str.<method> is well defined. 53 return self.accessor_cls. ---> 54 return self.construct_accessor(instance). 55 . 56 def __set__(self, instance, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:2774,modifiability,pac,packages,2774,"ls.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.categories) < len(c):. 1285 df[key] = c. -> 1286 df[key].cat.categories = df[key].cat.categories.astype('U'). 1287 logg.info(. 1288 '... storing \'{}\' as categorical'. ~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in __getattr__(self, name). 3608 if (name in self._internal_names_set or name in self._metadata or. 3609 name in self._accessors):. -> 3610 return object.__getattribute__(self, name). 3611 else:. 3612 if name in self._info_axis:. ~/anaconda3/lib/python3.6/site-packages/pandas/core/accessor.py in __get__(self, instance, owner). 52 # this ensures that Series.str.<method> is well defined. 53 return self.accessor_cls. ---> 54 return self.construct_accessor(instance). 55 . 56 def __set__(self, instance, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:3341,modifiability,coupl,couple,3341,"elf._accessors):. -> 3610 return object.__getattribute__(self, name). 3611 else:. 3612 if name in self._info_axis:. ~/anaconda3/lib/python3.6/site-packages/pandas/core/accessor.py in __get__(self, instance, owner). 52 # this ensures that Series.str.<method> is well defined. 53 return self.accessor_cls. ---> 54 return self.construct_accessor(instance). 55 . 56 def __set__(self, instance, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the pl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:3434,modifiability,variab,variable,3434," in self._info_axis:. ~/anaconda3/lib/python3.6/site-packages/pandas/core/accessor.py in __get__(self, instance, owner). 52 # this ensures that Series.str.<method> is well defined. 53 return self.accessor_cls. ---> 54 return self.construct_accessor(instance). 55 . 56 def __set__(self, instance, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the plotting functions should have a parameter to plot only a subset of the data. That way sanitize_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:3495,modifiability,variab,variable,3495,"/pandas/core/accessor.py in __get__(self, instance, owner). 52 # this ensures that Series.str.<method> is well defined. 53 return self.accessor_cls. ---> 54 return self.construct_accessor(instance). 55 . 56 def __set__(self, instance, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the plotting functions should have a parameter to plot only a subset of the data. That way sanitize_anndata can be called on the whole anndata object every time ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:3587,modifiability,variab,variables,3587,".<method> is well defined. 53 return self.accessor_cls. ---> 54 return self.construct_accessor(instance). 55 . 56 def __set__(self, instance, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the plotting functions should have a parameter to plot only a subset of the data. That way sanitize_anndata can be called on the whole anndata object every time as there is no longer a reason to pass a view of the object. You could then test if a view is",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:3619,modifiability,variab,variables,3619,"turn self.accessor_cls. ---> 54 return self.construct_accessor(instance). 55 . 56 def __set__(self, instance, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the plotting functions should have a parameter to plot only a subset of the data. That way sanitize_anndata can be called on the whole anndata object every time as there is no longer a reason to pass a view of the object. You could then test if a view is being passed to sanitize anndat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:3758,modifiability,variab,variables,3758,"e, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the plotting functions should have a parameter to plot only a subset of the data. That way sanitize_anndata can be called on the whole anndata object every time as there is no longer a reason to pass a view of the object. You could then test if a view is being passed to sanitize anndata, and then say ""please don't pass subsetted anndata objects to plotting functions"" or something like that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:4375,modifiability,paramet,parameter,4375,"e, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the plotting functions should have a parameter to plot only a subset of the data. That way sanitize_anndata can be called on the whole anndata object every time as there is no longer a reason to pass a view of the object. You could then test if a view is being passed to sanitize anndata, and then say ""please don't pass subsetted anndata objects to plotting functions"" or something like that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:126,performance,error,error,126,"Issue with sanitize_anndata() in plotting functions with subsets of anndata objects are passed.; I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:. `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:202,performance,time,time,202,"Issue with sanitize_anndata() in plotting functions with subsets of anndata objects are passed.; I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:. `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:425,performance,time,time,425,"Issue with sanitize_anndata() in plotting functions with subsets of anndata objects are passed.; I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:. `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:448,performance,error,error,448,"Issue with sanitize_anndata() in plotting functions with subsets of anndata objects are passed.; I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:. `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:3327,performance,time,time,3327," 3609 name in self._accessors):. -> 3610 return object.__getattribute__(self, name). 3611 else:. 3612 if name in self._info_axis:. ~/anaconda3/lib/python3.6/site-packages/pandas/core/accessor.py in __get__(self, instance, owner). 52 # this ensures that Series.str.<method> is well defined. 53 return self.accessor_cls. ---> 54 return self.construct_accessor(instance). 55 . 56 def __set__(self, instance, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implem",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:3714,performance,time,time,3714,"_(self, instance, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the plotting functions should have a parameter to plot only a subset of the data. That way sanitize_anndata can be called on the whole anndata object every time as there is no longer a reason to pass a view of the object. You could then test if a view is being passed to sanitize anndata, and then say ""please don't pass subsetted anndata objects to plotting functions"" or somet",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:3799,performance,time,time,3799,"e, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the plotting functions should have a parameter to plot only a subset of the data. That way sanitize_anndata can be called on the whole anndata object every time as there is no longer a reason to pass a view of the object. You could then test if a view is being passed to sanitize anndata, and then say ""please don't pass subsetted anndata objects to plotting functions"" or something like that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:4494,performance,time,time,4494,"e, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the plotting functions should have a parameter to plot only a subset of the data. That way sanitize_anndata can be called on the whole anndata object every time as there is no longer a reason to pass a view of the object. You could then test if a view is being passed to sanitize anndata, and then say ""please don't pass subsetted anndata objects to plotting functions"" or something like that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:126,safety,error,error,126,"Issue with sanitize_anndata() in plotting functions with subsets of anndata objects are passed.; I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:. `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:448,safety,error,error,448,"Issue with sanitize_anndata() in plotting functions with subsets of anndata objects are passed.; I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:. `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:698,safety,input,input-,698,"Issue with sanitize_anndata() in plotting functions with subsets of anndata objects are passed.; I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:. `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:725,safety,modul,module,725,"Issue with sanitize_anndata() in plotting functions with subsets of anndata objects are passed.; I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:. `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:2113,safety,log,logg,2113,"ht, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.categories) < len(c):. 1285 df[key] = c. -> 1286 df[key].cat.categories = df[key].cat.categories.astype('U'). 1287 logg.info(. 1288 '... storing \'{}\' as categorical'. ~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in __getattr__(self, name). 3608 if (name in self._internal_names_set or name in self._metadata or. 3609 name in self._accessors):. -> 3610 return object.__getattribute__(self, name). 3611 else:. 3612 if name in self._info_axis:. ~/anaconda3/lib/python3.6/site-packages/pandas/core/accessor.py in __get__(self, instance, owner). 52 # this ensures that Series.str.<method> is well defined. 53 return self.accessor_cls. ---> 54 return self.construct_accessor(instance). 55 . 56 def __set__(self, instance, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat access",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:3568,safety,detect,detects,3568,"ures that Series.str.<method> is well defined. 53 return self.accessor_cls. ---> 54 return self.construct_accessor(instance). 55 . 56 def __set__(self, instance, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the plotting functions should have a parameter to plot only a subset of the data. That way sanitize_anndata can be called on the whole anndata object every time as there is no longer a reason to pass a view of the object. You could th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:4575,safety,test,test,4575,"e, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the plotting functions should have a parameter to plot only a subset of the data. That way sanitize_anndata can be called on the whole anndata object every time as there is no longer a reason to pass a view of the object. You could then test if a view is being passed to sanitize anndata, and then say ""please don't pass subsetted anndata objects to plotting functions"" or something like that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:4609,safety,sanit,sanitize,4609,"e, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the plotting functions should have a parameter to plot only a subset of the data. That way sanitize_anndata can be called on the whole anndata object every time as there is no longer a reason to pass a view of the object. You could then test if a view is being passed to sanitize anndata, and then say ""please don't pass subsetted anndata objects to plotting functions"" or something like that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:2113,security,log,logg,2113,"ht, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.categories) < len(c):. 1285 df[key] = c. -> 1286 df[key].cat.categories = df[key].cat.categories.astype('U'). 1287 logg.info(. 1288 '... storing \'{}\' as categorical'. ~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in __getattr__(self, name). 3608 if (name in self._internal_names_set or name in self._metadata or. 3609 name in self._accessors):. -> 3610 return object.__getattribute__(self, name). 3611 else:. 3612 if name in self._info_axis:. ~/anaconda3/lib/python3.6/site-packages/pandas/core/accessor.py in __get__(self, instance, owner). 52 # this ensures that Series.str.<method> is well defined. 53 return self.accessor_cls. ---> 54 return self.construct_accessor(instance). 55 . 56 def __set__(self, instance, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat access",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:2512,security,access,accessor,2512,"d_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.categories) < len(c):. 1285 df[key] = c. -> 1286 df[key].cat.categories = df[key].cat.categories.astype('U'). 1287 logg.info(. 1288 '... storing \'{}\' as categorical'. ~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in __getattr__(self, name). 3608 if (name in self._internal_names_set or name in self._metadata or. 3609 name in self._accessors):. -> 3610 return object.__getattribute__(self, name). 3611 else:. 3612 if name in self._info_axis:. ~/anaconda3/lib/python3.6/site-packages/pandas/core/accessor.py in __get__(self, instance, owner). 52 # this ensures that Series.str.<method> is well defined. 53 return self.accessor_cls. ---> 54 return self.construct_accessor(instance). 55 . 56 def __set__(self, instance, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or somethin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:2972,security,access,accessor,2972,"(self). 1284 if len(c.categories) < len(c):. 1285 df[key] = c. -> 1286 df[key].cat.categories = df[key].cat.categories.astype('U'). 1287 logg.info(. 1288 '... storing \'{}\' as categorical'. ~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in __getattr__(self, name). 3608 if (name in self._internal_names_set or name in self._metadata or. 3609 name in self._accessors):. -> 3610 return object.__getattribute__(self, name). 3611 else:. 3612 if name in self._info_axis:. ~/anaconda3/lib/python3.6/site-packages/pandas/core/accessor.py in __get__(self, instance, owner). 52 # this ensures that Series.str.<method> is well defined. 53 return self.accessor_cls. ---> 54 return self.construct_accessor(instance). 55 . 56 def __set__(self, instance, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:3109,security,access,accessor,3109,"logg.info(. 1288 '... storing \'{}\' as categorical'. ~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in __getattr__(self, name). 3608 if (name in self._internal_names_set or name in self._metadata or. 3609 name in self._accessors):. -> 3610 return object.__getattribute__(self, name). 3611 else:. 3612 if name in self._info_axis:. ~/anaconda3/lib/python3.6/site-packages/pandas/core/accessor.py in __get__(self, instance, owner). 52 # this ensures that Series.str.<method> is well defined. 53 return self.accessor_cls. ---> 54 return self.construct_accessor(instance). 55 . 56 def __set__(self, instance, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted annd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:3568,security,detect,detects,3568,"ures that Series.str.<method> is well defined. 53 return self.accessor_cls. ---> 54 return self.construct_accessor(instance). 55 . 56 def __set__(self, instance, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the plotting functions should have a parameter to plot only a subset of the data. That way sanitize_anndata can be called on the whole anndata object every time as there is no longer a reason to pass a view of the object. You could th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:4609,security,sanit,sanitize,4609,"e, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the plotting functions should have a parameter to plot only a subset of the data. That way sanitize_anndata can be called on the whole anndata object every time as there is no longer a reason to pass a view of the object. You could then test if a view is being passed to sanitize anndata, and then say ""please don't pass subsetted anndata objects to plotting functions"" or something like that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:654,testability,Trace,Traceback,654,"Issue with sanitize_anndata() in plotting functions with subsets of anndata objects are passed.; I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:. `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:2113,testability,log,logg,2113,"ht, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.categories) < len(c):. 1285 df[key] = c. -> 1286 df[key].cat.categories = df[key].cat.categories.astype('U'). 1287 logg.info(. 1288 '... storing \'{}\' as categorical'. ~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py in __getattr__(self, name). 3608 if (name in self._internal_names_set or name in self._metadata or. 3609 name in self._accessors):. -> 3610 return object.__getattribute__(self, name). 3611 else:. 3612 if name in self._info_axis:. ~/anaconda3/lib/python3.6/site-packages/pandas/core/accessor.py in __get__(self, instance, owner). 52 # this ensures that Series.str.<method> is well defined. 53 return self.accessor_cls. ---> 54 return self.construct_accessor(instance). 55 . 56 def __set__(self, instance, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat access",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:3341,testability,coupl,couple,3341,"elf._accessors):. -> 3610 return object.__getattribute__(self, name). 3611 else:. 3612 if name in self._info_axis:. ~/anaconda3/lib/python3.6/site-packages/pandas/core/accessor.py in __get__(self, instance, owner). 52 # this ensures that Series.str.<method> is well defined. 53 return self.accessor_cls. ---> 54 return self.construct_accessor(instance). 55 . 56 def __set__(self, instance, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the pl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:4575,testability,test,test,4575,"e, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the plotting functions should have a parameter to plot only a subset of the data. That way sanitize_anndata can be called on the whole anndata object every time as there is no longer a reason to pass a view of the object. You could then test if a view is being passed to sanitize anndata, and then say ""please don't pass subsetted anndata objects to plotting functions"" or something like that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:126,usability,error,error,126,"Issue with sanitize_anndata() in plotting functions with subsets of anndata objects are passed.; I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:. `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:448,usability,error,error,448,"Issue with sanitize_anndata() in plotting functions with subsets of anndata objects are passed.; I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:. `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:698,usability,input,input-,698,"Issue with sanitize_anndata() in plotting functions with subsets of anndata objects are passed.; I get quite a strange scanpy error, which appears a bit stochastic... This is has happened for the first time in version 1.1. I am trying to get a scatter plot of a subsetted anndata object like this:. `p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac')`. When I do this the first time round, I get this error message about categorical variables from sanitize_anndata (none of which are actually used in the call). ```---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-66-fc1479c238f7> in <module>(). 9 plt.show(). 10 . ---> 11 p4 = sc.pl.scatter(adata[adata.obs['n_counts']<10000 ,:], 'n_counts', 'n_genes', color='mt_frac'). 12 p5 = sc.pl.scatter(adata, 'n_counts', 'n_genes', color='mt_frac'). 13 . ~/scanpy/scanpy/plotting/anndata.py in scatter(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 162 show=show,. 163 save=save,. --> 164 ax=ax). 165 . 166 elif x in adata.var_keys() and y in adata.var_keys() and color not in adata.obs_keys():. ~/scanpy/scanpy/plotting/anndata.py in _scatter_obs(adata, x, y, color, use_raw, sort_order, alpha, basis, groups, components, projection, legend_loc, legend_fontsize, legend_fontweight, color_map, palette, right_margin, left_margin, size, title, show, save, ax). 281 ax=None):. 282 """"""See docstring of scatter."""""". --> 283 sanitize_anndata(adata). 284 if legend_loc not in VALID_LEGENDLOCS:. 285 raise ValueError(. ~/scanpy/scanpy/utils.py in sanitize_anndata(adata). 481 # backwards compat... remove this in the future. 482 def sanitize_anndata(adata):. --> 483 adata._sanitize(). 484 . 485 . ~/anndata/anndata/base.py in _sanitize(self). 1284 if len(c.ca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:4195,usability,behavi,behaviour,4195,"e, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the plotting functions should have a parameter to plot only a subset of the data. That way sanitize_anndata can be called on the whole anndata object every time as there is no longer a reason to pass a view of the object. You could then test if a view is being passed to sanitize anndata, and then say ""please don't pass subsetted anndata objects to plotting functions"" or something like that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/166:4241,usability,user,user,4241,"e, value):. ~/anaconda3/lib/python3.6/site-packages/pandas/core/categorical.py in _make_accessor(cls, data). 2209 def _make_accessor(cls, data):. 2210 if not is_categorical_dtype(data.dtype):. -> 2211 raise AttributeError(""Can only use .cat accessor with a "". 2212 ""'category' dtype""). 2213 return CategoricalAccessor(data.values, data.index,. AttributeError: Can only use .cat accessor with a 'category' dtype. ```. Then, I comment out the respective line of code, run the whole thing again, and it works. And when I uncomment the line it works fine again. When I comment the line for the first time, I get a couple of lines displayed in the output saying:. > ... 'donor' was turned into a categorical variable. > ... 'gene_symbols' was turned into a categorical variable. or something like that... My theory is that sanitize_anndata() detects that these variables should be categorical variables and tries to convert them into categoricals. As this sc.pl.scatter call is the first time sanitize_anndata() is called after the variables are read in, this is the first time this conversion would take place. However, I am calling the sc.pl.scatter() on a subsetted anndata object, so it somehow cannot do the conversion. Once I call sc.pl.scatter on a non-subsetted anndata object once, the conversion can take place and I can subsequently call sc.pl.scatter also on a subsetted anndata object. If this is true, I can see why this is happening. However I feel this behaviour will be quite puzzling to a typical user. Maybe sanitize_anndata() should be called before plotting (probably hard to implement), or the plotting functions should have a parameter to plot only a subset of the data. That way sanitize_anndata can be called on the whole anndata object every time as there is no longer a reason to pass a view of the object. You could then test if a view is being passed to sanitize anndata, and then say ""please don't pass subsetted anndata objects to plotting functions"" or something like that.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/166
https://github.com/scverse/scanpy/issues/167:203,availability,error,error,203,"xlrd is missing in setup instructions; `anndata.readwrite.read.read_excel` is using pandas when fetching bundled datasets like `moignard15()`. However since xlrd is not bundles with pandas, it throws an error. See https://stackoverflow.com/questions/17063458/reading-an-excel-file-in-python-using-pandas#comment83338990_17063653. xlrd should be listed in the installation instructions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/167
https://github.com/scverse/scanpy/issues/167:222,deployability,stack,stackoverflow,222,"xlrd is missing in setup instructions; `anndata.readwrite.read.read_excel` is using pandas when fetching bundled datasets like `moignard15()`. However since xlrd is not bundles with pandas, it throws an error. See https://stackoverflow.com/questions/17063458/reading-an-excel-file-in-python-using-pandas#comment83338990_17063653. xlrd should be listed in the installation instructions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/167
https://github.com/scverse/scanpy/issues/167:359,deployability,instal,installation,359,"xlrd is missing in setup instructions; `anndata.readwrite.read.read_excel` is using pandas when fetching bundled datasets like `moignard15()`. However since xlrd is not bundles with pandas, it throws an error. See https://stackoverflow.com/questions/17063458/reading-an-excel-file-in-python-using-pandas#comment83338990_17063653. xlrd should be listed in the installation instructions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/167
https://github.com/scverse/scanpy/issues/167:203,performance,error,error,203,"xlrd is missing in setup instructions; `anndata.readwrite.read.read_excel` is using pandas when fetching bundled datasets like `moignard15()`. However since xlrd is not bundles with pandas, it throws an error. See https://stackoverflow.com/questions/17063458/reading-an-excel-file-in-python-using-pandas#comment83338990_17063653. xlrd should be listed in the installation instructions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/167
https://github.com/scverse/scanpy/issues/167:203,safety,error,error,203,"xlrd is missing in setup instructions; `anndata.readwrite.read.read_excel` is using pandas when fetching bundled datasets like `moignard15()`. However since xlrd is not bundles with pandas, it throws an error. See https://stackoverflow.com/questions/17063458/reading-an-excel-file-in-python-using-pandas#comment83338990_17063653. xlrd should be listed in the installation instructions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/167
https://github.com/scverse/scanpy/issues/167:203,usability,error,error,203,"xlrd is missing in setup instructions; `anndata.readwrite.read.read_excel` is using pandas when fetching bundled datasets like `moignard15()`. However since xlrd is not bundles with pandas, it throws an error. See https://stackoverflow.com/questions/17063458/reading-an-excel-file-in-python-using-pandas#comment83338990_17063653. xlrd should be listed in the installation instructions.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/167
https://github.com/scverse/scanpy/issues/168:18,integrability,batch,batch,18,"diffusion map and batch effect correction; Can you extend scanpy functions so that I can show gene expression level on plot generated by sc.pl.diffmap? just like that monocle2 does. And, in which step should I execute MNN batch effect correction ? Is it still necessary to regress out some variables ( n_counts, percent_mito, cell cycle et al.,) when I execute MNN ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/168
https://github.com/scverse/scanpy/issues/168:222,integrability,batch,batch,222,"diffusion map and batch effect correction; Can you extend scanpy functions so that I can show gene expression level on plot generated by sc.pl.diffmap? just like that monocle2 does. And, in which step should I execute MNN batch effect correction ? Is it still necessary to regress out some variables ( n_counts, percent_mito, cell cycle et al.,) when I execute MNN ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/168
https://github.com/scverse/scanpy/issues/168:51,modifiability,exten,extend,51,"diffusion map and batch effect correction; Can you extend scanpy functions so that I can show gene expression level on plot generated by sc.pl.diffmap? just like that monocle2 does. And, in which step should I execute MNN batch effect correction ? Is it still necessary to regress out some variables ( n_counts, percent_mito, cell cycle et al.,) when I execute MNN ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/168
https://github.com/scverse/scanpy/issues/168:290,modifiability,variab,variables,290,"diffusion map and batch effect correction; Can you extend scanpy functions so that I can show gene expression level on plot generated by sc.pl.diffmap? just like that monocle2 does. And, in which step should I execute MNN batch effect correction ? Is it still necessary to regress out some variables ( n_counts, percent_mito, cell cycle et al.,) when I execute MNN ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/168
https://github.com/scverse/scanpy/issues/168:18,performance,batch,batch,18,"diffusion map and batch effect correction; Can you extend scanpy functions so that I can show gene expression level on plot generated by sc.pl.diffmap? just like that monocle2 does. And, in which step should I execute MNN batch effect correction ? Is it still necessary to regress out some variables ( n_counts, percent_mito, cell cycle et al.,) when I execute MNN ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/168
https://github.com/scverse/scanpy/issues/168:222,performance,batch,batch,222,"diffusion map and batch effect correction; Can you extend scanpy functions so that I can show gene expression level on plot generated by sc.pl.diffmap? just like that monocle2 does. And, in which step should I execute MNN batch effect correction ? Is it still necessary to regress out some variables ( n_counts, percent_mito, cell cycle et al.,) when I execute MNN ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/168
https://github.com/scverse/scanpy/issues/168:176,reliability,doe,does,176,"diffusion map and batch effect correction; Can you extend scanpy functions so that I can show gene expression level on plot generated by sc.pl.diffmap? just like that monocle2 does. And, in which step should I execute MNN batch effect correction ? Is it still necessary to regress out some variables ( n_counts, percent_mito, cell cycle et al.,) when I execute MNN ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/168
https://github.com/scverse/scanpy/issues/168:273,testability,regress,regress,273,"diffusion map and batch effect correction; Can you extend scanpy functions so that I can show gene expression level on plot generated by sc.pl.diffmap? just like that monocle2 does. And, in which step should I execute MNN batch effect correction ? Is it still necessary to regress out some variables ( n_counts, percent_mito, cell cycle et al.,) when I execute MNN ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/168
https://github.com/scverse/scanpy/pull/169:625,integrability,batch,batch,625,"added highest expressed genes QC; This PR adds the option to make an image like the following:. ```python. sc.pl.highest_expr_genes(adata, n_top=40). ```. <img src=""https://user-images.githubusercontent.com/4964309/41143405-6ac1acd8-6af9-11e8-8a9f-6fc6c7d9846a.png"" width=""450px"">. This plot is similar to the one produced by `scater` function `plotQC` and is useful to identify highly expressed genes in a sample. To keep the code tidy I added the new plot on `scanpy/plotting/qc.py` I imagine that other QC plots can be added in the future. Possible future improvements can plot multiple panels by splitting the data using batch for example. Additionally, this PR:. * Changes the *grey* dot color of `_scatter_obs` to *ligh_grey*. This results in a better contrast of colors. E.g.:. ```python. sc.pl.umap(bdata, color='batch', groups=['PBMC']). ```. <img src=""https://user-images.githubusercontent.com/4964309/41143661-6341e17a-6afa-11e8-98e1-e48bd9c1a3d3.png"" width=""350px"">. * Added option to select the number of panels for `rank_genes_groups`. Without this option, if there are too many louvain groups, then the image is too wide. With the new parameter, it is easy to select how many panels per row should be plotted.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/169
https://github.com/scverse/scanpy/pull/169:821,integrability,batch,batch,821,"added highest expressed genes QC; This PR adds the option to make an image like the following:. ```python. sc.pl.highest_expr_genes(adata, n_top=40). ```. <img src=""https://user-images.githubusercontent.com/4964309/41143405-6ac1acd8-6af9-11e8-8a9f-6fc6c7d9846a.png"" width=""450px"">. This plot is similar to the one produced by `scater` function `plotQC` and is useful to identify highly expressed genes in a sample. To keep the code tidy I added the new plot on `scanpy/plotting/qc.py` I imagine that other QC plots can be added in the future. Possible future improvements can plot multiple panels by splitting the data using batch for example. Additionally, this PR:. * Changes the *grey* dot color of `_scatter_obs` to *ligh_grey*. This results in a better contrast of colors. E.g.:. ```python. sc.pl.umap(bdata, color='batch', groups=['PBMC']). ```. <img src=""https://user-images.githubusercontent.com/4964309/41143661-6341e17a-6afa-11e8-98e1-e48bd9c1a3d3.png"" width=""350px"">. * Added option to select the number of panels for `rank_genes_groups`. Without this option, if there are too many louvain groups, then the image is too wide. With the new parameter, it is easy to select how many panels per row should be plotted.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/169
https://github.com/scverse/scanpy/pull/169:1150,modifiability,paramet,parameter,1150,"added highest expressed genes QC; This PR adds the option to make an image like the following:. ```python. sc.pl.highest_expr_genes(adata, n_top=40). ```. <img src=""https://user-images.githubusercontent.com/4964309/41143405-6ac1acd8-6af9-11e8-8a9f-6fc6c7d9846a.png"" width=""450px"">. This plot is similar to the one produced by `scater` function `plotQC` and is useful to identify highly expressed genes in a sample. To keep the code tidy I added the new plot on `scanpy/plotting/qc.py` I imagine that other QC plots can be added in the future. Possible future improvements can plot multiple panels by splitting the data using batch for example. Additionally, this PR:. * Changes the *grey* dot color of `_scatter_obs` to *ligh_grey*. This results in a better contrast of colors. E.g.:. ```python. sc.pl.umap(bdata, color='batch', groups=['PBMC']). ```. <img src=""https://user-images.githubusercontent.com/4964309/41143661-6341e17a-6afa-11e8-98e1-e48bd9c1a3d3.png"" width=""350px"">. * Added option to select the number of panels for `rank_genes_groups`. Without this option, if there are too many louvain groups, then the image is too wide. With the new parameter, it is easy to select how many panels per row should be plotted.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/169
https://github.com/scverse/scanpy/pull/169:625,performance,batch,batch,625,"added highest expressed genes QC; This PR adds the option to make an image like the following:. ```python. sc.pl.highest_expr_genes(adata, n_top=40). ```. <img src=""https://user-images.githubusercontent.com/4964309/41143405-6ac1acd8-6af9-11e8-8a9f-6fc6c7d9846a.png"" width=""450px"">. This plot is similar to the one produced by `scater` function `plotQC` and is useful to identify highly expressed genes in a sample. To keep the code tidy I added the new plot on `scanpy/plotting/qc.py` I imagine that other QC plots can be added in the future. Possible future improvements can plot multiple panels by splitting the data using batch for example. Additionally, this PR:. * Changes the *grey* dot color of `_scatter_obs` to *ligh_grey*. This results in a better contrast of colors. E.g.:. ```python. sc.pl.umap(bdata, color='batch', groups=['PBMC']). ```. <img src=""https://user-images.githubusercontent.com/4964309/41143661-6341e17a-6afa-11e8-98e1-e48bd9c1a3d3.png"" width=""350px"">. * Added option to select the number of panels for `rank_genes_groups`. Without this option, if there are too many louvain groups, then the image is too wide. With the new parameter, it is easy to select how many panels per row should be plotted.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/169
https://github.com/scverse/scanpy/pull/169:821,performance,batch,batch,821,"added highest expressed genes QC; This PR adds the option to make an image like the following:. ```python. sc.pl.highest_expr_genes(adata, n_top=40). ```. <img src=""https://user-images.githubusercontent.com/4964309/41143405-6ac1acd8-6af9-11e8-8a9f-6fc6c7d9846a.png"" width=""450px"">. This plot is similar to the one produced by `scater` function `plotQC` and is useful to identify highly expressed genes in a sample. To keep the code tidy I added the new plot on `scanpy/plotting/qc.py` I imagine that other QC plots can be added in the future. Possible future improvements can plot multiple panels by splitting the data using batch for example. Additionally, this PR:. * Changes the *grey* dot color of `_scatter_obs` to *ligh_grey*. This results in a better contrast of colors. E.g.:. ```python. sc.pl.umap(bdata, color='batch', groups=['PBMC']). ```. <img src=""https://user-images.githubusercontent.com/4964309/41143661-6341e17a-6afa-11e8-98e1-e48bd9c1a3d3.png"" width=""350px"">. * Added option to select the number of panels for `rank_genes_groups`. Without this option, if there are too many louvain groups, then the image is too wide. With the new parameter, it is easy to select how many panels per row should be plotted.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/169
https://github.com/scverse/scanpy/pull/169:370,security,ident,identify,370,"added highest expressed genes QC; This PR adds the option to make an image like the following:. ```python. sc.pl.highest_expr_genes(adata, n_top=40). ```. <img src=""https://user-images.githubusercontent.com/4964309/41143405-6ac1acd8-6af9-11e8-8a9f-6fc6c7d9846a.png"" width=""450px"">. This plot is similar to the one produced by `scater` function `plotQC` and is useful to identify highly expressed genes in a sample. To keep the code tidy I added the new plot on `scanpy/plotting/qc.py` I imagine that other QC plots can be added in the future. Possible future improvements can plot multiple panels by splitting the data using batch for example. Additionally, this PR:. * Changes the *grey* dot color of `_scatter_obs` to *ligh_grey*. This results in a better contrast of colors. E.g.:. ```python. sc.pl.umap(bdata, color='batch', groups=['PBMC']). ```. <img src=""https://user-images.githubusercontent.com/4964309/41143661-6341e17a-6afa-11e8-98e1-e48bd9c1a3d3.png"" width=""350px"">. * Added option to select the number of panels for `rank_genes_groups`. Without this option, if there are too many louvain groups, then the image is too wide. With the new parameter, it is easy to select how many panels per row should be plotted.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/169
https://github.com/scverse/scanpy/pull/169:173,usability,user,user-images,173,"added highest expressed genes QC; This PR adds the option to make an image like the following:. ```python. sc.pl.highest_expr_genes(adata, n_top=40). ```. <img src=""https://user-images.githubusercontent.com/4964309/41143405-6ac1acd8-6af9-11e8-8a9f-6fc6c7d9846a.png"" width=""450px"">. This plot is similar to the one produced by `scater` function `plotQC` and is useful to identify highly expressed genes in a sample. To keep the code tidy I added the new plot on `scanpy/plotting/qc.py` I imagine that other QC plots can be added in the future. Possible future improvements can plot multiple panels by splitting the data using batch for example. Additionally, this PR:. * Changes the *grey* dot color of `_scatter_obs` to *ligh_grey*. This results in a better contrast of colors. E.g.:. ```python. sc.pl.umap(bdata, color='batch', groups=['PBMC']). ```. <img src=""https://user-images.githubusercontent.com/4964309/41143661-6341e17a-6afa-11e8-98e1-e48bd9c1a3d3.png"" width=""350px"">. * Added option to select the number of panels for `rank_genes_groups`. Without this option, if there are too many louvain groups, then the image is too wide. With the new parameter, it is easy to select how many panels per row should be plotted.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/169
https://github.com/scverse/scanpy/pull/169:870,usability,user,user-images,870,"added highest expressed genes QC; This PR adds the option to make an image like the following:. ```python. sc.pl.highest_expr_genes(adata, n_top=40). ```. <img src=""https://user-images.githubusercontent.com/4964309/41143405-6ac1acd8-6af9-11e8-8a9f-6fc6c7d9846a.png"" width=""450px"">. This plot is similar to the one produced by `scater` function `plotQC` and is useful to identify highly expressed genes in a sample. To keep the code tidy I added the new plot on `scanpy/plotting/qc.py` I imagine that other QC plots can be added in the future. Possible future improvements can plot multiple panels by splitting the data using batch for example. Additionally, this PR:. * Changes the *grey* dot color of `_scatter_obs` to *ligh_grey*. This results in a better contrast of colors. E.g.:. ```python. sc.pl.umap(bdata, color='batch', groups=['PBMC']). ```. <img src=""https://user-images.githubusercontent.com/4964309/41143661-6341e17a-6afa-11e8-98e1-e48bd9c1a3d3.png"" width=""350px"">. * Added option to select the number of panels for `rank_genes_groups`. Without this option, if there are too many louvain groups, then the image is too wide. With the new parameter, it is easy to select how many panels per row should be plotted.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/169
https://github.com/scverse/scanpy/issues/170:54,deployability,api,api,54,"diffmap - negative eigenvalues ; ```py. import scanpy.api as sc. adata = sc.datasets.paul15(). sc.pp.neighbors(adata, n_neighbors=20, use_rep='X'). sc.tl.diffmap(adata, n_comps=60). adata.uns['diffmap_evals']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/170
https://github.com/scverse/scanpy/issues/170:54,integrability,api,api,54,"diffmap - negative eigenvalues ; ```py. import scanpy.api as sc. adata = sc.datasets.paul15(). sc.pp.neighbors(adata, n_neighbors=20, use_rep='X'). sc.tl.diffmap(adata, n_comps=60). adata.uns['diffmap_evals']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/170
https://github.com/scverse/scanpy/issues/170:54,interoperability,api,api,54,"diffmap - negative eigenvalues ; ```py. import scanpy.api as sc. adata = sc.datasets.paul15(). sc.pp.neighbors(adata, n_neighbors=20, use_rep='X'). sc.tl.diffmap(adata, n_comps=60). adata.uns['diffmap_evals']. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/170
https://github.com/scverse/scanpy/issues/171:193,energy efficiency,load,loading,193,"anndata.raw.var casting categoricals to integers; When an anndata object is saved to h5ad the categorical variables in the .raw.var are casted to integers so that e.g. gene names are lost when loading the anndata object again. This functionality is especially unfortunate as anndata allows adata and adata.raw to have different sizes in the .var dimension. Thus, if anndata represents for example a highly variable gene set, where anndata.raw is the whole data set, then we can no longer visualize the expression of genes that were filtered out unless we call them by var_name and not by 'gene_name'. This bug is likely due to these lines:. https://github.com/theislab/anndata/blob/d9727cab88ba2100787e3e2ae0c6d72abd4d92b7/anndata/base.py#L1925-L1951. It would be good to add an uns_raw/ or raw_categories/ folder to the h5ad format which stores the categorical variables for raw.var.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/171
https://github.com/scverse/scanpy/issues/171:532,integrability,filter,filtered,532,"anndata.raw.var casting categoricals to integers; When an anndata object is saved to h5ad the categorical variables in the .raw.var are casted to integers so that e.g. gene names are lost when loading the anndata object again. This functionality is especially unfortunate as anndata allows adata and adata.raw to have different sizes in the .var dimension. Thus, if anndata represents for example a highly variable gene set, where anndata.raw is the whole data set, then we can no longer visualize the expression of genes that were filtered out unless we call them by var_name and not by 'gene_name'. This bug is likely due to these lines:. https://github.com/theislab/anndata/blob/d9727cab88ba2100787e3e2ae0c6d72abd4d92b7/anndata/base.py#L1925-L1951. It would be good to add an uns_raw/ or raw_categories/ folder to the h5ad format which stores the categorical variables for raw.var.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/171
https://github.com/scverse/scanpy/issues/171:826,interoperability,format,format,826,"anndata.raw.var casting categoricals to integers; When an anndata object is saved to h5ad the categorical variables in the .raw.var are casted to integers so that e.g. gene names are lost when loading the anndata object again. This functionality is especially unfortunate as anndata allows adata and adata.raw to have different sizes in the .var dimension. Thus, if anndata represents for example a highly variable gene set, where anndata.raw is the whole data set, then we can no longer visualize the expression of genes that were filtered out unless we call them by var_name and not by 'gene_name'. This bug is likely due to these lines:. https://github.com/theislab/anndata/blob/d9727cab88ba2100787e3e2ae0c6d72abd4d92b7/anndata/base.py#L1925-L1951. It would be good to add an uns_raw/ or raw_categories/ folder to the h5ad format which stores the categorical variables for raw.var.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/171
https://github.com/scverse/scanpy/issues/171:106,modifiability,variab,variables,106,"anndata.raw.var casting categoricals to integers; When an anndata object is saved to h5ad the categorical variables in the .raw.var are casted to integers so that e.g. gene names are lost when loading the anndata object again. This functionality is especially unfortunate as anndata allows adata and adata.raw to have different sizes in the .var dimension. Thus, if anndata represents for example a highly variable gene set, where anndata.raw is the whole data set, then we can no longer visualize the expression of genes that were filtered out unless we call them by var_name and not by 'gene_name'. This bug is likely due to these lines:. https://github.com/theislab/anndata/blob/d9727cab88ba2100787e3e2ae0c6d72abd4d92b7/anndata/base.py#L1925-L1951. It would be good to add an uns_raw/ or raw_categories/ folder to the h5ad format which stores the categorical variables for raw.var.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/171
https://github.com/scverse/scanpy/issues/171:406,modifiability,variab,variable,406,"anndata.raw.var casting categoricals to integers; When an anndata object is saved to h5ad the categorical variables in the .raw.var are casted to integers so that e.g. gene names are lost when loading the anndata object again. This functionality is especially unfortunate as anndata allows adata and adata.raw to have different sizes in the .var dimension. Thus, if anndata represents for example a highly variable gene set, where anndata.raw is the whole data set, then we can no longer visualize the expression of genes that were filtered out unless we call them by var_name and not by 'gene_name'. This bug is likely due to these lines:. https://github.com/theislab/anndata/blob/d9727cab88ba2100787e3e2ae0c6d72abd4d92b7/anndata/base.py#L1925-L1951. It would be good to add an uns_raw/ or raw_categories/ folder to the h5ad format which stores the categorical variables for raw.var.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/171
https://github.com/scverse/scanpy/issues/171:862,modifiability,variab,variables,862,"anndata.raw.var casting categoricals to integers; When an anndata object is saved to h5ad the categorical variables in the .raw.var are casted to integers so that e.g. gene names are lost when loading the anndata object again. This functionality is especially unfortunate as anndata allows adata and adata.raw to have different sizes in the .var dimension. Thus, if anndata represents for example a highly variable gene set, where anndata.raw is the whole data set, then we can no longer visualize the expression of genes that were filtered out unless we call them by var_name and not by 'gene_name'. This bug is likely due to these lines:. https://github.com/theislab/anndata/blob/d9727cab88ba2100787e3e2ae0c6d72abd4d92b7/anndata/base.py#L1925-L1951. It would be good to add an uns_raw/ or raw_categories/ folder to the h5ad format which stores the categorical variables for raw.var.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/171
https://github.com/scverse/scanpy/issues/171:193,performance,load,loading,193,"anndata.raw.var casting categoricals to integers; When an anndata object is saved to h5ad the categorical variables in the .raw.var are casted to integers so that e.g. gene names are lost when loading the anndata object again. This functionality is especially unfortunate as anndata allows adata and adata.raw to have different sizes in the .var dimension. Thus, if anndata represents for example a highly variable gene set, where anndata.raw is the whole data set, then we can no longer visualize the expression of genes that were filtered out unless we call them by var_name and not by 'gene_name'. This bug is likely due to these lines:. https://github.com/theislab/anndata/blob/d9727cab88ba2100787e3e2ae0c6d72abd4d92b7/anndata/base.py#L1925-L1951. It would be good to add an uns_raw/ or raw_categories/ folder to the h5ad format which stores the categorical variables for raw.var.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/171
https://github.com/scverse/scanpy/issues/171:488,usability,visual,visualize,488,"anndata.raw.var casting categoricals to integers; When an anndata object is saved to h5ad the categorical variables in the .raw.var are casted to integers so that e.g. gene names are lost when loading the anndata object again. This functionality is especially unfortunate as anndata allows adata and adata.raw to have different sizes in the .var dimension. Thus, if anndata represents for example a highly variable gene set, where anndata.raw is the whole data set, then we can no longer visualize the expression of genes that were filtered out unless we call them by var_name and not by 'gene_name'. This bug is likely due to these lines:. https://github.com/theislab/anndata/blob/d9727cab88ba2100787e3e2ae0c6d72abd4d92b7/anndata/base.py#L1925-L1951. It would be good to add an uns_raw/ or raw_categories/ folder to the h5ad format which stores the categorical variables for raw.var.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/171
https://github.com/scverse/scanpy/issues/172:167,energy efficiency,model,model,167,"sc.pp.filter_genes_dispersion() produces NaNs; I am trying to get the highly variable genes for a data set. The data set was normalized by fitting a negative binomial model and using the residuals as expression levels. This gives mean gene expression values that can be negative and are very close to 0. When I use the command:. `disp_filter = sc.pp.filter_genes_dispersion(adata.X, min_mean=0, min_disp=0.5)`. I get very few differentially expressed genes. Looking at the dispersions via `disp_filter['dispersions']` shows that many dispersions appear to be NaN. And superficial inspection shows that the genes with negative means have NaN dispersions. This feels like it shouldn't be the case. It is possible to calculate the variance for the genes that have NaN dispersions. Are all negative dispersion values cast to NaN? Changing the 'mean_mean' parameter to a negative value changes nothing.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/172
https://github.com/scverse/scanpy/issues/172:77,modifiability,variab,variable,77,"sc.pp.filter_genes_dispersion() produces NaNs; I am trying to get the highly variable genes for a data set. The data set was normalized by fitting a negative binomial model and using the residuals as expression levels. This gives mean gene expression values that can be negative and are very close to 0. When I use the command:. `disp_filter = sc.pp.filter_genes_dispersion(adata.X, min_mean=0, min_disp=0.5)`. I get very few differentially expressed genes. Looking at the dispersions via `disp_filter['dispersions']` shows that many dispersions appear to be NaN. And superficial inspection shows that the genes with negative means have NaN dispersions. This feels like it shouldn't be the case. It is possible to calculate the variance for the genes that have NaN dispersions. Are all negative dispersion values cast to NaN? Changing the 'mean_mean' parameter to a negative value changes nothing.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/172
https://github.com/scverse/scanpy/issues/172:851,modifiability,paramet,parameter,851,"sc.pp.filter_genes_dispersion() produces NaNs; I am trying to get the highly variable genes for a data set. The data set was normalized by fitting a negative binomial model and using the residuals as expression levels. This gives mean gene expression values that can be negative and are very close to 0. When I use the command:. `disp_filter = sc.pp.filter_genes_dispersion(adata.X, min_mean=0, min_disp=0.5)`. I get very few differentially expressed genes. Looking at the dispersions via `disp_filter['dispersions']` shows that many dispersions appear to be NaN. And superficial inspection shows that the genes with negative means have NaN dispersions. This feels like it shouldn't be the case. It is possible to calculate the variance for the genes that have NaN dispersions. Are all negative dispersion values cast to NaN? Changing the 'mean_mean' parameter to a negative value changes nothing.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/172
https://github.com/scverse/scanpy/issues/172:167,security,model,model,167,"sc.pp.filter_genes_dispersion() produces NaNs; I am trying to get the highly variable genes for a data set. The data set was normalized by fitting a negative binomial model and using the residuals as expression levels. This gives mean gene expression values that can be negative and are very close to 0. When I use the command:. `disp_filter = sc.pp.filter_genes_dispersion(adata.X, min_mean=0, min_disp=0.5)`. I get very few differentially expressed genes. Looking at the dispersions via `disp_filter['dispersions']` shows that many dispersions appear to be NaN. And superficial inspection shows that the genes with negative means have NaN dispersions. This feels like it shouldn't be the case. It is possible to calculate the variance for the genes that have NaN dispersions. Are all negative dispersion values cast to NaN? Changing the 'mean_mean' parameter to a negative value changes nothing.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/172
https://github.com/scverse/scanpy/issues/172:292,usability,close,close,292,"sc.pp.filter_genes_dispersion() produces NaNs; I am trying to get the highly variable genes for a data set. The data set was normalized by fitting a negative binomial model and using the residuals as expression levels. This gives mean gene expression values that can be negative and are very close to 0. When I use the command:. `disp_filter = sc.pp.filter_genes_dispersion(adata.X, min_mean=0, min_disp=0.5)`. I get very few differentially expressed genes. Looking at the dispersions via `disp_filter['dispersions']` shows that many dispersions appear to be NaN. And superficial inspection shows that the genes with negative means have NaN dispersions. This feels like it shouldn't be the case. It is possible to calculate the variance for the genes that have NaN dispersions. Are all negative dispersion values cast to NaN? Changing the 'mean_mean' parameter to a negative value changes nothing.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/172
https://github.com/scverse/scanpy/issues/172:319,usability,command,command,319,"sc.pp.filter_genes_dispersion() produces NaNs; I am trying to get the highly variable genes for a data set. The data set was normalized by fitting a negative binomial model and using the residuals as expression levels. This gives mean gene expression values that can be negative and are very close to 0. When I use the command:. `disp_filter = sc.pp.filter_genes_dispersion(adata.X, min_mean=0, min_disp=0.5)`. I get very few differentially expressed genes. Looking at the dispersions via `disp_filter['dispersions']` shows that many dispersions appear to be NaN. And superficial inspection shows that the genes with negative means have NaN dispersions. This feels like it shouldn't be the case. It is possible to calculate the variance for the genes that have NaN dispersions. Are all negative dispersion values cast to NaN? Changing the 'mean_mean' parameter to a negative value changes nothing.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/172
https://github.com/scverse/scanpy/issues/173:384,energy efficiency,predict,predict,384,"Doublet filtering function; Hi,. I tried the [`DoubletDetection`](https://github.com/JonathanShor/DoubletDetection) Python library on my data and got some interesting result. As it can be run directly on a numpy array of count matrix (`adata.X`), I thought it would be an interesting feature for `scanpy`. . ```. clf = doubletdetection.BoostClassifier() . doublets = clf.fit(adata.X).predict(). adata.obs['doublet'] = pd.Categorical(doublets.astype(bool)). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173
https://github.com/scverse/scanpy/issues/173:8,integrability,filter,filtering,8,"Doublet filtering function; Hi,. I tried the [`DoubletDetection`](https://github.com/JonathanShor/DoubletDetection) Python library on my data and got some interesting result. As it can be run directly on a numpy array of count matrix (`adata.X`), I thought it would be an interesting feature for `scanpy`. . ```. clf = doubletdetection.BoostClassifier() . doublets = clf.fit(adata.X).predict(). adata.obs['doublet'] = pd.Categorical(doublets.astype(bool)). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173
https://github.com/scverse/scanpy/issues/173:384,safety,predict,predict,384,"Doublet filtering function; Hi,. I tried the [`DoubletDetection`](https://github.com/JonathanShor/DoubletDetection) Python library on my data and got some interesting result. As it can be run directly on a numpy array of count matrix (`adata.X`), I thought it would be an interesting feature for `scanpy`. . ```. clf = doubletdetection.BoostClassifier() . doublets = clf.fit(adata.X).predict(). adata.obs['doublet'] = pd.Categorical(doublets.astype(bool)). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/173
https://github.com/scverse/scanpy/issues/174:25,availability,cluster,clusters,25,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:268,availability,cluster,clusters,268,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:289,availability,cluster,clusters,289,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:375,availability,cluster,clusters,375,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:441,availability,cluster,clusters,441,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:806,availability,cluster,clusters,806,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:820,availability,cluster,clusters,820,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:872,availability,cluster,clusters,872,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:1090,availability,cluster,clusters,1090,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:1153,availability,cluster,cluster,1153,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:1393,availability,cluster,clusters,1393,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:1600,availability,cluster,clusters,1600,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:25,deployability,cluster,clusters,25,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:133,deployability,continu,continuous,133,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:268,deployability,cluster,clusters,268,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:289,deployability,cluster,clusters,289,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:375,deployability,cluster,clusters,375,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:441,deployability,cluster,clusters,441,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:806,deployability,cluster,clusters,806,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:820,deployability,cluster,clusters,820,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:872,deployability,cluster,clusters,872,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:1090,deployability,cluster,clusters,1090,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:1134,deployability,continu,continuity,1134,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:1153,deployability,cluster,cluster,1153,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:1393,deployability,cluster,clusters,1393,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:1600,deployability,cluster,clusters,1600,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:1332,interoperability,distribut,distributed,1332,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:1588,interoperability,distribut,distributed,1588,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:475,modifiability,paramet,parameters,475,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:1116,modifiability,interm,intermingled,1116,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:521,reliability,doe,doesn,521,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:718,testability,plan,planaria,718,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:727,testability,plan,planaria,727,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:774,usability,Clear,Clear,774,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:953,usability,user,user-images,953,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:1202,usability,user,user-images,1202,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:1444,usability,user,user-images,1444,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:1627,usability,user,user-images,1627,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/issues/174:1773,usability,intuit,intuitive,1773,"UMAP: discrete cell type clusters tend to distort UMAP embeddings; Hi,. UMAP gives me nice embeddings when the cell types are mostly continuous. But I couldn't get it to work well on a dataset with more discrete cell types. When I use smaller min_dist to separate the clusters better, the clusters tend to become very tiny and distant. When I set larger min_dist to make the clusters occupy more space, the spatial separation between coarse clusters is gone. Adjusting other parameters such as n_neighbors, spread, gamma doesn't give me good results either. . This issue is somewhat similar to the first two UMAP plots in this notebook before doing special initialization: https://github.com/theislab/paga/blob/master/planaria/planaria.ipynb. `min_dist=0.2, n_neighbor=15`: Clear separation between coarse clusters, but clusters become tiny with too much white space. The clusters on the left seem to be repelling those on the right. . <img src=https://user-images.githubusercontent.com/5046690/41402335-46cf92c4-6f7f-11e8-9b72-48d23d553356.png width=50%>. `min_dist=0.4`: The coarse-level clusters on the right are intermingled (the continuity between cluster 4 and 6 is now broken). <img src=https://user-images.githubusercontent.com/5046690/41402348-57054968-6f7f-11e8-8e24-696ad4afb243.png width=50%>. `min_dist=0.6`: Cells are distributed more smoothly, but the separation between coarse clusters are much less obvious. . <img src=https://user-images.githubusercontent.com/5046690/41402394-7252b00c-6f7f-11e8-9ffb-2d09a03fc131.png width=50%>. t-SNE in this case gives me more evenly distributed clusters. <img src=https://user-images.githubusercontent.com/5046690/41403178-8257e722-6f81-11e8-9b64-be274e82eadc.png width=50%>. Is there a way to make the UMAP look more intuitive in this kind of situations? Thanks! (I changed the original question as I feel that this one is more important.)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/174
https://github.com/scverse/scanpy/pull/175:89,availability,cluster,cluster,89,"Added visualizations for variables ordered by observations. E.g. marker genes ordered by cluster; This PR adds extra functionality to `pl.violin` adding the option produce stacked violin plots for each `key` passed. The new optional boolean argument `stripplot` was added to add/remove the stripplot on top of the violin plots. An example image is:. ![image](https://user-images.githubusercontent.com/4964309/41411458-3e105336-6fdd-11e8-8e18-07e49fe7c8d1.png). Similarly, I added `pl.heatmap` that plots variables ordered by an observation as follows:. ![image](https://user-images.githubusercontent.com/4964309/41411511-6996f334-6fdd-11e8-93ff-176b89743d83.png). An example notebook using these visualizations is [here](https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/175
https://github.com/scverse/scanpy/pull/175:46,deployability,observ,observations,46,"Added visualizations for variables ordered by observations. E.g. marker genes ordered by cluster; This PR adds extra functionality to `pl.violin` adding the option produce stacked violin plots for each `key` passed. The new optional boolean argument `stripplot` was added to add/remove the stripplot on top of the violin plots. An example image is:. ![image](https://user-images.githubusercontent.com/4964309/41411458-3e105336-6fdd-11e8-8e18-07e49fe7c8d1.png). Similarly, I added `pl.heatmap` that plots variables ordered by an observation as follows:. ![image](https://user-images.githubusercontent.com/4964309/41411511-6996f334-6fdd-11e8-93ff-176b89743d83.png). An example notebook using these visualizations is [here](https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/175
https://github.com/scverse/scanpy/pull/175:89,deployability,cluster,cluster,89,"Added visualizations for variables ordered by observations. E.g. marker genes ordered by cluster; This PR adds extra functionality to `pl.violin` adding the option produce stacked violin plots for each `key` passed. The new optional boolean argument `stripplot` was added to add/remove the stripplot on top of the violin plots. An example image is:. ![image](https://user-images.githubusercontent.com/4964309/41411458-3e105336-6fdd-11e8-8e18-07e49fe7c8d1.png). Similarly, I added `pl.heatmap` that plots variables ordered by an observation as follows:. ![image](https://user-images.githubusercontent.com/4964309/41411511-6996f334-6fdd-11e8-93ff-176b89743d83.png). An example notebook using these visualizations is [here](https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/175
https://github.com/scverse/scanpy/pull/175:172,deployability,stack,stacked,172,"Added visualizations for variables ordered by observations. E.g. marker genes ordered by cluster; This PR adds extra functionality to `pl.violin` adding the option produce stacked violin plots for each `key` passed. The new optional boolean argument `stripplot` was added to add/remove the stripplot on top of the violin plots. An example image is:. ![image](https://user-images.githubusercontent.com/4964309/41411458-3e105336-6fdd-11e8-8e18-07e49fe7c8d1.png). Similarly, I added `pl.heatmap` that plots variables ordered by an observation as follows:. ![image](https://user-images.githubusercontent.com/4964309/41411511-6996f334-6fdd-11e8-93ff-176b89743d83.png). An example notebook using these visualizations is [here](https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/175
https://github.com/scverse/scanpy/pull/175:528,deployability,observ,observation,528,"Added visualizations for variables ordered by observations. E.g. marker genes ordered by cluster; This PR adds extra functionality to `pl.violin` adding the option produce stacked violin plots for each `key` passed. The new optional boolean argument `stripplot` was added to add/remove the stripplot on top of the violin plots. An example image is:. ![image](https://user-images.githubusercontent.com/4964309/41411458-3e105336-6fdd-11e8-8e18-07e49fe7c8d1.png). Similarly, I added `pl.heatmap` that plots variables ordered by an observation as follows:. ![image](https://user-images.githubusercontent.com/4964309/41411511-6996f334-6fdd-11e8-93ff-176b89743d83.png). An example notebook using these visualizations is [here](https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/175
https://github.com/scverse/scanpy/pull/175:484,energy efficiency,heat,heatmap,484,"Added visualizations for variables ordered by observations. E.g. marker genes ordered by cluster; This PR adds extra functionality to `pl.violin` adding the option produce stacked violin plots for each `key` passed. The new optional boolean argument `stripplot` was added to add/remove the stripplot on top of the violin plots. An example image is:. ![image](https://user-images.githubusercontent.com/4964309/41411458-3e105336-6fdd-11e8-8e18-07e49fe7c8d1.png). Similarly, I added `pl.heatmap` that plots variables ordered by an observation as follows:. ![image](https://user-images.githubusercontent.com/4964309/41411511-6996f334-6fdd-11e8-93ff-176b89743d83.png). An example notebook using these visualizations is [here](https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/175
https://github.com/scverse/scanpy/pull/175:25,modifiability,variab,variables,25,"Added visualizations for variables ordered by observations. E.g. marker genes ordered by cluster; This PR adds extra functionality to `pl.violin` adding the option produce stacked violin plots for each `key` passed. The new optional boolean argument `stripplot` was added to add/remove the stripplot on top of the violin plots. An example image is:. ![image](https://user-images.githubusercontent.com/4964309/41411458-3e105336-6fdd-11e8-8e18-07e49fe7c8d1.png). Similarly, I added `pl.heatmap` that plots variables ordered by an observation as follows:. ![image](https://user-images.githubusercontent.com/4964309/41411511-6996f334-6fdd-11e8-93ff-176b89743d83.png). An example notebook using these visualizations is [here](https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/175
https://github.com/scverse/scanpy/pull/175:504,modifiability,variab,variables,504,"Added visualizations for variables ordered by observations. E.g. marker genes ordered by cluster; This PR adds extra functionality to `pl.violin` adding the option produce stacked violin plots for each `key` passed. The new optional boolean argument `stripplot` was added to add/remove the stripplot on top of the violin plots. An example image is:. ![image](https://user-images.githubusercontent.com/4964309/41411458-3e105336-6fdd-11e8-8e18-07e49fe7c8d1.png). Similarly, I added `pl.heatmap` that plots variables ordered by an observation as follows:. ![image](https://user-images.githubusercontent.com/4964309/41411511-6996f334-6fdd-11e8-93ff-176b89743d83.png). An example notebook using these visualizations is [here](https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/175
https://github.com/scverse/scanpy/pull/175:46,testability,observ,observations,46,"Added visualizations for variables ordered by observations. E.g. marker genes ordered by cluster; This PR adds extra functionality to `pl.violin` adding the option produce stacked violin plots for each `key` passed. The new optional boolean argument `stripplot` was added to add/remove the stripplot on top of the violin plots. An example image is:. ![image](https://user-images.githubusercontent.com/4964309/41411458-3e105336-6fdd-11e8-8e18-07e49fe7c8d1.png). Similarly, I added `pl.heatmap` that plots variables ordered by an observation as follows:. ![image](https://user-images.githubusercontent.com/4964309/41411511-6996f334-6fdd-11e8-93ff-176b89743d83.png). An example notebook using these visualizations is [here](https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/175
https://github.com/scverse/scanpy/pull/175:528,testability,observ,observation,528,"Added visualizations for variables ordered by observations. E.g. marker genes ordered by cluster; This PR adds extra functionality to `pl.violin` adding the option produce stacked violin plots for each `key` passed. The new optional boolean argument `stripplot` was added to add/remove the stripplot on top of the violin plots. An example image is:. ![image](https://user-images.githubusercontent.com/4964309/41411458-3e105336-6fdd-11e8-8e18-07e49fe7c8d1.png). Similarly, I added `pl.heatmap` that plots variables ordered by an observation as follows:. ![image](https://user-images.githubusercontent.com/4964309/41411511-6996f334-6fdd-11e8-93ff-176b89743d83.png). An example notebook using these visualizations is [here](https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/175
https://github.com/scverse/scanpy/pull/175:6,usability,visual,visualizations,6,"Added visualizations for variables ordered by observations. E.g. marker genes ordered by cluster; This PR adds extra functionality to `pl.violin` adding the option produce stacked violin plots for each `key` passed. The new optional boolean argument `stripplot` was added to add/remove the stripplot on top of the violin plots. An example image is:. ![image](https://user-images.githubusercontent.com/4964309/41411458-3e105336-6fdd-11e8-8e18-07e49fe7c8d1.png). Similarly, I added `pl.heatmap` that plots variables ordered by an observation as follows:. ![image](https://user-images.githubusercontent.com/4964309/41411511-6996f334-6fdd-11e8-93ff-176b89743d83.png). An example notebook using these visualizations is [here](https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/175
https://github.com/scverse/scanpy/pull/175:367,usability,user,user-images,367,"Added visualizations for variables ordered by observations. E.g. marker genes ordered by cluster; This PR adds extra functionality to `pl.violin` adding the option produce stacked violin plots for each `key` passed. The new optional boolean argument `stripplot` was added to add/remove the stripplot on top of the violin plots. An example image is:. ![image](https://user-images.githubusercontent.com/4964309/41411458-3e105336-6fdd-11e8-8e18-07e49fe7c8d1.png). Similarly, I added `pl.heatmap` that plots variables ordered by an observation as follows:. ![image](https://user-images.githubusercontent.com/4964309/41411511-6996f334-6fdd-11e8-93ff-176b89743d83.png). An example notebook using these visualizations is [here](https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/175
https://github.com/scverse/scanpy/pull/175:570,usability,user,user-images,570,"Added visualizations for variables ordered by observations. E.g. marker genes ordered by cluster; This PR adds extra functionality to `pl.violin` adding the option produce stacked violin plots for each `key` passed. The new optional boolean argument `stripplot` was added to add/remove the stripplot on top of the violin plots. An example image is:. ![image](https://user-images.githubusercontent.com/4964309/41411458-3e105336-6fdd-11e8-8e18-07e49fe7c8d1.png). Similarly, I added `pl.heatmap` that plots variables ordered by an observation as follows:. ![image](https://user-images.githubusercontent.com/4964309/41411511-6996f334-6fdd-11e8-93ff-176b89743d83.png). An example notebook using these visualizations is [here](https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/175
https://github.com/scverse/scanpy/pull/175:696,usability,visual,visualizations,696,"Added visualizations for variables ordered by observations. E.g. marker genes ordered by cluster; This PR adds extra functionality to `pl.violin` adding the option produce stacked violin plots for each `key` passed. The new optional boolean argument `stripplot` was added to add/remove the stripplot on top of the violin plots. An example image is:. ![image](https://user-images.githubusercontent.com/4964309/41411458-3e105336-6fdd-11e8-8e18-07e49fe7c8d1.png). Similarly, I added `pl.heatmap` that plots variables ordered by an observation as follows:. ![image](https://user-images.githubusercontent.com/4964309/41411511-6996f334-6fdd-11e8-93ff-176b89743d83.png). An example notebook using these visualizations is [here](https://gist.github.com/fidelram/2289b7a8d6da055fb058ac9a79ed485c).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/175
https://github.com/scverse/scanpy/issues/177:41,availability,cluster,clustering,41,"Neighbors with `metric='jaccard'` breaks clustering; Hello! I found an odd bug where computing `sc.pp.neighbors()` with `metric='jaccard'` results in random cluster assignments coming out of `sc.tl.louvain()`. Running with the `euclidean` distance metric yields appropriate cluster assignments from `sc.tl.louvain()`. . Reproduce (adata is a bone marrow data set, with ""ground truth"" cell type annotations in `adata.obs['cell_type']`: . ```. sc.pl.tsne(adata, color='cell_type', title='Ground truth') # Color tsne plot by ground truth cell annotations. plt.show(). plt.clf(). sc.pp.neighbors(adata, metric='jaccard', random_state=2018) # compute neighbor graph with jaccard metric. sc.tl.louvain(adata,random_state=2018) # Then use the Louvain algorithm to identify clusters. sc.pl.tsne(adata, color='louvain', title='Louvain + jaccard metric'). plt.show(). plt.clf(). sc.pp.neighbors(adata,metric='euclidean', random_state=2018) # compute neighbor graph with euclidean distance metric. sc.tl.louvain(adata, random_state=2018) # Rerun cluster identification. sc.pl.tsne(adata, color='louvain', title='Louvain + default metric'). plt.show(). plt.clf(). ```. ![image](https://user-images.githubusercontent.com/12618847/41443622-ed8840ac-6ff2-11e8-9cd6-d853e017a8ab.png). Thanks! Let me know if you need another set of eyes in tracking this one down :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/177
https://github.com/scverse/scanpy/issues/177:157,availability,cluster,cluster,157,"Neighbors with `metric='jaccard'` breaks clustering; Hello! I found an odd bug where computing `sc.pp.neighbors()` with `metric='jaccard'` results in random cluster assignments coming out of `sc.tl.louvain()`. Running with the `euclidean` distance metric yields appropriate cluster assignments from `sc.tl.louvain()`. . Reproduce (adata is a bone marrow data set, with ""ground truth"" cell type annotations in `adata.obs['cell_type']`: . ```. sc.pl.tsne(adata, color='cell_type', title='Ground truth') # Color tsne plot by ground truth cell annotations. plt.show(). plt.clf(). sc.pp.neighbors(adata, metric='jaccard', random_state=2018) # compute neighbor graph with jaccard metric. sc.tl.louvain(adata,random_state=2018) # Then use the Louvain algorithm to identify clusters. sc.pl.tsne(adata, color='louvain', title='Louvain + jaccard metric'). plt.show(). plt.clf(). sc.pp.neighbors(adata,metric='euclidean', random_state=2018) # compute neighbor graph with euclidean distance metric. sc.tl.louvain(adata, random_state=2018) # Rerun cluster identification. sc.pl.tsne(adata, color='louvain', title='Louvain + default metric'). plt.show(). plt.clf(). ```. ![image](https://user-images.githubusercontent.com/12618847/41443622-ed8840ac-6ff2-11e8-9cd6-d853e017a8ab.png). Thanks! Let me know if you need another set of eyes in tracking this one down :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/177
https://github.com/scverse/scanpy/issues/177:274,availability,cluster,cluster,274,"Neighbors with `metric='jaccard'` breaks clustering; Hello! I found an odd bug where computing `sc.pp.neighbors()` with `metric='jaccard'` results in random cluster assignments coming out of `sc.tl.louvain()`. Running with the `euclidean` distance metric yields appropriate cluster assignments from `sc.tl.louvain()`. . Reproduce (adata is a bone marrow data set, with ""ground truth"" cell type annotations in `adata.obs['cell_type']`: . ```. sc.pl.tsne(adata, color='cell_type', title='Ground truth') # Color tsne plot by ground truth cell annotations. plt.show(). plt.clf(). sc.pp.neighbors(adata, metric='jaccard', random_state=2018) # compute neighbor graph with jaccard metric. sc.tl.louvain(adata,random_state=2018) # Then use the Louvain algorithm to identify clusters. sc.pl.tsne(adata, color='louvain', title='Louvain + jaccard metric'). plt.show(). plt.clf(). sc.pp.neighbors(adata,metric='euclidean', random_state=2018) # compute neighbor graph with euclidean distance metric. sc.tl.louvain(adata, random_state=2018) # Rerun cluster identification. sc.pl.tsne(adata, color='louvain', title='Louvain + default metric'). plt.show(). plt.clf(). ```. ![image](https://user-images.githubusercontent.com/12618847/41443622-ed8840ac-6ff2-11e8-9cd6-d853e017a8ab.png). Thanks! Let me know if you need another set of eyes in tracking this one down :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/177
https://github.com/scverse/scanpy/issues/177:766,availability,cluster,clusters,766,"Neighbors with `metric='jaccard'` breaks clustering; Hello! I found an odd bug where computing `sc.pp.neighbors()` with `metric='jaccard'` results in random cluster assignments coming out of `sc.tl.louvain()`. Running with the `euclidean` distance metric yields appropriate cluster assignments from `sc.tl.louvain()`. . Reproduce (adata is a bone marrow data set, with ""ground truth"" cell type annotations in `adata.obs['cell_type']`: . ```. sc.pl.tsne(adata, color='cell_type', title='Ground truth') # Color tsne plot by ground truth cell annotations. plt.show(). plt.clf(). sc.pp.neighbors(adata, metric='jaccard', random_state=2018) # compute neighbor graph with jaccard metric. sc.tl.louvain(adata,random_state=2018) # Then use the Louvain algorithm to identify clusters. sc.pl.tsne(adata, color='louvain', title='Louvain + jaccard metric'). plt.show(). plt.clf(). sc.pp.neighbors(adata,metric='euclidean', random_state=2018) # compute neighbor graph with euclidean distance metric. sc.tl.louvain(adata, random_state=2018) # Rerun cluster identification. sc.pl.tsne(adata, color='louvain', title='Louvain + default metric'). plt.show(). plt.clf(). ```. ![image](https://user-images.githubusercontent.com/12618847/41443622-ed8840ac-6ff2-11e8-9cd6-d853e017a8ab.png). Thanks! Let me know if you need another set of eyes in tracking this one down :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/177
https://github.com/scverse/scanpy/issues/177:1035,availability,cluster,cluster,1035,"Neighbors with `metric='jaccard'` breaks clustering; Hello! I found an odd bug where computing `sc.pp.neighbors()` with `metric='jaccard'` results in random cluster assignments coming out of `sc.tl.louvain()`. Running with the `euclidean` distance metric yields appropriate cluster assignments from `sc.tl.louvain()`. . Reproduce (adata is a bone marrow data set, with ""ground truth"" cell type annotations in `adata.obs['cell_type']`: . ```. sc.pl.tsne(adata, color='cell_type', title='Ground truth') # Color tsne plot by ground truth cell annotations. plt.show(). plt.clf(). sc.pp.neighbors(adata, metric='jaccard', random_state=2018) # compute neighbor graph with jaccard metric. sc.tl.louvain(adata,random_state=2018) # Then use the Louvain algorithm to identify clusters. sc.pl.tsne(adata, color='louvain', title='Louvain + jaccard metric'). plt.show(). plt.clf(). sc.pp.neighbors(adata,metric='euclidean', random_state=2018) # compute neighbor graph with euclidean distance metric. sc.tl.louvain(adata, random_state=2018) # Rerun cluster identification. sc.pl.tsne(adata, color='louvain', title='Louvain + default metric'). plt.show(). plt.clf(). ```. ![image](https://user-images.githubusercontent.com/12618847/41443622-ed8840ac-6ff2-11e8-9cd6-d853e017a8ab.png). Thanks! Let me know if you need another set of eyes in tracking this one down :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/177
https://github.com/scverse/scanpy/issues/177:1342,availability,down,down,1342,"Neighbors with `metric='jaccard'` breaks clustering; Hello! I found an odd bug where computing `sc.pp.neighbors()` with `metric='jaccard'` results in random cluster assignments coming out of `sc.tl.louvain()`. Running with the `euclidean` distance metric yields appropriate cluster assignments from `sc.tl.louvain()`. . Reproduce (adata is a bone marrow data set, with ""ground truth"" cell type annotations in `adata.obs['cell_type']`: . ```. sc.pl.tsne(adata, color='cell_type', title='Ground truth') # Color tsne plot by ground truth cell annotations. plt.show(). plt.clf(). sc.pp.neighbors(adata, metric='jaccard', random_state=2018) # compute neighbor graph with jaccard metric. sc.tl.louvain(adata,random_state=2018) # Then use the Louvain algorithm to identify clusters. sc.pl.tsne(adata, color='louvain', title='Louvain + jaccard metric'). plt.show(). plt.clf(). sc.pp.neighbors(adata,metric='euclidean', random_state=2018) # compute neighbor graph with euclidean distance metric. sc.tl.louvain(adata, random_state=2018) # Rerun cluster identification. sc.pl.tsne(adata, color='louvain', title='Louvain + default metric'). plt.show(). plt.clf(). ```. ![image](https://user-images.githubusercontent.com/12618847/41443622-ed8840ac-6ff2-11e8-9cd6-d853e017a8ab.png). Thanks! Let me know if you need another set of eyes in tracking this one down :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/177
https://github.com/scverse/scanpy/issues/177:41,deployability,cluster,clustering,41,"Neighbors with `metric='jaccard'` breaks clustering; Hello! I found an odd bug where computing `sc.pp.neighbors()` with `metric='jaccard'` results in random cluster assignments coming out of `sc.tl.louvain()`. Running with the `euclidean` distance metric yields appropriate cluster assignments from `sc.tl.louvain()`. . Reproduce (adata is a bone marrow data set, with ""ground truth"" cell type annotations in `adata.obs['cell_type']`: . ```. sc.pl.tsne(adata, color='cell_type', title='Ground truth') # Color tsne plot by ground truth cell annotations. plt.show(). plt.clf(). sc.pp.neighbors(adata, metric='jaccard', random_state=2018) # compute neighbor graph with jaccard metric. sc.tl.louvain(adata,random_state=2018) # Then use the Louvain algorithm to identify clusters. sc.pl.tsne(adata, color='louvain', title='Louvain + jaccard metric'). plt.show(). plt.clf(). sc.pp.neighbors(adata,metric='euclidean', random_state=2018) # compute neighbor graph with euclidean distance metric. sc.tl.louvain(adata, random_state=2018) # Rerun cluster identification. sc.pl.tsne(adata, color='louvain', title='Louvain + default metric'). plt.show(). plt.clf(). ```. ![image](https://user-images.githubusercontent.com/12618847/41443622-ed8840ac-6ff2-11e8-9cd6-d853e017a8ab.png). Thanks! Let me know if you need another set of eyes in tracking this one down :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/177
https://github.com/scverse/scanpy/issues/177:157,deployability,cluster,cluster,157,"Neighbors with `metric='jaccard'` breaks clustering; Hello! I found an odd bug where computing `sc.pp.neighbors()` with `metric='jaccard'` results in random cluster assignments coming out of `sc.tl.louvain()`. Running with the `euclidean` distance metric yields appropriate cluster assignments from `sc.tl.louvain()`. . Reproduce (adata is a bone marrow data set, with ""ground truth"" cell type annotations in `adata.obs['cell_type']`: . ```. sc.pl.tsne(adata, color='cell_type', title='Ground truth') # Color tsne plot by ground truth cell annotations. plt.show(). plt.clf(). sc.pp.neighbors(adata, metric='jaccard', random_state=2018) # compute neighbor graph with jaccard metric. sc.tl.louvain(adata,random_state=2018) # Then use the Louvain algorithm to identify clusters. sc.pl.tsne(adata, color='louvain', title='Louvain + jaccard metric'). plt.show(). plt.clf(). sc.pp.neighbors(adata,metric='euclidean', random_state=2018) # compute neighbor graph with euclidean distance metric. sc.tl.louvain(adata, random_state=2018) # Rerun cluster identification. sc.pl.tsne(adata, color='louvain', title='Louvain + default metric'). plt.show(). plt.clf(). ```. ![image](https://user-images.githubusercontent.com/12618847/41443622-ed8840ac-6ff2-11e8-9cd6-d853e017a8ab.png). Thanks! Let me know if you need another set of eyes in tracking this one down :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/177
https://github.com/scverse/scanpy/issues/177:274,deployability,cluster,cluster,274,"Neighbors with `metric='jaccard'` breaks clustering; Hello! I found an odd bug where computing `sc.pp.neighbors()` with `metric='jaccard'` results in random cluster assignments coming out of `sc.tl.louvain()`. Running with the `euclidean` distance metric yields appropriate cluster assignments from `sc.tl.louvain()`. . Reproduce (adata is a bone marrow data set, with ""ground truth"" cell type annotations in `adata.obs['cell_type']`: . ```. sc.pl.tsne(adata, color='cell_type', title='Ground truth') # Color tsne plot by ground truth cell annotations. plt.show(). plt.clf(). sc.pp.neighbors(adata, metric='jaccard', random_state=2018) # compute neighbor graph with jaccard metric. sc.tl.louvain(adata,random_state=2018) # Then use the Louvain algorithm to identify clusters. sc.pl.tsne(adata, color='louvain', title='Louvain + jaccard metric'). plt.show(). plt.clf(). sc.pp.neighbors(adata,metric='euclidean', random_state=2018) # compute neighbor graph with euclidean distance metric. sc.tl.louvain(adata, random_state=2018) # Rerun cluster identification. sc.pl.tsne(adata, color='louvain', title='Louvain + default metric'). plt.show(). plt.clf(). ```. ![image](https://user-images.githubusercontent.com/12618847/41443622-ed8840ac-6ff2-11e8-9cd6-d853e017a8ab.png). Thanks! Let me know if you need another set of eyes in tracking this one down :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/177
https://github.com/scverse/scanpy/issues/177:766,deployability,cluster,clusters,766,"Neighbors with `metric='jaccard'` breaks clustering; Hello! I found an odd bug where computing `sc.pp.neighbors()` with `metric='jaccard'` results in random cluster assignments coming out of `sc.tl.louvain()`. Running with the `euclidean` distance metric yields appropriate cluster assignments from `sc.tl.louvain()`. . Reproduce (adata is a bone marrow data set, with ""ground truth"" cell type annotations in `adata.obs['cell_type']`: . ```. sc.pl.tsne(adata, color='cell_type', title='Ground truth') # Color tsne plot by ground truth cell annotations. plt.show(). plt.clf(). sc.pp.neighbors(adata, metric='jaccard', random_state=2018) # compute neighbor graph with jaccard metric. sc.tl.louvain(adata,random_state=2018) # Then use the Louvain algorithm to identify clusters. sc.pl.tsne(adata, color='louvain', title='Louvain + jaccard metric'). plt.show(). plt.clf(). sc.pp.neighbors(adata,metric='euclidean', random_state=2018) # compute neighbor graph with euclidean distance metric. sc.tl.louvain(adata, random_state=2018) # Rerun cluster identification. sc.pl.tsne(adata, color='louvain', title='Louvain + default metric'). plt.show(). plt.clf(). ```. ![image](https://user-images.githubusercontent.com/12618847/41443622-ed8840ac-6ff2-11e8-9cd6-d853e017a8ab.png). Thanks! Let me know if you need another set of eyes in tracking this one down :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/177
https://github.com/scverse/scanpy/issues/177:1035,deployability,cluster,cluster,1035,"Neighbors with `metric='jaccard'` breaks clustering; Hello! I found an odd bug where computing `sc.pp.neighbors()` with `metric='jaccard'` results in random cluster assignments coming out of `sc.tl.louvain()`. Running with the `euclidean` distance metric yields appropriate cluster assignments from `sc.tl.louvain()`. . Reproduce (adata is a bone marrow data set, with ""ground truth"" cell type annotations in `adata.obs['cell_type']`: . ```. sc.pl.tsne(adata, color='cell_type', title='Ground truth') # Color tsne plot by ground truth cell annotations. plt.show(). plt.clf(). sc.pp.neighbors(adata, metric='jaccard', random_state=2018) # compute neighbor graph with jaccard metric. sc.tl.louvain(adata,random_state=2018) # Then use the Louvain algorithm to identify clusters. sc.pl.tsne(adata, color='louvain', title='Louvain + jaccard metric'). plt.show(). plt.clf(). sc.pp.neighbors(adata,metric='euclidean', random_state=2018) # compute neighbor graph with euclidean distance metric. sc.tl.louvain(adata, random_state=2018) # Rerun cluster identification. sc.pl.tsne(adata, color='louvain', title='Louvain + default metric'). plt.show(). plt.clf(). ```. ![image](https://user-images.githubusercontent.com/12618847/41443622-ed8840ac-6ff2-11e8-9cd6-d853e017a8ab.png). Thanks! Let me know if you need another set of eyes in tracking this one down :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/177
https://github.com/scverse/scanpy/issues/177:757,security,ident,identify,757,"Neighbors with `metric='jaccard'` breaks clustering; Hello! I found an odd bug where computing `sc.pp.neighbors()` with `metric='jaccard'` results in random cluster assignments coming out of `sc.tl.louvain()`. Running with the `euclidean` distance metric yields appropriate cluster assignments from `sc.tl.louvain()`. . Reproduce (adata is a bone marrow data set, with ""ground truth"" cell type annotations in `adata.obs['cell_type']`: . ```. sc.pl.tsne(adata, color='cell_type', title='Ground truth') # Color tsne plot by ground truth cell annotations. plt.show(). plt.clf(). sc.pp.neighbors(adata, metric='jaccard', random_state=2018) # compute neighbor graph with jaccard metric. sc.tl.louvain(adata,random_state=2018) # Then use the Louvain algorithm to identify clusters. sc.pl.tsne(adata, color='louvain', title='Louvain + jaccard metric'). plt.show(). plt.clf(). sc.pp.neighbors(adata,metric='euclidean', random_state=2018) # compute neighbor graph with euclidean distance metric. sc.tl.louvain(adata, random_state=2018) # Rerun cluster identification. sc.pl.tsne(adata, color='louvain', title='Louvain + default metric'). plt.show(). plt.clf(). ```. ![image](https://user-images.githubusercontent.com/12618847/41443622-ed8840ac-6ff2-11e8-9cd6-d853e017a8ab.png). Thanks! Let me know if you need another set of eyes in tracking this one down :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/177
https://github.com/scverse/scanpy/issues/177:1043,security,ident,identification,1043,"Neighbors with `metric='jaccard'` breaks clustering; Hello! I found an odd bug where computing `sc.pp.neighbors()` with `metric='jaccard'` results in random cluster assignments coming out of `sc.tl.louvain()`. Running with the `euclidean` distance metric yields appropriate cluster assignments from `sc.tl.louvain()`. . Reproduce (adata is a bone marrow data set, with ""ground truth"" cell type annotations in `adata.obs['cell_type']`: . ```. sc.pl.tsne(adata, color='cell_type', title='Ground truth') # Color tsne plot by ground truth cell annotations. plt.show(). plt.clf(). sc.pp.neighbors(adata, metric='jaccard', random_state=2018) # compute neighbor graph with jaccard metric. sc.tl.louvain(adata,random_state=2018) # Then use the Louvain algorithm to identify clusters. sc.pl.tsne(adata, color='louvain', title='Louvain + jaccard metric'). plt.show(). plt.clf(). sc.pp.neighbors(adata,metric='euclidean', random_state=2018) # compute neighbor graph with euclidean distance metric. sc.tl.louvain(adata, random_state=2018) # Rerun cluster identification. sc.pl.tsne(adata, color='louvain', title='Louvain + default metric'). plt.show(). plt.clf(). ```. ![image](https://user-images.githubusercontent.com/12618847/41443622-ed8840ac-6ff2-11e8-9cd6-d853e017a8ab.png). Thanks! Let me know if you need another set of eyes in tracking this one down :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/177
https://github.com/scverse/scanpy/issues/177:1174,usability,user,user-images,1174,"Neighbors with `metric='jaccard'` breaks clustering; Hello! I found an odd bug where computing `sc.pp.neighbors()` with `metric='jaccard'` results in random cluster assignments coming out of `sc.tl.louvain()`. Running with the `euclidean` distance metric yields appropriate cluster assignments from `sc.tl.louvain()`. . Reproduce (adata is a bone marrow data set, with ""ground truth"" cell type annotations in `adata.obs['cell_type']`: . ```. sc.pl.tsne(adata, color='cell_type', title='Ground truth') # Color tsne plot by ground truth cell annotations. plt.show(). plt.clf(). sc.pp.neighbors(adata, metric='jaccard', random_state=2018) # compute neighbor graph with jaccard metric. sc.tl.louvain(adata,random_state=2018) # Then use the Louvain algorithm to identify clusters. sc.pl.tsne(adata, color='louvain', title='Louvain + jaccard metric'). plt.show(). plt.clf(). sc.pp.neighbors(adata,metric='euclidean', random_state=2018) # compute neighbor graph with euclidean distance metric. sc.tl.louvain(adata, random_state=2018) # Rerun cluster identification. sc.pl.tsne(adata, color='louvain', title='Louvain + default metric'). plt.show(). plt.clf(). ```. ![image](https://user-images.githubusercontent.com/12618847/41443622-ed8840ac-6ff2-11e8-9cd6-d853e017a8ab.png). Thanks! Let me know if you need another set of eyes in tracking this one down :)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/177
https://github.com/scverse/scanpy/issues/178:0,availability,cluster,cluster,0,"cluster heatmap; In scanpy, clustermap uses all the clusters and genes by default to plot the heatmap, however, it is more flexible if users can use a certain clusters and marker genes they are interested in. Can scanpy perform this function, or anyone who can add some extensions to scanpy to achieve this goal?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/178
https://github.com/scverse/scanpy/issues/178:28,availability,cluster,clustermap,28,"cluster heatmap; In scanpy, clustermap uses all the clusters and genes by default to plot the heatmap, however, it is more flexible if users can use a certain clusters and marker genes they are interested in. Can scanpy perform this function, or anyone who can add some extensions to scanpy to achieve this goal?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/178
https://github.com/scverse/scanpy/issues/178:52,availability,cluster,clusters,52,"cluster heatmap; In scanpy, clustermap uses all the clusters and genes by default to plot the heatmap, however, it is more flexible if users can use a certain clusters and marker genes they are interested in. Can scanpy perform this function, or anyone who can add some extensions to scanpy to achieve this goal?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/178
https://github.com/scverse/scanpy/issues/178:159,availability,cluster,clusters,159,"cluster heatmap; In scanpy, clustermap uses all the clusters and genes by default to plot the heatmap, however, it is more flexible if users can use a certain clusters and marker genes they are interested in. Can scanpy perform this function, or anyone who can add some extensions to scanpy to achieve this goal?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/178
https://github.com/scverse/scanpy/issues/178:0,deployability,cluster,cluster,0,"cluster heatmap; In scanpy, clustermap uses all the clusters and genes by default to plot the heatmap, however, it is more flexible if users can use a certain clusters and marker genes they are interested in. Can scanpy perform this function, or anyone who can add some extensions to scanpy to achieve this goal?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/178
https://github.com/scverse/scanpy/issues/178:28,deployability,cluster,clustermap,28,"cluster heatmap; In scanpy, clustermap uses all the clusters and genes by default to plot the heatmap, however, it is more flexible if users can use a certain clusters and marker genes they are interested in. Can scanpy perform this function, or anyone who can add some extensions to scanpy to achieve this goal?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/178
https://github.com/scverse/scanpy/issues/178:52,deployability,cluster,clusters,52,"cluster heatmap; In scanpy, clustermap uses all the clusters and genes by default to plot the heatmap, however, it is more flexible if users can use a certain clusters and marker genes they are interested in. Can scanpy perform this function, or anyone who can add some extensions to scanpy to achieve this goal?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/178
https://github.com/scverse/scanpy/issues/178:159,deployability,cluster,clusters,159,"cluster heatmap; In scanpy, clustermap uses all the clusters and genes by default to plot the heatmap, however, it is more flexible if users can use a certain clusters and marker genes they are interested in. Can scanpy perform this function, or anyone who can add some extensions to scanpy to achieve this goal?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/178
https://github.com/scverse/scanpy/issues/178:8,energy efficiency,heat,heatmap,8,"cluster heatmap; In scanpy, clustermap uses all the clusters and genes by default to plot the heatmap, however, it is more flexible if users can use a certain clusters and marker genes they are interested in. Can scanpy perform this function, or anyone who can add some extensions to scanpy to achieve this goal?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/178
https://github.com/scverse/scanpy/issues/178:94,energy efficiency,heat,heatmap,94,"cluster heatmap; In scanpy, clustermap uses all the clusters and genes by default to plot the heatmap, however, it is more flexible if users can use a certain clusters and marker genes they are interested in. Can scanpy perform this function, or anyone who can add some extensions to scanpy to achieve this goal?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/178
https://github.com/scverse/scanpy/issues/178:270,modifiability,extens,extensions,270,"cluster heatmap; In scanpy, clustermap uses all the clusters and genes by default to plot the heatmap, however, it is more flexible if users can use a certain clusters and marker genes they are interested in. Can scanpy perform this function, or anyone who can add some extensions to scanpy to achieve this goal?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/178
https://github.com/scverse/scanpy/issues/178:220,performance,perform,perform,220,"cluster heatmap; In scanpy, clustermap uses all the clusters and genes by default to plot the heatmap, however, it is more flexible if users can use a certain clusters and marker genes they are interested in. Can scanpy perform this function, or anyone who can add some extensions to scanpy to achieve this goal?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/178
https://github.com/scverse/scanpy/issues/178:135,usability,user,users,135,"cluster heatmap; In scanpy, clustermap uses all the clusters and genes by default to plot the heatmap, however, it is more flexible if users can use a certain clusters and marker genes they are interested in. Can scanpy perform this function, or anyone who can add some extensions to scanpy to achieve this goal?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/178
https://github.com/scverse/scanpy/issues/178:220,usability,perform,perform,220,"cluster heatmap; In scanpy, clustermap uses all the clusters and genes by default to plot the heatmap, however, it is more flexible if users can use a certain clusters and marker genes they are interested in. Can scanpy perform this function, or anyone who can add some extensions to scanpy to achieve this goal?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/178
https://github.com/scverse/scanpy/issues/181:0,availability,cluster,cluster,0,"cluster average expression; Dear, . Can you add a function to calculate the average expression of each gene in each cluster ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/181
https://github.com/scverse/scanpy/issues/181:116,availability,cluster,cluster,116,"cluster average expression; Dear, . Can you add a function to calculate the average expression of each gene in each cluster ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/181
https://github.com/scverse/scanpy/issues/181:0,deployability,cluster,cluster,0,"cluster average expression; Dear, . Can you add a function to calculate the average expression of each gene in each cluster ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/181
https://github.com/scverse/scanpy/issues/181:116,deployability,cluster,cluster,116,"cluster average expression; Dear, . Can you add a function to calculate the average expression of each gene in each cluster ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/181
https://github.com/scverse/scanpy/issues/182:233,availability,monitor,monitor,233,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:639,availability,fault,fault,639,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:233,deployability,monitor,monitor,233,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:389,deployability,log,log,389,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:893,deployability,Version,Versions,893,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:906,deployability,Resourc,Resources,906,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:1988,deployability,api,api,1988,"g telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. adata = AnnData(random(5000, 2000, density=0.6, format='csr')). adata.obs['percent_mito'] = np.random.rand(adata.X.shape[0]). adata.obs['n_counts'] = adata.X.sum(axis=1). multi = sc.pp.regress_out(adata, keys=['n_counts', 'percent_mito'], n_jobs=8, copy=True). ```. I've gotten the same results on master and the current releases.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:2382,deployability,releas,releases,2382,"g telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. adata = AnnData(random(5000, 2000, density=0.6, format='csr')). adata.obs['percent_mito'] = np.random.rand(adata.X.shape[0]). adata.obs['n_counts'] = adata.X.sum(axis=1). multi = sc.pp.regress_out(adata, keys=['n_counts', 'percent_mito'], n_jobs=8, copy=True). ```. I've gotten the same results on master and the current releases.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:149,energy efficiency,cpu,cpu,149,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:233,energy efficiency,monitor,monitor,233,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:260,energy efficiency,cpu,cpu,260,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:639,energy efficiency,fault,fault,639,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:906,energy efficiency,Resourc,Resources,906,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:2374,energy efficiency,current,current,2374,"g telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. adata = AnnData(random(5000, 2000, density=0.6, format='csr')). adata.obs['percent_mito'] = np.random.rand(adata.X.shape[0]). adata.obs['n_counts'] = adata.X.sum(axis=1). multi = sc.pp.regress_out(adata, keys=['n_counts', 'percent_mito'], n_jobs=8, copy=True). ```. I've gotten the same results on master and the current releases.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:320,integrability,rout,routinely,320,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:438,integrability,queue,queue,438,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:893,integrability,Version,Versions,893,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:1093,integrability,queue,queue,1093,"egression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. adata = AnnData(random(5000, 2000, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:1988,integrability,api,api,1988,"g telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. adata = AnnData(random(5000, 2000, density=0.6, format='csr')). adata.obs['percent_mito'] = np.random.rand(adata.X.shape[0]). adata.obs['n_counts'] = adata.X.sum(axis=1). multi = sc.pp.regress_out(adata, keys=['n_counts', 'percent_mito'], n_jobs=8, copy=True). ```. I've gotten the same results on master and the current releases.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:963,interoperability,Specif,Specific,963,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:1988,interoperability,api,api,1988,"g telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. adata = AnnData(random(5000, 2000, density=0.6, format='csr')). adata.obs['percent_mito'] = np.random.rand(adata.X.shape[0]). adata.obs['n_counts'] = adata.X.sum(axis=1). multi = sc.pp.regress_out(adata, keys=['n_counts', 'percent_mito'], n_jobs=8, copy=True). ```. I've gotten the same results on master and the current releases.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:2109,interoperability,format,format,2109,"g telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. adata = AnnData(random(5000, 2000, density=0.6, format='csr')). adata.obs['percent_mito'] = np.random.rand(adata.X.shape[0]). adata.obs['n_counts'] = adata.X.sum(axis=1). multi = sc.pp.regress_out(adata, keys=['n_counts', 'percent_mito'], n_jobs=8, copy=True). ```. I've gotten the same results on master and the current releases.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:893,modifiability,Version,Versions,893,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:149,performance,cpu,cpu,149,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:260,performance,cpu,cpu,260,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:286,performance,lock,locking,286,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:438,performance,queue,queue,438,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:639,performance,fault,fault,639,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:906,performance,Resourc,Resources,906,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:927,performance,Content,Contents,927,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:990,performance,multi-thread,multi-threaded,990,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:1093,performance,queue,queue,1093,"egression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. from anndata import AnnData. from scipy.sparse import random. adata = AnnData(random(5000, 2000, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:233,reliability,monitor,monitor,233,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:639,reliability,fault,fault,639,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:29,safety,test,test,29,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:106,safety,test,test,106,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:233,safety,monitor,monitor,233,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:389,safety,log,log,389,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:468,safety,Except,Exception,468,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:510,safety,Except,Exception,510,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:571,safety,Except,Exception,571,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:639,safety,fault,fault,639,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:906,safety,Resourc,Resources,906,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:286,security,lock,locking,286,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:389,security,log,log,389,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:618,security,Sign,Signal,618,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:680,security,SIGN,SIGNAL,680,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:18,testability,regress,regression,18,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:29,testability,test,test,29,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:95,testability,regress,regression,95,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:106,testability,test,test,106,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:233,testability,monitor,monitor,233,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:389,testability,log,log,389,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/issues/182:906,testability,Resourc,Resources,906,"Can't get ordinal regression test with multiple processes to run; Hi,. I can't get the ordinal regression test case to run on my MacBook. The single cpu case works fine, but if I ask for multiple processes, they launch, but activity monitor has them all at 0% cpu, with the main thread locking while waiting. Sometimes (routinely if I switch out `map_async` with `map`) I will get a crash log telling me:. ```. Crashed Thread: 0 Dispatch queue: com.apple.main-thread. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 0000000102a16000-0000000102a18000 [ 8K] r-x/rwx SM=COW j [/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python]. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. Thread 0 Crashed:: Dispatch queue: com.apple.main-thread. 0 libdispatch.dylib 	0x00007fff572df8e1 _dispatch_root_queue_push + 108. 1 libBLAS.dylib 	0x00007fff2bfd0c9a rowMajorTranspose + 546. 2 libBLAS.dylib 	0x00007fff2bfd0a65 cblas_dgemv + 757. 3 multiarray.cpython-36m-darwin.so	0x00000001035c4f86 gemv + 182. 4 multiarray.cpython-36m-darwin.so	0x00000001035c4527 cblas_matrixproduct + 2807. 5 multiarray.cpython-36m-darwin.so	0x000000010358ab27 PyArray_MatrixProduct2 + 215. 6 multiarray.cpython-36m-darwin.so	0x000000010358626c array_dot + 188. 7 org.python.python 	0x0000000102a5d12e _PyCFunction_FastCallDict + 463. 8 org.python.python 	0x0000000102ac30e6 call_function + 491. 9 org.python.python 	0x0000000102abb621 _PyEval_EvalFrameDefault + 1659. 10 org.python.python 	0x0000000102ac3866 _PyEval_EvalCodeWithName + 1747. ```. Here's what I was running to cause that:. ```python. import numpy as np. import scanpy.api as sc. f",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/182
https://github.com/scverse/scanpy/pull/183:33,modifiability,extens,extensions,33,"Fix sc.write() for files without extensions; `sc.write('filewithoutextension', adata)` is broken right now. I noticed it via a related report in DCA (https://github.com/theislab/dca/issues/13). Filenames without extension should fallback to final else and return False, but now IndexError exception is raised since `ext[-1]` is invalid for empty list.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/183
https://github.com/scverse/scanpy/pull/183:212,modifiability,extens,extension,212,"Fix sc.write() for files without extensions; `sc.write('filewithoutextension', adata)` is broken right now. I noticed it via a related report in DCA (https://github.com/theislab/dca/issues/13). Filenames without extension should fallback to final else and return False, but now IndexError exception is raised since `ext[-1]` is invalid for empty list.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/183
https://github.com/scverse/scanpy/pull/183:289,safety,except,exception,289,"Fix sc.write() for files without extensions; `sc.write('filewithoutextension', adata)` is broken right now. I noticed it via a related report in DCA (https://github.com/theislab/dca/issues/13). Filenames without extension should fallback to final else and return False, but now IndexError exception is raised since `ext[-1]` is invalid for empty list.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/183
https://github.com/scverse/scanpy/pull/184:31,energy efficiency,heat,heatmap,31,fixed position of labels in pl.heatmap; In some cases the ordering of the labels of the `groupby` categories was not correct. This is fixed now. Also I did some small layout changes to increase the colorbars width.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/184
https://github.com/scverse/scanpy/issues/185:990,availability,State,State,990,"Gradient color ; Hi,. I really like using scanpy for our large scale single cell aging project. I am uploading several libraries from different age mice (8 time points) and concatinate them together (see example cmd I used below). I would like to control the color display so that I have a gradient color that changes with age and visualise in umap plot for example sc.pl.umap(adata, color= ['Age','louvain']). How could I do that? Thank you very for your help and for this wonderful package. path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/13_mouse_IL33_8w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_13_mouse_IL33_8w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_13_mouse_IL33_8w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_13_mouse_IL33_8w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_13_mouse_IL33_8w_X.obs['Tissue'] = 'X'. adata_13_mouse_IL33_8w_X.obs['Age'] = '8Weeks'. adata_13_mouse_IL33_8w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_13_mouse_IL33_8w_X, min_genes=250). path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/1_mouse_IL33_16w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_1_mouse_IL33_16w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_1_mouse_IL33_16w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_1_mouse_IL33_16w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_1_mouse_IL33_16w_X.obs['Tissue'] = 'X'. adata_1_mouse_IL33_16w_X.obs['Age'] = '16Weeks'. adata_1_mouse_IL33_16w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_1_mouse_IL33_16w_X, min_genes=250). etc............ adata = adata_13_mouse_IL33_8w_X.concatenate([adata_1_mouse_IL33_16w_X, etc ....).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/185
https://github.com/scverse/scanpy/issues/185:1577,availability,State,State,1577,"Gradient color ; Hi,. I really like using scanpy for our large scale single cell aging project. I am uploading several libraries from different age mice (8 time points) and concatinate them together (see example cmd I used below). I would like to control the color display so that I have a gradient color that changes with age and visualise in umap plot for example sc.pl.umap(adata, color= ['Age','louvain']). How could I do that? Thank you very for your help and for this wonderful package. path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/13_mouse_IL33_8w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_13_mouse_IL33_8w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_13_mouse_IL33_8w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_13_mouse_IL33_8w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_13_mouse_IL33_8w_X.obs['Tissue'] = 'X'. adata_13_mouse_IL33_8w_X.obs['Age'] = '8Weeks'. adata_13_mouse_IL33_8w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_13_mouse_IL33_8w_X, min_genes=250). path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/1_mouse_IL33_16w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_1_mouse_IL33_16w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_1_mouse_IL33_16w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_1_mouse_IL33_16w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_1_mouse_IL33_16w_X.obs['Tissue'] = 'X'. adata_1_mouse_IL33_16w_X.obs['Age'] = '16Weeks'. adata_1_mouse_IL33_16w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_1_mouse_IL33_16w_X, min_genes=250). etc............ adata = adata_13_mouse_IL33_8w_X.concatenate([adata_1_mouse_IL33_16w_X, etc ....).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/185
https://github.com/scverse/scanpy/issues/185:63,deployability,scale,scale,63,"Gradient color ; Hi,. I really like using scanpy for our large scale single cell aging project. I am uploading several libraries from different age mice (8 time points) and concatinate them together (see example cmd I used below). I would like to control the color display so that I have a gradient color that changes with age and visualise in umap plot for example sc.pl.umap(adata, color= ['Age','louvain']). How could I do that? Thank you very for your help and for this wonderful package. path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/13_mouse_IL33_8w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_13_mouse_IL33_8w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_13_mouse_IL33_8w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_13_mouse_IL33_8w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_13_mouse_IL33_8w_X.obs['Tissue'] = 'X'. adata_13_mouse_IL33_8w_X.obs['Age'] = '8Weeks'. adata_13_mouse_IL33_8w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_13_mouse_IL33_8w_X, min_genes=250). path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/1_mouse_IL33_16w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_1_mouse_IL33_16w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_1_mouse_IL33_16w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_1_mouse_IL33_16w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_1_mouse_IL33_16w_X.obs['Tissue'] = 'X'. adata_1_mouse_IL33_16w_X.obs['Age'] = '16Weeks'. adata_1_mouse_IL33_16w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_1_mouse_IL33_16w_X, min_genes=250). etc............ adata = adata_13_mouse_IL33_8w_X.concatenate([adata_1_mouse_IL33_16w_X, etc ....).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/185
https://github.com/scverse/scanpy/issues/185:63,energy efficiency,scale,scale,63,"Gradient color ; Hi,. I really like using scanpy for our large scale single cell aging project. I am uploading several libraries from different age mice (8 time points) and concatinate them together (see example cmd I used below). I would like to control the color display so that I have a gradient color that changes with age and visualise in umap plot for example sc.pl.umap(adata, color= ['Age','louvain']). How could I do that? Thank you very for your help and for this wonderful package. path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/13_mouse_IL33_8w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_13_mouse_IL33_8w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_13_mouse_IL33_8w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_13_mouse_IL33_8w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_13_mouse_IL33_8w_X.obs['Tissue'] = 'X'. adata_13_mouse_IL33_8w_X.obs['Age'] = '8Weeks'. adata_13_mouse_IL33_8w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_13_mouse_IL33_8w_X, min_genes=250). path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/1_mouse_IL33_16w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_1_mouse_IL33_16w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_1_mouse_IL33_16w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_1_mouse_IL33_16w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_1_mouse_IL33_16w_X.obs['Tissue'] = 'X'. adata_1_mouse_IL33_16w_X.obs['Age'] = '16Weeks'. adata_1_mouse_IL33_16w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_1_mouse_IL33_16w_X, min_genes=250). etc............ adata = adata_13_mouse_IL33_8w_X.concatenate([adata_1_mouse_IL33_16w_X, etc ....).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/185
https://github.com/scverse/scanpy/issues/185:990,integrability,State,State,990,"Gradient color ; Hi,. I really like using scanpy for our large scale single cell aging project. I am uploading several libraries from different age mice (8 time points) and concatinate them together (see example cmd I used below). I would like to control the color display so that I have a gradient color that changes with age and visualise in umap plot for example sc.pl.umap(adata, color= ['Age','louvain']). How could I do that? Thank you very for your help and for this wonderful package. path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/13_mouse_IL33_8w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_13_mouse_IL33_8w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_13_mouse_IL33_8w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_13_mouse_IL33_8w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_13_mouse_IL33_8w_X.obs['Tissue'] = 'X'. adata_13_mouse_IL33_8w_X.obs['Age'] = '8Weeks'. adata_13_mouse_IL33_8w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_13_mouse_IL33_8w_X, min_genes=250). path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/1_mouse_IL33_16w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_1_mouse_IL33_16w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_1_mouse_IL33_16w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_1_mouse_IL33_16w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_1_mouse_IL33_16w_X.obs['Tissue'] = 'X'. adata_1_mouse_IL33_16w_X.obs['Age'] = '16Weeks'. adata_1_mouse_IL33_16w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_1_mouse_IL33_16w_X, min_genes=250). etc............ adata = adata_13_mouse_IL33_8w_X.concatenate([adata_1_mouse_IL33_16w_X, etc ....).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/185
https://github.com/scverse/scanpy/issues/185:1577,integrability,State,State,1577,"Gradient color ; Hi,. I really like using scanpy for our large scale single cell aging project. I am uploading several libraries from different age mice (8 time points) and concatinate them together (see example cmd I used below). I would like to control the color display so that I have a gradient color that changes with age and visualise in umap plot for example sc.pl.umap(adata, color= ['Age','louvain']). How could I do that? Thank you very for your help and for this wonderful package. path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/13_mouse_IL33_8w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_13_mouse_IL33_8w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_13_mouse_IL33_8w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_13_mouse_IL33_8w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_13_mouse_IL33_8w_X.obs['Tissue'] = 'X'. adata_13_mouse_IL33_8w_X.obs['Age'] = '8Weeks'. adata_13_mouse_IL33_8w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_13_mouse_IL33_8w_X, min_genes=250). path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/1_mouse_IL33_16w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_1_mouse_IL33_16w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_1_mouse_IL33_16w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_1_mouse_IL33_16w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_1_mouse_IL33_16w_X.obs['Tissue'] = 'X'. adata_1_mouse_IL33_16w_X.obs['Age'] = '16Weeks'. adata_1_mouse_IL33_16w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_1_mouse_IL33_16w_X, min_genes=250). etc............ adata = adata_13_mouse_IL33_8w_X.concatenate([adata_1_mouse_IL33_16w_X, etc ....).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/185
https://github.com/scverse/scanpy/issues/185:63,modifiability,scal,scale,63,"Gradient color ; Hi,. I really like using scanpy for our large scale single cell aging project. I am uploading several libraries from different age mice (8 time points) and concatinate them together (see example cmd I used below). I would like to control the color display so that I have a gradient color that changes with age and visualise in umap plot for example sc.pl.umap(adata, color= ['Age','louvain']). How could I do that? Thank you very for your help and for this wonderful package. path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/13_mouse_IL33_8w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_13_mouse_IL33_8w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_13_mouse_IL33_8w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_13_mouse_IL33_8w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_13_mouse_IL33_8w_X.obs['Tissue'] = 'X'. adata_13_mouse_IL33_8w_X.obs['Age'] = '8Weeks'. adata_13_mouse_IL33_8w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_13_mouse_IL33_8w_X, min_genes=250). path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/1_mouse_IL33_16w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_1_mouse_IL33_16w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_1_mouse_IL33_16w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_1_mouse_IL33_16w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_1_mouse_IL33_16w_X.obs['Tissue'] = 'X'. adata_1_mouse_IL33_16w_X.obs['Age'] = '16Weeks'. adata_1_mouse_IL33_16w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_1_mouse_IL33_16w_X, min_genes=250). etc............ adata = adata_13_mouse_IL33_8w_X.concatenate([adata_1_mouse_IL33_16w_X, etc ....).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/185
https://github.com/scverse/scanpy/issues/185:484,modifiability,pac,package,484,"Gradient color ; Hi,. I really like using scanpy for our large scale single cell aging project. I am uploading several libraries from different age mice (8 time points) and concatinate them together (see example cmd I used below). I would like to control the color display so that I have a gradient color that changes with age and visualise in umap plot for example sc.pl.umap(adata, color= ['Age','louvain']). How could I do that? Thank you very for your help and for this wonderful package. path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/13_mouse_IL33_8w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_13_mouse_IL33_8w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_13_mouse_IL33_8w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_13_mouse_IL33_8w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_13_mouse_IL33_8w_X.obs['Tissue'] = 'X'. adata_13_mouse_IL33_8w_X.obs['Age'] = '8Weeks'. adata_13_mouse_IL33_8w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_13_mouse_IL33_8w_X, min_genes=250). path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/1_mouse_IL33_16w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_1_mouse_IL33_16w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_1_mouse_IL33_16w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_1_mouse_IL33_16w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_1_mouse_IL33_16w_X.obs['Tissue'] = 'X'. adata_1_mouse_IL33_16w_X.obs['Age'] = '16Weeks'. adata_1_mouse_IL33_16w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_1_mouse_IL33_16w_X, min_genes=250). etc............ adata = adata_13_mouse_IL33_8w_X.concatenate([adata_1_mouse_IL33_16w_X, etc ....).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/185
https://github.com/scverse/scanpy/issues/185:63,performance,scale,scale,63,"Gradient color ; Hi,. I really like using scanpy for our large scale single cell aging project. I am uploading several libraries from different age mice (8 time points) and concatinate them together (see example cmd I used below). I would like to control the color display so that I have a gradient color that changes with age and visualise in umap plot for example sc.pl.umap(adata, color= ['Age','louvain']). How could I do that? Thank you very for your help and for this wonderful package. path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/13_mouse_IL33_8w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_13_mouse_IL33_8w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_13_mouse_IL33_8w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_13_mouse_IL33_8w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_13_mouse_IL33_8w_X.obs['Tissue'] = 'X'. adata_13_mouse_IL33_8w_X.obs['Age'] = '8Weeks'. adata_13_mouse_IL33_8w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_13_mouse_IL33_8w_X, min_genes=250). path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/1_mouse_IL33_16w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_1_mouse_IL33_16w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_1_mouse_IL33_16w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_1_mouse_IL33_16w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_1_mouse_IL33_16w_X.obs['Tissue'] = 'X'. adata_1_mouse_IL33_16w_X.obs['Age'] = '16Weeks'. adata_1_mouse_IL33_16w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_1_mouse_IL33_16w_X, min_genes=250). etc............ adata = adata_13_mouse_IL33_8w_X.concatenate([adata_1_mouse_IL33_16w_X, etc ....).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/185
https://github.com/scverse/scanpy/issues/185:156,performance,time,time,156,"Gradient color ; Hi,. I really like using scanpy for our large scale single cell aging project. I am uploading several libraries from different age mice (8 time points) and concatinate them together (see example cmd I used below). I would like to control the color display so that I have a gradient color that changes with age and visualise in umap plot for example sc.pl.umap(adata, color= ['Age','louvain']). How could I do that? Thank you very for your help and for this wonderful package. path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/13_mouse_IL33_8w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_13_mouse_IL33_8w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_13_mouse_IL33_8w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_13_mouse_IL33_8w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_13_mouse_IL33_8w_X.obs['Tissue'] = 'X'. adata_13_mouse_IL33_8w_X.obs['Age'] = '8Weeks'. adata_13_mouse_IL33_8w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_13_mouse_IL33_8w_X, min_genes=250). path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/1_mouse_IL33_16w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_1_mouse_IL33_16w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_1_mouse_IL33_16w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_1_mouse_IL33_16w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_1_mouse_IL33_16w_X.obs['Tissue'] = 'X'. adata_1_mouse_IL33_16w_X.obs['Age'] = '16Weeks'. adata_1_mouse_IL33_16w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_1_mouse_IL33_16w_X, min_genes=250). etc............ adata = adata_13_mouse_IL33_8w_X.concatenate([adata_1_mouse_IL33_16w_X, etc ....).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/185
https://github.com/scverse/scanpy/issues/185:666,performance,cach,cache,666,"Gradient color ; Hi,. I really like using scanpy for our large scale single cell aging project. I am uploading several libraries from different age mice (8 time points) and concatinate them together (see example cmd I used below). I would like to control the color display so that I have a gradient color that changes with age and visualise in umap plot for example sc.pl.umap(adata, color= ['Age','louvain']). How could I do that? Thank you very for your help and for this wonderful package. path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/13_mouse_IL33_8w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_13_mouse_IL33_8w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_13_mouse_IL33_8w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_13_mouse_IL33_8w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_13_mouse_IL33_8w_X.obs['Tissue'] = 'X'. adata_13_mouse_IL33_8w_X.obs['Age'] = '8Weeks'. adata_13_mouse_IL33_8w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_13_mouse_IL33_8w_X, min_genes=250). path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/1_mouse_IL33_16w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_1_mouse_IL33_16w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_1_mouse_IL33_16w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_1_mouse_IL33_16w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_1_mouse_IL33_16w_X.obs['Tissue'] = 'X'. adata_1_mouse_IL33_16w_X.obs['Age'] = '16Weeks'. adata_1_mouse_IL33_16w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_1_mouse_IL33_16w_X, min_genes=250). etc............ adata = adata_13_mouse_IL33_8w_X.concatenate([adata_1_mouse_IL33_16w_X, etc ....).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/185
https://github.com/scverse/scanpy/issues/185:1252,performance,cach,cache,1252,"Gradient color ; Hi,. I really like using scanpy for our large scale single cell aging project. I am uploading several libraries from different age mice (8 time points) and concatinate them together (see example cmd I used below). I would like to control the color display so that I have a gradient color that changes with age and visualise in umap plot for example sc.pl.umap(adata, color= ['Age','louvain']). How could I do that? Thank you very for your help and for this wonderful package. path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/13_mouse_IL33_8w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_13_mouse_IL33_8w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_13_mouse_IL33_8w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_13_mouse_IL33_8w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_13_mouse_IL33_8w_X.obs['Tissue'] = 'X'. adata_13_mouse_IL33_8w_X.obs['Age'] = '8Weeks'. adata_13_mouse_IL33_8w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_13_mouse_IL33_8w_X, min_genes=250). path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/1_mouse_IL33_16w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_1_mouse_IL33_16w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_1_mouse_IL33_16w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_1_mouse_IL33_16w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_1_mouse_IL33_16w_X.obs['Tissue'] = 'X'. adata_1_mouse_IL33_16w_X.obs['Age'] = '16Weeks'. adata_1_mouse_IL33_16w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_1_mouse_IL33_16w_X, min_genes=250). etc............ adata = adata_13_mouse_IL33_8w_X.concatenate([adata_1_mouse_IL33_16w_X, etc ....).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/185
https://github.com/scverse/scanpy/issues/185:247,security,control,control,247,"Gradient color ; Hi,. I really like using scanpy for our large scale single cell aging project. I am uploading several libraries from different age mice (8 time points) and concatinate them together (see example cmd I used below). I would like to control the color display so that I have a gradient color that changes with age and visualise in umap plot for example sc.pl.umap(adata, color= ['Age','louvain']). How could I do that? Thank you very for your help and for this wonderful package. path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/13_mouse_IL33_8w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_13_mouse_IL33_8w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_13_mouse_IL33_8w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_13_mouse_IL33_8w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_13_mouse_IL33_8w_X.obs['Tissue'] = 'X'. adata_13_mouse_IL33_8w_X.obs['Age'] = '8Weeks'. adata_13_mouse_IL33_8w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_13_mouse_IL33_8w_X, min_genes=250). path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/1_mouse_IL33_16w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_1_mouse_IL33_16w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_1_mouse_IL33_16w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_1_mouse_IL33_16w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_1_mouse_IL33_16w_X.obs['Tissue'] = 'X'. adata_1_mouse_IL33_16w_X.obs['Age'] = '16Weeks'. adata_1_mouse_IL33_16w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_1_mouse_IL33_16w_X, min_genes=250). etc............ adata = adata_13_mouse_IL33_8w_X.concatenate([adata_1_mouse_IL33_16w_X, etc ....).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/185
https://github.com/scverse/scanpy/issues/185:247,testability,control,control,247,"Gradient color ; Hi,. I really like using scanpy for our large scale single cell aging project. I am uploading several libraries from different age mice (8 time points) and concatinate them together (see example cmd I used below). I would like to control the color display so that I have a gradient color that changes with age and visualise in umap plot for example sc.pl.umap(adata, color= ['Age','louvain']). How could I do that? Thank you very for your help and for this wonderful package. path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/13_mouse_IL33_8w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_13_mouse_IL33_8w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_13_mouse_IL33_8w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_13_mouse_IL33_8w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_13_mouse_IL33_8w_X.obs['Tissue'] = 'X'. adata_13_mouse_IL33_8w_X.obs['Age'] = '8Weeks'. adata_13_mouse_IL33_8w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_13_mouse_IL33_8w_X, min_genes=250). path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/1_mouse_IL33_16w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_1_mouse_IL33_16w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_1_mouse_IL33_16w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_1_mouse_IL33_16w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_1_mouse_IL33_16w_X.obs['Tissue'] = 'X'. adata_1_mouse_IL33_16w_X.obs['Age'] = '16Weeks'. adata_1_mouse_IL33_16w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_1_mouse_IL33_16w_X, min_genes=250). etc............ adata = adata_13_mouse_IL33_8w_X.concatenate([adata_1_mouse_IL33_16w_X, etc ....).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/185
https://github.com/scverse/scanpy/issues/185:331,usability,visual,visualise,331,"Gradient color ; Hi,. I really like using scanpy for our large scale single cell aging project. I am uploading several libraries from different age mice (8 time points) and concatinate them together (see example cmd I used below). I would like to control the color display so that I have a gradient color that changes with age and visualise in umap plot for example sc.pl.umap(adata, color= ['Age','louvain']). How could I do that? Thank you very for your help and for this wonderful package. path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/13_mouse_IL33_8w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_13_mouse_IL33_8w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_13_mouse_IL33_8w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_13_mouse_IL33_8w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_13_mouse_IL33_8w_X.obs['Tissue'] = 'X'. adata_13_mouse_IL33_8w_X.obs['Age'] = '8Weeks'. adata_13_mouse_IL33_8w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_13_mouse_IL33_8w_X, min_genes=250). path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/1_mouse_IL33_16w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_1_mouse_IL33_16w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_1_mouse_IL33_16w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_1_mouse_IL33_16w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_1_mouse_IL33_16w_X.obs['Tissue'] = 'X'. adata_1_mouse_IL33_16w_X.obs['Age'] = '16Weeks'. adata_1_mouse_IL33_16w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_1_mouse_IL33_16w_X, min_genes=250). etc............ adata = adata_13_mouse_IL33_8w_X.concatenate([adata_1_mouse_IL33_16w_X, etc ....).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/185
https://github.com/scverse/scanpy/issues/185:456,usability,help,help,456,"Gradient color ; Hi,. I really like using scanpy for our large scale single cell aging project. I am uploading several libraries from different age mice (8 time points) and concatinate them together (see example cmd I used below). I would like to control the color display so that I have a gradient color that changes with age and visualise in umap plot for example sc.pl.umap(adata, color= ['Age','louvain']). How could I do that? Thank you very for your help and for this wonderful package. path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/13_mouse_IL33_8w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_13_mouse_IL33_8w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_13_mouse_IL33_8w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_13_mouse_IL33_8w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_13_mouse_IL33_8w_X.obs['Tissue'] = 'X'. adata_13_mouse_IL33_8w_X.obs['Age'] = '8Weeks'. adata_13_mouse_IL33_8w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_13_mouse_IL33_8w_X, min_genes=250). path = '/home/10XG6_ILC2_thirdrun/cellranger_count_results/1_mouse_IL33_16w_X/outs/filtered_gene_bc_matrices/mm10/'. adata_1_mouse_IL33_16w_X = sc.read(path + 'matrix.mtx', cache=True).transpose(). adata_1_mouse_IL33_16w_X.var_names = np.genfromtxt(path + 'genes.tsv', dtype=str)[:, 1]. adata_1_mouse_IL33_16w_X.obs_names = np.genfromtxt(path + 'barcodes.tsv', dtype=str). adata_1_mouse_IL33_16w_X.obs['Tissue'] = 'X'. adata_1_mouse_IL33_16w_X.obs['Age'] = '16Weeks'. adata_1_mouse_IL33_16w_X.obs['State'] = 'IL33_activated'. sc.pp.filter_cells(adata_1_mouse_IL33_16w_X, min_genes=250). etc............ adata = adata_13_mouse_IL33_8w_X.concatenate([adata_1_mouse_IL33_16w_X, etc ....).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/185
https://github.com/scverse/scanpy/pull/186:8,deployability,integr,integration,8,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:31,deployability,integr,integration,31,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:281,deployability,integr,integration,281,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:306,deployability,API,API,306,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:330,deployability,API,API,330,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:377,deployability,integr,integration,377,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:8,integrability,integr,integration,8,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:31,integrability,integr,integration,31,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:281,integrability,integr,integration,281,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:306,integrability,API,API,306,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:330,integrability,API,API,330,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:377,integrability,integr,integration,377,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:8,interoperability,integr,integration,8,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:31,interoperability,integr,integration,31,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:281,interoperability,integr,integration,281,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:306,interoperability,API,API,306,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:330,interoperability,API,API,330,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:377,interoperability,integr,integration,377,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:8,modifiability,integr,integration,8,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:31,modifiability,integr,integration,31,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:281,modifiability,integr,integration,281,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:377,modifiability,integr,integration,377,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:8,reliability,integr,integration,8,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:31,reliability,integr,integration,31,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:281,reliability,integr,integration,281,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:377,reliability,integr,integration,377,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:8,security,integr,integration,8,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:31,security,integr,integration,31,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:281,security,integr,integration,281,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:348,security,expos,exposed,348,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:377,security,integr,integration,377,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:8,testability,integr,integration,8,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:31,testability,integr,integration,31,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:281,testability,integr,integration,281,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:377,testability,integr,integration,377,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/pull/186:360,usability,usab,usable,360,"Add DCA integration; Added DCA integration, as discussed in #142 . For denoising, uses can call:. `sc.pp.dca(adata)`. which replaces adata.X inplace. For latent representations:. `sc.pp.dca(adata, mode='latent')`. can be called, which adds 'X_dca' to adata.obsm. Fixes #142 . This integration uses new DCA API (>= 0.2.1). All DCA API arguments are exposed and usable in scanpy integration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/186
https://github.com/scverse/scanpy/issues/187:246,availability,state,state,246,"Adding MAGIC to Scanpy; Hi,. We spoke a while ago about adding [PHATE](https://github.com/KrishnaswamyLab/PHATE) and eventually [MAGIC](https://github.com/KrishnaswamyLab/MAGIC) to Scanpy. MAGIC has just been submitted to CRAN and is in a stable state. . How should a tool such as MAGIC interact with Scanpy? Do you currently have any imputation methods included in the package that I can use to model the API? Thanks,. Scott",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/187
https://github.com/scverse/scanpy/issues/187:406,deployability,API,API,406,"Adding MAGIC to Scanpy; Hi,. We spoke a while ago about adding [PHATE](https://github.com/KrishnaswamyLab/PHATE) and eventually [MAGIC](https://github.com/KrishnaswamyLab/MAGIC) to Scanpy. MAGIC has just been submitted to CRAN and is in a stable state. . How should a tool such as MAGIC interact with Scanpy? Do you currently have any imputation methods included in the package that I can use to model the API? Thanks,. Scott",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/187
https://github.com/scverse/scanpy/issues/187:316,energy efficiency,current,currently,316,"Adding MAGIC to Scanpy; Hi,. We spoke a while ago about adding [PHATE](https://github.com/KrishnaswamyLab/PHATE) and eventually [MAGIC](https://github.com/KrishnaswamyLab/MAGIC) to Scanpy. MAGIC has just been submitted to CRAN and is in a stable state. . How should a tool such as MAGIC interact with Scanpy? Do you currently have any imputation methods included in the package that I can use to model the API? Thanks,. Scott",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/187
https://github.com/scverse/scanpy/issues/187:396,energy efficiency,model,model,396,"Adding MAGIC to Scanpy; Hi,. We spoke a while ago about adding [PHATE](https://github.com/KrishnaswamyLab/PHATE) and eventually [MAGIC](https://github.com/KrishnaswamyLab/MAGIC) to Scanpy. MAGIC has just been submitted to CRAN and is in a stable state. . How should a tool such as MAGIC interact with Scanpy? Do you currently have any imputation methods included in the package that I can use to model the API? Thanks,. Scott",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/187
https://github.com/scverse/scanpy/issues/187:117,integrability,event,eventually,117,"Adding MAGIC to Scanpy; Hi,. We spoke a while ago about adding [PHATE](https://github.com/KrishnaswamyLab/PHATE) and eventually [MAGIC](https://github.com/KrishnaswamyLab/MAGIC) to Scanpy. MAGIC has just been submitted to CRAN and is in a stable state. . How should a tool such as MAGIC interact with Scanpy? Do you currently have any imputation methods included in the package that I can use to model the API? Thanks,. Scott",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/187
https://github.com/scverse/scanpy/issues/187:209,integrability,sub,submitted,209,"Adding MAGIC to Scanpy; Hi,. We spoke a while ago about adding [PHATE](https://github.com/KrishnaswamyLab/PHATE) and eventually [MAGIC](https://github.com/KrishnaswamyLab/MAGIC) to Scanpy. MAGIC has just been submitted to CRAN and is in a stable state. . How should a tool such as MAGIC interact with Scanpy? Do you currently have any imputation methods included in the package that I can use to model the API? Thanks,. Scott",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/187
https://github.com/scverse/scanpy/issues/187:246,integrability,state,state,246,"Adding MAGIC to Scanpy; Hi,. We spoke a while ago about adding [PHATE](https://github.com/KrishnaswamyLab/PHATE) and eventually [MAGIC](https://github.com/KrishnaswamyLab/MAGIC) to Scanpy. MAGIC has just been submitted to CRAN and is in a stable state. . How should a tool such as MAGIC interact with Scanpy? Do you currently have any imputation methods included in the package that I can use to model the API? Thanks,. Scott",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/187
https://github.com/scverse/scanpy/issues/187:406,integrability,API,API,406,"Adding MAGIC to Scanpy; Hi,. We spoke a while ago about adding [PHATE](https://github.com/KrishnaswamyLab/PHATE) and eventually [MAGIC](https://github.com/KrishnaswamyLab/MAGIC) to Scanpy. MAGIC has just been submitted to CRAN and is in a stable state. . How should a tool such as MAGIC interact with Scanpy? Do you currently have any imputation methods included in the package that I can use to model the API? Thanks,. Scott",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/187
https://github.com/scverse/scanpy/issues/187:406,interoperability,API,API,406,"Adding MAGIC to Scanpy; Hi,. We spoke a while ago about adding [PHATE](https://github.com/KrishnaswamyLab/PHATE) and eventually [MAGIC](https://github.com/KrishnaswamyLab/MAGIC) to Scanpy. MAGIC has just been submitted to CRAN and is in a stable state. . How should a tool such as MAGIC interact with Scanpy? Do you currently have any imputation methods included in the package that I can use to model the API? Thanks,. Scott",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/187
https://github.com/scverse/scanpy/issues/187:370,modifiability,pac,package,370,"Adding MAGIC to Scanpy; Hi,. We spoke a while ago about adding [PHATE](https://github.com/KrishnaswamyLab/PHATE) and eventually [MAGIC](https://github.com/KrishnaswamyLab/MAGIC) to Scanpy. MAGIC has just been submitted to CRAN and is in a stable state. . How should a tool such as MAGIC interact with Scanpy? Do you currently have any imputation methods included in the package that I can use to model the API? Thanks,. Scott",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/187
https://github.com/scverse/scanpy/issues/187:396,security,model,model,396,"Adding MAGIC to Scanpy; Hi,. We spoke a while ago about adding [PHATE](https://github.com/KrishnaswamyLab/PHATE) and eventually [MAGIC](https://github.com/KrishnaswamyLab/MAGIC) to Scanpy. MAGIC has just been submitted to CRAN and is in a stable state. . How should a tool such as MAGIC interact with Scanpy? Do you currently have any imputation methods included in the package that I can use to model the API? Thanks,. Scott",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/187
https://github.com/scverse/scanpy/issues/187:268,usability,tool,tool,268,"Adding MAGIC to Scanpy; Hi,. We spoke a while ago about adding [PHATE](https://github.com/KrishnaswamyLab/PHATE) and eventually [MAGIC](https://github.com/KrishnaswamyLab/MAGIC) to Scanpy. MAGIC has just been submitted to CRAN and is in a stable state. . How should a tool such as MAGIC interact with Scanpy? Do you currently have any imputation methods included in the package that I can use to model the API? Thanks,. Scott",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/187
https://github.com/scverse/scanpy/issues/187:287,usability,interact,interact,287,"Adding MAGIC to Scanpy; Hi,. We spoke a while ago about adding [PHATE](https://github.com/KrishnaswamyLab/PHATE) and eventually [MAGIC](https://github.com/KrishnaswamyLab/MAGIC) to Scanpy. MAGIC has just been submitted to CRAN and is in a stable state. . How should a tool such as MAGIC interact with Scanpy? Do you currently have any imputation methods included in the package that I can use to model the API? Thanks,. Scott",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/187
https://github.com/scverse/scanpy/issues/188:115,availability,Cluster,Clustering,115,"high variable genes; Hi,. Scanpy detect high variable genes with normalized (but not logarithmized) data (refer to Clustering 3k PBMCs following a Seurat Tutorial), while Seurat do this by first normalize the raw data, then logarithmize the data and finally detect high variable genes, which one is better ? or both of them works well ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/188
https://github.com/scverse/scanpy/issues/188:85,deployability,log,logarithmized,85,"high variable genes; Hi,. Scanpy detect high variable genes with normalized (but not logarithmized) data (refer to Clustering 3k PBMCs following a Seurat Tutorial), while Seurat do this by first normalize the raw data, then logarithmize the data and finally detect high variable genes, which one is better ? or both of them works well ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/188
https://github.com/scverse/scanpy/issues/188:115,deployability,Cluster,Clustering,115,"high variable genes; Hi,. Scanpy detect high variable genes with normalized (but not logarithmized) data (refer to Clustering 3k PBMCs following a Seurat Tutorial), while Seurat do this by first normalize the raw data, then logarithmize the data and finally detect high variable genes, which one is better ? or both of them works well ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/188
https://github.com/scverse/scanpy/issues/188:224,deployability,log,logarithmize,224,"high variable genes; Hi,. Scanpy detect high variable genes with normalized (but not logarithmized) data (refer to Clustering 3k PBMCs following a Seurat Tutorial), while Seurat do this by first normalize the raw data, then logarithmize the data and finally detect high variable genes, which one is better ? or both of them works well ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/188
https://github.com/scverse/scanpy/issues/188:5,modifiability,variab,variable,5,"high variable genes; Hi,. Scanpy detect high variable genes with normalized (but not logarithmized) data (refer to Clustering 3k PBMCs following a Seurat Tutorial), while Seurat do this by first normalize the raw data, then logarithmize the data and finally detect high variable genes, which one is better ? or both of them works well ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/188
https://github.com/scverse/scanpy/issues/188:45,modifiability,variab,variable,45,"high variable genes; Hi,. Scanpy detect high variable genes with normalized (but not logarithmized) data (refer to Clustering 3k PBMCs following a Seurat Tutorial), while Seurat do this by first normalize the raw data, then logarithmize the data and finally detect high variable genes, which one is better ? or both of them works well ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/188
https://github.com/scverse/scanpy/issues/188:270,modifiability,variab,variable,270,"high variable genes; Hi,. Scanpy detect high variable genes with normalized (but not logarithmized) data (refer to Clustering 3k PBMCs following a Seurat Tutorial), while Seurat do this by first normalize the raw data, then logarithmize the data and finally detect high variable genes, which one is better ? or both of them works well ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/188
https://github.com/scverse/scanpy/issues/188:33,safety,detect,detect,33,"high variable genes; Hi,. Scanpy detect high variable genes with normalized (but not logarithmized) data (refer to Clustering 3k PBMCs following a Seurat Tutorial), while Seurat do this by first normalize the raw data, then logarithmize the data and finally detect high variable genes, which one is better ? or both of them works well ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/188
https://github.com/scverse/scanpy/issues/188:85,safety,log,logarithmized,85,"high variable genes; Hi,. Scanpy detect high variable genes with normalized (but not logarithmized) data (refer to Clustering 3k PBMCs following a Seurat Tutorial), while Seurat do this by first normalize the raw data, then logarithmize the data and finally detect high variable genes, which one is better ? or both of them works well ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/188
https://github.com/scverse/scanpy/issues/188:224,safety,log,logarithmize,224,"high variable genes; Hi,. Scanpy detect high variable genes with normalized (but not logarithmized) data (refer to Clustering 3k PBMCs following a Seurat Tutorial), while Seurat do this by first normalize the raw data, then logarithmize the data and finally detect high variable genes, which one is better ? or both of them works well ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/188
https://github.com/scverse/scanpy/issues/188:258,safety,detect,detect,258,"high variable genes; Hi,. Scanpy detect high variable genes with normalized (but not logarithmized) data (refer to Clustering 3k PBMCs following a Seurat Tutorial), while Seurat do this by first normalize the raw data, then logarithmize the data and finally detect high variable genes, which one is better ? or both of them works well ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/188
https://github.com/scverse/scanpy/issues/188:33,security,detect,detect,33,"high variable genes; Hi,. Scanpy detect high variable genes with normalized (but not logarithmized) data (refer to Clustering 3k PBMCs following a Seurat Tutorial), while Seurat do this by first normalize the raw data, then logarithmize the data and finally detect high variable genes, which one is better ? or both of them works well ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/188
https://github.com/scverse/scanpy/issues/188:85,security,log,logarithmized,85,"high variable genes; Hi,. Scanpy detect high variable genes with normalized (but not logarithmized) data (refer to Clustering 3k PBMCs following a Seurat Tutorial), while Seurat do this by first normalize the raw data, then logarithmize the data and finally detect high variable genes, which one is better ? or both of them works well ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/188
https://github.com/scverse/scanpy/issues/188:224,security,log,logarithmize,224,"high variable genes; Hi,. Scanpy detect high variable genes with normalized (but not logarithmized) data (refer to Clustering 3k PBMCs following a Seurat Tutorial), while Seurat do this by first normalize the raw data, then logarithmize the data and finally detect high variable genes, which one is better ? or both of them works well ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/188
https://github.com/scverse/scanpy/issues/188:258,security,detect,detect,258,"high variable genes; Hi,. Scanpy detect high variable genes with normalized (but not logarithmized) data (refer to Clustering 3k PBMCs following a Seurat Tutorial), while Seurat do this by first normalize the raw data, then logarithmize the data and finally detect high variable genes, which one is better ? or both of them works well ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/188
https://github.com/scverse/scanpy/issues/188:85,testability,log,logarithmized,85,"high variable genes; Hi,. Scanpy detect high variable genes with normalized (but not logarithmized) data (refer to Clustering 3k PBMCs following a Seurat Tutorial), while Seurat do this by first normalize the raw data, then logarithmize the data and finally detect high variable genes, which one is better ? or both of them works well ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/188
https://github.com/scverse/scanpy/issues/188:224,testability,log,logarithmize,224,"high variable genes; Hi,. Scanpy detect high variable genes with normalized (but not logarithmized) data (refer to Clustering 3k PBMCs following a Seurat Tutorial), while Seurat do this by first normalize the raw data, then logarithmize the data and finally detect high variable genes, which one is better ? or both of them works well ?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/188
https://github.com/scverse/scanpy/issues/189:231,availability,avail,available,231,"Imputation methods; @falexwolf, @flying-sheep . From the discussion on #45, I think some more discussion should be had as to what imputation methods are to be included in scanpy. Validation of and comparisons between the currently available imputation methods are both severely lacking---I only know of [1][2][3][4][5], none of which include comprehensive benchmarks, and the updated MAGIC (#187) article at Cell doesn't include relevant comparisons between current methods. . I'd be very interested in hearing/having an open discussion about the motivation, benefits, and limitations of the various imputation methods available. [1]: Zhang and Zhang, 2017. https://www.biorxiv.org/content/early/2017/12/31/241190. [2]: Lopez et al. 2018, https://www.biorxiv.org/content/early/2018/03/30/292037. [3]: Li and Li, 2018. https://www.nature.com/articles/s41467-018-03405-7. [4]: Eraslan et al. 2018. https://www.biorxiv.org/content/early/2018/04/13/300681. [5]: Huang et al. 2018. https://www.biorxiv.org/content/early/2018/03/08/138677",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189
https://github.com/scverse/scanpy/issues/189:619,availability,avail,available,619,"Imputation methods; @falexwolf, @flying-sheep . From the discussion on #45, I think some more discussion should be had as to what imputation methods are to be included in scanpy. Validation of and comparisons between the currently available imputation methods are both severely lacking---I only know of [1][2][3][4][5], none of which include comprehensive benchmarks, and the updated MAGIC (#187) article at Cell doesn't include relevant comparisons between current methods. . I'd be very interested in hearing/having an open discussion about the motivation, benefits, and limitations of the various imputation methods available. [1]: Zhang and Zhang, 2017. https://www.biorxiv.org/content/early/2017/12/31/241190. [2]: Lopez et al. 2018, https://www.biorxiv.org/content/early/2018/03/30/292037. [3]: Li and Li, 2018. https://www.nature.com/articles/s41467-018-03405-7. [4]: Eraslan et al. 2018. https://www.biorxiv.org/content/early/2018/04/13/300681. [5]: Huang et al. 2018. https://www.biorxiv.org/content/early/2018/03/08/138677",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189
https://github.com/scverse/scanpy/issues/189:376,deployability,updat,updated,376,"Imputation methods; @falexwolf, @flying-sheep . From the discussion on #45, I think some more discussion should be had as to what imputation methods are to be included in scanpy. Validation of and comparisons between the currently available imputation methods are both severely lacking---I only know of [1][2][3][4][5], none of which include comprehensive benchmarks, and the updated MAGIC (#187) article at Cell doesn't include relevant comparisons between current methods. . I'd be very interested in hearing/having an open discussion about the motivation, benefits, and limitations of the various imputation methods available. [1]: Zhang and Zhang, 2017. https://www.biorxiv.org/content/early/2017/12/31/241190. [2]: Lopez et al. 2018, https://www.biorxiv.org/content/early/2018/03/30/292037. [3]: Li and Li, 2018. https://www.nature.com/articles/s41467-018-03405-7. [4]: Eraslan et al. 2018. https://www.biorxiv.org/content/early/2018/04/13/300681. [5]: Huang et al. 2018. https://www.biorxiv.org/content/early/2018/03/08/138677",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189
https://github.com/scverse/scanpy/issues/189:221,energy efficiency,current,currently,221,"Imputation methods; @falexwolf, @flying-sheep . From the discussion on #45, I think some more discussion should be had as to what imputation methods are to be included in scanpy. Validation of and comparisons between the currently available imputation methods are both severely lacking---I only know of [1][2][3][4][5], none of which include comprehensive benchmarks, and the updated MAGIC (#187) article at Cell doesn't include relevant comparisons between current methods. . I'd be very interested in hearing/having an open discussion about the motivation, benefits, and limitations of the various imputation methods available. [1]: Zhang and Zhang, 2017. https://www.biorxiv.org/content/early/2017/12/31/241190. [2]: Lopez et al. 2018, https://www.biorxiv.org/content/early/2018/03/30/292037. [3]: Li and Li, 2018. https://www.nature.com/articles/s41467-018-03405-7. [4]: Eraslan et al. 2018. https://www.biorxiv.org/content/early/2018/04/13/300681. [5]: Huang et al. 2018. https://www.biorxiv.org/content/early/2018/03/08/138677",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189
https://github.com/scverse/scanpy/issues/189:458,energy efficiency,current,current,458,"Imputation methods; @falexwolf, @flying-sheep . From the discussion on #45, I think some more discussion should be had as to what imputation methods are to be included in scanpy. Validation of and comparisons between the currently available imputation methods are both severely lacking---I only know of [1][2][3][4][5], none of which include comprehensive benchmarks, and the updated MAGIC (#187) article at Cell doesn't include relevant comparisons between current methods. . I'd be very interested in hearing/having an open discussion about the motivation, benefits, and limitations of the various imputation methods available. [1]: Zhang and Zhang, 2017. https://www.biorxiv.org/content/early/2017/12/31/241190. [2]: Lopez et al. 2018, https://www.biorxiv.org/content/early/2018/03/30/292037. [3]: Li and Li, 2018. https://www.nature.com/articles/s41467-018-03405-7. [4]: Eraslan et al. 2018. https://www.biorxiv.org/content/early/2018/04/13/300681. [5]: Huang et al. 2018. https://www.biorxiv.org/content/early/2018/03/08/138677",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189
https://github.com/scverse/scanpy/issues/189:682,performance,content,content,682,"Imputation methods; @falexwolf, @flying-sheep . From the discussion on #45, I think some more discussion should be had as to what imputation methods are to be included in scanpy. Validation of and comparisons between the currently available imputation methods are both severely lacking---I only know of [1][2][3][4][5], none of which include comprehensive benchmarks, and the updated MAGIC (#187) article at Cell doesn't include relevant comparisons between current methods. . I'd be very interested in hearing/having an open discussion about the motivation, benefits, and limitations of the various imputation methods available. [1]: Zhang and Zhang, 2017. https://www.biorxiv.org/content/early/2017/12/31/241190. [2]: Lopez et al. 2018, https://www.biorxiv.org/content/early/2018/03/30/292037. [3]: Li and Li, 2018. https://www.nature.com/articles/s41467-018-03405-7. [4]: Eraslan et al. 2018. https://www.biorxiv.org/content/early/2018/04/13/300681. [5]: Huang et al. 2018. https://www.biorxiv.org/content/early/2018/03/08/138677",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189
https://github.com/scverse/scanpy/issues/189:763,performance,content,content,763,"Imputation methods; @falexwolf, @flying-sheep . From the discussion on #45, I think some more discussion should be had as to what imputation methods are to be included in scanpy. Validation of and comparisons between the currently available imputation methods are both severely lacking---I only know of [1][2][3][4][5], none of which include comprehensive benchmarks, and the updated MAGIC (#187) article at Cell doesn't include relevant comparisons between current methods. . I'd be very interested in hearing/having an open discussion about the motivation, benefits, and limitations of the various imputation methods available. [1]: Zhang and Zhang, 2017. https://www.biorxiv.org/content/early/2017/12/31/241190. [2]: Lopez et al. 2018, https://www.biorxiv.org/content/early/2018/03/30/292037. [3]: Li and Li, 2018. https://www.nature.com/articles/s41467-018-03405-7. [4]: Eraslan et al. 2018. https://www.biorxiv.org/content/early/2018/04/13/300681. [5]: Huang et al. 2018. https://www.biorxiv.org/content/early/2018/03/08/138677",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189
https://github.com/scverse/scanpy/issues/189:920,performance,content,content,920,"Imputation methods; @falexwolf, @flying-sheep . From the discussion on #45, I think some more discussion should be had as to what imputation methods are to be included in scanpy. Validation of and comparisons between the currently available imputation methods are both severely lacking---I only know of [1][2][3][4][5], none of which include comprehensive benchmarks, and the updated MAGIC (#187) article at Cell doesn't include relevant comparisons between current methods. . I'd be very interested in hearing/having an open discussion about the motivation, benefits, and limitations of the various imputation methods available. [1]: Zhang and Zhang, 2017. https://www.biorxiv.org/content/early/2017/12/31/241190. [2]: Lopez et al. 2018, https://www.biorxiv.org/content/early/2018/03/30/292037. [3]: Li and Li, 2018. https://www.nature.com/articles/s41467-018-03405-7. [4]: Eraslan et al. 2018. https://www.biorxiv.org/content/early/2018/04/13/300681. [5]: Huang et al. 2018. https://www.biorxiv.org/content/early/2018/03/08/138677",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189
https://github.com/scverse/scanpy/issues/189:1001,performance,content,content,1001,"Imputation methods; @falexwolf, @flying-sheep . From the discussion on #45, I think some more discussion should be had as to what imputation methods are to be included in scanpy. Validation of and comparisons between the currently available imputation methods are both severely lacking---I only know of [1][2][3][4][5], none of which include comprehensive benchmarks, and the updated MAGIC (#187) article at Cell doesn't include relevant comparisons between current methods. . I'd be very interested in hearing/having an open discussion about the motivation, benefits, and limitations of the various imputation methods available. [1]: Zhang and Zhang, 2017. https://www.biorxiv.org/content/early/2017/12/31/241190. [2]: Lopez et al. 2018, https://www.biorxiv.org/content/early/2018/03/30/292037. [3]: Li and Li, 2018. https://www.nature.com/articles/s41467-018-03405-7. [4]: Eraslan et al. 2018. https://www.biorxiv.org/content/early/2018/04/13/300681. [5]: Huang et al. 2018. https://www.biorxiv.org/content/early/2018/03/08/138677",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189
https://github.com/scverse/scanpy/issues/189:231,reliability,availab,available,231,"Imputation methods; @falexwolf, @flying-sheep . From the discussion on #45, I think some more discussion should be had as to what imputation methods are to be included in scanpy. Validation of and comparisons between the currently available imputation methods are both severely lacking---I only know of [1][2][3][4][5], none of which include comprehensive benchmarks, and the updated MAGIC (#187) article at Cell doesn't include relevant comparisons between current methods. . I'd be very interested in hearing/having an open discussion about the motivation, benefits, and limitations of the various imputation methods available. [1]: Zhang and Zhang, 2017. https://www.biorxiv.org/content/early/2017/12/31/241190. [2]: Lopez et al. 2018, https://www.biorxiv.org/content/early/2018/03/30/292037. [3]: Li and Li, 2018. https://www.nature.com/articles/s41467-018-03405-7. [4]: Eraslan et al. 2018. https://www.biorxiv.org/content/early/2018/04/13/300681. [5]: Huang et al. 2018. https://www.biorxiv.org/content/early/2018/03/08/138677",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189
https://github.com/scverse/scanpy/issues/189:413,reliability,doe,doesn,413,"Imputation methods; @falexwolf, @flying-sheep . From the discussion on #45, I think some more discussion should be had as to what imputation methods are to be included in scanpy. Validation of and comparisons between the currently available imputation methods are both severely lacking---I only know of [1][2][3][4][5], none of which include comprehensive benchmarks, and the updated MAGIC (#187) article at Cell doesn't include relevant comparisons between current methods. . I'd be very interested in hearing/having an open discussion about the motivation, benefits, and limitations of the various imputation methods available. [1]: Zhang and Zhang, 2017. https://www.biorxiv.org/content/early/2017/12/31/241190. [2]: Lopez et al. 2018, https://www.biorxiv.org/content/early/2018/03/30/292037. [3]: Li and Li, 2018. https://www.nature.com/articles/s41467-018-03405-7. [4]: Eraslan et al. 2018. https://www.biorxiv.org/content/early/2018/04/13/300681. [5]: Huang et al. 2018. https://www.biorxiv.org/content/early/2018/03/08/138677",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189
https://github.com/scverse/scanpy/issues/189:619,reliability,availab,available,619,"Imputation methods; @falexwolf, @flying-sheep . From the discussion on #45, I think some more discussion should be had as to what imputation methods are to be included in scanpy. Validation of and comparisons between the currently available imputation methods are both severely lacking---I only know of [1][2][3][4][5], none of which include comprehensive benchmarks, and the updated MAGIC (#187) article at Cell doesn't include relevant comparisons between current methods. . I'd be very interested in hearing/having an open discussion about the motivation, benefits, and limitations of the various imputation methods available. [1]: Zhang and Zhang, 2017. https://www.biorxiv.org/content/early/2017/12/31/241190. [2]: Lopez et al. 2018, https://www.biorxiv.org/content/early/2018/03/30/292037. [3]: Li and Li, 2018. https://www.nature.com/articles/s41467-018-03405-7. [4]: Eraslan et al. 2018. https://www.biorxiv.org/content/early/2018/04/13/300681. [5]: Huang et al. 2018. https://www.biorxiv.org/content/early/2018/03/08/138677",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189
https://github.com/scverse/scanpy/issues/189:179,safety,Valid,Validation,179,"Imputation methods; @falexwolf, @flying-sheep . From the discussion on #45, I think some more discussion should be had as to what imputation methods are to be included in scanpy. Validation of and comparisons between the currently available imputation methods are both severely lacking---I only know of [1][2][3][4][5], none of which include comprehensive benchmarks, and the updated MAGIC (#187) article at Cell doesn't include relevant comparisons between current methods. . I'd be very interested in hearing/having an open discussion about the motivation, benefits, and limitations of the various imputation methods available. [1]: Zhang and Zhang, 2017. https://www.biorxiv.org/content/early/2017/12/31/241190. [2]: Lopez et al. 2018, https://www.biorxiv.org/content/early/2018/03/30/292037. [3]: Li and Li, 2018. https://www.nature.com/articles/s41467-018-03405-7. [4]: Eraslan et al. 2018. https://www.biorxiv.org/content/early/2018/04/13/300681. [5]: Huang et al. 2018. https://www.biorxiv.org/content/early/2018/03/08/138677",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189
https://github.com/scverse/scanpy/issues/189:231,safety,avail,available,231,"Imputation methods; @falexwolf, @flying-sheep . From the discussion on #45, I think some more discussion should be had as to what imputation methods are to be included in scanpy. Validation of and comparisons between the currently available imputation methods are both severely lacking---I only know of [1][2][3][4][5], none of which include comprehensive benchmarks, and the updated MAGIC (#187) article at Cell doesn't include relevant comparisons between current methods. . I'd be very interested in hearing/having an open discussion about the motivation, benefits, and limitations of the various imputation methods available. [1]: Zhang and Zhang, 2017. https://www.biorxiv.org/content/early/2017/12/31/241190. [2]: Lopez et al. 2018, https://www.biorxiv.org/content/early/2018/03/30/292037. [3]: Li and Li, 2018. https://www.nature.com/articles/s41467-018-03405-7. [4]: Eraslan et al. 2018. https://www.biorxiv.org/content/early/2018/04/13/300681. [5]: Huang et al. 2018. https://www.biorxiv.org/content/early/2018/03/08/138677",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189
https://github.com/scverse/scanpy/issues/189:376,safety,updat,updated,376,"Imputation methods; @falexwolf, @flying-sheep . From the discussion on #45, I think some more discussion should be had as to what imputation methods are to be included in scanpy. Validation of and comparisons between the currently available imputation methods are both severely lacking---I only know of [1][2][3][4][5], none of which include comprehensive benchmarks, and the updated MAGIC (#187) article at Cell doesn't include relevant comparisons between current methods. . I'd be very interested in hearing/having an open discussion about the motivation, benefits, and limitations of the various imputation methods available. [1]: Zhang and Zhang, 2017. https://www.biorxiv.org/content/early/2017/12/31/241190. [2]: Lopez et al. 2018, https://www.biorxiv.org/content/early/2018/03/30/292037. [3]: Li and Li, 2018. https://www.nature.com/articles/s41467-018-03405-7. [4]: Eraslan et al. 2018. https://www.biorxiv.org/content/early/2018/04/13/300681. [5]: Huang et al. 2018. https://www.biorxiv.org/content/early/2018/03/08/138677",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189
https://github.com/scverse/scanpy/issues/189:619,safety,avail,available,619,"Imputation methods; @falexwolf, @flying-sheep . From the discussion on #45, I think some more discussion should be had as to what imputation methods are to be included in scanpy. Validation of and comparisons between the currently available imputation methods are both severely lacking---I only know of [1][2][3][4][5], none of which include comprehensive benchmarks, and the updated MAGIC (#187) article at Cell doesn't include relevant comparisons between current methods. . I'd be very interested in hearing/having an open discussion about the motivation, benefits, and limitations of the various imputation methods available. [1]: Zhang and Zhang, 2017. https://www.biorxiv.org/content/early/2017/12/31/241190. [2]: Lopez et al. 2018, https://www.biorxiv.org/content/early/2018/03/30/292037. [3]: Li and Li, 2018. https://www.nature.com/articles/s41467-018-03405-7. [4]: Eraslan et al. 2018. https://www.biorxiv.org/content/early/2018/04/13/300681. [5]: Huang et al. 2018. https://www.biorxiv.org/content/early/2018/03/08/138677",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189
https://github.com/scverse/scanpy/issues/189:179,security,Validat,Validation,179,"Imputation methods; @falexwolf, @flying-sheep . From the discussion on #45, I think some more discussion should be had as to what imputation methods are to be included in scanpy. Validation of and comparisons between the currently available imputation methods are both severely lacking---I only know of [1][2][3][4][5], none of which include comprehensive benchmarks, and the updated MAGIC (#187) article at Cell doesn't include relevant comparisons between current methods. . I'd be very interested in hearing/having an open discussion about the motivation, benefits, and limitations of the various imputation methods available. [1]: Zhang and Zhang, 2017. https://www.biorxiv.org/content/early/2017/12/31/241190. [2]: Lopez et al. 2018, https://www.biorxiv.org/content/early/2018/03/30/292037. [3]: Li and Li, 2018. https://www.nature.com/articles/s41467-018-03405-7. [4]: Eraslan et al. 2018. https://www.biorxiv.org/content/early/2018/04/13/300681. [5]: Huang et al. 2018. https://www.biorxiv.org/content/early/2018/03/08/138677",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189
https://github.com/scverse/scanpy/issues/189:231,security,availab,available,231,"Imputation methods; @falexwolf, @flying-sheep . From the discussion on #45, I think some more discussion should be had as to what imputation methods are to be included in scanpy. Validation of and comparisons between the currently available imputation methods are both severely lacking---I only know of [1][2][3][4][5], none of which include comprehensive benchmarks, and the updated MAGIC (#187) article at Cell doesn't include relevant comparisons between current methods. . I'd be very interested in hearing/having an open discussion about the motivation, benefits, and limitations of the various imputation methods available. [1]: Zhang and Zhang, 2017. https://www.biorxiv.org/content/early/2017/12/31/241190. [2]: Lopez et al. 2018, https://www.biorxiv.org/content/early/2018/03/30/292037. [3]: Li and Li, 2018. https://www.nature.com/articles/s41467-018-03405-7. [4]: Eraslan et al. 2018. https://www.biorxiv.org/content/early/2018/04/13/300681. [5]: Huang et al. 2018. https://www.biorxiv.org/content/early/2018/03/08/138677",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189
https://github.com/scverse/scanpy/issues/189:376,security,updat,updated,376,"Imputation methods; @falexwolf, @flying-sheep . From the discussion on #45, I think some more discussion should be had as to what imputation methods are to be included in scanpy. Validation of and comparisons between the currently available imputation methods are both severely lacking---I only know of [1][2][3][4][5], none of which include comprehensive benchmarks, and the updated MAGIC (#187) article at Cell doesn't include relevant comparisons between current methods. . I'd be very interested in hearing/having an open discussion about the motivation, benefits, and limitations of the various imputation methods available. [1]: Zhang and Zhang, 2017. https://www.biorxiv.org/content/early/2017/12/31/241190. [2]: Lopez et al. 2018, https://www.biorxiv.org/content/early/2018/03/30/292037. [3]: Li and Li, 2018. https://www.nature.com/articles/s41467-018-03405-7. [4]: Eraslan et al. 2018. https://www.biorxiv.org/content/early/2018/04/13/300681. [5]: Huang et al. 2018. https://www.biorxiv.org/content/early/2018/03/08/138677",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189
https://github.com/scverse/scanpy/issues/189:619,security,availab,available,619,"Imputation methods; @falexwolf, @flying-sheep . From the discussion on #45, I think some more discussion should be had as to what imputation methods are to be included in scanpy. Validation of and comparisons between the currently available imputation methods are both severely lacking---I only know of [1][2][3][4][5], none of which include comprehensive benchmarks, and the updated MAGIC (#187) article at Cell doesn't include relevant comparisons between current methods. . I'd be very interested in hearing/having an open discussion about the motivation, benefits, and limitations of the various imputation methods available. [1]: Zhang and Zhang, 2017. https://www.biorxiv.org/content/early/2017/12/31/241190. [2]: Lopez et al. 2018, https://www.biorxiv.org/content/early/2018/03/30/292037. [3]: Li and Li, 2018. https://www.nature.com/articles/s41467-018-03405-7. [4]: Eraslan et al. 2018. https://www.biorxiv.org/content/early/2018/04/13/300681. [5]: Huang et al. 2018. https://www.biorxiv.org/content/early/2018/03/08/138677",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/189
https://github.com/scverse/scanpy/pull/191:568,availability,slo,slow,568,"Speed up log1p; We noticed some performance issues with `scanpy.api.pp.log1p` and I think these changes will make it faster and more memory efficient. The `out` argument of `np.log1p` can be used to modify data in-place, conserving memory (this does require special-casing for sparse matrices, unfortunately). Because it's a ufunc, it's quite fast and efficient. With those changes I removed the `chunked` and `chunk_size` arguments for this function, because I don't think they would actually help performance. In fact I found that using `chunked=True` was extremely slow, possibly because of having so many function calls. The only advantage I can imagine there is if you used parallelization on the chunks, but until that's implemented I think the option should be removed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191
https://github.com/scverse/scanpy/pull/191:64,deployability,api,api,64,"Speed up log1p; We noticed some performance issues with `scanpy.api.pp.log1p` and I think these changes will make it faster and more memory efficient. The `out` argument of `np.log1p` can be used to modify data in-place, conserving memory (this does require special-casing for sparse matrices, unfortunately). Because it's a ufunc, it's quite fast and efficient. With those changes I removed the `chunked` and `chunk_size` arguments for this function, because I don't think they would actually help performance. In fact I found that using `chunked=True` was extremely slow, possibly because of having so many function calls. The only advantage I can imagine there is if you used parallelization on the chunks, but until that's implemented I think the option should be removed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191
https://github.com/scverse/scanpy/pull/191:64,integrability,api,api,64,"Speed up log1p; We noticed some performance issues with `scanpy.api.pp.log1p` and I think these changes will make it faster and more memory efficient. The `out` argument of `np.log1p` can be used to modify data in-place, conserving memory (this does require special-casing for sparse matrices, unfortunately). Because it's a ufunc, it's quite fast and efficient. With those changes I removed the `chunked` and `chunk_size` arguments for this function, because I don't think they would actually help performance. In fact I found that using `chunked=True` was extremely slow, possibly because of having so many function calls. The only advantage I can imagine there is if you used parallelization on the chunks, but until that's implemented I think the option should be removed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191
https://github.com/scverse/scanpy/pull/191:64,interoperability,api,api,64,"Speed up log1p; We noticed some performance issues with `scanpy.api.pp.log1p` and I think these changes will make it faster and more memory efficient. The `out` argument of `np.log1p` can be used to modify data in-place, conserving memory (this does require special-casing for sparse matrices, unfortunately). Because it's a ufunc, it's quite fast and efficient. With those changes I removed the `chunked` and `chunk_size` arguments for this function, because I don't think they would actually help performance. In fact I found that using `chunked=True` was extremely slow, possibly because of having so many function calls. The only advantage I can imagine there is if you used parallelization on the chunks, but until that's implemented I think the option should be removed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191
https://github.com/scverse/scanpy/pull/191:32,performance,performance issu,performance issues,32,"Speed up log1p; We noticed some performance issues with `scanpy.api.pp.log1p` and I think these changes will make it faster and more memory efficient. The `out` argument of `np.log1p` can be used to modify data in-place, conserving memory (this does require special-casing for sparse matrices, unfortunately). Because it's a ufunc, it's quite fast and efficient. With those changes I removed the `chunked` and `chunk_size` arguments for this function, because I don't think they would actually help performance. In fact I found that using `chunked=True` was extremely slow, possibly because of having so many function calls. The only advantage I can imagine there is if you used parallelization on the chunks, but until that's implemented I think the option should be removed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191
https://github.com/scverse/scanpy/pull/191:133,performance,memor,memory,133,"Speed up log1p; We noticed some performance issues with `scanpy.api.pp.log1p` and I think these changes will make it faster and more memory efficient. The `out` argument of `np.log1p` can be used to modify data in-place, conserving memory (this does require special-casing for sparse matrices, unfortunately). Because it's a ufunc, it's quite fast and efficient. With those changes I removed the `chunked` and `chunk_size` arguments for this function, because I don't think they would actually help performance. In fact I found that using `chunked=True` was extremely slow, possibly because of having so many function calls. The only advantage I can imagine there is if you used parallelization on the chunks, but until that's implemented I think the option should be removed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191
https://github.com/scverse/scanpy/pull/191:232,performance,memor,memory,232,"Speed up log1p; We noticed some performance issues with `scanpy.api.pp.log1p` and I think these changes will make it faster and more memory efficient. The `out` argument of `np.log1p` can be used to modify data in-place, conserving memory (this does require special-casing for sparse matrices, unfortunately). Because it's a ufunc, it's quite fast and efficient. With those changes I removed the `chunked` and `chunk_size` arguments for this function, because I don't think they would actually help performance. In fact I found that using `chunked=True` was extremely slow, possibly because of having so many function calls. The only advantage I can imagine there is if you used parallelization on the chunks, but until that's implemented I think the option should be removed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191
https://github.com/scverse/scanpy/pull/191:499,performance,perform,performance,499,"Speed up log1p; We noticed some performance issues with `scanpy.api.pp.log1p` and I think these changes will make it faster and more memory efficient. The `out` argument of `np.log1p` can be used to modify data in-place, conserving memory (this does require special-casing for sparse matrices, unfortunately). Because it's a ufunc, it's quite fast and efficient. With those changes I removed the `chunked` and `chunk_size` arguments for this function, because I don't think they would actually help performance. In fact I found that using `chunked=True` was extremely slow, possibly because of having so many function calls. The only advantage I can imagine there is if you used parallelization on the chunks, but until that's implemented I think the option should be removed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191
https://github.com/scverse/scanpy/pull/191:679,performance,parallel,parallelization,679,"Speed up log1p; We noticed some performance issues with `scanpy.api.pp.log1p` and I think these changes will make it faster and more memory efficient. The `out` argument of `np.log1p` can be used to modify data in-place, conserving memory (this does require special-casing for sparse matrices, unfortunately). Because it's a ufunc, it's quite fast and efficient. With those changes I removed the `chunked` and `chunk_size` arguments for this function, because I don't think they would actually help performance. In fact I found that using `chunked=True` was extremely slow, possibly because of having so many function calls. The only advantage I can imagine there is if you used parallelization on the chunks, but until that's implemented I think the option should be removed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191
https://github.com/scverse/scanpy/pull/191:245,reliability,doe,does,245,"Speed up log1p; We noticed some performance issues with `scanpy.api.pp.log1p` and I think these changes will make it faster and more memory efficient. The `out` argument of `np.log1p` can be used to modify data in-place, conserving memory (this does require special-casing for sparse matrices, unfortunately). Because it's a ufunc, it's quite fast and efficient. With those changes I removed the `chunked` and `chunk_size` arguments for this function, because I don't think they would actually help performance. In fact I found that using `chunked=True` was extremely slow, possibly because of having so many function calls. The only advantage I can imagine there is if you used parallelization on the chunks, but until that's implemented I think the option should be removed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191
https://github.com/scverse/scanpy/pull/191:568,reliability,slo,slow,568,"Speed up log1p; We noticed some performance issues with `scanpy.api.pp.log1p` and I think these changes will make it faster and more memory efficient. The `out` argument of `np.log1p` can be used to modify data in-place, conserving memory (this does require special-casing for sparse matrices, unfortunately). Because it's a ufunc, it's quite fast and efficient. With those changes I removed the `chunked` and `chunk_size` arguments for this function, because I don't think they would actually help performance. In fact I found that using `chunked=True` was extremely slow, possibly because of having so many function calls. The only advantage I can imagine there is if you used parallelization on the chunks, but until that's implemented I think the option should be removed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191
https://github.com/scverse/scanpy/pull/191:199,security,modif,modify,199,"Speed up log1p; We noticed some performance issues with `scanpy.api.pp.log1p` and I think these changes will make it faster and more memory efficient. The `out` argument of `np.log1p` can be used to modify data in-place, conserving memory (this does require special-casing for sparse matrices, unfortunately). Because it's a ufunc, it's quite fast and efficient. With those changes I removed the `chunked` and `chunk_size` arguments for this function, because I don't think they would actually help performance. In fact I found that using `chunked=True` was extremely slow, possibly because of having so many function calls. The only advantage I can imagine there is if you used parallelization on the chunks, but until that's implemented I think the option should be removed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191
https://github.com/scverse/scanpy/pull/191:32,usability,perform,performance,32,"Speed up log1p; We noticed some performance issues with `scanpy.api.pp.log1p` and I think these changes will make it faster and more memory efficient. The `out` argument of `np.log1p` can be used to modify data in-place, conserving memory (this does require special-casing for sparse matrices, unfortunately). Because it's a ufunc, it's quite fast and efficient. With those changes I removed the `chunked` and `chunk_size` arguments for this function, because I don't think they would actually help performance. In fact I found that using `chunked=True` was extremely slow, possibly because of having so many function calls. The only advantage I can imagine there is if you used parallelization on the chunks, but until that's implemented I think the option should be removed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191
https://github.com/scverse/scanpy/pull/191:133,usability,memor,memory,133,"Speed up log1p; We noticed some performance issues with `scanpy.api.pp.log1p` and I think these changes will make it faster and more memory efficient. The `out` argument of `np.log1p` can be used to modify data in-place, conserving memory (this does require special-casing for sparse matrices, unfortunately). Because it's a ufunc, it's quite fast and efficient. With those changes I removed the `chunked` and `chunk_size` arguments for this function, because I don't think they would actually help performance. In fact I found that using `chunked=True` was extremely slow, possibly because of having so many function calls. The only advantage I can imagine there is if you used parallelization on the chunks, but until that's implemented I think the option should be removed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191
https://github.com/scverse/scanpy/pull/191:140,usability,efficien,efficient,140,"Speed up log1p; We noticed some performance issues with `scanpy.api.pp.log1p` and I think these changes will make it faster and more memory efficient. The `out` argument of `np.log1p` can be used to modify data in-place, conserving memory (this does require special-casing for sparse matrices, unfortunately). Because it's a ufunc, it's quite fast and efficient. With those changes I removed the `chunked` and `chunk_size` arguments for this function, because I don't think they would actually help performance. In fact I found that using `chunked=True` was extremely slow, possibly because of having so many function calls. The only advantage I can imagine there is if you used parallelization on the chunks, but until that's implemented I think the option should be removed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191
https://github.com/scverse/scanpy/pull/191:232,usability,memor,memory,232,"Speed up log1p; We noticed some performance issues with `scanpy.api.pp.log1p` and I think these changes will make it faster and more memory efficient. The `out` argument of `np.log1p` can be used to modify data in-place, conserving memory (this does require special-casing for sparse matrices, unfortunately). Because it's a ufunc, it's quite fast and efficient. With those changes I removed the `chunked` and `chunk_size` arguments for this function, because I don't think they would actually help performance. In fact I found that using `chunked=True` was extremely slow, possibly because of having so many function calls. The only advantage I can imagine there is if you used parallelization on the chunks, but until that's implemented I think the option should be removed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191
https://github.com/scverse/scanpy/pull/191:352,usability,efficien,efficient,352,"Speed up log1p; We noticed some performance issues with `scanpy.api.pp.log1p` and I think these changes will make it faster and more memory efficient. The `out` argument of `np.log1p` can be used to modify data in-place, conserving memory (this does require special-casing for sparse matrices, unfortunately). Because it's a ufunc, it's quite fast and efficient. With those changes I removed the `chunked` and `chunk_size` arguments for this function, because I don't think they would actually help performance. In fact I found that using `chunked=True` was extremely slow, possibly because of having so many function calls. The only advantage I can imagine there is if you used parallelization on the chunks, but until that's implemented I think the option should be removed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191
https://github.com/scverse/scanpy/pull/191:494,usability,help,help,494,"Speed up log1p; We noticed some performance issues with `scanpy.api.pp.log1p` and I think these changes will make it faster and more memory efficient. The `out` argument of `np.log1p` can be used to modify data in-place, conserving memory (this does require special-casing for sparse matrices, unfortunately). Because it's a ufunc, it's quite fast and efficient. With those changes I removed the `chunked` and `chunk_size` arguments for this function, because I don't think they would actually help performance. In fact I found that using `chunked=True` was extremely slow, possibly because of having so many function calls. The only advantage I can imagine there is if you used parallelization on the chunks, but until that's implemented I think the option should be removed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191
https://github.com/scverse/scanpy/pull/191:499,usability,perform,performance,499,"Speed up log1p; We noticed some performance issues with `scanpy.api.pp.log1p` and I think these changes will make it faster and more memory efficient. The `out` argument of `np.log1p` can be used to modify data in-place, conserving memory (this does require special-casing for sparse matrices, unfortunately). Because it's a ufunc, it's quite fast and efficient. With those changes I removed the `chunked` and `chunk_size` arguments for this function, because I don't think they would actually help performance. In fact I found that using `chunked=True` was extremely slow, possibly because of having so many function calls. The only advantage I can imagine there is if you used parallelization on the chunks, but until that's implemented I think the option should be removed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/191
https://github.com/scverse/scanpy/pull/192:458,availability,avail,available,458,"Automatically add type annotations to all API functions; Fixes #58. ## readthedocs. For RTD I switched from numpydoc to napoleon, with the same customizations as in anndata:. - Numpydoc-style HTML rendering of param docs with custom CSS. - A custom class template that supersedes numpy’s autodoc hack and makes attributes appear above methods in class docs. ## docstrings. The docstring part is implemented via `obj.getdoc()`, a method invoked by IPython if available, which means that it leaves `__doc__` alone. As an example, it converts `scanpy.api.Neighbors.compute_neighbors`’ docs like this, leaving alone explicit type/default info and adding info from the signature. A huge advantage here is that by *removing* explicit info, we gain always-up-to-date defaults and types. Whenever we change something, we can’t forget to change everything else anymore. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors. Use this number of nearest neighbors. knn. Restrict result to `n_neighbors` nearest neighbors. {n_pcs}. {use_rep}. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```. <p align=center>↓↓↓</p>. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors : int, optional (default: 30). Use this number of nearest neighbors. knn : bool, optional (default: True). Restrict result to `n_neighbors` nearest neighbors. n_pcs : `int` or `None`, optional (default: `None`). Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`. use_rep : {`None`, 'X'} or any key for `.obsm`, optional (default: `None`). Use the indicated representation. If `None`, the representation is chosen. automatically: for `.n_vars` < 50, `.X` is used, otherwise 'X_pca' is used. If 'X_pca' is not present, it's computed with default parameters. Returns. -------. Writes sparse graph attributes `.distances` and `.co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192
https://github.com/scverse/scanpy/pull/192:0,deployability,Automat,Automatically,0,"Automatically add type annotations to all API functions; Fixes #58. ## readthedocs. For RTD I switched from numpydoc to napoleon, with the same customizations as in anndata:. - Numpydoc-style HTML rendering of param docs with custom CSS. - A custom class template that supersedes numpy’s autodoc hack and makes attributes appear above methods in class docs. ## docstrings. The docstring part is implemented via `obj.getdoc()`, a method invoked by IPython if available, which means that it leaves `__doc__` alone. As an example, it converts `scanpy.api.Neighbors.compute_neighbors`’ docs like this, leaving alone explicit type/default info and adding info from the signature. A huge advantage here is that by *removing* explicit info, we gain always-up-to-date defaults and types. Whenever we change something, we can’t forget to change everything else anymore. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors. Use this number of nearest neighbors. knn. Restrict result to `n_neighbors` nearest neighbors. {n_pcs}. {use_rep}. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```. <p align=center>↓↓↓</p>. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors : int, optional (default: 30). Use this number of nearest neighbors. knn : bool, optional (default: True). Restrict result to `n_neighbors` nearest neighbors. n_pcs : `int` or `None`, optional (default: `None`). Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`. use_rep : {`None`, 'X'} or any key for `.obsm`, optional (default: `None`). Use the indicated representation. If `None`, the representation is chosen. automatically: for `.n_vars` < 50, `.X` is used, otherwise 'X_pca' is used. If 'X_pca' is not present, it's computed with default parameters. Returns. -------. Writes sparse graph attributes `.distances` and `.co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192
https://github.com/scverse/scanpy/pull/192:42,deployability,API,API,42,"Automatically add type annotations to all API functions; Fixes #58. ## readthedocs. For RTD I switched from numpydoc to napoleon, with the same customizations as in anndata:. - Numpydoc-style HTML rendering of param docs with custom CSS. - A custom class template that supersedes numpy’s autodoc hack and makes attributes appear above methods in class docs. ## docstrings. The docstring part is implemented via `obj.getdoc()`, a method invoked by IPython if available, which means that it leaves `__doc__` alone. As an example, it converts `scanpy.api.Neighbors.compute_neighbors`’ docs like this, leaving alone explicit type/default info and adding info from the signature. A huge advantage here is that by *removing* explicit info, we gain always-up-to-date defaults and types. Whenever we change something, we can’t forget to change everything else anymore. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors. Use this number of nearest neighbors. knn. Restrict result to `n_neighbors` nearest neighbors. {n_pcs}. {use_rep}. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```. <p align=center>↓↓↓</p>. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors : int, optional (default: 30). Use this number of nearest neighbors. knn : bool, optional (default: True). Restrict result to `n_neighbors` nearest neighbors. n_pcs : `int` or `None`, optional (default: `None`). Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`. use_rep : {`None`, 'X'} or any key for `.obsm`, optional (default: `None`). Use the indicated representation. If `None`, the representation is chosen. automatically: for `.n_vars` < 50, `.X` is used, otherwise 'X_pca' is used. If 'X_pca' is not present, it's computed with default parameters. Returns. -------. Writes sparse graph attributes `.distances` and `.co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192
https://github.com/scverse/scanpy/pull/192:548,deployability,api,api,548,"Automatically add type annotations to all API functions; Fixes #58. ## readthedocs. For RTD I switched from numpydoc to napoleon, with the same customizations as in anndata:. - Numpydoc-style HTML rendering of param docs with custom CSS. - A custom class template that supersedes numpy’s autodoc hack and makes attributes appear above methods in class docs. ## docstrings. The docstring part is implemented via `obj.getdoc()`, a method invoked by IPython if available, which means that it leaves `__doc__` alone. As an example, it converts `scanpy.api.Neighbors.compute_neighbors`’ docs like this, leaving alone explicit type/default info and adding info from the signature. A huge advantage here is that by *removing* explicit info, we gain always-up-to-date defaults and types. Whenever we change something, we can’t forget to change everything else anymore. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors. Use this number of nearest neighbors. knn. Restrict result to `n_neighbors` nearest neighbors. {n_pcs}. {use_rep}. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```. <p align=center>↓↓↓</p>. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors : int, optional (default: 30). Use this number of nearest neighbors. knn : bool, optional (default: True). Restrict result to `n_neighbors` nearest neighbors. n_pcs : `int` or `None`, optional (default: `None`). Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`. use_rep : {`None`, 'X'} or any key for `.obsm`, optional (default: `None`). Use the indicated representation. If `None`, the representation is chosen. automatically: for `.n_vars` < 50, `.X` is used, otherwise 'X_pca' is used. If 'X_pca' is not present, it's computed with default parameters. Returns. -------. Writes sparse graph attributes `.distances` and `.co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192
https://github.com/scverse/scanpy/pull/192:1788,deployability,automat,automatically,1788,"tched from numpydoc to napoleon, with the same customizations as in anndata:. - Numpydoc-style HTML rendering of param docs with custom CSS. - A custom class template that supersedes numpy’s autodoc hack and makes attributes appear above methods in class docs. ## docstrings. The docstring part is implemented via `obj.getdoc()`, a method invoked by IPython if available, which means that it leaves `__doc__` alone. As an example, it converts `scanpy.api.Neighbors.compute_neighbors`’ docs like this, leaving alone explicit type/default info and adding info from the signature. A huge advantage here is that by *removing* explicit info, we gain always-up-to-date defaults and types. Whenever we change something, we can’t forget to change everything else anymore. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors. Use this number of nearest neighbors. knn. Restrict result to `n_neighbors` nearest neighbors. {n_pcs}. {use_rep}. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```. <p align=center>↓↓↓</p>. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors : int, optional (default: 30). Use this number of nearest neighbors. knn : bool, optional (default: True). Restrict result to `n_neighbors` nearest neighbors. n_pcs : `int` or `None`, optional (default: `None`). Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`. use_rep : {`None`, 'X'} or any key for `.obsm`, optional (default: `None`). Use the indicated representation. If `None`, the representation is chosen. automatically: for `.n_vars` < 50, `.X` is used, otherwise 'X_pca' is used. If 'X_pca' is not present, it's computed with default parameters. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192
https://github.com/scverse/scanpy/pull/192:42,integrability,API,API,42,"Automatically add type annotations to all API functions; Fixes #58. ## readthedocs. For RTD I switched from numpydoc to napoleon, with the same customizations as in anndata:. - Numpydoc-style HTML rendering of param docs with custom CSS. - A custom class template that supersedes numpy’s autodoc hack and makes attributes appear above methods in class docs. ## docstrings. The docstring part is implemented via `obj.getdoc()`, a method invoked by IPython if available, which means that it leaves `__doc__` alone. As an example, it converts `scanpy.api.Neighbors.compute_neighbors`’ docs like this, leaving alone explicit type/default info and adding info from the signature. A huge advantage here is that by *removing* explicit info, we gain always-up-to-date defaults and types. Whenever we change something, we can’t forget to change everything else anymore. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors. Use this number of nearest neighbors. knn. Restrict result to `n_neighbors` nearest neighbors. {n_pcs}. {use_rep}. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```. <p align=center>↓↓↓</p>. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors : int, optional (default: 30). Use this number of nearest neighbors. knn : bool, optional (default: True). Restrict result to `n_neighbors` nearest neighbors. n_pcs : `int` or `None`, optional (default: `None`). Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`. use_rep : {`None`, 'X'} or any key for `.obsm`, optional (default: `None`). Use the indicated representation. If `None`, the representation is chosen. automatically: for `.n_vars` < 50, `.X` is used, otherwise 'X_pca' is used. If 'X_pca' is not present, it's computed with default parameters. Returns. -------. Writes sparse graph attributes `.distances` and `.co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192
https://github.com/scverse/scanpy/pull/192:548,integrability,api,api,548,"Automatically add type annotations to all API functions; Fixes #58. ## readthedocs. For RTD I switched from numpydoc to napoleon, with the same customizations as in anndata:. - Numpydoc-style HTML rendering of param docs with custom CSS. - A custom class template that supersedes numpy’s autodoc hack and makes attributes appear above methods in class docs. ## docstrings. The docstring part is implemented via `obj.getdoc()`, a method invoked by IPython if available, which means that it leaves `__doc__` alone. As an example, it converts `scanpy.api.Neighbors.compute_neighbors`’ docs like this, leaving alone explicit type/default info and adding info from the signature. A huge advantage here is that by *removing* explicit info, we gain always-up-to-date defaults and types. Whenever we change something, we can’t forget to change everything else anymore. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors. Use this number of nearest neighbors. knn. Restrict result to `n_neighbors` nearest neighbors. {n_pcs}. {use_rep}. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```. <p align=center>↓↓↓</p>. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors : int, optional (default: 30). Use this number of nearest neighbors. knn : bool, optional (default: True). Restrict result to `n_neighbors` nearest neighbors. n_pcs : `int` or `None`, optional (default: `None`). Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`. use_rep : {`None`, 'X'} or any key for `.obsm`, optional (default: `None`). Use the indicated representation. If `None`, the representation is chosen. automatically: for `.n_vars` < 50, `.X` is used, otherwise 'X_pca' is used. If 'X_pca' is not present, it's computed with default parameters. Returns. -------. Writes sparse graph attributes `.distances` and `.co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192
https://github.com/scverse/scanpy/pull/192:42,interoperability,API,API,42,"Automatically add type annotations to all API functions; Fixes #58. ## readthedocs. For RTD I switched from numpydoc to napoleon, with the same customizations as in anndata:. - Numpydoc-style HTML rendering of param docs with custom CSS. - A custom class template that supersedes numpy’s autodoc hack and makes attributes appear above methods in class docs. ## docstrings. The docstring part is implemented via `obj.getdoc()`, a method invoked by IPython if available, which means that it leaves `__doc__` alone. As an example, it converts `scanpy.api.Neighbors.compute_neighbors`’ docs like this, leaving alone explicit type/default info and adding info from the signature. A huge advantage here is that by *removing* explicit info, we gain always-up-to-date defaults and types. Whenever we change something, we can’t forget to change everything else anymore. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors. Use this number of nearest neighbors. knn. Restrict result to `n_neighbors` nearest neighbors. {n_pcs}. {use_rep}. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```. <p align=center>↓↓↓</p>. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors : int, optional (default: 30). Use this number of nearest neighbors. knn : bool, optional (default: True). Restrict result to `n_neighbors` nearest neighbors. n_pcs : `int` or `None`, optional (default: `None`). Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`. use_rep : {`None`, 'X'} or any key for `.obsm`, optional (default: `None`). Use the indicated representation. If `None`, the representation is chosen. automatically: for `.n_vars` < 50, `.X` is used, otherwise 'X_pca' is used. If 'X_pca' is not present, it's computed with default parameters. Returns. -------. Writes sparse graph attributes `.distances` and `.co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192
https://github.com/scverse/scanpy/pull/192:548,interoperability,api,api,548,"Automatically add type annotations to all API functions; Fixes #58. ## readthedocs. For RTD I switched from numpydoc to napoleon, with the same customizations as in anndata:. - Numpydoc-style HTML rendering of param docs with custom CSS. - A custom class template that supersedes numpy’s autodoc hack and makes attributes appear above methods in class docs. ## docstrings. The docstring part is implemented via `obj.getdoc()`, a method invoked by IPython if available, which means that it leaves `__doc__` alone. As an example, it converts `scanpy.api.Neighbors.compute_neighbors`’ docs like this, leaving alone explicit type/default info and adding info from the signature. A huge advantage here is that by *removing* explicit info, we gain always-up-to-date defaults and types. Whenever we change something, we can’t forget to change everything else anymore. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors. Use this number of nearest neighbors. knn. Restrict result to `n_neighbors` nearest neighbors. {n_pcs}. {use_rep}. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```. <p align=center>↓↓↓</p>. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors : int, optional (default: 30). Use this number of nearest neighbors. knn : bool, optional (default: True). Restrict result to `n_neighbors` nearest neighbors. n_pcs : `int` or `None`, optional (default: `None`). Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`. use_rep : {`None`, 'X'} or any key for `.obsm`, optional (default: `None`). Use the indicated representation. If `None`, the representation is chosen. automatically: for `.n_vars` < 50, `.X` is used, otherwise 'X_pca' is used. If 'X_pca' is not present, it's computed with default parameters. Returns. -------. Writes sparse graph attributes `.distances` and `.co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192
https://github.com/scverse/scanpy/pull/192:920,modifiability,Paramet,Parameters,920,"Automatically add type annotations to all API functions; Fixes #58. ## readthedocs. For RTD I switched from numpydoc to napoleon, with the same customizations as in anndata:. - Numpydoc-style HTML rendering of param docs with custom CSS. - A custom class template that supersedes numpy’s autodoc hack and makes attributes appear above methods in class docs. ## docstrings. The docstring part is implemented via `obj.getdoc()`, a method invoked by IPython if available, which means that it leaves `__doc__` alone. As an example, it converts `scanpy.api.Neighbors.compute_neighbors`’ docs like this, leaving alone explicit type/default info and adding info from the signature. A huge advantage here is that by *removing* explicit info, we gain always-up-to-date defaults and types. Whenever we change something, we can’t forget to change everything else anymore. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors. Use this number of nearest neighbors. knn. Restrict result to `n_neighbors` nearest neighbors. {n_pcs}. {use_rep}. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```. <p align=center>↓↓↓</p>. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors : int, optional (default: 30). Use this number of nearest neighbors. knn : bool, optional (default: True). Restrict result to `n_neighbors` nearest neighbors. n_pcs : `int` or `None`, optional (default: `None`). Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`. use_rep : {`None`, 'X'} or any key for `.obsm`, optional (default: `None`). Use the indicated representation. If `None`, the representation is chosen. automatically: for `.n_vars` < 50, `.X` is used, otherwise 'X_pca' is used. If 'X_pca' is not present, it's computed with default parameters. Returns. -------. Writes sparse graph attributes `.distances` and `.co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192
https://github.com/scverse/scanpy/pull/192:1325,modifiability,Paramet,Parameters,1325,"tched from numpydoc to napoleon, with the same customizations as in anndata:. - Numpydoc-style HTML rendering of param docs with custom CSS. - A custom class template that supersedes numpy’s autodoc hack and makes attributes appear above methods in class docs. ## docstrings. The docstring part is implemented via `obj.getdoc()`, a method invoked by IPython if available, which means that it leaves `__doc__` alone. As an example, it converts `scanpy.api.Neighbors.compute_neighbors`’ docs like this, leaving alone explicit type/default info and adding info from the signature. A huge advantage here is that by *removing* explicit info, we gain always-up-to-date defaults and types. Whenever we change something, we can’t forget to change everything else anymore. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors. Use this number of nearest neighbors. knn. Restrict result to `n_neighbors` nearest neighbors. {n_pcs}. {use_rep}. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```. <p align=center>↓↓↓</p>. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors : int, optional (default: 30). Use this number of nearest neighbors. knn : bool, optional (default: True). Restrict result to `n_neighbors` nearest neighbors. n_pcs : `int` or `None`, optional (default: `None`). Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`. use_rep : {`None`, 'X'} or any key for `.obsm`, optional (default: `None`). Use the indicated representation. If `None`, the representation is chosen. automatically: for `.n_vars` < 50, `.X` is used, otherwise 'X_pca' is used. If 'X_pca' is not present, it's computed with default parameters. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192
https://github.com/scverse/scanpy/pull/192:1918,modifiability,paramet,parameters,1918,"tched from numpydoc to napoleon, with the same customizations as in anndata:. - Numpydoc-style HTML rendering of param docs with custom CSS. - A custom class template that supersedes numpy’s autodoc hack and makes attributes appear above methods in class docs. ## docstrings. The docstring part is implemented via `obj.getdoc()`, a method invoked by IPython if available, which means that it leaves `__doc__` alone. As an example, it converts `scanpy.api.Neighbors.compute_neighbors`’ docs like this, leaving alone explicit type/default info and adding info from the signature. A huge advantage here is that by *removing* explicit info, we gain always-up-to-date defaults and types. Whenever we change something, we can’t forget to change everything else anymore. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors. Use this number of nearest neighbors. knn. Restrict result to `n_neighbors` nearest neighbors. {n_pcs}. {use_rep}. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```. <p align=center>↓↓↓</p>. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors : int, optional (default: 30). Use this number of nearest neighbors. knn : bool, optional (default: True). Restrict result to `n_neighbors` nearest neighbors. n_pcs : `int` or `None`, optional (default: `None`). Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`. use_rep : {`None`, 'X'} or any key for `.obsm`, optional (default: `None`). Use the indicated representation. If `None`, the representation is chosen. automatically: for `.n_vars` < 50, `.X` is used, otherwise 'X_pca' is used. If 'X_pca' is not present, it's computed with default parameters. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192
https://github.com/scverse/scanpy/pull/192:458,reliability,availab,available,458,"Automatically add type annotations to all API functions; Fixes #58. ## readthedocs. For RTD I switched from numpydoc to napoleon, with the same customizations as in anndata:. - Numpydoc-style HTML rendering of param docs with custom CSS. - A custom class template that supersedes numpy’s autodoc hack and makes attributes appear above methods in class docs. ## docstrings. The docstring part is implemented via `obj.getdoc()`, a method invoked by IPython if available, which means that it leaves `__doc__` alone. As an example, it converts `scanpy.api.Neighbors.compute_neighbors`’ docs like this, leaving alone explicit type/default info and adding info from the signature. A huge advantage here is that by *removing* explicit info, we gain always-up-to-date defaults and types. Whenever we change something, we can’t forget to change everything else anymore. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors. Use this number of nearest neighbors. knn. Restrict result to `n_neighbors` nearest neighbors. {n_pcs}. {use_rep}. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```. <p align=center>↓↓↓</p>. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors : int, optional (default: 30). Use this number of nearest neighbors. knn : bool, optional (default: True). Restrict result to `n_neighbors` nearest neighbors. n_pcs : `int` or `None`, optional (default: `None`). Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`. use_rep : {`None`, 'X'} or any key for `.obsm`, optional (default: `None`). Use the indicated representation. If `None`, the representation is chosen. automatically: for `.n_vars` < 50, `.X` is used, otherwise 'X_pca' is used. If 'X_pca' is not present, it's computed with default parameters. Returns. -------. Writes sparse graph attributes `.distances` and `.co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192
https://github.com/scverse/scanpy/pull/192:458,safety,avail,available,458,"Automatically add type annotations to all API functions; Fixes #58. ## readthedocs. For RTD I switched from numpydoc to napoleon, with the same customizations as in anndata:. - Numpydoc-style HTML rendering of param docs with custom CSS. - A custom class template that supersedes numpy’s autodoc hack and makes attributes appear above methods in class docs. ## docstrings. The docstring part is implemented via `obj.getdoc()`, a method invoked by IPython if available, which means that it leaves `__doc__` alone. As an example, it converts `scanpy.api.Neighbors.compute_neighbors`’ docs like this, leaving alone explicit type/default info and adding info from the signature. A huge advantage here is that by *removing* explicit info, we gain always-up-to-date defaults and types. Whenever we change something, we can’t forget to change everything else anymore. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors. Use this number of nearest neighbors. knn. Restrict result to `n_neighbors` nearest neighbors. {n_pcs}. {use_rep}. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```. <p align=center>↓↓↓</p>. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors : int, optional (default: 30). Use this number of nearest neighbors. knn : bool, optional (default: True). Restrict result to `n_neighbors` nearest neighbors. n_pcs : `int` or `None`, optional (default: `None`). Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`. use_rep : {`None`, 'X'} or any key for `.obsm`, optional (default: `None`). Use the indicated representation. If `None`, the representation is chosen. automatically: for `.n_vars` < 50, `.X` is used, otherwise 'X_pca' is used. If 'X_pca' is not present, it's computed with default parameters. Returns. -------. Writes sparse graph attributes `.distances` and `.co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192
https://github.com/scverse/scanpy/pull/192:296,security,hack,hack,296,"Automatically add type annotations to all API functions; Fixes #58. ## readthedocs. For RTD I switched from numpydoc to napoleon, with the same customizations as in anndata:. - Numpydoc-style HTML rendering of param docs with custom CSS. - A custom class template that supersedes numpy’s autodoc hack and makes attributes appear above methods in class docs. ## docstrings. The docstring part is implemented via `obj.getdoc()`, a method invoked by IPython if available, which means that it leaves `__doc__` alone. As an example, it converts `scanpy.api.Neighbors.compute_neighbors`’ docs like this, leaving alone explicit type/default info and adding info from the signature. A huge advantage here is that by *removing* explicit info, we gain always-up-to-date defaults and types. Whenever we change something, we can’t forget to change everything else anymore. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors. Use this number of nearest neighbors. knn. Restrict result to `n_neighbors` nearest neighbors. {n_pcs}. {use_rep}. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```. <p align=center>↓↓↓</p>. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors : int, optional (default: 30). Use this number of nearest neighbors. knn : bool, optional (default: True). Restrict result to `n_neighbors` nearest neighbors. n_pcs : `int` or `None`, optional (default: `None`). Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`. use_rep : {`None`, 'X'} or any key for `.obsm`, optional (default: `None`). Use the indicated representation. If `None`, the representation is chosen. automatically: for `.n_vars` < 50, `.X` is used, otherwise 'X_pca' is used. If 'X_pca' is not present, it's computed with default parameters. Returns. -------. Writes sparse graph attributes `.distances` and `.co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192
https://github.com/scverse/scanpy/pull/192:458,security,availab,available,458,"Automatically add type annotations to all API functions; Fixes #58. ## readthedocs. For RTD I switched from numpydoc to napoleon, with the same customizations as in anndata:. - Numpydoc-style HTML rendering of param docs with custom CSS. - A custom class template that supersedes numpy’s autodoc hack and makes attributes appear above methods in class docs. ## docstrings. The docstring part is implemented via `obj.getdoc()`, a method invoked by IPython if available, which means that it leaves `__doc__` alone. As an example, it converts `scanpy.api.Neighbors.compute_neighbors`’ docs like this, leaving alone explicit type/default info and adding info from the signature. A huge advantage here is that by *removing* explicit info, we gain always-up-to-date defaults and types. Whenever we change something, we can’t forget to change everything else anymore. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors. Use this number of nearest neighbors. knn. Restrict result to `n_neighbors` nearest neighbors. {n_pcs}. {use_rep}. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```. <p align=center>↓↓↓</p>. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors : int, optional (default: 30). Use this number of nearest neighbors. knn : bool, optional (default: True). Restrict result to `n_neighbors` nearest neighbors. n_pcs : `int` or `None`, optional (default: `None`). Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`. use_rep : {`None`, 'X'} or any key for `.obsm`, optional (default: `None`). Use the indicated representation. If `None`, the representation is chosen. automatically: for `.n_vars` < 50, `.X` is used, otherwise 'X_pca' is used. If 'X_pca' is not present, it's computed with default parameters. Returns. -------. Writes sparse graph attributes `.distances` and `.co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192
https://github.com/scverse/scanpy/pull/192:664,security,sign,signature,664,"Automatically add type annotations to all API functions; Fixes #58. ## readthedocs. For RTD I switched from numpydoc to napoleon, with the same customizations as in anndata:. - Numpydoc-style HTML rendering of param docs with custom CSS. - A custom class template that supersedes numpy’s autodoc hack and makes attributes appear above methods in class docs. ## docstrings. The docstring part is implemented via `obj.getdoc()`, a method invoked by IPython if available, which means that it leaves `__doc__` alone. As an example, it converts `scanpy.api.Neighbors.compute_neighbors`’ docs like this, leaving alone explicit type/default info and adding info from the signature. A huge advantage here is that by *removing* explicit info, we gain always-up-to-date defaults and types. Whenever we change something, we can’t forget to change everything else anymore. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors. Use this number of nearest neighbors. knn. Restrict result to `n_neighbors` nearest neighbors. {n_pcs}. {use_rep}. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```. <p align=center>↓↓↓</p>. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors : int, optional (default: 30). Use this number of nearest neighbors. knn : bool, optional (default: True). Restrict result to `n_neighbors` nearest neighbors. n_pcs : `int` or `None`, optional (default: `None`). Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`. use_rep : {`None`, 'X'} or any key for `.obsm`, optional (default: `None`). Use the indicated representation. If `None`, the representation is chosen. automatically: for `.n_vars` < 50, `.X` is used, otherwise 'X_pca' is used. If 'X_pca' is not present, it's computed with default parameters. Returns. -------. Writes sparse graph attributes `.distances` and `.co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192
https://github.com/scverse/scanpy/pull/192:0,testability,Automat,Automatically,0,"Automatically add type annotations to all API functions; Fixes #58. ## readthedocs. For RTD I switched from numpydoc to napoleon, with the same customizations as in anndata:. - Numpydoc-style HTML rendering of param docs with custom CSS. - A custom class template that supersedes numpy’s autodoc hack and makes attributes appear above methods in class docs. ## docstrings. The docstring part is implemented via `obj.getdoc()`, a method invoked by IPython if available, which means that it leaves `__doc__` alone. As an example, it converts `scanpy.api.Neighbors.compute_neighbors`’ docs like this, leaving alone explicit type/default info and adding info from the signature. A huge advantage here is that by *removing* explicit info, we gain always-up-to-date defaults and types. Whenever we change something, we can’t forget to change everything else anymore. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors. Use this number of nearest neighbors. knn. Restrict result to `n_neighbors` nearest neighbors. {n_pcs}. {use_rep}. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```. <p align=center>↓↓↓</p>. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors : int, optional (default: 30). Use this number of nearest neighbors. knn : bool, optional (default: True). Restrict result to `n_neighbors` nearest neighbors. n_pcs : `int` or `None`, optional (default: `None`). Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`. use_rep : {`None`, 'X'} or any key for `.obsm`, optional (default: `None`). Use the indicated representation. If `None`, the representation is chosen. automatically: for `.n_vars` < 50, `.X` is used, otherwise 'X_pca' is used. If 'X_pca' is not present, it's computed with default parameters. Returns. -------. Writes sparse graph attributes `.distances` and `.co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192
https://github.com/scverse/scanpy/pull/192:1788,testability,automat,automatically,1788,"tched from numpydoc to napoleon, with the same customizations as in anndata:. - Numpydoc-style HTML rendering of param docs with custom CSS. - A custom class template that supersedes numpy’s autodoc hack and makes attributes appear above methods in class docs. ## docstrings. The docstring part is implemented via `obj.getdoc()`, a method invoked by IPython if available, which means that it leaves `__doc__` alone. As an example, it converts `scanpy.api.Neighbors.compute_neighbors`’ docs like this, leaving alone explicit type/default info and adding info from the signature. A huge advantage here is that by *removing* explicit info, we gain always-up-to-date defaults and types. Whenever we change something, we can’t forget to change everything else anymore. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors. Use this number of nearest neighbors. knn. Restrict result to `n_neighbors` nearest neighbors. {n_pcs}. {use_rep}. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```. <p align=center>↓↓↓</p>. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors : int, optional (default: 30). Use this number of nearest neighbors. knn : bool, optional (default: True). Restrict result to `n_neighbors` nearest neighbors. n_pcs : `int` or `None`, optional (default: `None`). Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`. use_rep : {`None`, 'X'} or any key for `.obsm`, optional (default: `None`). Use the indicated representation. If `None`, the representation is chosen. automatically: for `.n_vars` < 50, `.X` is used, otherwise 'X_pca' is used. If 'X_pca' is not present, it's computed with default parameters. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192
https://github.com/scverse/scanpy/pull/192:144,usability,custom,customizations,144,"Automatically add type annotations to all API functions; Fixes #58. ## readthedocs. For RTD I switched from numpydoc to napoleon, with the same customizations as in anndata:. - Numpydoc-style HTML rendering of param docs with custom CSS. - A custom class template that supersedes numpy’s autodoc hack and makes attributes appear above methods in class docs. ## docstrings. The docstring part is implemented via `obj.getdoc()`, a method invoked by IPython if available, which means that it leaves `__doc__` alone. As an example, it converts `scanpy.api.Neighbors.compute_neighbors`’ docs like this, leaving alone explicit type/default info and adding info from the signature. A huge advantage here is that by *removing* explicit info, we gain always-up-to-date defaults and types. Whenever we change something, we can’t forget to change everything else anymore. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors. Use this number of nearest neighbors. knn. Restrict result to `n_neighbors` nearest neighbors. {n_pcs}. {use_rep}. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```. <p align=center>↓↓↓</p>. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors : int, optional (default: 30). Use this number of nearest neighbors. knn : bool, optional (default: True). Restrict result to `n_neighbors` nearest neighbors. n_pcs : `int` or `None`, optional (default: `None`). Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`. use_rep : {`None`, 'X'} or any key for `.obsm`, optional (default: `None`). Use the indicated representation. If `None`, the representation is chosen. automatically: for `.n_vars` < 50, `.X` is used, otherwise 'X_pca' is used. If 'X_pca' is not present, it's computed with default parameters. Returns. -------. Writes sparse graph attributes `.distances` and `.co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192
https://github.com/scverse/scanpy/pull/192:226,usability,custom,custom,226,"Automatically add type annotations to all API functions; Fixes #58. ## readthedocs. For RTD I switched from numpydoc to napoleon, with the same customizations as in anndata:. - Numpydoc-style HTML rendering of param docs with custom CSS. - A custom class template that supersedes numpy’s autodoc hack and makes attributes appear above methods in class docs. ## docstrings. The docstring part is implemented via `obj.getdoc()`, a method invoked by IPython if available, which means that it leaves `__doc__` alone. As an example, it converts `scanpy.api.Neighbors.compute_neighbors`’ docs like this, leaving alone explicit type/default info and adding info from the signature. A huge advantage here is that by *removing* explicit info, we gain always-up-to-date defaults and types. Whenever we change something, we can’t forget to change everything else anymore. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors. Use this number of nearest neighbors. knn. Restrict result to `n_neighbors` nearest neighbors. {n_pcs}. {use_rep}. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```. <p align=center>↓↓↓</p>. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors : int, optional (default: 30). Use this number of nearest neighbors. knn : bool, optional (default: True). Restrict result to `n_neighbors` nearest neighbors. n_pcs : `int` or `None`, optional (default: `None`). Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`. use_rep : {`None`, 'X'} or any key for `.obsm`, optional (default: `None`). Use the indicated representation. If `None`, the representation is chosen. automatically: for `.n_vars` < 50, `.X` is used, otherwise 'X_pca' is used. If 'X_pca' is not present, it's computed with default parameters. Returns. -------. Writes sparse graph attributes `.distances` and `.co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192
https://github.com/scverse/scanpy/pull/192:242,usability,custom,custom,242,"Automatically add type annotations to all API functions; Fixes #58. ## readthedocs. For RTD I switched from numpydoc to napoleon, with the same customizations as in anndata:. - Numpydoc-style HTML rendering of param docs with custom CSS. - A custom class template that supersedes numpy’s autodoc hack and makes attributes appear above methods in class docs. ## docstrings. The docstring part is implemented via `obj.getdoc()`, a method invoked by IPython if available, which means that it leaves `__doc__` alone. As an example, it converts `scanpy.api.Neighbors.compute_neighbors`’ docs like this, leaving alone explicit type/default info and adding info from the signature. A huge advantage here is that by *removing* explicit info, we gain always-up-to-date defaults and types. Whenever we change something, we can’t forget to change everything else anymore. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors. Use this number of nearest neighbors. knn. Restrict result to `n_neighbors` nearest neighbors. {n_pcs}. {use_rep}. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```. <p align=center>↓↓↓</p>. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors : int, optional (default: 30). Use this number of nearest neighbors. knn : bool, optional (default: True). Restrict result to `n_neighbors` nearest neighbors. n_pcs : `int` or `None`, optional (default: `None`). Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`. use_rep : {`None`, 'X'} or any key for `.obsm`, optional (default: `None`). Use the indicated representation. If `None`, the representation is chosen. automatically: for `.n_vars` < 50, `.X` is used, otherwise 'X_pca' is used. If 'X_pca' is not present, it's computed with default parameters. Returns. -------. Writes sparse graph attributes `.distances` and `.co",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192
https://github.com/scverse/scanpy/pull/192:1721,usability,indicat,indicated,1721,"tched from numpydoc to napoleon, with the same customizations as in anndata:. - Numpydoc-style HTML rendering of param docs with custom CSS. - A custom class template that supersedes numpy’s autodoc hack and makes attributes appear above methods in class docs. ## docstrings. The docstring part is implemented via `obj.getdoc()`, a method invoked by IPython if available, which means that it leaves `__doc__` alone. As an example, it converts `scanpy.api.Neighbors.compute_neighbors`’ docs like this, leaving alone explicit type/default info and adding info from the signature. A huge advantage here is that by *removing* explicit info, we gain always-up-to-date defaults and types. Whenever we change something, we can’t forget to change everything else anymore. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors. Use this number of nearest neighbors. knn. Restrict result to `n_neighbors` nearest neighbors. {n_pcs}. {use_rep}. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```. <p align=center>↓↓↓</p>. ```rst. Compute distances and connectivities of neighbors. Parameters. ----------. n_neighbors : int, optional (default: 30). Use this number of nearest neighbors. knn : bool, optional (default: True). Restrict result to `n_neighbors` nearest neighbors. n_pcs : `int` or `None`, optional (default: `None`). Use this many PCs. If `n_pcs==0` use `.X` if `use_rep is None`. use_rep : {`None`, 'X'} or any key for `.obsm`, optional (default: `None`). Use the indicated representation. If `None`, the representation is chosen. automatically: for `.n_vars` < 50, `.X` is used, otherwise 'X_pca' is used. If 'X_pca' is not present, it's computed with default parameters. Returns. -------. Writes sparse graph attributes `.distances` and `.connectivities`. Also writes `.knn_indices` and `.knn_distances` if. `write_knn_indices==True`. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/192
https://github.com/scverse/scanpy/pull/193:10,deployability,API,API,10,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:21,deployability,API,API,21,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:46,deployability,API,API,46,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:125,deployability,API,API,125,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:209,deployability,updat,updated,209,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:227,deployability,API,API,227,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:884,deployability,API,API,884,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:25,energy efficiency,model,modelled,25,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:387,energy efficiency,current,currently,387,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:483,energy efficiency,reduc,reduced,483,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:805,energy efficiency,current,currently,805,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:10,integrability,API,API,10,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:21,integrability,API,API,21,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:46,integrability,API,API,46,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:53,integrability,coupl,couple,53,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:125,integrability,API,API,125,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:227,integrability,API,API,227,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:884,integrability,API,API,884,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:10,interoperability,API,API,10,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:21,interoperability,API,API,21,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:46,interoperability,API,API,46,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:125,interoperability,API,API,125,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:227,interoperability,API,API,227,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:445,interoperability,specif,specified,445,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:884,interoperability,API,API,884,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:53,modifiability,coupl,couple,53,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:209,safety,updat,updated,209,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:796,safety,input,input,796,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:25,security,model,modelled,25,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:209,security,updat,updated,209,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:53,testability,coupl,couple,53,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/pull/193:796,usability,input,input,796,"Add MAGIC API; MAGIC API modelled off the DCA API. A couple of comments:. - I changed `threads` to `n_jobs` to match `sc.tl` API. - I use `sc.settings.verbosity` rather than `False` for `verbose` default. - I updated the PHATE API while I was here. - I'm open to suggestions on how to handle `name_list`. Re: `name_list`: MAGIC accepts both gene names and column indices. I've set it up currently to return to adata.obsm['X_magic'] if genes are specified as the number of columns is reduced from the original data, and to adata.X if all genes are returned. However, adata.obsm['X_magic'] now has no information about the order of the genes, unless I return it from MAGIC as a `pandas.DataFrame`, or as an AnnData object in its own right. What do you think? P.S. MAGIC handling `genes` on AnnData input is currently on the dev branch, but will be merged to master once we settle on an API.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/193
https://github.com/scverse/scanpy/issues/194:31,availability,fault,fault,31,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:206,availability,error,error,206,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:442,availability,fault,fault,442,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:668,deployability,Version,Versions,668,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:681,deployability,Resourc,Resources,681,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:31,energy efficiency,fault,fault,31,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:442,energy efficiency,fault,fault,442,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:681,energy efficiency,Resourc,Resources,681,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:212,integrability,messag,message,212,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:668,integrability,Version,Versions,668,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:212,interoperability,messag,message,212,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:737,interoperability,Specif,Specific,737,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:668,modifiability,Version,Versions,668,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:31,performance,fault,fault,31,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:206,performance,error,error,206,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:442,performance,fault,fault,442,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:681,performance,Resourc,Resources,681,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:702,performance,Content,Contents,702,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:764,performance,multi-thread,multi-threaded,764,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:31,reliability,fault,fault,31,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:442,reliability,fault,fault,442,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:31,safety,fault,fault,31,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:206,safety,error,error,206,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:271,safety,Except,Exception,271,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:313,safety,Except,Exception,313,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:374,safety,Except,Exception,374,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:442,safety,fault,fault,442,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:681,safety,Resourc,Resources,681,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:421,security,Sign,Signal,421,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:483,security,SIGN,SIGNAL,483,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:113,testability,regress,regress,113,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:681,testability,Resourc,Resources,681,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:63,usability,experien,experience,63,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/issues/194:206,usability,error,error,206,"sc.pp.regress_out segmentation fault Mac OS X 10.13.3; Anybody experience something similar? . I'm attempting to regress out cell cycle gene information from a single cell dataset. ```. # . # # Part of the error message that probably matters most. # . Crashed Thread: 0. Exception Type: EXC_BAD_ACCESS (SIGSEGV). Exception Codes: KERN_INVALID_ADDRESS at 0x0000000000000110. Exception Note: EXC_CORPSE_NOTIFY. Termination Signal: Segmentation fault: 11. Termination Reason: Namespace SIGNAL, Code 0xb. Terminating Process: exc handler [0]. VM Regions Near 0x110:. --> . __TEXT 00000001039d0000-00000001039d1000 [ 4K] r-x/rwx SM=COW /Library/Frameworks/Python.framework/Versions/3.6/Resources/Python.app/Contents/MacOS/Python. Application Specific Information:. *** multi-threaded process forked ***. crashed on child side of fork pre-exec. # . # . # . ```. Any ideas on what the problem could be?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/194
https://github.com/scverse/scanpy/pull/195:14,deployability,API,API,14,"Add new MAGIC API; Fix #187 and #193 . The bulk of the new API is contained within https://github.com/KrishnaswamyLab/MAGIC and https://github.com/KrishnaswamyLab/graphtools , both of which now natively accept AnnData as of https://github.com/KrishnaswamyLab/MAGIC/pull/116 and https://github.com/KrishnaswamyLab/graphtools/pull/18. MAGIC also returns an AnnData object containing the original `.obs` and (optionally subsetted) `.var` from the input. The `scanpy` API forces this to be a new `AnnData` if the genes are subsetted, allows modification in-place if all genes are returned, and adds the returned values to `.obsm['X_magic']` if the returned values are PCA on MAGIC. . @falexwolf let me know if this fits what you think the API should be.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/195
https://github.com/scverse/scanpy/pull/195:59,deployability,API,API,59,"Add new MAGIC API; Fix #187 and #193 . The bulk of the new API is contained within https://github.com/KrishnaswamyLab/MAGIC and https://github.com/KrishnaswamyLab/graphtools , both of which now natively accept AnnData as of https://github.com/KrishnaswamyLab/MAGIC/pull/116 and https://github.com/KrishnaswamyLab/graphtools/pull/18. MAGIC also returns an AnnData object containing the original `.obs` and (optionally subsetted) `.var` from the input. The `scanpy` API forces this to be a new `AnnData` if the genes are subsetted, allows modification in-place if all genes are returned, and adds the returned values to `.obsm['X_magic']` if the returned values are PCA on MAGIC. . @falexwolf let me know if this fits what you think the API should be.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/195
https://github.com/scverse/scanpy/pull/195:66,deployability,contain,contained,66,"Add new MAGIC API; Fix #187 and #193 . The bulk of the new API is contained within https://github.com/KrishnaswamyLab/MAGIC and https://github.com/KrishnaswamyLab/graphtools , both of which now natively accept AnnData as of https://github.com/KrishnaswamyLab/MAGIC/pull/116 and https://github.com/KrishnaswamyLab/graphtools/pull/18. MAGIC also returns an AnnData object containing the original `.obs` and (optionally subsetted) `.var` from the input. The `scanpy` API forces this to be a new `AnnData` if the genes are subsetted, allows modification in-place if all genes are returned, and adds the returned values to `.obsm['X_magic']` if the returned values are PCA on MAGIC. . @falexwolf let me know if this fits what you think the API should be.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/195
https://github.com/scverse/scanpy/pull/195:370,deployability,contain,containing,370,"Add new MAGIC API; Fix #187 and #193 . The bulk of the new API is contained within https://github.com/KrishnaswamyLab/MAGIC and https://github.com/KrishnaswamyLab/graphtools , both of which now natively accept AnnData as of https://github.com/KrishnaswamyLab/MAGIC/pull/116 and https://github.com/KrishnaswamyLab/graphtools/pull/18. MAGIC also returns an AnnData object containing the original `.obs` and (optionally subsetted) `.var` from the input. The `scanpy` API forces this to be a new `AnnData` if the genes are subsetted, allows modification in-place if all genes are returned, and adds the returned values to `.obsm['X_magic']` if the returned values are PCA on MAGIC. . @falexwolf let me know if this fits what you think the API should be.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/195
https://github.com/scverse/scanpy/pull/195:464,deployability,API,API,464,"Add new MAGIC API; Fix #187 and #193 . The bulk of the new API is contained within https://github.com/KrishnaswamyLab/MAGIC and https://github.com/KrishnaswamyLab/graphtools , both of which now natively accept AnnData as of https://github.com/KrishnaswamyLab/MAGIC/pull/116 and https://github.com/KrishnaswamyLab/graphtools/pull/18. MAGIC also returns an AnnData object containing the original `.obs` and (optionally subsetted) `.var` from the input. The `scanpy` API forces this to be a new `AnnData` if the genes are subsetted, allows modification in-place if all genes are returned, and adds the returned values to `.obsm['X_magic']` if the returned values are PCA on MAGIC. . @falexwolf let me know if this fits what you think the API should be.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/195
https://github.com/scverse/scanpy/pull/195:735,deployability,API,API,735,"Add new MAGIC API; Fix #187 and #193 . The bulk of the new API is contained within https://github.com/KrishnaswamyLab/MAGIC and https://github.com/KrishnaswamyLab/graphtools , both of which now natively accept AnnData as of https://github.com/KrishnaswamyLab/MAGIC/pull/116 and https://github.com/KrishnaswamyLab/graphtools/pull/18. MAGIC also returns an AnnData object containing the original `.obs` and (optionally subsetted) `.var` from the input. The `scanpy` API forces this to be a new `AnnData` if the genes are subsetted, allows modification in-place if all genes are returned, and adds the returned values to `.obsm['X_magic']` if the returned values are PCA on MAGIC. . @falexwolf let me know if this fits what you think the API should be.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/195
https://github.com/scverse/scanpy/pull/195:14,integrability,API,API,14,"Add new MAGIC API; Fix #187 and #193 . The bulk of the new API is contained within https://github.com/KrishnaswamyLab/MAGIC and https://github.com/KrishnaswamyLab/graphtools , both of which now natively accept AnnData as of https://github.com/KrishnaswamyLab/MAGIC/pull/116 and https://github.com/KrishnaswamyLab/graphtools/pull/18. MAGIC also returns an AnnData object containing the original `.obs` and (optionally subsetted) `.var` from the input. The `scanpy` API forces this to be a new `AnnData` if the genes are subsetted, allows modification in-place if all genes are returned, and adds the returned values to `.obsm['X_magic']` if the returned values are PCA on MAGIC. . @falexwolf let me know if this fits what you think the API should be.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/195
https://github.com/scverse/scanpy/pull/195:59,integrability,API,API,59,"Add new MAGIC API; Fix #187 and #193 . The bulk of the new API is contained within https://github.com/KrishnaswamyLab/MAGIC and https://github.com/KrishnaswamyLab/graphtools , both of which now natively accept AnnData as of https://github.com/KrishnaswamyLab/MAGIC/pull/116 and https://github.com/KrishnaswamyLab/graphtools/pull/18. MAGIC also returns an AnnData object containing the original `.obs` and (optionally subsetted) `.var` from the input. The `scanpy` API forces this to be a new `AnnData` if the genes are subsetted, allows modification in-place if all genes are returned, and adds the returned values to `.obsm['X_magic']` if the returned values are PCA on MAGIC. . @falexwolf let me know if this fits what you think the API should be.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/195
https://github.com/scverse/scanpy/pull/195:417,integrability,sub,subsetted,417,"Add new MAGIC API; Fix #187 and #193 . The bulk of the new API is contained within https://github.com/KrishnaswamyLab/MAGIC and https://github.com/KrishnaswamyLab/graphtools , both of which now natively accept AnnData as of https://github.com/KrishnaswamyLab/MAGIC/pull/116 and https://github.com/KrishnaswamyLab/graphtools/pull/18. MAGIC also returns an AnnData object containing the original `.obs` and (optionally subsetted) `.var` from the input. The `scanpy` API forces this to be a new `AnnData` if the genes are subsetted, allows modification in-place if all genes are returned, and adds the returned values to `.obsm['X_magic']` if the returned values are PCA on MAGIC. . @falexwolf let me know if this fits what you think the API should be.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/195
https://github.com/scverse/scanpy/pull/195:464,integrability,API,API,464,"Add new MAGIC API; Fix #187 and #193 . The bulk of the new API is contained within https://github.com/KrishnaswamyLab/MAGIC and https://github.com/KrishnaswamyLab/graphtools , both of which now natively accept AnnData as of https://github.com/KrishnaswamyLab/MAGIC/pull/116 and https://github.com/KrishnaswamyLab/graphtools/pull/18. MAGIC also returns an AnnData object containing the original `.obs` and (optionally subsetted) `.var` from the input. The `scanpy` API forces this to be a new `AnnData` if the genes are subsetted, allows modification in-place if all genes are returned, and adds the returned values to `.obsm['X_magic']` if the returned values are PCA on MAGIC. . @falexwolf let me know if this fits what you think the API should be.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/195
https://github.com/scverse/scanpy/pull/195:519,integrability,sub,subsetted,519,"Add new MAGIC API; Fix #187 and #193 . The bulk of the new API is contained within https://github.com/KrishnaswamyLab/MAGIC and https://github.com/KrishnaswamyLab/graphtools , both of which now natively accept AnnData as of https://github.com/KrishnaswamyLab/MAGIC/pull/116 and https://github.com/KrishnaswamyLab/graphtools/pull/18. MAGIC also returns an AnnData object containing the original `.obs` and (optionally subsetted) `.var` from the input. The `scanpy` API forces this to be a new `AnnData` if the genes are subsetted, allows modification in-place if all genes are returned, and adds the returned values to `.obsm['X_magic']` if the returned values are PCA on MAGIC. . @falexwolf let me know if this fits what you think the API should be.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/195
https://github.com/scverse/scanpy/pull/195:735,integrability,API,API,735,"Add new MAGIC API; Fix #187 and #193 . The bulk of the new API is contained within https://github.com/KrishnaswamyLab/MAGIC and https://github.com/KrishnaswamyLab/graphtools , both of which now natively accept AnnData as of https://github.com/KrishnaswamyLab/MAGIC/pull/116 and https://github.com/KrishnaswamyLab/graphtools/pull/18. MAGIC also returns an AnnData object containing the original `.obs` and (optionally subsetted) `.var` from the input. The `scanpy` API forces this to be a new `AnnData` if the genes are subsetted, allows modification in-place if all genes are returned, and adds the returned values to `.obsm['X_magic']` if the returned values are PCA on MAGIC. . @falexwolf let me know if this fits what you think the API should be.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/195
https://github.com/scverse/scanpy/pull/195:14,interoperability,API,API,14,"Add new MAGIC API; Fix #187 and #193 . The bulk of the new API is contained within https://github.com/KrishnaswamyLab/MAGIC and https://github.com/KrishnaswamyLab/graphtools , both of which now natively accept AnnData as of https://github.com/KrishnaswamyLab/MAGIC/pull/116 and https://github.com/KrishnaswamyLab/graphtools/pull/18. MAGIC also returns an AnnData object containing the original `.obs` and (optionally subsetted) `.var` from the input. The `scanpy` API forces this to be a new `AnnData` if the genes are subsetted, allows modification in-place if all genes are returned, and adds the returned values to `.obsm['X_magic']` if the returned values are PCA on MAGIC. . @falexwolf let me know if this fits what you think the API should be.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/195
https://github.com/scverse/scanpy/pull/195:59,interoperability,API,API,59,"Add new MAGIC API; Fix #187 and #193 . The bulk of the new API is contained within https://github.com/KrishnaswamyLab/MAGIC and https://github.com/KrishnaswamyLab/graphtools , both of which now natively accept AnnData as of https://github.com/KrishnaswamyLab/MAGIC/pull/116 and https://github.com/KrishnaswamyLab/graphtools/pull/18. MAGIC also returns an AnnData object containing the original `.obs` and (optionally subsetted) `.var` from the input. The `scanpy` API forces this to be a new `AnnData` if the genes are subsetted, allows modification in-place if all genes are returned, and adds the returned values to `.obsm['X_magic']` if the returned values are PCA on MAGIC. . @falexwolf let me know if this fits what you think the API should be.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/195
https://github.com/scverse/scanpy/pull/195:464,interoperability,API,API,464,"Add new MAGIC API; Fix #187 and #193 . The bulk of the new API is contained within https://github.com/KrishnaswamyLab/MAGIC and https://github.com/KrishnaswamyLab/graphtools , both of which now natively accept AnnData as of https://github.com/KrishnaswamyLab/MAGIC/pull/116 and https://github.com/KrishnaswamyLab/graphtools/pull/18. MAGIC also returns an AnnData object containing the original `.obs` and (optionally subsetted) `.var` from the input. The `scanpy` API forces this to be a new `AnnData` if the genes are subsetted, allows modification in-place if all genes are returned, and adds the returned values to `.obsm['X_magic']` if the returned values are PCA on MAGIC. . @falexwolf let me know if this fits what you think the API should be.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/195
https://github.com/scverse/scanpy/pull/195:735,interoperability,API,API,735,"Add new MAGIC API; Fix #187 and #193 . The bulk of the new API is contained within https://github.com/KrishnaswamyLab/MAGIC and https://github.com/KrishnaswamyLab/graphtools , both of which now natively accept AnnData as of https://github.com/KrishnaswamyLab/MAGIC/pull/116 and https://github.com/KrishnaswamyLab/graphtools/pull/18. MAGIC also returns an AnnData object containing the original `.obs` and (optionally subsetted) `.var` from the input. The `scanpy` API forces this to be a new `AnnData` if the genes are subsetted, allows modification in-place if all genes are returned, and adds the returned values to `.obsm['X_magic']` if the returned values are PCA on MAGIC. . @falexwolf let me know if this fits what you think the API should be.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/195
https://github.com/scverse/scanpy/pull/195:444,safety,input,input,444,"Add new MAGIC API; Fix #187 and #193 . The bulk of the new API is contained within https://github.com/KrishnaswamyLab/MAGIC and https://github.com/KrishnaswamyLab/graphtools , both of which now natively accept AnnData as of https://github.com/KrishnaswamyLab/MAGIC/pull/116 and https://github.com/KrishnaswamyLab/graphtools/pull/18. MAGIC also returns an AnnData object containing the original `.obs` and (optionally subsetted) `.var` from the input. The `scanpy` API forces this to be a new `AnnData` if the genes are subsetted, allows modification in-place if all genes are returned, and adds the returned values to `.obsm['X_magic']` if the returned values are PCA on MAGIC. . @falexwolf let me know if this fits what you think the API should be.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/195
https://github.com/scverse/scanpy/pull/195:537,security,modif,modification,537,"Add new MAGIC API; Fix #187 and #193 . The bulk of the new API is contained within https://github.com/KrishnaswamyLab/MAGIC and https://github.com/KrishnaswamyLab/graphtools , both of which now natively accept AnnData as of https://github.com/KrishnaswamyLab/MAGIC/pull/116 and https://github.com/KrishnaswamyLab/graphtools/pull/18. MAGIC also returns an AnnData object containing the original `.obs` and (optionally subsetted) `.var` from the input. The `scanpy` API forces this to be a new `AnnData` if the genes are subsetted, allows modification in-place if all genes are returned, and adds the returned values to `.obsm['X_magic']` if the returned values are PCA on MAGIC. . @falexwolf let me know if this fits what you think the API should be.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/195
https://github.com/scverse/scanpy/pull/195:444,usability,input,input,444,"Add new MAGIC API; Fix #187 and #193 . The bulk of the new API is contained within https://github.com/KrishnaswamyLab/MAGIC and https://github.com/KrishnaswamyLab/graphtools , both of which now natively accept AnnData as of https://github.com/KrishnaswamyLab/MAGIC/pull/116 and https://github.com/KrishnaswamyLab/graphtools/pull/18. MAGIC also returns an AnnData object containing the original `.obs` and (optionally subsetted) `.var` from the input. The `scanpy` API forces this to be a new `AnnData` if the genes are subsetted, allows modification in-place if all genes are returned, and adds the returned values to `.obsm['X_magic']` if the returned values are PCA on MAGIC. . @falexwolf let me know if this fits what you think the API should be.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/195
https://github.com/scverse/scanpy/issues/196:441,availability,error,error,441,"Converting a seurat object to anndata format; Hi, I left an issue to seurat repository as well, but it might be of interest for scanpy:. https://github.com/satijalab/seurat/issues/604#issue-339640125. In my systems, as long as it has `Seurat` and `scanpy` (or `anndata` to be more specific) installed, the above one-liner command to convert a merged seurat object to anndata fails within the anndata python code (with the index out of range error), in the `convert_dictionary_to_structured_array` module. I am not sure whether it is an issue with `Seurat` or `anndata`, but leaving here a link as well (actually curious whether the issue reproduces to anyone using the `scanpy`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/196
https://github.com/scverse/scanpy/issues/196:291,deployability,instal,installed,291,"Converting a seurat object to anndata format; Hi, I left an issue to seurat repository as well, but it might be of interest for scanpy:. https://github.com/satijalab/seurat/issues/604#issue-339640125. In my systems, as long as it has `Seurat` and `scanpy` (or `anndata` to be more specific) installed, the above one-liner command to convert a merged seurat object to anndata fails within the anndata python code (with the index out of range error), in the `convert_dictionary_to_structured_array` module. I am not sure whether it is an issue with `Seurat` or `anndata`, but leaving here a link as well (actually curious whether the issue reproduces to anyone using the `scanpy`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/196
https://github.com/scverse/scanpy/issues/196:375,deployability,fail,fails,375,"Converting a seurat object to anndata format; Hi, I left an issue to seurat repository as well, but it might be of interest for scanpy:. https://github.com/satijalab/seurat/issues/604#issue-339640125. In my systems, as long as it has `Seurat` and `scanpy` (or `anndata` to be more specific) installed, the above one-liner command to convert a merged seurat object to anndata fails within the anndata python code (with the index out of range error), in the `convert_dictionary_to_structured_array` module. I am not sure whether it is an issue with `Seurat` or `anndata`, but leaving here a link as well (actually curious whether the issue reproduces to anyone using the `scanpy`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/196
https://github.com/scverse/scanpy/issues/196:497,deployability,modul,module,497,"Converting a seurat object to anndata format; Hi, I left an issue to seurat repository as well, but it might be of interest for scanpy:. https://github.com/satijalab/seurat/issues/604#issue-339640125. In my systems, as long as it has `Seurat` and `scanpy` (or `anndata` to be more specific) installed, the above one-liner command to convert a merged seurat object to anndata fails within the anndata python code (with the index out of range error), in the `convert_dictionary_to_structured_array` module. I am not sure whether it is an issue with `Seurat` or `anndata`, but leaving here a link as well (actually curious whether the issue reproduces to anyone using the `scanpy`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/196
https://github.com/scverse/scanpy/issues/196:76,integrability,repositor,repository,76,"Converting a seurat object to anndata format; Hi, I left an issue to seurat repository as well, but it might be of interest for scanpy:. https://github.com/satijalab/seurat/issues/604#issue-339640125. In my systems, as long as it has `Seurat` and `scanpy` (or `anndata` to be more specific) installed, the above one-liner command to convert a merged seurat object to anndata fails within the anndata python code (with the index out of range error), in the `convert_dictionary_to_structured_array` module. I am not sure whether it is an issue with `Seurat` or `anndata`, but leaving here a link as well (actually curious whether the issue reproduces to anyone using the `scanpy`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/196
https://github.com/scverse/scanpy/issues/196:38,interoperability,format,format,38,"Converting a seurat object to anndata format; Hi, I left an issue to seurat repository as well, but it might be of interest for scanpy:. https://github.com/satijalab/seurat/issues/604#issue-339640125. In my systems, as long as it has `Seurat` and `scanpy` (or `anndata` to be more specific) installed, the above one-liner command to convert a merged seurat object to anndata fails within the anndata python code (with the index out of range error), in the `convert_dictionary_to_structured_array` module. I am not sure whether it is an issue with `Seurat` or `anndata`, but leaving here a link as well (actually curious whether the issue reproduces to anyone using the `scanpy`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/196
https://github.com/scverse/scanpy/issues/196:76,interoperability,repositor,repository,76,"Converting a seurat object to anndata format; Hi, I left an issue to seurat repository as well, but it might be of interest for scanpy:. https://github.com/satijalab/seurat/issues/604#issue-339640125. In my systems, as long as it has `Seurat` and `scanpy` (or `anndata` to be more specific) installed, the above one-liner command to convert a merged seurat object to anndata fails within the anndata python code (with the index out of range error), in the `convert_dictionary_to_structured_array` module. I am not sure whether it is an issue with `Seurat` or `anndata`, but leaving here a link as well (actually curious whether the issue reproduces to anyone using the `scanpy`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/196
https://github.com/scverse/scanpy/issues/196:281,interoperability,specif,specific,281,"Converting a seurat object to anndata format; Hi, I left an issue to seurat repository as well, but it might be of interest for scanpy:. https://github.com/satijalab/seurat/issues/604#issue-339640125. In my systems, as long as it has `Seurat` and `scanpy` (or `anndata` to be more specific) installed, the above one-liner command to convert a merged seurat object to anndata fails within the anndata python code (with the index out of range error), in the `convert_dictionary_to_structured_array` module. I am not sure whether it is an issue with `Seurat` or `anndata`, but leaving here a link as well (actually curious whether the issue reproduces to anyone using the `scanpy`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/196
https://github.com/scverse/scanpy/issues/196:497,modifiability,modul,module,497,"Converting a seurat object to anndata format; Hi, I left an issue to seurat repository as well, but it might be of interest for scanpy:. https://github.com/satijalab/seurat/issues/604#issue-339640125. In my systems, as long as it has `Seurat` and `scanpy` (or `anndata` to be more specific) installed, the above one-liner command to convert a merged seurat object to anndata fails within the anndata python code (with the index out of range error), in the `convert_dictionary_to_structured_array` module. I am not sure whether it is an issue with `Seurat` or `anndata`, but leaving here a link as well (actually curious whether the issue reproduces to anyone using the `scanpy`)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/196
