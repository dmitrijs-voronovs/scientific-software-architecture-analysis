id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/issues/990:1065,interoperability,conflict,conflicts,1065,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1116,interoperability,conflict,conflicts,1116,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1170,interoperability,conflict,conflicts,1170,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1225,interoperability,conflict,conflicts,1225,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1277,interoperability,conflict,conflicts,1277,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1371,interoperability,conflict,conflicts,1371,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1444,interoperability,conflict,conflicts,1444,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1520,interoperability,conflict,conflicts,1520,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1567,interoperability,conflict,conflicts,1567,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1638,interoperability,conflict,conflicts,1638,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1709,interoperability,conflict,conflicts,1709,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1758,interoperability,conflict,conflicts,1758,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1808,interoperability,conflict,conflicts,1808,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1896,interoperability,conflict,conflicts,1896,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1957,interoperability,conflict,conflicts,1957,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:153,modifiability,pac,package,153,"scanpy conda installation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:320,modifiability,pac,package,320,"scanpy conda installation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:427,modifiability,pac,packages,427,"scanpy conda installation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:597,modifiability,Pac,Package,597,"scanpy conda installation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:643,modifiability,version,version,643,"scanpy conda installation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:664,modifiability,Pac,Package,664,"scanpy conda installation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:720,modifiability,version,version,720,"scanpy conda installation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:744,modifiability,Pac,Package,744,"scanpy conda installation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:797,modifiability,Pac,Package,797,"scanpy conda installation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:850,modifiability,Pac,Package,850,"scanpy conda installation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:896,modifiability,version,version,896,"scanpy conda installation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:919,modifiability,Pac,Package,919,"scanpy conda installation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:979,modifiability,version,version,979,"scanpy conda installation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1000,modifiability,Pac,Package,1000,"py conda installation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1049,modifiability,Pac,Package,1049,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1100,modifiability,Pac,Package,1100,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1151,modifiability,Pac,Package,1151,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1208,modifiability,Pac,Package,1208,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1261,modifiability,Pac,Package,1261,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1311,modifiability,version,version,1311,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1344,modifiability,Pac,Package,1344,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1417,modifiability,Pac,Package,1417,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1489,modifiability,version,version,1489,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1507,modifiability,Pac,Package,1507,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1552,modifiability,Pac,Package,1552,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1600,modifiability,version,version,1600,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1619,modifiability,Pac,Package,1619,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1675,modifiability,version,version,1675,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1695,modifiability,Pac,Package,1695,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1742,modifiability,Pac,Package,1742,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1793,modifiability,Pac,Package,1793,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1841,modifiability,version,version,1841,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1874,modifiability,Pac,Package,1874,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1937,modifiability,Pac,Package,1937,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1995,modifiability,version,version,1995,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:26,performance,error,error,26,"scanpy conda installation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:805,performance,network,networkx,805,"scanpy conda installation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:840,performance,network,networkx,840,"scanpy conda installation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:222,reliability,fail,failed,222,"scanpy conda installation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:491,reliability,fail,failed,491,"scanpy conda installation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:26,safety,error,error,26,"scanpy conda installation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:805,security,network,networkx,805,"scanpy conda installation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:840,security,network,networkx,840,"scanpy conda installation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:26,usability,error,error,26,"scanpy conda installation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:934,usability,learn,learn,934,"scanpy conda installation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:973,usability,learn,learn,973,"scanpy conda installation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[versi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1632,usability,learn,learn,1632,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/990:1669,usability,learn,learn,1669,"llation error; I cannot install scanpy successfully. (conda v. 4.7.12). $ conda create -n scanpy_scRNA -c bioconda scanpy . Collecting package metadata (current_repodata.json): done. Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source. Collecting package metadata (repodata.json): done. Solving environment: / . Found conflicts! Looking for incompatible packages. This can take several minutes. Press CTRL-C to abort. failed . UnsatisfiableError: The following specifications were found to be incompatible with each other:. Package numba conflicts for:. scanpy -> numba[version='>=0.41.0']. Package matplotlib conflicts for:. scanpy -> matplotlib[version='3.0.*|>=2.2']. Package h5py conflicts for:. scanpy -> h5py!=2.10.0. Package networkx conflicts for:. scanpy -> networkx. Package scipy conflicts for:. scanpy -> scipy[version='<1.3|>=1.3']. Package scikit-learn conflicts for:. scanpy -> scikit-learn[version='>=0.21.2']. Package joblib conflicts for:. scanpy -> joblib. Package natsort conflicts for:. scanpy -> natsort. Package seaborn conflicts for:. scanpy -> seaborn. Package setuptools conflicts for:. scanpy -> setuptools. Package pytables conflicts for:. scanpy -> pytables. Package anndata conflicts for:. scanpy -> anndata[version='>=0.6.10|>=0.6.22rc1']. Package importlib-metadata conflicts for:. scanpy -> importlib-metadata. Package importlib_metadata conflicts for:. scanpy -> importlib_metadata[version='>=0.7']. Package tqdm conflicts for:. scanpy -> tqdm. Package pandas conflicts for:. scanpy -> pandas[version='>=0.21']. Package umap-learn conflicts for:. scanpy -> umap-learn[version='>=0.3.0']. Package patsy conflicts for:. scanpy -> patsy. Package louvain conflicts for:. scanpy -> louvain. Package python conflicts for:. scanpy -> python[version='>=3.6|>=3.6,<3.7.0a0']. Package python-igraph conflicts for:. scanpy -> python-igraph. Package statsmodels conflicts for:. scanpy -> statsmodels[version='>=0.10.0rc2'].",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/990
https://github.com/scverse/scanpy/issues/991:40,deployability,upgrad,upgrading,40,PCA analysis doesn't look correct after upgrading; . ![image (10)](https://user-images.githubusercontent.com/25906087/72300922-09d19080-361a-11ea-8834-0cdc35b7b367.png). The PCs are no longer in order after upgrading to v.1.4.5.post1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/991
https://github.com/scverse/scanpy/issues/991:207,deployability,upgrad,upgrading,207,PCA analysis doesn't look correct after upgrading; . ![image (10)](https://user-images.githubusercontent.com/25906087/72300922-09d19080-361a-11ea-8834-0cdc35b7b367.png). The PCs are no longer in order after upgrading to v.1.4.5.post1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/991
https://github.com/scverse/scanpy/issues/991:40,modifiability,upgrad,upgrading,40,PCA analysis doesn't look correct after upgrading; . ![image (10)](https://user-images.githubusercontent.com/25906087/72300922-09d19080-361a-11ea-8834-0cdc35b7b367.png). The PCs are no longer in order after upgrading to v.1.4.5.post1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/991
https://github.com/scverse/scanpy/issues/991:207,modifiability,upgrad,upgrading,207,PCA analysis doesn't look correct after upgrading; . ![image (10)](https://user-images.githubusercontent.com/25906087/72300922-09d19080-361a-11ea-8834-0cdc35b7b367.png). The PCs are no longer in order after upgrading to v.1.4.5.post1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/991
https://github.com/scverse/scanpy/issues/991:13,reliability,doe,doesn,13,PCA analysis doesn't look correct after upgrading; . ![image (10)](https://user-images.githubusercontent.com/25906087/72300922-09d19080-361a-11ea-8834-0cdc35b7b367.png). The PCs are no longer in order after upgrading to v.1.4.5.post1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/991
https://github.com/scverse/scanpy/issues/991:75,usability,user,user-images,75,PCA analysis doesn't look correct after upgrading; . ![image (10)](https://user-images.githubusercontent.com/25906087/72300922-09d19080-361a-11ea-8834-0cdc35b7b367.png). The PCs are no longer in order after upgrading to v.1.4.5.post1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/991
https://github.com/scverse/scanpy/issues/992:37,integrability,batch,batch,37,scanpy.pp.filter_genes should have a batch key option; It would be great if `scanpy.pp.filter_genes` had a batch key option so that options like `min_counts` were taken with respect to each batch.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/992
https://github.com/scverse/scanpy/issues/992:107,integrability,batch,batch,107,scanpy.pp.filter_genes should have a batch key option; It would be great if `scanpy.pp.filter_genes` had a batch key option so that options like `min_counts` were taken with respect to each batch.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/992
https://github.com/scverse/scanpy/issues/992:190,integrability,batch,batch,190,scanpy.pp.filter_genes should have a batch key option; It would be great if `scanpy.pp.filter_genes` had a batch key option so that options like `min_counts` were taken with respect to each batch.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/992
https://github.com/scverse/scanpy/issues/992:37,performance,batch,batch,37,scanpy.pp.filter_genes should have a batch key option; It would be great if `scanpy.pp.filter_genes` had a batch key option so that options like `min_counts` were taken with respect to each batch.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/992
https://github.com/scverse/scanpy/issues/992:107,performance,batch,batch,107,scanpy.pp.filter_genes should have a batch key option; It would be great if `scanpy.pp.filter_genes` had a batch key option so that options like `min_counts` were taken with respect to each batch.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/992
https://github.com/scverse/scanpy/issues/992:190,performance,batch,batch,190,scanpy.pp.filter_genes should have a batch key option; It would be great if `scanpy.pp.filter_genes` had a batch key option so that options like `min_counts` were taken with respect to each batch.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/992
https://github.com/scverse/scanpy/issues/993:255,deployability,log,log-transformed,255,"Seurat v3 VST highly variable gene method; I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:497,deployability,api,api,497,"Seurat v3 VST highly variable gene method; I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:451,energy efficiency,model,models,451,"Seurat v3 VST highly variable gene method; I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:259,integrability,transform,transformed,259,"Seurat v3 VST highly variable gene method; I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:497,integrability,api,api,497,"Seurat v3 VST highly variable gene method; I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:633,integrability,batch,batch,633,"Seurat v3 VST highly variable gene method; I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:695,integrability,batch,batch,695,"Seurat v3 VST highly variable gene method; I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:765,integrability,batch,batch,765,"Seurat v3 VST highly variable gene method; I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:799,integrability,batch,batch,799,"Seurat v3 VST highly variable gene method; I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:865,integrability,batch,batch,865,"Seurat v3 VST highly variable gene method; I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:1189,integrability,batch,batch,1189," that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median_variance""] = median_norm_gene_vars. df.sort_values(. [""highly_variable_n_batches"", ""highly_variable_median_rank""],. ascending=False,. na_position=""last"",. inplace=True,. ). df[""highly_variabl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:1351,integrability,batch,batch,1351,"dding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median_variance""] = median_norm_gene_vars. df.sort_values(. [""highly_variable_n_batches"", ""highly_variable_median_rank""],. ascending=False,. na_position=""last"",. inplace=True,. ). df[""highly_variable""] = False. df.loc[:n_top_genes, ""highly_variable""] = True. df = df.loc[adata.var_names]. if del_batch is True:. del adata.obs[""batch""]. adata.var[""highly_variab",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:2321,integrability,batch,batch,2321," b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median_variance""] = median_norm_gene_vars. df.sort_values(. [""highly_variable_n_batches"", ""highly_variable_median_rank""],. ascending=False,. na_position=""last"",. inplace=True,. ). df[""highly_variable""] = False. df.loc[:n_top_genes, ""highly_variable""] = True. df = df.loc[adata.var_names]. if del_batch is True:. del adata.obs[""batch""]. adata.var[""highly_variable""] = df[""highly_variable""].values. adata.var[""highly_variable_n_batches""] = df[""highly_variable_n_batches""].values. adata.var[""highly_variable_median_variance""] = df[. ""highly_variable_median_variance"". ].values. def loess(y, x, span=0.3):. from rpy2.robjects import r. import rpy2.robjects as robjects. a, b = robjects.FloatVector(x), robjects.FloatVector(y). df = robjects.DataFrame({""a"": a, ""b"": b}). loess_fit = r.loess(""b ~ a"", data=df, span=span). return np.array(loess_fit[loess_fit.names.index(""fitted"")]). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:259,interoperability,transform,transformed,259,"Seurat v3 VST highly variable gene method; I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:497,interoperability,api,api,497,"Seurat v3 VST highly variable gene method; I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:21,modifiability,variab,variable,21,"Seurat v3 VST highly variable gene method; I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:633,performance,batch,batch,633,"Seurat v3 VST highly variable gene method; I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:695,performance,batch,batch,695,"Seurat v3 VST highly variable gene method; I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:765,performance,batch,batch,765,"Seurat v3 VST highly variable gene method; I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:799,performance,batch,batch,799,"Seurat v3 VST highly variable gene method; I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:865,performance,batch,batch,865,"Seurat v3 VST highly variable gene method; I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:1189,performance,batch,batch,1189," that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median_variance""] = median_norm_gene_vars. df.sort_values(. [""highly_variable_n_batches"", ""highly_variable_median_rank""],. ascending=False,. na_position=""last"",. inplace=True,. ). df[""highly_variabl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:1351,performance,batch,batch,1351,"dding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median_variance""] = median_norm_gene_vars. df.sort_values(. [""highly_variable_n_batches"", ""highly_variable_median_rank""],. ascending=False,. na_position=""last"",. inplace=True,. ). df[""highly_variable""] = False. df.loc[:n_top_genes, ""highly_variable""] = True. df = df.loc[adata.var_names]. if del_batch is True:. del adata.obs[""batch""]. adata.var[""highly_variab",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:2321,performance,batch,batch,2321," b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median_variance""] = median_norm_gene_vars. df.sort_values(. [""highly_variable_n_batches"", ""highly_variable_median_rank""],. ascending=False,. na_position=""last"",. inplace=True,. ). df[""highly_variable""] = False. df.loc[:n_top_genes, ""highly_variable""] = True. df = df.loc[adata.var_names]. if del_batch is True:. del adata.obs[""batch""]. adata.var[""highly_variable""] = df[""highly_variable""].values. adata.var[""highly_variable_n_batches""] = df[""highly_variable_n_batches""].values. adata.var[""highly_variable_median_variance""] = df[. ""highly_variable_median_variance"". ].values. def loess(y, x, span=0.3):. from rpy2.robjects import r. import rpy2.robjects as robjects. a, b = robjects.FloatVector(x), robjects.FloatVector(y). df = robjects.DataFrame({""a"": a, ""b"": b}). loess_fit = r.loess(""b ~ a"", data=df, span=span). return np.array(loess_fit[loess_fit.names.index(""fitted"")]). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:139,safety,test,tests,139,"Seurat v3 VST highly variable gene method; I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:255,safety,log,log-transformed,255,"Seurat v3 VST highly variable gene method; I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:255,security,log,log-transformed,255,"Seurat v3 VST highly variable gene method; I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:451,security,model,models,451,"Seurat v3 VST highly variable gene method; I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:139,testability,test,tests,139,"Seurat v3 VST highly variable gene method; I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:255,testability,log,log-transformed,255,"Seurat v3 VST highly variable gene method; I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:337,testability,understand,understand,337,"Seurat v3 VST highly variable gene method; I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/issues/993:416,usability,close,close,416,"Seurat v3 VST highly variable gene method; I find this method to be the most conceptually straightforward and it gives great results in my tests. I have a rough implementation in python. I see that making a PR would be more involved as the code relies on log-transformed data, while the Seurat method should be on the raw counts. I also understand that adding `rpy2` to scanpy could be a bit challenging so I have a close approximation with the stats models library. ```python. import statsmodels.api as sm. def seurat_v3_highly_variable_genes(adata, n_top_genes=4000, use_lowess=False):. norm_gene_vars = []. del_batch = False. if ""batch"" not in adata.obs_keys():. del_batch = True. adata.obs[""batch""] = np.zeros((adata.X.shape[0])). for b in np.unique(adata.obs[""batch""]):. var = adata[adata.obs[""batch""] == b].X.var(0). print(var.shape). mean = adata[adata.obs[""batch""] == b].X.mean(0). estimat_var = np.zeros((adata.X.shape[1])). y = np.log10(var). x = np.log10(mean). if use_lowess is True:. lowess = sm.nonparametric.lowess. # output is sorted by x. v = lowess(y, x, frac=0.15). estimat_var[np.argsort(x)] = v[:, 1]. else:. estimat_var = loess(y, x). norm_values = (adata[adata.obs[""batch""] == b].X - mean) / np.sqrt(10 ** estimat_var). # as in seurat paper, clip max values. norm_values = np.clip(. norm_values, None, np.sqrt(np.sum(adata.obs[""batch""] == b)). ). norm_gene_var = norm_values.var(0). norm_gene_vars.append(norm_gene_var.reshape(1, -1)). norm_gene_vars = np.concatenate(norm_gene_vars, axis=0). ranked_norm_gene_vars = np.argsort(np.argsort(norm_gene_vars, axis=1), axis=1). median_norm_gene_vars = np.median(norm_gene_vars, axis=0). median_ranked = np.median(ranked_norm_gene_vars, axis=0). num_batches_high_var = np.sum(. ranked_norm_gene_vars >= (adata.X.shape[1] - n_top_genes), axis=0. ). df = pd.DataFrame(index=np.array(adata.var_names)). df[""highly_variable_n_batches""] = num_batches_high_var. df[""highly_variable_median_rank""] = median_ranked. df[""highly_variable_median",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/993
https://github.com/scverse/scanpy/pull/994:49,performance,time,time,49,"Harmony_timeseries - connects data from discrete time points; Harmony_timeseries, a framework for connecting scRNA-seq data from discrete time points",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/994
https://github.com/scverse/scanpy/pull/994:138,performance,time,time,138,"Harmony_timeseries - connects data from discrete time points; Harmony_timeseries, a framework for connecting scRNA-seq data from discrete time points",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/994
https://github.com/scverse/scanpy/issues/995:33,deployability,contain,contained,33,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:302,deployability,instal,installs,302,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:483,deployability,Version,Version,483,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:611,deployability,modul,module,611,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:483,integrability,Version,Version,483,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:1864,integrability,wrap,wrapper,1864,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:1935,integrability,wrap,wrapper,1935,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:1864,interoperability,wrapper,wrapper,1864,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:1935,interoperability,wrapper,wrapper,1935,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:55,modifiability,pac,package,55,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:483,modifiability,Version,Version,483,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:611,modifiability,modul,module,611,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:672,modifiability,pac,packages,672,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:816,modifiability,pac,packages,816,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:929,modifiability,pac,packages,929,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:1075,modifiability,pac,packages,1075,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:1271,modifiability,pac,packages,1271,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:1425,modifiability,pac,packages,1425,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:1545,modifiability,pac,packages,1545,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:1710,modifiability,pac,packages,1710,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:611,safety,modul,module,611,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:547,testability,Trace,Traceback,547,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:159,usability,experien,experienced,159,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:627,usability,User,Users,627,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:771,usability,User,Users,771,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:884,usability,User,Users,884,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:1030,usability,User,Users,1030,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:1226,usability,User,Users,1226,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:1380,usability,User,Users,1380,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:1500,usability,User,Users,1500,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/995:1665,usability,User,Users,1665,"`datasets.pbmc68k_reduced` isn't contained in the pypi package anymore; This still works in `1.4.4.post1`. It's very likely caused by changes to `setup.py`. I experienced similar problems before and fixed them via `package_data`. But this got removed. It's probably only a problem for the source-based installs. https://github.com/theislab/scanpy/commit/881f0bef31cdfe0df7333641dc847a60894b5c41#diff-2eeaed663bd0d25b7e608891384b7298. ```. >>> import scanpy. >>> scanpy.__version__. <Version('1.4.5.post2')>. >>> scanpy.datasets.pbmc68k_reduced(). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/datasets/__init__.py"", line 239, in pbmc68k_reduced. return read(filename). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 114, in read. **kwargs,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/scanpy/readwrite.py"", line 524, in _read. return read_h5ad(filename, backed=backed). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 447, in read_h5ad. constructor_args = _read_args_from_h5ad(filename=filename, chunk_size=chunk_size). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/readwrite/read.py"", line 481, in _read_args_from_h5ad. f = h5py.File(filename, 'r'). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/anndata/h5py/h5sparse.py"", line 162, in __init__. **kwds,. File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 312, in __init__. fid = make_fid(name, mode, userblock_size, fapl, swmr=swmr). File ""/Users/alexwolf/miniconda3/lib/python3.6/site-packages/h5py/_hl/files.py"", line 142, in make_fid. fid = h5f.open(name, flags, fapl=fapl). File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper. File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper. File ""h5py/h5f.pyx"", line 78, in h5py.h5f.open. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/995
https://github.com/scverse/scanpy/issues/996:8,deployability,integr,integration,8,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:784,deployability,integr,integrate,784,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:847,deployability,integr,integrating,847,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:8,integrability,integr,integration,8,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:759,integrability,wrap,wrapping,759,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:784,integrability,integr,integrate,784,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:847,integrability,integr,integrating,847,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:8,interoperability,integr,integration,8,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:784,interoperability,integr,integrate,784,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:847,interoperability,integr,integrating,847,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:8,modifiability,integr,integration,8,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:106,modifiability,paramet,parameters,106,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:383,modifiability,pac,package,383,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:784,modifiability,integr,integrate,784,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:847,modifiability,integr,integrating,847,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:8,reliability,integr,integration,8,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:784,reliability,integr,integrate,784,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:847,reliability,integr,integrating,847,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:8,security,integr,integration,8,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:784,security,integr,integrate,784,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:847,security,integr,integrating,847,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:8,testability,integr,integration,8,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:188,testability,simpl,simple,188,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:784,testability,integr,integrate,784,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:847,testability,integr,integrating,847,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:180,usability,tool,tool,180,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:188,usability,simpl,simple,188,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:204,usability,tool,tool,204,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:252,usability,tool,tools,252,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/issues/996:352,usability,tool,tools,352,"FIt-SNE integration?; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ... Hi! We're considering implementing some of the t-SNE recommendations in https://www.nature.com/articles/s41467-019-13056-x for our single-cell analysis. They use a different t-SNE implementation (https://github.com/KlugerLab/FIt-SNE), and before I ran off doing my own wrapping and plumbing to integrate with Scanpy I thought I'd check: have you considered integrating this yourselves? Thanks! Jon",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/996
https://github.com/scverse/scanpy/pull/997:45,deployability,instal,install,45,Use include_package_data=True again; To make install from source tarball work. Fixes #995. @falexwolf can you check if it works for you now?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/997
https://github.com/scverse/scanpy/issues/998:303,reliability,doe,does,303,"No grouping lines at top of dotplot; In the tutorial there are lines grouping the genes at the top of the dotplot. <img width=""667"" alt=""Screen Shot 2020-01-15 at 11 47 42 AM"" src=""https://user-images.githubusercontent.com/10859440/72465969-eb3fd680-378c-11ea-925a-4f6b9f8039ed.png"">. A minimal example does not generate those lines... ![Screen Shot 2020-01-15 at 11 44 30 AM](https://user-images.githubusercontent.com/10859440/72465706-81bfc800-378c-11ea-9700-f2e4b4b69eac.png). ```python. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.3.1 pandas==0.25.1 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1. matplotlib==3.0.3. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/998
https://github.com/scverse/scanpy/issues/998:189,usability,user,user-images,189,"No grouping lines at top of dotplot; In the tutorial there are lines grouping the genes at the top of the dotplot. <img width=""667"" alt=""Screen Shot 2020-01-15 at 11 47 42 AM"" src=""https://user-images.githubusercontent.com/10859440/72465969-eb3fd680-378c-11ea-925a-4f6b9f8039ed.png"">. A minimal example does not generate those lines... ![Screen Shot 2020-01-15 at 11 44 30 AM](https://user-images.githubusercontent.com/10859440/72465706-81bfc800-378c-11ea-9700-f2e4b4b69eac.png). ```python. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.3.1 pandas==0.25.1 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1. matplotlib==3.0.3. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/998
https://github.com/scverse/scanpy/issues/998:287,usability,minim,minimal,287,"No grouping lines at top of dotplot; In the tutorial there are lines grouping the genes at the top of the dotplot. <img width=""667"" alt=""Screen Shot 2020-01-15 at 11 47 42 AM"" src=""https://user-images.githubusercontent.com/10859440/72465969-eb3fd680-378c-11ea-925a-4f6b9f8039ed.png"">. A minimal example does not generate those lines... ![Screen Shot 2020-01-15 at 11 44 30 AM](https://user-images.githubusercontent.com/10859440/72465706-81bfc800-378c-11ea-9700-f2e4b4b69eac.png). ```python. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.3.1 pandas==0.25.1 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1. matplotlib==3.0.3. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/998
https://github.com/scverse/scanpy/issues/998:385,usability,user,user-images,385,"No grouping lines at top of dotplot; In the tutorial there are lines grouping the genes at the top of the dotplot. <img width=""667"" alt=""Screen Shot 2020-01-15 at 11 47 42 AM"" src=""https://user-images.githubusercontent.com/10859440/72465969-eb3fd680-378c-11ea-925a-4f6b9f8039ed.png"">. A minimal example does not generate those lines... ![Screen Shot 2020-01-15 at 11 44 30 AM](https://user-images.githubusercontent.com/10859440/72465706-81bfc800-378c-11ea-9700-f2e4b4b69eac.png). ```python. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.3.1 pandas==0.25.1 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1. matplotlib==3.0.3. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/998
https://github.com/scverse/scanpy/issues/998:595,usability,learn,learn,595,"No grouping lines at top of dotplot; In the tutorial there are lines grouping the genes at the top of the dotplot. <img width=""667"" alt=""Screen Shot 2020-01-15 at 11 47 42 AM"" src=""https://user-images.githubusercontent.com/10859440/72465969-eb3fd680-378c-11ea-925a-4f6b9f8039ed.png"">. A minimal example does not generate those lines... ![Screen Shot 2020-01-15 at 11 44 30 AM](https://user-images.githubusercontent.com/10859440/72465706-81bfc800-378c-11ea-9700-f2e4b4b69eac.png). ```python. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.3.1 pandas==0.25.1 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1. matplotlib==3.0.3. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/998
https://github.com/scverse/scanpy/issues/999:651,availability,Error,Error,651,"gene find with visualization functions but not with subsetting; <!-- Please give a clear and concise description of what the bug is: -->. I am looking for the expression of 'NCAM1'. It works when I am plotting my data (umap, violin plot, matrix plot) but I cant find it in the adata.var and I am not able to subset adata for this particular gene while it is working with the other genes. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. #what works:. marker_genes = ['NCAM1']. ax = sc.pl.violin(adata, marker_genes, groupby='timepoint'). # what doesnt work:. subset_NCAM = adata[:, 'NCAM1']. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ""None of [Index(['NCAM1'], dtype='object', name='index')] are in the [index]"". #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > 1.4.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/999
https://github.com/scverse/scanpy/issues/999:812,deployability,Version,Versions,812,"gene find with visualization functions but not with subsetting; <!-- Please give a clear and concise description of what the bug is: -->. I am looking for the expression of 'NCAM1'. It works when I am plotting my data (umap, violin plot, matrix plot) but I cant find it in the adata.var and I am not able to subset adata for this particular gene while it is working with the other genes. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. #what works:. marker_genes = ['NCAM1']. ax = sc.pl.violin(adata, marker_genes, groupby='timepoint'). # what doesnt work:. subset_NCAM = adata[:, 'NCAM1']. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ""None of [Index(['NCAM1'], dtype='object', name='index')] are in the [index]"". #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > 1.4.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/999
https://github.com/scverse/scanpy/issues/999:845,deployability,log,logging,845,"gene find with visualization functions but not with subsetting; <!-- Please give a clear and concise description of what the bug is: -->. I am looking for the expression of 'NCAM1'. It works when I am plotting my data (umap, violin plot, matrix plot) but I cant find it in the adata.var and I am not able to subset adata for this particular gene while it is working with the other genes. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. #what works:. marker_genes = ['NCAM1']. ax = sc.pl.violin(adata, marker_genes, groupby='timepoint'). # what doesnt work:. subset_NCAM = adata[:, 'NCAM1']. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ""None of [Index(['NCAM1'], dtype='object', name='index')] are in the [index]"". #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > 1.4.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/999
https://github.com/scverse/scanpy/issues/999:52,integrability,sub,subsetting,52,"gene find with visualization functions but not with subsetting; <!-- Please give a clear and concise description of what the bug is: -->. I am looking for the expression of 'NCAM1'. It works when I am plotting my data (umap, violin plot, matrix plot) but I cant find it in the adata.var and I am not able to subset adata for this particular gene while it is working with the other genes. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. #what works:. marker_genes = ['NCAM1']. ax = sc.pl.violin(adata, marker_genes, groupby='timepoint'). # what doesnt work:. subset_NCAM = adata[:, 'NCAM1']. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ""None of [Index(['NCAM1'], dtype='object', name='index')] are in the [index]"". #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > 1.4.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/999
https://github.com/scverse/scanpy/issues/999:308,integrability,sub,subset,308,"gene find with visualization functions but not with subsetting; <!-- Please give a clear and concise description of what the bug is: -->. I am looking for the expression of 'NCAM1'. It works when I am plotting my data (umap, violin plot, matrix plot) but I cant find it in the adata.var and I am not able to subset adata for this particular gene while it is working with the other genes. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. #what works:. marker_genes = ['NCAM1']. ax = sc.pl.violin(adata, marker_genes, groupby='timepoint'). # what doesnt work:. subset_NCAM = adata[:, 'NCAM1']. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ""None of [Index(['NCAM1'], dtype='object', name='index')] are in the [index]"". #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > 1.4.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/999
https://github.com/scverse/scanpy/issues/999:812,integrability,Version,Versions,812,"gene find with visualization functions but not with subsetting; <!-- Please give a clear and concise description of what the bug is: -->. I am looking for the expression of 'NCAM1'. It works when I am plotting my data (umap, violin plot, matrix plot) but I cant find it in the adata.var and I am not able to subset adata for this particular gene while it is working with the other genes. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. #what works:. marker_genes = ['NCAM1']. ax = sc.pl.violin(adata, marker_genes, groupby='timepoint'). # what doesnt work:. subset_NCAM = adata[:, 'NCAM1']. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ""None of [Index(['NCAM1'], dtype='object', name='index')] are in the [index]"". #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > 1.4.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/999
https://github.com/scverse/scanpy/issues/999:812,modifiability,Version,Versions,812,"gene find with visualization functions but not with subsetting; <!-- Please give a clear and concise description of what the bug is: -->. I am looking for the expression of 'NCAM1'. It works when I am plotting my data (umap, violin plot, matrix plot) but I cant find it in the adata.var and I am not able to subset adata for this particular gene while it is working with the other genes. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. #what works:. marker_genes = ['NCAM1']. ax = sc.pl.violin(adata, marker_genes, groupby='timepoint'). # what doesnt work:. subset_NCAM = adata[:, 'NCAM1']. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ""None of [Index(['NCAM1'], dtype='object', name='index')] are in the [index]"". #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > 1.4.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/999
https://github.com/scverse/scanpy/issues/999:570,performance,time,timepoint,570,"gene find with visualization functions but not with subsetting; <!-- Please give a clear and concise description of what the bug is: -->. I am looking for the expression of 'NCAM1'. It works when I am plotting my data (umap, violin plot, matrix plot) but I cant find it in the adata.var and I am not able to subset adata for this particular gene while it is working with the other genes. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. #what works:. marker_genes = ['NCAM1']. ax = sc.pl.violin(adata, marker_genes, groupby='timepoint'). # what doesnt work:. subset_NCAM = adata[:, 'NCAM1']. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ""None of [Index(['NCAM1'], dtype='object', name='index')] are in the [index]"". #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > 1.4.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/999
https://github.com/scverse/scanpy/issues/999:651,performance,Error,Error,651,"gene find with visualization functions but not with subsetting; <!-- Please give a clear and concise description of what the bug is: -->. I am looking for the expression of 'NCAM1'. It works when I am plotting my data (umap, violin plot, matrix plot) but I cant find it in the adata.var and I am not able to subset adata for this particular gene while it is working with the other genes. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. #what works:. marker_genes = ['NCAM1']. ax = sc.pl.violin(adata, marker_genes, groupby='timepoint'). # what doesnt work:. subset_NCAM = adata[:, 'NCAM1']. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ""None of [Index(['NCAM1'], dtype='object', name='index')] are in the [index]"". #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > 1.4.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/999
https://github.com/scverse/scanpy/issues/999:590,reliability,doe,doesnt,590,"gene find with visualization functions but not with subsetting; <!-- Please give a clear and concise description of what the bug is: -->. I am looking for the expression of 'NCAM1'. It works when I am plotting my data (umap, violin plot, matrix plot) but I cant find it in the adata.var and I am not able to subset adata for this particular gene while it is working with the other genes. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. #what works:. marker_genes = ['NCAM1']. ax = sc.pl.violin(adata, marker_genes, groupby='timepoint'). # what doesnt work:. subset_NCAM = adata[:, 'NCAM1']. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ""None of [Index(['NCAM1'], dtype='object', name='index')] are in the [index]"". #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > 1.4.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/999
https://github.com/scverse/scanpy/issues/999:651,safety,Error,Error,651,"gene find with visualization functions but not with subsetting; <!-- Please give a clear and concise description of what the bug is: -->. I am looking for the expression of 'NCAM1'. It works when I am plotting my data (umap, violin plot, matrix plot) but I cant find it in the adata.var and I am not able to subset adata for this particular gene while it is working with the other genes. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. #what works:. marker_genes = ['NCAM1']. ax = sc.pl.violin(adata, marker_genes, groupby='timepoint'). # what doesnt work:. subset_NCAM = adata[:, 'NCAM1']. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ""None of [Index(['NCAM1'], dtype='object', name='index')] are in the [index]"". #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > 1.4.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/999
https://github.com/scverse/scanpy/issues/999:845,safety,log,logging,845,"gene find with visualization functions but not with subsetting; <!-- Please give a clear and concise description of what the bug is: -->. I am looking for the expression of 'NCAM1'. It works when I am plotting my data (umap, violin plot, matrix plot) but I cant find it in the adata.var and I am not able to subset adata for this particular gene while it is working with the other genes. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. #what works:. marker_genes = ['NCAM1']. ax = sc.pl.violin(adata, marker_genes, groupby='timepoint'). # what doesnt work:. subset_NCAM = adata[:, 'NCAM1']. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ""None of [Index(['NCAM1'], dtype='object', name='index')] are in the [index]"". #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > 1.4.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/999
https://github.com/scverse/scanpy/issues/999:845,security,log,logging,845,"gene find with visualization functions but not with subsetting; <!-- Please give a clear and concise description of what the bug is: -->. I am looking for the expression of 'NCAM1'. It works when I am plotting my data (umap, violin plot, matrix plot) but I cant find it in the adata.var and I am not able to subset adata for this particular gene while it is working with the other genes. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. #what works:. marker_genes = ['NCAM1']. ax = sc.pl.violin(adata, marker_genes, groupby='timepoint'). # what doesnt work:. subset_NCAM = adata[:, 'NCAM1']. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ""None of [Index(['NCAM1'], dtype='object', name='index')] are in the [index]"". #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > 1.4.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/999
https://github.com/scverse/scanpy/issues/999:845,testability,log,logging,845,"gene find with visualization functions but not with subsetting; <!-- Please give a clear and concise description of what the bug is: -->. I am looking for the expression of 'NCAM1'. It works when I am plotting my data (umap, violin plot, matrix plot) but I cant find it in the adata.var and I am not able to subset adata for this particular gene while it is working with the other genes. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. #what works:. marker_genes = ['NCAM1']. ax = sc.pl.violin(adata, marker_genes, groupby='timepoint'). # what doesnt work:. subset_NCAM = adata[:, 'NCAM1']. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ""None of [Index(['NCAM1'], dtype='object', name='index')] are in the [index]"". #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > 1.4.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/999
https://github.com/scverse/scanpy/issues/999:15,usability,visual,visualization,15,"gene find with visualization functions but not with subsetting; <!-- Please give a clear and concise description of what the bug is: -->. I am looking for the expression of 'NCAM1'. It works when I am plotting my data (umap, violin plot, matrix plot) but I cant find it in the adata.var and I am not able to subset adata for this particular gene while it is working with the other genes. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. #what works:. marker_genes = ['NCAM1']. ax = sc.pl.violin(adata, marker_genes, groupby='timepoint'). # what doesnt work:. subset_NCAM = adata[:, 'NCAM1']. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ""None of [Index(['NCAM1'], dtype='object', name='index')] are in the [index]"". #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > 1.4.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/999
https://github.com/scverse/scanpy/issues/999:83,usability,clear,clear,83,"gene find with visualization functions but not with subsetting; <!-- Please give a clear and concise description of what the bug is: -->. I am looking for the expression of 'NCAM1'. It works when I am plotting my data (umap, violin plot, matrix plot) but I cant find it in the adata.var and I am not able to subset adata for this particular gene while it is working with the other genes. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. #what works:. marker_genes = ['NCAM1']. ax = sc.pl.violin(adata, marker_genes, groupby='timepoint'). # what doesnt work:. subset_NCAM = adata[:, 'NCAM1']. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ""None of [Index(['NCAM1'], dtype='object', name='index')] are in the [index]"". #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > 1.4.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/999
https://github.com/scverse/scanpy/issues/999:399,usability,minim,minimal,399,"gene find with visualization functions but not with subsetting; <!-- Please give a clear and concise description of what the bug is: -->. I am looking for the expression of 'NCAM1'. It works when I am plotting my data (umap, violin plot, matrix plot) but I cant find it in the adata.var and I am not able to subset adata for this particular gene while it is working with the other genes. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. #what works:. marker_genes = ['NCAM1']. ax = sc.pl.violin(adata, marker_genes, groupby='timepoint'). # what doesnt work:. subset_NCAM = adata[:, 'NCAM1']. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ""None of [Index(['NCAM1'], dtype='object', name='index')] are in the [index]"". #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > 1.4.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/999
https://github.com/scverse/scanpy/issues/999:651,usability,Error,Error,651,"gene find with visualization functions but not with subsetting; <!-- Please give a clear and concise description of what the bug is: -->. I am looking for the expression of 'NCAM1'. It works when I am plotting my data (umap, violin plot, matrix plot) but I cant find it in the adata.var and I am not able to subset adata for this particular gene while it is working with the other genes. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. #what works:. marker_genes = ['NCAM1']. ax = sc.pl.violin(adata, marker_genes, groupby='timepoint'). # what doesnt work:. subset_NCAM = adata[:, 'NCAM1']. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ""None of [Index(['NCAM1'], dtype='object', name='index')] are in the [index]"". #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > 1.4.4.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/999
https://github.com/scverse/scanpy/issues/1000:1052,performance,memor,memory,1052,"Plotting triggering copy of view; Example using scanpy 9dd2e94846aa and anndata `762fdb924e757cdd758231`. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pl.umap(pbmc, color=""louvain"") # To make sure that ""louvain_colors"" has been made. bcells = pbmc[pbmc.obs[""louvain""] == ""B cells""]. # This line triggers a copy being made:. sc.pl.umap(bcells). # /Users/isaac/github/anndata/anndata/_core/anndata.py:1120: ImplicitModificationWarning: # Initializing view as actual. # ""Initializing view as actual."", ImplicitModificationWarning,. assert not bcells.is_view. ```. Pretty sure that shouldn't be making a copy, since nothing should be modified in the view. To make sure:. ```python. from anndata.tests.helpers import assert_equal. bcells_view = pbmc[pbmc.obs[""louvain""] == ""B cells""]. assert_equal(bcells, bcells_view, exact=True). ```. This also seems to be happening with some of the other plotting functions, like `sc.pl.rank_genes_groups_dotplot`. Elaborating a bit:. To me this is an issue since it will use quite a lot of memory for cases where it isn't needed. Why copy a large number of arrays when you don't need to?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1000
https://github.com/scverse/scanpy/issues/1000:720,safety,test,tests,720,"Plotting triggering copy of view; Example using scanpy 9dd2e94846aa and anndata `762fdb924e757cdd758231`. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pl.umap(pbmc, color=""louvain"") # To make sure that ""louvain_colors"" has been made. bcells = pbmc[pbmc.obs[""louvain""] == ""B cells""]. # This line triggers a copy being made:. sc.pl.umap(bcells). # /Users/isaac/github/anndata/anndata/_core/anndata.py:1120: ImplicitModificationWarning: # Initializing view as actual. # ""Initializing view as actual."", ImplicitModificationWarning,. assert not bcells.is_view. ```. Pretty sure that shouldn't be making a copy, since nothing should be modified in the view. To make sure:. ```python. from anndata.tests.helpers import assert_equal. bcells_view = pbmc[pbmc.obs[""louvain""] == ""B cells""]. assert_equal(bcells, bcells_view, exact=True). ```. This also seems to be happening with some of the other plotting functions, like `sc.pl.rank_genes_groups_dotplot`. Elaborating a bit:. To me this is an issue since it will use quite a lot of memory for cases where it isn't needed. Why copy a large number of arrays when you don't need to?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1000
https://github.com/scverse/scanpy/issues/1000:659,security,modif,modified,659,"Plotting triggering copy of view; Example using scanpy 9dd2e94846aa and anndata `762fdb924e757cdd758231`. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pl.umap(pbmc, color=""louvain"") # To make sure that ""louvain_colors"" has been made. bcells = pbmc[pbmc.obs[""louvain""] == ""B cells""]. # This line triggers a copy being made:. sc.pl.umap(bcells). # /Users/isaac/github/anndata/anndata/_core/anndata.py:1120: ImplicitModificationWarning: # Initializing view as actual. # ""Initializing view as actual."", ImplicitModificationWarning,. assert not bcells.is_view. ```. Pretty sure that shouldn't be making a copy, since nothing should be modified in the view. To make sure:. ```python. from anndata.tests.helpers import assert_equal. bcells_view = pbmc[pbmc.obs[""louvain""] == ""B cells""]. assert_equal(bcells, bcells_view, exact=True). ```. This also seems to be happening with some of the other plotting functions, like `sc.pl.rank_genes_groups_dotplot`. Elaborating a bit:. To me this is an issue since it will use quite a lot of memory for cases where it isn't needed. Why copy a large number of arrays when you don't need to?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1000
https://github.com/scverse/scanpy/issues/1000:558,testability,assert,assert,558,"Plotting triggering copy of view; Example using scanpy 9dd2e94846aa and anndata `762fdb924e757cdd758231`. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pl.umap(pbmc, color=""louvain"") # To make sure that ""louvain_colors"" has been made. bcells = pbmc[pbmc.obs[""louvain""] == ""B cells""]. # This line triggers a copy being made:. sc.pl.umap(bcells). # /Users/isaac/github/anndata/anndata/_core/anndata.py:1120: ImplicitModificationWarning: # Initializing view as actual. # ""Initializing view as actual."", ImplicitModificationWarning,. assert not bcells.is_view. ```. Pretty sure that shouldn't be making a copy, since nothing should be modified in the view. To make sure:. ```python. from anndata.tests.helpers import assert_equal. bcells_view = pbmc[pbmc.obs[""louvain""] == ""B cells""]. assert_equal(bcells, bcells_view, exact=True). ```. This also seems to be happening with some of the other plotting functions, like `sc.pl.rank_genes_groups_dotplot`. Elaborating a bit:. To me this is an issue since it will use quite a lot of memory for cases where it isn't needed. Why copy a large number of arrays when you don't need to?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1000
https://github.com/scverse/scanpy/issues/1000:720,testability,test,tests,720,"Plotting triggering copy of view; Example using scanpy 9dd2e94846aa and anndata `762fdb924e757cdd758231`. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pl.umap(pbmc, color=""louvain"") # To make sure that ""louvain_colors"" has been made. bcells = pbmc[pbmc.obs[""louvain""] == ""B cells""]. # This line triggers a copy being made:. sc.pl.umap(bcells). # /Users/isaac/github/anndata/anndata/_core/anndata.py:1120: ImplicitModificationWarning: # Initializing view as actual. # ""Initializing view as actual."", ImplicitModificationWarning,. assert not bcells.is_view. ```. Pretty sure that shouldn't be making a copy, since nothing should be modified in the view. To make sure:. ```python. from anndata.tests.helpers import assert_equal. bcells_view = pbmc[pbmc.obs[""louvain""] == ""B cells""]. assert_equal(bcells, bcells_view, exact=True). ```. This also seems to be happening with some of the other plotting functions, like `sc.pl.rank_genes_groups_dotplot`. Elaborating a bit:. To me this is an issue since it will use quite a lot of memory for cases where it isn't needed. Why copy a large number of arrays when you don't need to?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1000
https://github.com/scverse/scanpy/issues/1000:376,usability,User,Users,376,"Plotting triggering copy of view; Example using scanpy 9dd2e94846aa and anndata `762fdb924e757cdd758231`. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pl.umap(pbmc, color=""louvain"") # To make sure that ""louvain_colors"" has been made. bcells = pbmc[pbmc.obs[""louvain""] == ""B cells""]. # This line triggers a copy being made:. sc.pl.umap(bcells). # /Users/isaac/github/anndata/anndata/_core/anndata.py:1120: ImplicitModificationWarning: # Initializing view as actual. # ""Initializing view as actual."", ImplicitModificationWarning,. assert not bcells.is_view. ```. Pretty sure that shouldn't be making a copy, since nothing should be modified in the view. To make sure:. ```python. from anndata.tests.helpers import assert_equal. bcells_view = pbmc[pbmc.obs[""louvain""] == ""B cells""]. assert_equal(bcells, bcells_view, exact=True). ```. This also seems to be happening with some of the other plotting functions, like `sc.pl.rank_genes_groups_dotplot`. Elaborating a bit:. To me this is an issue since it will use quite a lot of memory for cases where it isn't needed. Why copy a large number of arrays when you don't need to?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1000
https://github.com/scverse/scanpy/issues/1000:726,usability,help,helpers,726,"Plotting triggering copy of view; Example using scanpy 9dd2e94846aa and anndata `762fdb924e757cdd758231`. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pl.umap(pbmc, color=""louvain"") # To make sure that ""louvain_colors"" has been made. bcells = pbmc[pbmc.obs[""louvain""] == ""B cells""]. # This line triggers a copy being made:. sc.pl.umap(bcells). # /Users/isaac/github/anndata/anndata/_core/anndata.py:1120: ImplicitModificationWarning: # Initializing view as actual. # ""Initializing view as actual."", ImplicitModificationWarning,. assert not bcells.is_view. ```. Pretty sure that shouldn't be making a copy, since nothing should be modified in the view. To make sure:. ```python. from anndata.tests.helpers import assert_equal. bcells_view = pbmc[pbmc.obs[""louvain""] == ""B cells""]. assert_equal(bcells, bcells_view, exact=True). ```. This also seems to be happening with some of the other plotting functions, like `sc.pl.rank_genes_groups_dotplot`. Elaborating a bit:. To me this is an issue since it will use quite a lot of memory for cases where it isn't needed. Why copy a large number of arrays when you don't need to?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1000
https://github.com/scverse/scanpy/issues/1000:1052,usability,memor,memory,1052,"Plotting triggering copy of view; Example using scanpy 9dd2e94846aa and anndata `762fdb924e757cdd758231`. ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pl.umap(pbmc, color=""louvain"") # To make sure that ""louvain_colors"" has been made. bcells = pbmc[pbmc.obs[""louvain""] == ""B cells""]. # This line triggers a copy being made:. sc.pl.umap(bcells). # /Users/isaac/github/anndata/anndata/_core/anndata.py:1120: ImplicitModificationWarning: # Initializing view as actual. # ""Initializing view as actual."", ImplicitModificationWarning,. assert not bcells.is_view. ```. Pretty sure that shouldn't be making a copy, since nothing should be modified in the view. To make sure:. ```python. from anndata.tests.helpers import assert_equal. bcells_view = pbmc[pbmc.obs[""louvain""] == ""B cells""]. assert_equal(bcells, bcells_view, exact=True). ```. This also seems to be happening with some of the other plotting functions, like `sc.pl.rank_genes_groups_dotplot`. Elaborating a bit:. To me this is an issue since it will use quite a lot of memory for cases where it isn't needed. Why copy a large number of arrays when you don't need to?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1000
https://github.com/scverse/scanpy/issues/1001:30,availability,failur,failures,30,"MAGIC in external causes test failures if its not installed; @scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001
https://github.com/scverse/scanpy/issues/1001:157,availability,error,error,157,"MAGIC in external causes test failures if its not installed; @scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001
https://github.com/scverse/scanpy/issues/1001:30,deployability,fail,failures,30,"MAGIC in external causes test failures if its not installed; @scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001
https://github.com/scverse/scanpy/issues/1001:50,deployability,instal,installed,50,"MAGIC in external causes test failures if its not installed; @scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001
https://github.com/scverse/scanpy/issues/1001:118,deployability,fail,fail,118,"MAGIC in external causes test failures if its not installed; @scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001
https://github.com/scverse/scanpy/issues/1001:147,deployability,instal,installed,147,"MAGIC in external causes test failures if its not installed; @scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001
https://github.com/scverse/scanpy/issues/1001:263,deployability,instal,installed,263,"MAGIC in external causes test failures if its not installed; @scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001
https://github.com/scverse/scanpy/issues/1001:93,energy efficiency,current,current,93,"MAGIC in external causes test failures if its not installed; @scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001
https://github.com/scverse/scanpy/issues/1001:249,modifiability,pac,package,249,"MAGIC in external causes test failures if its not installed; @scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001
https://github.com/scverse/scanpy/issues/1001:30,performance,failur,failures,30,"MAGIC in external causes test failures if its not installed; @scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001
https://github.com/scverse/scanpy/issues/1001:157,performance,error,error,157,"MAGIC in external causes test failures if its not installed; @scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001
https://github.com/scverse/scanpy/issues/1001:30,reliability,fail,failures,30,"MAGIC in external causes test failures if its not installed; @scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001
https://github.com/scverse/scanpy/issues/1001:118,reliability,fail,fail,118,"MAGIC in external causes test failures if its not installed; @scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001
https://github.com/scverse/scanpy/issues/1001:25,safety,test,test,25,"MAGIC in external causes test failures if its not installed; @scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001
https://github.com/scverse/scanpy/issues/1001:112,safety,test,tests,112,"MAGIC in external causes test failures if its not installed; @scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001
https://github.com/scverse/scanpy/issues/1001:157,safety,error,error,157,"MAGIC in external causes test failures if its not installed; @scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001
https://github.com/scverse/scanpy/issues/1001:173,safety,test,tests,173,"MAGIC in external causes test failures if its not installed; @scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001
https://github.com/scverse/scanpy/issues/1001:25,testability,test,test,25,"MAGIC in external causes test failures if its not installed; @scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001
https://github.com/scverse/scanpy/issues/1001:112,testability,test,tests,112,"MAGIC in external causes test failures if its not installed; @scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001
https://github.com/scverse/scanpy/issues/1001:173,testability,test,tests,173,"MAGIC in external causes test failures if its not installed; @scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001
https://github.com/scverse/scanpy/issues/1001:157,usability,error,error,157,"MAGIC in external causes test failures if its not installed; @scottgigante @flying-sheep, on current master the tests fail for me with a MAGIC not installed error. External tests should have some mark to make sure they don't get run if the required package isn't installed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1001
https://github.com/scverse/scanpy/pull/1002:194,deployability,releas,release,194,"Prevent unnecessary copying when plotting; When combined with https://github.com/theislab/anndata/pull/298, fixes #1000. Unfortunately, the tests here won't pass until the PR at anndata is in a release. * Adds tests checking for copying when plotting a view. * Prevents setting color palette when it doesn't need to change",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1002
https://github.com/scverse/scanpy/pull/1002:300,reliability,doe,doesn,300,"Prevent unnecessary copying when plotting; When combined with https://github.com/theislab/anndata/pull/298, fixes #1000. Unfortunately, the tests here won't pass until the PR at anndata is in a release. * Adds tests checking for copying when plotting a view. * Prevents setting color palette when it doesn't need to change",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1002
https://github.com/scverse/scanpy/pull/1002:0,safety,Prevent,Prevent,0,"Prevent unnecessary copying when plotting; When combined with https://github.com/theislab/anndata/pull/298, fixes #1000. Unfortunately, the tests here won't pass until the PR at anndata is in a release. * Adds tests checking for copying when plotting a view. * Prevents setting color palette when it doesn't need to change",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1002
https://github.com/scverse/scanpy/pull/1002:140,safety,test,tests,140,"Prevent unnecessary copying when plotting; When combined with https://github.com/theislab/anndata/pull/298, fixes #1000. Unfortunately, the tests here won't pass until the PR at anndata is in a release. * Adds tests checking for copying when plotting a view. * Prevents setting color palette when it doesn't need to change",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1002
https://github.com/scverse/scanpy/pull/1002:210,safety,test,tests,210,"Prevent unnecessary copying when plotting; When combined with https://github.com/theislab/anndata/pull/298, fixes #1000. Unfortunately, the tests here won't pass until the PR at anndata is in a release. * Adds tests checking for copying when plotting a view. * Prevents setting color palette when it doesn't need to change",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1002
https://github.com/scverse/scanpy/pull/1002:261,safety,Prevent,Prevents,261,"Prevent unnecessary copying when plotting; When combined with https://github.com/theislab/anndata/pull/298, fixes #1000. Unfortunately, the tests here won't pass until the PR at anndata is in a release. * Adds tests checking for copying when plotting a view. * Prevents setting color palette when it doesn't need to change",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1002
https://github.com/scverse/scanpy/pull/1002:0,security,Preven,Prevent,0,"Prevent unnecessary copying when plotting; When combined with https://github.com/theislab/anndata/pull/298, fixes #1000. Unfortunately, the tests here won't pass until the PR at anndata is in a release. * Adds tests checking for copying when plotting a view. * Prevents setting color palette when it doesn't need to change",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1002
https://github.com/scverse/scanpy/pull/1002:261,security,Preven,Prevents,261,"Prevent unnecessary copying when plotting; When combined with https://github.com/theislab/anndata/pull/298, fixes #1000. Unfortunately, the tests here won't pass until the PR at anndata is in a release. * Adds tests checking for copying when plotting a view. * Prevents setting color palette when it doesn't need to change",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1002
https://github.com/scverse/scanpy/pull/1002:140,testability,test,tests,140,"Prevent unnecessary copying when plotting; When combined with https://github.com/theislab/anndata/pull/298, fixes #1000. Unfortunately, the tests here won't pass until the PR at anndata is in a release. * Adds tests checking for copying when plotting a view. * Prevents setting color palette when it doesn't need to change",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1002
https://github.com/scverse/scanpy/pull/1002:210,testability,test,tests,210,"Prevent unnecessary copying when plotting; When combined with https://github.com/theislab/anndata/pull/298, fixes #1000. Unfortunately, the tests here won't pass until the PR at anndata is in a release. * Adds tests checking for copying when plotting a view. * Prevents setting color palette when it doesn't need to change",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1002
https://github.com/scverse/scanpy/pull/1003:14,safety,test,tests,14,Make external tests for MAGIC optional; Closes #1001,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1003
https://github.com/scverse/scanpy/pull/1003:14,testability,test,tests,14,Make external tests for MAGIC optional; Closes #1001,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1003
https://github.com/scverse/scanpy/pull/1003:40,usability,Close,Closes,40,Make external tests for MAGIC optional; Closes #1001,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1003
https://github.com/scverse/scanpy/pull/1004:26,deployability,depend,depend,26,"Fix plotting and harmony, depend on anndata 0.7 for obsp (#1004, #1007); This. - moves all the external plotting routines to `scanpy/external/pl.py`. - adds one for harmony. - Fixes a plotting bug this triggered. - Makes harmony the first tool using obsp/varp. @awnimo can you please test this? Does the plot look like you want it to?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1004
https://github.com/scverse/scanpy/pull/1004:26,integrability,depend,depend,26,"Fix plotting and harmony, depend on anndata 0.7 for obsp (#1004, #1007); This. - moves all the external plotting routines to `scanpy/external/pl.py`. - adds one for harmony. - Fixes a plotting bug this triggered. - Makes harmony the first tool using obsp/varp. @awnimo can you please test this? Does the plot look like you want it to?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1004
https://github.com/scverse/scanpy/pull/1004:113,integrability,rout,routines,113,"Fix plotting and harmony, depend on anndata 0.7 for obsp (#1004, #1007); This. - moves all the external plotting routines to `scanpy/external/pl.py`. - adds one for harmony. - Fixes a plotting bug this triggered. - Makes harmony the first tool using obsp/varp. @awnimo can you please test this? Does the plot look like you want it to?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1004
https://github.com/scverse/scanpy/pull/1004:26,modifiability,depend,depend,26,"Fix plotting and harmony, depend on anndata 0.7 for obsp (#1004, #1007); This. - moves all the external plotting routines to `scanpy/external/pl.py`. - adds one for harmony. - Fixes a plotting bug this triggered. - Makes harmony the first tool using obsp/varp. @awnimo can you please test this? Does the plot look like you want it to?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1004
https://github.com/scverse/scanpy/pull/1004:295,reliability,Doe,Does,295,"Fix plotting and harmony, depend on anndata 0.7 for obsp (#1004, #1007); This. - moves all the external plotting routines to `scanpy/external/pl.py`. - adds one for harmony. - Fixes a plotting bug this triggered. - Makes harmony the first tool using obsp/varp. @awnimo can you please test this? Does the plot look like you want it to?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1004
https://github.com/scverse/scanpy/pull/1004:26,safety,depend,depend,26,"Fix plotting and harmony, depend on anndata 0.7 for obsp (#1004, #1007); This. - moves all the external plotting routines to `scanpy/external/pl.py`. - adds one for harmony. - Fixes a plotting bug this triggered. - Makes harmony the first tool using obsp/varp. @awnimo can you please test this? Does the plot look like you want it to?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1004
https://github.com/scverse/scanpy/pull/1004:284,safety,test,test,284,"Fix plotting and harmony, depend on anndata 0.7 for obsp (#1004, #1007); This. - moves all the external plotting routines to `scanpy/external/pl.py`. - adds one for harmony. - Fixes a plotting bug this triggered. - Makes harmony the first tool using obsp/varp. @awnimo can you please test this? Does the plot look like you want it to?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1004
https://github.com/scverse/scanpy/pull/1004:26,testability,depend,depend,26,"Fix plotting and harmony, depend on anndata 0.7 for obsp (#1004, #1007); This. - moves all the external plotting routines to `scanpy/external/pl.py`. - adds one for harmony. - Fixes a plotting bug this triggered. - Makes harmony the first tool using obsp/varp. @awnimo can you please test this? Does the plot look like you want it to?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1004
https://github.com/scverse/scanpy/pull/1004:284,testability,test,test,284,"Fix plotting and harmony, depend on anndata 0.7 for obsp (#1004, #1007); This. - moves all the external plotting routines to `scanpy/external/pl.py`. - adds one for harmony. - Fixes a plotting bug this triggered. - Makes harmony the first tool using obsp/varp. @awnimo can you please test this? Does the plot look like you want it to?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1004
https://github.com/scverse/scanpy/pull/1004:239,usability,tool,tool,239,"Fix plotting and harmony, depend on anndata 0.7 for obsp (#1004, #1007); This. - moves all the external plotting routines to `scanpy/external/pl.py`. - adds one for harmony. - Fixes a plotting bug this triggered. - Makes harmony the first tool using obsp/varp. @awnimo can you please test this? Does the plot look like you want it to?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1004
https://github.com/scverse/scanpy/pull/1005:9,deployability,build,build,9,"Add a CI build which uses anndata master; It doesn't look like I can make the install process a matrix expansion, so this only tests against one version of python for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1005
https://github.com/scverse/scanpy/pull/1005:78,deployability,instal,install,78,"Add a CI build which uses anndata master; It doesn't look like I can make the install process a matrix expansion, so this only tests against one version of python for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1005
https://github.com/scverse/scanpy/pull/1005:145,deployability,version,version,145,"Add a CI build which uses anndata master; It doesn't look like I can make the install process a matrix expansion, so this only tests against one version of python for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1005
https://github.com/scverse/scanpy/pull/1005:145,integrability,version,version,145,"Add a CI build which uses anndata master; It doesn't look like I can make the install process a matrix expansion, so this only tests against one version of python for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1005
https://github.com/scverse/scanpy/pull/1005:145,modifiability,version,version,145,"Add a CI build which uses anndata master; It doesn't look like I can make the install process a matrix expansion, so this only tests against one version of python for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1005
https://github.com/scverse/scanpy/pull/1005:45,reliability,doe,doesn,45,"Add a CI build which uses anndata master; It doesn't look like I can make the install process a matrix expansion, so this only tests against one version of python for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1005
https://github.com/scverse/scanpy/pull/1005:127,safety,test,tests,127,"Add a CI build which uses anndata master; It doesn't look like I can make the install process a matrix expansion, so this only tests against one version of python for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1005
https://github.com/scverse/scanpy/pull/1005:127,testability,test,tests,127,"Add a CI build which uses anndata master; It doesn't look like I can make the install process a matrix expansion, so this only tests against one version of python for now.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1005
https://github.com/scverse/scanpy/pull/1006:12,deployability,depend,dependency,12,"Unlock h5py dependency; @ivirshup said:. > I'm pretty sure I fixed [the reason h5py was version-locked] around here: theislab/anndata@38e687c, but I opened the issue here: h5py/h5py#1307",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1006
https://github.com/scverse/scanpy/pull/1006:88,deployability,version,version-locked,88,"Unlock h5py dependency; @ivirshup said:. > I'm pretty sure I fixed [the reason h5py was version-locked] around here: theislab/anndata@38e687c, but I opened the issue here: h5py/h5py#1307",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1006
https://github.com/scverse/scanpy/pull/1006:12,integrability,depend,dependency,12,"Unlock h5py dependency; @ivirshup said:. > I'm pretty sure I fixed [the reason h5py was version-locked] around here: theislab/anndata@38e687c, but I opened the issue here: h5py/h5py#1307",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1006
https://github.com/scverse/scanpy/pull/1006:88,integrability,version,version-locked,88,"Unlock h5py dependency; @ivirshup said:. > I'm pretty sure I fixed [the reason h5py was version-locked] around here: theislab/anndata@38e687c, but I opened the issue here: h5py/h5py#1307",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1006
https://github.com/scverse/scanpy/pull/1006:12,modifiability,depend,dependency,12,"Unlock h5py dependency; @ivirshup said:. > I'm pretty sure I fixed [the reason h5py was version-locked] around here: theislab/anndata@38e687c, but I opened the issue here: h5py/h5py#1307",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1006
https://github.com/scverse/scanpy/pull/1006:88,modifiability,version,version-locked,88,"Unlock h5py dependency; @ivirshup said:. > I'm pretty sure I fixed [the reason h5py was version-locked] around here: theislab/anndata@38e687c, but I opened the issue here: h5py/h5py#1307",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1006
https://github.com/scverse/scanpy/pull/1006:96,performance,lock,locked,96,"Unlock h5py dependency; @ivirshup said:. > I'm pretty sure I fixed [the reason h5py was version-locked] around here: theislab/anndata@38e687c, but I opened the issue here: h5py/h5py#1307",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1006
https://github.com/scverse/scanpy/pull/1006:12,safety,depend,dependency,12,"Unlock h5py dependency; @ivirshup said:. > I'm pretty sure I fixed [the reason h5py was version-locked] around here: theislab/anndata@38e687c, but I opened the issue here: h5py/h5py#1307",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1006
https://github.com/scverse/scanpy/pull/1006:96,security,lock,locked,96,"Unlock h5py dependency; @ivirshup said:. > I'm pretty sure I fixed [the reason h5py was version-locked] around here: theislab/anndata@38e687c, but I opened the issue here: h5py/h5py#1307",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1006
https://github.com/scverse/scanpy/pull/1006:12,testability,depend,dependency,12,"Unlock h5py dependency; @ivirshup said:. > I'm pretty sure I fixed [the reason h5py was version-locked] around here: theislab/anndata@38e687c, but I opened the issue here: h5py/h5py#1307",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1006
https://github.com/scverse/scanpy/pull/1007:39,safety,test,test,39,"Ext plotting; Suggested changes to the test function, and harmony_timeseries",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1007
https://github.com/scverse/scanpy/pull/1007:39,testability,test,test,39,"Ext plotting; Suggested changes to the test function, and harmony_timeseries",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1007
https://github.com/scverse/scanpy/pull/1008:70,usability,document,documentation,70,Replace rank_genes_groups_dotplot with function link in sc.pl.dotplot documentation;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1008
https://github.com/scverse/scanpy/issues/1009:271,availability,cluster,clustering,271,"Problem at reproducibility of UMAP / leiden; Hi,. I am working on a project with a labmate and we are using the same dataset. We have found that, when running the same pipeline on the same adata the neighbors / bbknn + UMAP + leiden results, even with the same seed, the clustering solution and UMAP are considerably different. This renders the analysis _unreproducible_ and makes the downstream analysis far more difficult to do, since I have to map my clustering solutions and UMAP plots with hers using markers, and it is quite impractical. We have the same versions of scanpy, leiden, umap, and bbknn on the two computers:. - `scanpy==1.4.5.post2`. - `umap-learn==0.3.10`. - `leidenalg==0.7.0`. - `bbknn==1.3.6`. To try to reproduce the issue, we have created a random matrix with the same seed (10), and create one annData with `sc.pp.neighbours`, and another one with `bbknn`. We have made the adatas to have two batches, so that we can use bbknn. ```. seed = 10. np.random.seed(seed). a = np.random.rand(100, 100). b = np.random.rand(100, 100). print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']). sc.tl.pca(adata). sce.pp.bbknn(adata, metric='angular'). sc.tl.umap(adata, random_state=seed). sc.tl.leiden(adata, resolution=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:385,availability,down,downstream,385,"Problem at reproducibility of UMAP / leiden; Hi,. I am working on a project with a labmate and we are using the same dataset. We have found that, when running the same pipeline on the same adata the neighbors / bbknn + UMAP + leiden results, even with the same seed, the clustering solution and UMAP are considerably different. This renders the analysis _unreproducible_ and makes the downstream analysis far more difficult to do, since I have to map my clustering solutions and UMAP plots with hers using markers, and it is quite impractical. We have the same versions of scanpy, leiden, umap, and bbknn on the two computers:. - `scanpy==1.4.5.post2`. - `umap-learn==0.3.10`. - `leidenalg==0.7.0`. - `bbknn==1.3.6`. To try to reproduce the issue, we have created a random matrix with the same seed (10), and create one annData with `sc.pp.neighbours`, and another one with `bbknn`. We have made the adatas to have two batches, so that we can use bbknn. ```. seed = 10. np.random.seed(seed). a = np.random.rand(100, 100). b = np.random.rand(100, 100). print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']). sc.tl.pca(adata). sce.pp.bbknn(adata, metric='angular'). sc.tl.umap(adata, random_state=seed). sc.tl.leiden(adata, resolution=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:454,availability,cluster,clustering,454,"Problem at reproducibility of UMAP / leiden; Hi,. I am working on a project with a labmate and we are using the same dataset. We have found that, when running the same pipeline on the same adata the neighbors / bbknn + UMAP + leiden results, even with the same seed, the clustering solution and UMAP are considerably different. This renders the analysis _unreproducible_ and makes the downstream analysis far more difficult to do, since I have to map my clustering solutions and UMAP plots with hers using markers, and it is quite impractical. We have the same versions of scanpy, leiden, umap, and bbknn on the two computers:. - `scanpy==1.4.5.post2`. - `umap-learn==0.3.10`. - `leidenalg==0.7.0`. - `bbknn==1.3.6`. To try to reproduce the issue, we have created a random matrix with the same seed (10), and create one annData with `sc.pp.neighbours`, and another one with `bbknn`. We have made the adatas to have two batches, so that we can use bbknn. ```. seed = 10. np.random.seed(seed). a = np.random.rand(100, 100). b = np.random.rand(100, 100). print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']). sc.tl.pca(adata). sce.pp.bbknn(adata, metric='angular'). sc.tl.umap(adata, random_state=seed). sc.tl.leiden(adata, resolution=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:1905,availability,cluster,clustering,1905,"have two batches, so that we can use bbknn. ```. seed = 10. np.random.seed(seed). a = np.random.rand(100, 100). b = np.random.rand(100, 100). print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']). sc.tl.pca(adata). sce.pp.bbknn(adata, metric='angular'). sc.tl.umap(adata, random_state=seed). sc.tl.leiden(adata, resolution=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches and right are `leiden` cluster labels):. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087502-e12b7f80-3ed2-11ea-9df9-177cec32d208.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087537-f0aac880-3ed2-11ea-8c45-115023be9bff.png). For the adata run with `sce.pp.bbknn`:. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087518-ea1c5100-3ed2-11ea-97de-4b6ce0e0d389.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087545-f43e4f80-3ed2-11ea-82b9-a5dcb5d804b7.png). Our PCA decomposition has the same coordinates, so we discard the PCA as the source of variability. Also, since both UMAP and leiden look different, we think the source might come from the neighbor calculation. When running `adata.uns['neighbors']['connectivities'].sum()` I get 801.5580058219996 and 1204.5274490986717 for `adata` and `adata_neigh`. I don'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:2023,availability,cluster,cluster,2023,"p.random.rand(100, 100). print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']). sc.tl.pca(adata). sce.pp.bbknn(adata, metric='angular'). sc.tl.umap(adata, random_state=seed). sc.tl.leiden(adata, resolution=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches and right are `leiden` cluster labels):. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087502-e12b7f80-3ed2-11ea-9df9-177cec32d208.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087537-f0aac880-3ed2-11ea-8c45-115023be9bff.png). For the adata run with `sce.pp.bbknn`:. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087518-ea1c5100-3ed2-11ea-97de-4b6ce0e0d389.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087545-f43e4f80-3ed2-11ea-82b9-a5dcb5d804b7.png). Our PCA decomposition has the same coordinates, so we discard the PCA as the source of variability. Also, since both UMAP and leiden look different, we think the source might come from the neighbor calculation. When running `adata.uns['neighbors']['connectivities'].sum()` I get 801.5580058219996 and 1204.5274490986717 for `adata` and `adata_neigh`. I don't have her values now, but the values using the _real_ dataset were in the order of 5000, and they were of by less th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:168,deployability,pipelin,pipeline,168,"Problem at reproducibility of UMAP / leiden; Hi,. I am working on a project with a labmate and we are using the same dataset. We have found that, when running the same pipeline on the same adata the neighbors / bbknn + UMAP + leiden results, even with the same seed, the clustering solution and UMAP are considerably different. This renders the analysis _unreproducible_ and makes the downstream analysis far more difficult to do, since I have to map my clustering solutions and UMAP plots with hers using markers, and it is quite impractical. We have the same versions of scanpy, leiden, umap, and bbknn on the two computers:. - `scanpy==1.4.5.post2`. - `umap-learn==0.3.10`. - `leidenalg==0.7.0`. - `bbknn==1.3.6`. To try to reproduce the issue, we have created a random matrix with the same seed (10), and create one annData with `sc.pp.neighbours`, and another one with `bbknn`. We have made the adatas to have two batches, so that we can use bbknn. ```. seed = 10. np.random.seed(seed). a = np.random.rand(100, 100). b = np.random.rand(100, 100). print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']). sc.tl.pca(adata). sce.pp.bbknn(adata, metric='angular'). sc.tl.umap(adata, random_state=seed). sc.tl.leiden(adata, resolution=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:271,deployability,cluster,clustering,271,"Problem at reproducibility of UMAP / leiden; Hi,. I am working on a project with a labmate and we are using the same dataset. We have found that, when running the same pipeline on the same adata the neighbors / bbknn + UMAP + leiden results, even with the same seed, the clustering solution and UMAP are considerably different. This renders the analysis _unreproducible_ and makes the downstream analysis far more difficult to do, since I have to map my clustering solutions and UMAP plots with hers using markers, and it is quite impractical. We have the same versions of scanpy, leiden, umap, and bbknn on the two computers:. - `scanpy==1.4.5.post2`. - `umap-learn==0.3.10`. - `leidenalg==0.7.0`. - `bbknn==1.3.6`. To try to reproduce the issue, we have created a random matrix with the same seed (10), and create one annData with `sc.pp.neighbours`, and another one with `bbknn`. We have made the adatas to have two batches, so that we can use bbknn. ```. seed = 10. np.random.seed(seed). a = np.random.rand(100, 100). b = np.random.rand(100, 100). print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']). sc.tl.pca(adata). sce.pp.bbknn(adata, metric='angular'). sc.tl.umap(adata, random_state=seed). sc.tl.leiden(adata, resolution=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:454,deployability,cluster,clustering,454,"Problem at reproducibility of UMAP / leiden; Hi,. I am working on a project with a labmate and we are using the same dataset. We have found that, when running the same pipeline on the same adata the neighbors / bbknn + UMAP + leiden results, even with the same seed, the clustering solution and UMAP are considerably different. This renders the analysis _unreproducible_ and makes the downstream analysis far more difficult to do, since I have to map my clustering solutions and UMAP plots with hers using markers, and it is quite impractical. We have the same versions of scanpy, leiden, umap, and bbknn on the two computers:. - `scanpy==1.4.5.post2`. - `umap-learn==0.3.10`. - `leidenalg==0.7.0`. - `bbknn==1.3.6`. To try to reproduce the issue, we have created a random matrix with the same seed (10), and create one annData with `sc.pp.neighbours`, and another one with `bbknn`. We have made the adatas to have two batches, so that we can use bbknn. ```. seed = 10. np.random.seed(seed). a = np.random.rand(100, 100). b = np.random.rand(100, 100). print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']). sc.tl.pca(adata). sce.pp.bbknn(adata, metric='angular'). sc.tl.umap(adata, random_state=seed). sc.tl.leiden(adata, resolution=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:561,deployability,version,versions,561,"Problem at reproducibility of UMAP / leiden; Hi,. I am working on a project with a labmate and we are using the same dataset. We have found that, when running the same pipeline on the same adata the neighbors / bbknn + UMAP + leiden results, even with the same seed, the clustering solution and UMAP are considerably different. This renders the analysis _unreproducible_ and makes the downstream analysis far more difficult to do, since I have to map my clustering solutions and UMAP plots with hers using markers, and it is quite impractical. We have the same versions of scanpy, leiden, umap, and bbknn on the two computers:. - `scanpy==1.4.5.post2`. - `umap-learn==0.3.10`. - `leidenalg==0.7.0`. - `bbknn==1.3.6`. To try to reproduce the issue, we have created a random matrix with the same seed (10), and create one annData with `sc.pp.neighbours`, and another one with `bbknn`. We have made the adatas to have two batches, so that we can use bbknn. ```. seed = 10. np.random.seed(seed). a = np.random.rand(100, 100). b = np.random.rand(100, 100). print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']). sc.tl.pca(adata). sce.pp.bbknn(adata, metric='angular'). sc.tl.umap(adata, random_state=seed). sc.tl.leiden(adata, resolution=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:1905,deployability,cluster,clustering,1905,"have two batches, so that we can use bbknn. ```. seed = 10. np.random.seed(seed). a = np.random.rand(100, 100). b = np.random.rand(100, 100). print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']). sc.tl.pca(adata). sce.pp.bbknn(adata, metric='angular'). sc.tl.umap(adata, random_state=seed). sc.tl.leiden(adata, resolution=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches and right are `leiden` cluster labels):. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087502-e12b7f80-3ed2-11ea-9df9-177cec32d208.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087537-f0aac880-3ed2-11ea-8c45-115023be9bff.png). For the adata run with `sce.pp.bbknn`:. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087518-ea1c5100-3ed2-11ea-97de-4b6ce0e0d389.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087545-f43e4f80-3ed2-11ea-82b9-a5dcb5d804b7.png). Our PCA decomposition has the same coordinates, so we discard the PCA as the source of variability. Also, since both UMAP and leiden look different, we think the source might come from the neighbor calculation. When running `adata.uns['neighbors']['connectivities'].sum()` I get 801.5580058219996 and 1204.5274490986717 for `adata` and `adata_neigh`. I don'",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:2023,deployability,cluster,cluster,2023,"p.random.rand(100, 100). print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']). sc.tl.pca(adata). sce.pp.bbknn(adata, metric='angular'). sc.tl.umap(adata, random_state=seed). sc.tl.leiden(adata, resolution=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches and right are `leiden` cluster labels):. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087502-e12b7f80-3ed2-11ea-9df9-177cec32d208.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087537-f0aac880-3ed2-11ea-8c45-115023be9bff.png). For the adata run with `sce.pp.bbknn`:. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087518-ea1c5100-3ed2-11ea-97de-4b6ce0e0d389.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087545-f43e4f80-3ed2-11ea-82b9-a5dcb5d804b7.png). Our PCA decomposition has the same coordinates, so we discard the PCA as the source of variability. Also, since both UMAP and leiden look different, we think the source might come from the neighbor calculation. When running `adata.uns['neighbors']['connectivities'].sum()` I get 801.5580058219996 and 1204.5274490986717 for `adata` and `adata_neigh`. I don't have her values now, but the values using the _real_ dataset were in the order of 5000, and they were of by less th",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:168,integrability,pipelin,pipeline,168,"Problem at reproducibility of UMAP / leiden; Hi,. I am working on a project with a labmate and we are using the same dataset. We have found that, when running the same pipeline on the same adata the neighbors / bbknn + UMAP + leiden results, even with the same seed, the clustering solution and UMAP are considerably different. This renders the analysis _unreproducible_ and makes the downstream analysis far more difficult to do, since I have to map my clustering solutions and UMAP plots with hers using markers, and it is quite impractical. We have the same versions of scanpy, leiden, umap, and bbknn on the two computers:. - `scanpy==1.4.5.post2`. - `umap-learn==0.3.10`. - `leidenalg==0.7.0`. - `bbknn==1.3.6`. To try to reproduce the issue, we have created a random matrix with the same seed (10), and create one annData with `sc.pp.neighbours`, and another one with `bbknn`. We have made the adatas to have two batches, so that we can use bbknn. ```. seed = 10. np.random.seed(seed). a = np.random.rand(100, 100). b = np.random.rand(100, 100). print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']). sc.tl.pca(adata). sce.pp.bbknn(adata, metric='angular'). sc.tl.umap(adata, random_state=seed). sc.tl.leiden(adata, resolution=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:561,integrability,version,versions,561,"Problem at reproducibility of UMAP / leiden; Hi,. I am working on a project with a labmate and we are using the same dataset. We have found that, when running the same pipeline on the same adata the neighbors / bbknn + UMAP + leiden results, even with the same seed, the clustering solution and UMAP are considerably different. This renders the analysis _unreproducible_ and makes the downstream analysis far more difficult to do, since I have to map my clustering solutions and UMAP plots with hers using markers, and it is quite impractical. We have the same versions of scanpy, leiden, umap, and bbknn on the two computers:. - `scanpy==1.4.5.post2`. - `umap-learn==0.3.10`. - `leidenalg==0.7.0`. - `bbknn==1.3.6`. To try to reproduce the issue, we have created a random matrix with the same seed (10), and create one annData with `sc.pp.neighbours`, and another one with `bbknn`. We have made the adatas to have two batches, so that we can use bbknn. ```. seed = 10. np.random.seed(seed). a = np.random.rand(100, 100). b = np.random.rand(100, 100). print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']). sc.tl.pca(adata). sce.pp.bbknn(adata, metric='angular'). sc.tl.umap(adata, random_state=seed). sc.tl.leiden(adata, resolution=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:919,integrability,batch,batches,919,"Problem at reproducibility of UMAP / leiden; Hi,. I am working on a project with a labmate and we are using the same dataset. We have found that, when running the same pipeline on the same adata the neighbors / bbknn + UMAP + leiden results, even with the same seed, the clustering solution and UMAP are considerably different. This renders the analysis _unreproducible_ and makes the downstream analysis far more difficult to do, since I have to map my clustering solutions and UMAP plots with hers using markers, and it is quite impractical. We have the same versions of scanpy, leiden, umap, and bbknn on the two computers:. - `scanpy==1.4.5.post2`. - `umap-learn==0.3.10`. - `leidenalg==0.7.0`. - `bbknn==1.3.6`. To try to reproduce the issue, we have created a random matrix with the same seed (10), and create one annData with `sc.pp.neighbours`, and another one with `bbknn`. We have made the adatas to have two batches, so that we can use bbknn. ```. seed = 10. np.random.seed(seed). a = np.random.rand(100, 100). b = np.random.rand(100, 100). print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']). sc.tl.pca(adata). sce.pp.bbknn(adata, metric='angular'). sc.tl.umap(adata, random_state=seed). sc.tl.leiden(adata, resolution=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:1353,integrability,batch,batch,1353,"nreproducible_ and makes the downstream analysis far more difficult to do, since I have to map my clustering solutions and UMAP plots with hers using markers, and it is quite impractical. We have the same versions of scanpy, leiden, umap, and bbknn on the two computers:. - `scanpy==1.4.5.post2`. - `umap-learn==0.3.10`. - `leidenalg==0.7.0`. - `bbknn==1.3.6`. To try to reproduce the issue, we have created a random matrix with the same seed (10), and create one annData with `sc.pp.neighbours`, and another one with `bbknn`. We have made the adatas to have two batches, so that we can use bbknn. ```. seed = 10. np.random.seed(seed). a = np.random.rand(100, 100). b = np.random.rand(100, 100). print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']). sc.tl.pca(adata). sce.pp.bbknn(adata, metric='angular'). sc.tl.umap(adata, random_state=seed). sc.tl.leiden(adata, resolution=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches and right are `leiden` cluster labels):. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087502-e12b7f80-3ed2-11ea-9df9-177cec32d208.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087537-f0aac880-3ed2-11ea-8c45-115023be9bff.png). For the adata run with `sce.pp.bbknn`:. Mine. ![image](https://user-images.gith",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:1671,integrability,batch,batch,1671,"`. - `leidenalg==0.7.0`. - `bbknn==1.3.6`. To try to reproduce the issue, we have created a random matrix with the same seed (10), and create one annData with `sc.pp.neighbours`, and another one with `bbknn`. We have made the adatas to have two batches, so that we can use bbknn. ```. seed = 10. np.random.seed(seed). a = np.random.rand(100, 100). b = np.random.rand(100, 100). print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']). sc.tl.pca(adata). sce.pp.bbknn(adata, metric='angular'). sc.tl.umap(adata, random_state=seed). sc.tl.leiden(adata, resolution=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches and right are `leiden` cluster labels):. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087502-e12b7f80-3ed2-11ea-9df9-177cec32d208.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087537-f0aac880-3ed2-11ea-8c45-115023be9bff.png). For the adata run with `sce.pp.bbknn`:. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087518-ea1c5100-3ed2-11ea-97de-4b6ce0e0d389.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087545-f43e4f80-3ed2-11ea-82b9-a5dcb5d804b7.png). Our PCA decomposition has the same coordinates, so we discard the PCA as the source of variability. Also, since both UMAP",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:1992,integrability,batch,batches,1992,"np.random.rand(100, 100). b = np.random.rand(100, 100). print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']). sc.tl.pca(adata). sce.pp.bbknn(adata, metric='angular'). sc.tl.umap(adata, random_state=seed). sc.tl.leiden(adata, resolution=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches and right are `leiden` cluster labels):. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087502-e12b7f80-3ed2-11ea-9df9-177cec32d208.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087537-f0aac880-3ed2-11ea-8c45-115023be9bff.png). For the adata run with `sce.pp.bbknn`:. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087518-ea1c5100-3ed2-11ea-97de-4b6ce0e0d389.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087545-f43e4f80-3ed2-11ea-82b9-a5dcb5d804b7.png). Our PCA decomposition has the same coordinates, so we discard the PCA as the source of variability. Also, since both UMAP and leiden look different, we think the source might come from the neighbor calculation. When running `adata.uns['neighbors']['connectivities'].sum()` I get 801.5580058219996 and 1204.5274490986717 for `adata` and `adata_neigh`. I don't have her values now, but the values using the _real_ dataset were in the order of 50",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:2588,interoperability,coordinat,coordinates,2588,"tion=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches and right are `leiden` cluster labels):. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087502-e12b7f80-3ed2-11ea-9df9-177cec32d208.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087537-f0aac880-3ed2-11ea-8c45-115023be9bff.png). For the adata run with `sce.pp.bbknn`:. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087518-ea1c5100-3ed2-11ea-97de-4b6ce0e0d389.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087545-f43e4f80-3ed2-11ea-82b9-a5dcb5d804b7.png). Our PCA decomposition has the same coordinates, so we discard the PCA as the source of variability. Also, since both UMAP and leiden look different, we think the source might come from the neighbor calculation. When running `adata.uns['neighbors']['connectivities'].sum()` I get 801.5580058219996 and 1204.5274490986717 for `adata` and `adata_neigh`. I don't have her values now, but the values using the _real_ dataset were in the order of 5000, and they were of by less than 0.001; so we are confused that with such a small difference on the sum, the results can be so different. I attach the adatas for you to inspect them if you need more info. [adatas.zip](https://github.com/theislab/scanpy/files/4109668/adatas.zip). Thanks for the help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:561,modifiability,version,versions,561,"Problem at reproducibility of UMAP / leiden; Hi,. I am working on a project with a labmate and we are using the same dataset. We have found that, when running the same pipeline on the same adata the neighbors / bbknn + UMAP + leiden results, even with the same seed, the clustering solution and UMAP are considerably different. This renders the analysis _unreproducible_ and makes the downstream analysis far more difficult to do, since I have to map my clustering solutions and UMAP plots with hers using markers, and it is quite impractical. We have the same versions of scanpy, leiden, umap, and bbknn on the two computers:. - `scanpy==1.4.5.post2`. - `umap-learn==0.3.10`. - `leidenalg==0.7.0`. - `bbknn==1.3.6`. To try to reproduce the issue, we have created a random matrix with the same seed (10), and create one annData with `sc.pp.neighbours`, and another one with `bbknn`. We have made the adatas to have two batches, so that we can use bbknn. ```. seed = 10. np.random.seed(seed). a = np.random.rand(100, 100). b = np.random.rand(100, 100). print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']). sc.tl.pca(adata). sce.pp.bbknn(adata, metric='angular'). sc.tl.umap(adata, random_state=seed). sc.tl.leiden(adata, resolution=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:2561,modifiability,deco,decomposition,2561,"tion=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches and right are `leiden` cluster labels):. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087502-e12b7f80-3ed2-11ea-9df9-177cec32d208.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087537-f0aac880-3ed2-11ea-8c45-115023be9bff.png). For the adata run with `sce.pp.bbknn`:. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087518-ea1c5100-3ed2-11ea-97de-4b6ce0e0d389.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087545-f43e4f80-3ed2-11ea-82b9-a5dcb5d804b7.png). Our PCA decomposition has the same coordinates, so we discard the PCA as the source of variability. Also, since both UMAP and leiden look different, we think the source might come from the neighbor calculation. When running `adata.uns['neighbors']['connectivities'].sum()` I get 801.5580058219996 and 1204.5274490986717 for `adata` and `adata_neigh`. I don't have her values now, but the values using the _real_ dataset were in the order of 5000, and they were of by less than 0.001; so we are confused that with such a small difference on the sum, the results can be so different. I attach the adatas for you to inspect them if you need more info. [adatas.zip](https://github.com/theislab/scanpy/files/4109668/adatas.zip). Thanks for the help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:2640,modifiability,variab,variability,2640,"tion=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches and right are `leiden` cluster labels):. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087502-e12b7f80-3ed2-11ea-9df9-177cec32d208.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087537-f0aac880-3ed2-11ea-8c45-115023be9bff.png). For the adata run with `sce.pp.bbknn`:. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087518-ea1c5100-3ed2-11ea-97de-4b6ce0e0d389.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087545-f43e4f80-3ed2-11ea-82b9-a5dcb5d804b7.png). Our PCA decomposition has the same coordinates, so we discard the PCA as the source of variability. Also, since both UMAP and leiden look different, we think the source might come from the neighbor calculation. When running `adata.uns['neighbors']['connectivities'].sum()` I get 801.5580058219996 and 1204.5274490986717 for `adata` and `adata_neigh`. I don't have her values now, but the values using the _real_ dataset were in the order of 5000, and they were of by less than 0.001; so we are confused that with such a small difference on the sum, the results can be so different. I attach the adatas for you to inspect them if you need more info. [adatas.zip](https://github.com/theislab/scanpy/files/4109668/adatas.zip). Thanks for the help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:919,performance,batch,batches,919,"Problem at reproducibility of UMAP / leiden; Hi,. I am working on a project with a labmate and we are using the same dataset. We have found that, when running the same pipeline on the same adata the neighbors / bbknn + UMAP + leiden results, even with the same seed, the clustering solution and UMAP are considerably different. This renders the analysis _unreproducible_ and makes the downstream analysis far more difficult to do, since I have to map my clustering solutions and UMAP plots with hers using markers, and it is quite impractical. We have the same versions of scanpy, leiden, umap, and bbknn on the two computers:. - `scanpy==1.4.5.post2`. - `umap-learn==0.3.10`. - `leidenalg==0.7.0`. - `bbknn==1.3.6`. To try to reproduce the issue, we have created a random matrix with the same seed (10), and create one annData with `sc.pp.neighbours`, and another one with `bbknn`. We have made the adatas to have two batches, so that we can use bbknn. ```. seed = 10. np.random.seed(seed). a = np.random.rand(100, 100). b = np.random.rand(100, 100). print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']). sc.tl.pca(adata). sce.pp.bbknn(adata, metric='angular'). sc.tl.umap(adata, random_state=seed). sc.tl.leiden(adata, resolution=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:1353,performance,batch,batch,1353,"nreproducible_ and makes the downstream analysis far more difficult to do, since I have to map my clustering solutions and UMAP plots with hers using markers, and it is quite impractical. We have the same versions of scanpy, leiden, umap, and bbknn on the two computers:. - `scanpy==1.4.5.post2`. - `umap-learn==0.3.10`. - `leidenalg==0.7.0`. - `bbknn==1.3.6`. To try to reproduce the issue, we have created a random matrix with the same seed (10), and create one annData with `sc.pp.neighbours`, and another one with `bbknn`. We have made the adatas to have two batches, so that we can use bbknn. ```. seed = 10. np.random.seed(seed). a = np.random.rand(100, 100). b = np.random.rand(100, 100). print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']). sc.tl.pca(adata). sce.pp.bbknn(adata, metric='angular'). sc.tl.umap(adata, random_state=seed). sc.tl.leiden(adata, resolution=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches and right are `leiden` cluster labels):. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087502-e12b7f80-3ed2-11ea-9df9-177cec32d208.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087537-f0aac880-3ed2-11ea-8c45-115023be9bff.png). For the adata run with `sce.pp.bbknn`:. Mine. ![image](https://user-images.gith",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:1671,performance,batch,batch,1671,"`. - `leidenalg==0.7.0`. - `bbknn==1.3.6`. To try to reproduce the issue, we have created a random matrix with the same seed (10), and create one annData with `sc.pp.neighbours`, and another one with `bbknn`. We have made the adatas to have two batches, so that we can use bbknn. ```. seed = 10. np.random.seed(seed). a = np.random.rand(100, 100). b = np.random.rand(100, 100). print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']). sc.tl.pca(adata). sce.pp.bbknn(adata, metric='angular'). sc.tl.umap(adata, random_state=seed). sc.tl.leiden(adata, resolution=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches and right are `leiden` cluster labels):. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087502-e12b7f80-3ed2-11ea-9df9-177cec32d208.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087537-f0aac880-3ed2-11ea-8c45-115023be9bff.png). For the adata run with `sce.pp.bbknn`:. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087518-ea1c5100-3ed2-11ea-97de-4b6ce0e0d389.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087545-f43e4f80-3ed2-11ea-82b9-a5dcb5d804b7.png). Our PCA decomposition has the same coordinates, so we discard the PCA as the source of variability. Also, since both UMAP",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:1992,performance,batch,batches,1992,"np.random.rand(100, 100). b = np.random.rand(100, 100). print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']). sc.tl.pca(adata). sce.pp.bbknn(adata, metric='angular'). sc.tl.umap(adata, random_state=seed). sc.tl.leiden(adata, resolution=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches and right are `leiden` cluster labels):. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087502-e12b7f80-3ed2-11ea-9df9-177cec32d208.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087537-f0aac880-3ed2-11ea-8c45-115023be9bff.png). For the adata run with `sce.pp.bbknn`:. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087518-ea1c5100-3ed2-11ea-97de-4b6ce0e0d389.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087545-f43e4f80-3ed2-11ea-82b9-a5dcb5d804b7.png). Our PCA decomposition has the same coordinates, so we discard the PCA as the source of variability. Also, since both UMAP and leiden look different, we think the source might come from the neighbor calculation. When running `adata.uns['neighbors']['connectivities'].sum()` I get 801.5580058219996 and 1204.5274490986717 for `adata` and `adata_neigh`. I don't have her values now, but the values using the _real_ dataset were in the order of 50",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:661,usability,learn,learn,661,"Problem at reproducibility of UMAP / leiden; Hi,. I am working on a project with a labmate and we are using the same dataset. We have found that, when running the same pipeline on the same adata the neighbors / bbknn + UMAP + leiden results, even with the same seed, the clustering solution and UMAP are considerably different. This renders the analysis _unreproducible_ and makes the downstream analysis far more difficult to do, since I have to map my clustering solutions and UMAP plots with hers using markers, and it is quite impractical. We have the same versions of scanpy, leiden, umap, and bbknn on the two computers:. - `scanpy==1.4.5.post2`. - `umap-learn==0.3.10`. - `leidenalg==0.7.0`. - `bbknn==1.3.6`. To try to reproduce the issue, we have created a random matrix with the same seed (10), and create one annData with `sc.pp.neighbours`, and another one with `bbknn`. We have made the adatas to have two batches, so that we can use bbknn. ```. seed = 10. np.random.seed(seed). a = np.random.rand(100, 100). b = np.random.rand(100, 100). print(np.sum(a), np.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']). sc.tl.pca(adata). sce.pp.bbknn(adata, metric='angular'). sc.tl.umap(adata, random_state=seed). sc.tl.leiden(adata, resolution=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:2064,usability,user,user-images,2064,"p.sum(b)). adata = sc.AnnData.concatenate(sc.AnnData(X=a), sc.AnnData(X=b), batch_categories=['a', 'b']). sc.tl.pca(adata). sce.pp.bbknn(adata, metric='angular'). sc.tl.umap(adata, random_state=seed). sc.tl.leiden(adata, resolution=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches and right are `leiden` cluster labels):. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087502-e12b7f80-3ed2-11ea-9df9-177cec32d208.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087537-f0aac880-3ed2-11ea-8c45-115023be9bff.png). For the adata run with `sce.pp.bbknn`:. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087518-ea1c5100-3ed2-11ea-97de-4b6ce0e0d389.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087545-f43e4f80-3ed2-11ea-82b9-a5dcb5d804b7.png). Our PCA decomposition has the same coordinates, so we discard the PCA as the source of variability. Also, since both UMAP and leiden look different, we think the source might come from the neighbor calculation. When running `adata.uns['neighbors']['connectivities'].sum()` I get 801.5580058219996 and 1204.5274490986717 for `adata` and `adata_neigh`. I don't have her values now, but the values using the _real_ dataset were in the order of 5000, and they were of by less than 0.001; so we are confused that with such",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:2182,usability,user,user-images,2182,"ata). sce.pp.bbknn(adata, metric='angular'). sc.tl.umap(adata, random_state=seed). sc.tl.leiden(adata, resolution=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches and right are `leiden` cluster labels):. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087502-e12b7f80-3ed2-11ea-9df9-177cec32d208.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087537-f0aac880-3ed2-11ea-8c45-115023be9bff.png). For the adata run with `sce.pp.bbknn`:. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087518-ea1c5100-3ed2-11ea-97de-4b6ce0e0d389.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087545-f43e4f80-3ed2-11ea-82b9-a5dcb5d804b7.png). Our PCA decomposition has the same coordinates, so we discard the PCA as the source of variability. Also, since both UMAP and leiden look different, we think the source might come from the neighbor calculation. When running `adata.uns['neighbors']['connectivities'].sum()` I get 801.5580058219996 and 1204.5274490986717 for `adata` and `adata_neigh`. I don't have her values now, but the values using the _real_ dataset were in the order of 5000, and they were of by less than 0.001; so we are confused that with such a small difference on the sum, the results can be so different. I attach the adatas for you to inspect them if you ne",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:2340,usability,user,user-images,2340,"tion=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches and right are `leiden` cluster labels):. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087502-e12b7f80-3ed2-11ea-9df9-177cec32d208.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087537-f0aac880-3ed2-11ea-8c45-115023be9bff.png). For the adata run with `sce.pp.bbknn`:. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087518-ea1c5100-3ed2-11ea-97de-4b6ce0e0d389.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087545-f43e4f80-3ed2-11ea-82b9-a5dcb5d804b7.png). Our PCA decomposition has the same coordinates, so we discard the PCA as the source of variability. Also, since both UMAP and leiden look different, we think the source might come from the neighbor calculation. When running `adata.uns['neighbors']['connectivities'].sum()` I get 801.5580058219996 and 1204.5274490986717 for `adata` and `adata_neigh`. I don't have her values now, but the values using the _real_ dataset were in the order of 5000, and they were of by less than 0.001; so we are confused that with such a small difference on the sum, the results can be so different. I attach the adatas for you to inspect them if you need more info. [adatas.zip](https://github.com/theislab/scanpy/files/4109668/adatas.zip). Thanks for the help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:2458,usability,user,user-images,2458,"tion=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches and right are `leiden` cluster labels):. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087502-e12b7f80-3ed2-11ea-9df9-177cec32d208.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087537-f0aac880-3ed2-11ea-8c45-115023be9bff.png). For the adata run with `sce.pp.bbknn`:. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087518-ea1c5100-3ed2-11ea-97de-4b6ce0e0d389.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087545-f43e4f80-3ed2-11ea-82b9-a5dcb5d804b7.png). Our PCA decomposition has the same coordinates, so we discard the PCA as the source of variability. Also, since both UMAP and leiden look different, we think the source might come from the neighbor calculation. When running `adata.uns['neighbors']['connectivities'].sum()` I get 801.5580058219996 and 1204.5274490986717 for `adata` and `adata_neigh`. I don't have her values now, but the values using the _real_ dataset were in the order of 5000, and they were of by less than 0.001; so we are confused that with such a small difference on the sum, the results can be so different. I attach the adatas for you to inspect them if you need more info. [adatas.zip](https://github.com/theislab/scanpy/files/4109668/adatas.zip). Thanks for the help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1009:3292,usability,help,help,3292,"tion=0.5, random_state=seed). sc.pl.umap(adata, color=['batch', 'leiden'], alpha=0.3). print(adata.uns['neighbors']['connectivities'].sum()). adata_neigh = adata.copy(). sc.pp.neighbors(adata_neigh, metric='cosine', random_state=seed). sc.tl.umap(adata_neigh, random_state=seed). sc.tl.leiden(adata_neigh, resolution=0.6, random_state=seed). sc.pl.umap(adata_neigh, color=['batch', 'leiden'], alpha=0.3). print(adata_neigh.uns['neighbors']['connectivities'].sum()). ```. Our matrices are the same (the sums are 4918.370372081173 and 5005.088472351332), so the random generation works, but then the UMAPs and clustering solutions are different. For the adata run with `sc.pp.neighbors` (left are batches and right are `leiden` cluster labels):. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087502-e12b7f80-3ed2-11ea-9df9-177cec32d208.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087537-f0aac880-3ed2-11ea-8c45-115023be9bff.png). For the adata run with `sce.pp.bbknn`:. Mine. ![image](https://user-images.githubusercontent.com/35657291/73087518-ea1c5100-3ed2-11ea-97de-4b6ce0e0d389.png). Hers. ![image](https://user-images.githubusercontent.com/35657291/73087545-f43e4f80-3ed2-11ea-82b9-a5dcb5d804b7.png). Our PCA decomposition has the same coordinates, so we discard the PCA as the source of variability. Also, since both UMAP and leiden look different, we think the source might come from the neighbor calculation. When running `adata.uns['neighbors']['connectivities'].sum()` I get 801.5580058219996 and 1204.5274490986717 for `adata` and `adata_neigh`. I don't have her values now, but the values using the _real_ dataset were in the order of 5000, and they were of by less than 0.001; so we are confused that with such a small difference on the sum, the results can be so different. I attach the adatas for you to inspect them if you need more info. [adatas.zip](https://github.com/theislab/scanpy/files/4109668/adatas.zip). Thanks for the help!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1009
https://github.com/scverse/scanpy/issues/1010:326,availability,Error,Error,326,"regress_out failed in the pbmc3k tutorial; AxisError was encountered while executing the regress_out function following the pbmc3k tutorial . ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. regressing out ['n_counts', 'percent_mito']. sparse input is densified and may lead to high memory use. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:12,deployability,fail,failed,12,"regress_out failed in the pbmc3k tutorial; AxisError was encountered while executing the regress_out function following the pbmc3k tutorial . ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. regressing out ['n_counts', 'percent_mito']. sparse input is densified and may lead to high memory use. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:674,deployability,modul,module,674,"regress_out failed in the pbmc3k tutorial; AxisError was encountered while executing the regress_out function following the pbmc3k tutorial . ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. regressing out ['n_counts', 'percent_mito']. sparse input is densified and may lead to high memory use. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:2342,deployability,Version,Versions,2342,"-----------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds). 45 except AttributeError:. 46 wrap = None. ---> 47 result = getattr(asarray(obj), method)(*args, **kwds). 48 if wrap:. 49 if not isinstance(result, mu.ndarray):. AxisError: axis1: axis 1 is out of bounds for array of dimension 0. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:2375,deployability,log,logging,2375,"-----------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds). 45 except AttributeError:. 46 wrap = None. ---> 47 result = getattr(asarray(obj), method)(*args, **kwds). 48 if wrap:. 49 if not isinstance(result, mu.ndarray):. AxisError: axis1: axis 1 is out of bounds for array of dimension 0. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:1605,energy efficiency,core,core,1605,"-----------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds). 45 except AttributeError:. 46 wrap = None. ---> 47 result = getattr(asarray(obj), method)(*args, **kwds). 48 if wrap:. 49 if not isinstance(result, mu.ndarray):. AxisError: axis1: axis 1 is out of bounds for array of dimension 0. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:1795,energy efficiency,core,core,1795,"-----------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds). 45 except AttributeError:. 46 wrap = None. ---> 47 result = getattr(asarray(obj), method)(*args, **kwds). 48 if wrap:. 49 if not isinstance(result, mu.ndarray):. AxisError: axis1: axis 1 is out of bounds for array of dimension 0. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:2042,energy efficiency,core,core,2042,"-----------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds). 45 except AttributeError:. 46 wrap = None. ---> 47 result = getattr(asarray(obj), method)(*args, **kwds). 48 if wrap:. 49 if not isinstance(result, mu.ndarray):. AxisError: axis1: axis 1 is out of bounds for array of dimension 0. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:2132,integrability,wrap,wrap,2132,"-----------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds). 45 except AttributeError:. 46 wrap = None. ---> 47 result = getattr(asarray(obj), method)(*args, **kwds). 48 if wrap:. 49 if not isinstance(result, mu.ndarray):. AxisError: axis1: axis 1 is out of bounds for array of dimension 0. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:2214,integrability,wrap,wrap,2214,"-----------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds). 45 except AttributeError:. 46 wrap = None. ---> 47 result = getattr(asarray(obj), method)(*args, **kwds). 48 if wrap:. 49 if not isinstance(result, mu.ndarray):. AxisError: axis1: axis 1 is out of bounds for array of dimension 0. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:2342,integrability,Version,Versions,2342,"-----------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds). 45 except AttributeError:. 46 wrap = None. ---> 47 result = getattr(asarray(obj), method)(*args, **kwds). 48 if wrap:. 49 if not isinstance(result, mu.ndarray):. AxisError: axis1: axis 1 is out of bounds for array of dimension 0. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:674,modifiability,modul,module,674,"regress_out failed in the pbmc3k tutorial; AxisError was encountered while executing the regress_out function following the pbmc3k tutorial . ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. regressing out ['n_counts', 'percent_mito']. sparse input is densified and may lead to high memory use. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:790,modifiability,pac,packages,790,"regress_out failed in the pbmc3k tutorial; AxisError was encountered while executing the regress_out function following the pbmc3k tutorial . ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. regressing out ['n_counts', 'percent_mito']. sparse input is densified and may lead to high memory use. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:1281,modifiability,pac,packages,1281,"s', 'percent_mito']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. regressing out ['n_counts', 'percent_mito']. sparse input is densified and may lead to high memory use. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds). 45 except AttributeError:. 46 wrap = None. ---> 47 result = getattr(asarray(obj), method)(*args, **kwds). 48 if wrap:. 49 if not isinstance(result, mu.ndarray):. AxisError: axis1: axi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:1590,modifiability,pac,packages,1590,"-----------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds). 45 except AttributeError:. 46 wrap = None. ---> 47 result = getattr(asarray(obj), method)(*args, **kwds). 48 if wrap:. 49 if not isinstance(result, mu.ndarray):. AxisError: axis1: axis 1 is out of bounds for array of dimension 0. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:1780,modifiability,pac,packages,1780,"-----------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds). 45 except AttributeError:. 46 wrap = None. ---> 47 result = getattr(asarray(obj), method)(*args, **kwds). 48 if wrap:. 49 if not isinstance(result, mu.ndarray):. AxisError: axis1: axis 1 is out of bounds for array of dimension 0. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:2027,modifiability,pac,packages,2027,"-----------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds). 45 except AttributeError:. 46 wrap = None. ---> 47 result = getattr(asarray(obj), method)(*args, **kwds). 48 if wrap:. 49 if not isinstance(result, mu.ndarray):. AxisError: axis1: axis 1 is out of bounds for array of dimension 0. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:2342,modifiability,Version,Versions,2342,"-----------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds). 45 except AttributeError:. 46 wrap = None. ---> 47 result = getattr(asarray(obj), method)(*args, **kwds). 48 if wrap:. 49 if not isinstance(result, mu.ndarray):. AxisError: axis1: axis 1 is out of bounds for array of dimension 0. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:326,performance,Error,Error,326,"regress_out failed in the pbmc3k tutorial; AxisError was encountered while executing the regress_out function following the pbmc3k tutorial . ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. regressing out ['n_counts', 'percent_mito']. sparse input is densified and may lead to high memory use. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:504,performance,memor,memory,504,"regress_out failed in the pbmc3k tutorial; AxisError was encountered while executing the regress_out function following the pbmc3k tutorial . ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. regressing out ['n_counts', 'percent_mito']. sparse input is densified and may lead to high memory use. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:12,reliability,fail,failed,12,"regress_out failed in the pbmc3k tutorial; AxisError was encountered while executing the regress_out function following the pbmc3k tutorial . ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. regressing out ['n_counts', 'percent_mito']. sparse input is densified and may lead to high memory use. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:326,safety,Error,Error,326,"regress_out failed in the pbmc3k tutorial; AxisError was encountered while executing the regress_out function following the pbmc3k tutorial . ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. regressing out ['n_counts', 'percent_mito']. sparse input is densified and may lead to high memory use. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:464,safety,input,input,464,"regress_out failed in the pbmc3k tutorial; AxisError was encountered while executing the regress_out function following the pbmc3k tutorial . ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. regressing out ['n_counts', 'percent_mito']. sparse input is densified and may lead to high memory use. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:647,safety,input,input-,647,"regress_out failed in the pbmc3k tutorial; AxisError was encountered while executing the regress_out function following the pbmc3k tutorial . ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. regressing out ['n_counts', 'percent_mito']. sparse input is densified and may lead to high memory use. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:674,safety,modul,module,674,"regress_out failed in the pbmc3k tutorial; AxisError was encountered while executing the regress_out function following the pbmc3k tutorial . ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. regressing out ['n_counts', 'percent_mito']. sparse input is densified and may lead to high memory use. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:2105,safety,except,except,2105,"-----------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds). 45 except AttributeError:. 46 wrap = None. ---> 47 result = getattr(asarray(obj), method)(*args, **kwds). 48 if wrap:. 49 if not isinstance(result, mu.ndarray):. AxisError: axis1: axis 1 is out of bounds for array of dimension 0. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:2375,safety,log,logging,2375,"-----------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds). 45 except AttributeError:. 46 wrap = None. ---> 47 result = getattr(asarray(obj), method)(*args, **kwds). 48 if wrap:. 49 if not isinstance(result, mu.ndarray):. AxisError: axis1: axis 1 is out of bounds for array of dimension 0. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:2375,security,log,logging,2375,"-----------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds). 45 except AttributeError:. 46 wrap = None. ---> 47 result = getattr(asarray(obj), method)(*args, **kwds). 48 if wrap:. 49 if not isinstance(result, mu.ndarray):. AxisError: axis1: axis 1 is out of bounds for array of dimension 0. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:412,testability,regress,regressing,412,"regress_out failed in the pbmc3k tutorial; AxisError was encountered while executing the regress_out function following the pbmc3k tutorial . ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. regressing out ['n_counts', 'percent_mito']. sparse input is densified and may lead to high memory use. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:603,testability,Trace,Traceback,603,"regress_out failed in the pbmc3k tutorial; AxisError was encountered while executing the regress_out function following the pbmc3k tutorial . ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. regressing out ['n_counts', 'percent_mito']. sparse input is densified and may lead to high memory use. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:1143,testability,regress,regressors,1143,"-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. regressing out ['n_counts', 'percent_mito']. sparse input is densified and may lead to high memory use. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds). 45 except AttributeError:. 46 wrap = None. ---",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:2375,testability,log,logging,2375,"-----------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds). 45 except AttributeError:. 46 wrap = None. ---> 47 result = getattr(asarray(obj), method)(*args, **kwds). 48 if wrap:. 49 if not isinstance(result, mu.ndarray):. AxisError: axis1: axis 1 is out of bounds for array of dimension 0. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:157,usability,minim,minimal,157,"regress_out failed in the pbmc3k tutorial; AxisError was encountered while executing the regress_out function following the pbmc3k tutorial . ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. regressing out ['n_counts', 'percent_mito']. sparse input is densified and may lead to high memory use. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:326,usability,Error,Error,326,"regress_out failed in the pbmc3k tutorial; AxisError was encountered while executing the regress_out function following the pbmc3k tutorial . ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. regressing out ['n_counts', 'percent_mito']. sparse input is densified and may lead to high memory use. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:464,usability,input,input,464,"regress_out failed in the pbmc3k tutorial; AxisError was encountered while executing the regress_out function following the pbmc3k tutorial . ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. regressing out ['n_counts', 'percent_mito']. sparse input is densified and may lead to high memory use. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:504,usability,memor,memory,504,"regress_out failed in the pbmc3k tutorial; AxisError was encountered while executing the regress_out function following the pbmc3k tutorial . ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. regressing out ['n_counts', 'percent_mito']. sparse input is densified and may lead to high memory use. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:647,usability,input,input-,647,"regress_out failed in the pbmc3k tutorial; AxisError was encountered while executing the regress_out function following the pbmc3k tutorial . ... <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. regressing out ['n_counts', 'percent_mito']. sparse input is densified and may lead to high memory use. ---------------------------------------------------------------------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1010:2504,usability,learn,learn,2504,"-----------------. AxisError Traceback (most recent call last). <ipython-input-55-c0d016811ded> in <module>. ----> 1 sc.pp.regress_out(adata, ['n_counts', 'percent_mito']). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in regress_out(adata, keys, n_jobs, copy). 817 # split the adata.X matrix by columns in chunks of size n_chunk. 818 # (the last chunk could be of smaller size than the others). --> 819 chunk_list = np.array_split(adata.X, n_chunks, axis=1). 820 if variable_is_categorical:. 821 regressors_chunk = np.array_split(regressors, n_chunks, axis=1). <__array_function__ internals> in array_split(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/lib/shape_base.py in array_split(ary, indices_or_sections, axis). 782 . 783 sub_arys = []. --> 784 sary = _nx.swapaxes(ary, axis, 0). 785 for i in range(Nsections):. 786 st = div_points[i]. <__array_function__ internals> in swapaxes(*args, **kwargs). ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in swapaxes(a, axis1, axis2). 595 . 596 """""". --> 597 return _wrapfunc(a, 'swapaxes', axis1, axis2). 598 . 599 . ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~/anaconda3/envs/scanpy/lib/python3.6/site-packages/numpy/core/fromnumeric.py in _wrapit(obj, method, *args, **kwds). 45 except AttributeError:. 46 wrap = None. ---> 47 result = getattr(asarray(obj), method)(*args, **kwds). 48 if wrap:. 49 if not isinstance(result, mu.ndarray):. AxisError: axis1: axis 1 is out of bounds for array of dimension 0. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1010
https://github.com/scverse/scanpy/issues/1011:119,deployability,version,version,119,"New UMAP distances like ll_dirichlet and hellinger throw exception with small AnnDatas; If adata.n_obs < 4096 and umap version >= 0.4 and if `metric` is a distance that is not supported by scikit-learn (like ll_dirichlet or hellinger), we get a ValueError:. Code for reproducing with UMAP >= 0.4:. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.neighbors(adata, metric='hellinger'). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-5-e2c66b650fd3> in <module>. 2 . 3 adata = sc.datasets.paul15(). ----> 4 sc.pp.neighbors(adata, metric='hellinger'). ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 109 method=method, metric=metric, metric_kwds=metric_kwds,. --> 110 random_state=random_state,. 111 ). 112 adata.uns['neighbors'] = {}. ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 686 # non-euclidean case and approx nearest neighbors. 687 if X.shape[0] < 4096:. --> 688 X = pairwise_distances(X, metric=metric, **metric_kwds). 689 metric = 'precomputed'. 690 knn_indices, knn_distances, forest = compute_neighbors_umap(. ~/.anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, **kwds). 1550 raise ValueError(""Unknown metric %s. "". 1551 ""Valid metrics are %s, or 'precomputed', or a "". -> 1552 ""callable"" % (metric, _VALID_METRICS)). 1553 . 1554 if metric == ""precomputed"":. ValueError: Unknown metric hellinger. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1011
https://github.com/scverse/scanpy/issues/1011:499,deployability,modul,module,499,"New UMAP distances like ll_dirichlet and hellinger throw exception with small AnnDatas; If adata.n_obs < 4096 and umap version >= 0.4 and if `metric` is a distance that is not supported by scikit-learn (like ll_dirichlet or hellinger), we get a ValueError:. Code for reproducing with UMAP >= 0.4:. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.neighbors(adata, metric='hellinger'). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-5-e2c66b650fd3> in <module>. 2 . 3 adata = sc.datasets.paul15(). ----> 4 sc.pp.neighbors(adata, metric='hellinger'). ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 109 method=method, metric=metric, metric_kwds=metric_kwds,. --> 110 random_state=random_state,. 111 ). 112 adata.uns['neighbors'] = {}. ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 686 # non-euclidean case and approx nearest neighbors. 687 if X.shape[0] < 4096:. --> 688 X = pairwise_distances(X, metric=metric, **metric_kwds). 689 metric = 'precomputed'. 690 knn_indices, knn_distances, forest = compute_neighbors_umap(. ~/.anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, **kwds). 1550 raise ValueError(""Unknown metric %s. "". 1551 ""Valid metrics are %s, or 'precomputed', or a "". -> 1552 ""callable"" % (metric, _VALID_METRICS)). 1553 . 1554 if metric == ""precomputed"":. ValueError: Unknown metric hellinger. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1011
https://github.com/scverse/scanpy/issues/1011:119,integrability,version,version,119,"New UMAP distances like ll_dirichlet and hellinger throw exception with small AnnDatas; If adata.n_obs < 4096 and umap version >= 0.4 and if `metric` is a distance that is not supported by scikit-learn (like ll_dirichlet or hellinger), we get a ValueError:. Code for reproducing with UMAP >= 0.4:. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.neighbors(adata, metric='hellinger'). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-5-e2c66b650fd3> in <module>. 2 . 3 adata = sc.datasets.paul15(). ----> 4 sc.pp.neighbors(adata, metric='hellinger'). ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 109 method=method, metric=metric, metric_kwds=metric_kwds,. --> 110 random_state=random_state,. 111 ). 112 adata.uns['neighbors'] = {}. ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 686 # non-euclidean case and approx nearest neighbors. 687 if X.shape[0] < 4096:. --> 688 X = pairwise_distances(X, metric=metric, **metric_kwds). 689 metric = 'precomputed'. 690 knn_indices, knn_distances, forest = compute_neighbors_umap(. ~/.anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, **kwds). 1550 raise ValueError(""Unknown metric %s. "". 1551 ""Valid metrics are %s, or 'precomputed', or a "". -> 1552 ""callable"" % (metric, _VALID_METRICS)). 1553 . 1554 if metric == ""precomputed"":. ValueError: Unknown metric hellinger. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1011
https://github.com/scverse/scanpy/issues/1011:119,modifiability,version,version,119,"New UMAP distances like ll_dirichlet and hellinger throw exception with small AnnDatas; If adata.n_obs < 4096 and umap version >= 0.4 and if `metric` is a distance that is not supported by scikit-learn (like ll_dirichlet or hellinger), we get a ValueError:. Code for reproducing with UMAP >= 0.4:. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.neighbors(adata, metric='hellinger'). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-5-e2c66b650fd3> in <module>. 2 . 3 adata = sc.datasets.paul15(). ----> 4 sc.pp.neighbors(adata, metric='hellinger'). ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 109 method=method, metric=metric, metric_kwds=metric_kwds,. --> 110 random_state=random_state,. 111 ). 112 adata.uns['neighbors'] = {}. ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 686 # non-euclidean case and approx nearest neighbors. 687 if X.shape[0] < 4096:. --> 688 X = pairwise_distances(X, metric=metric, **metric_kwds). 689 metric = 'precomputed'. 690 knn_indices, knn_distances, forest = compute_neighbors_umap(. ~/.anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, **kwds). 1550 raise ValueError(""Unknown metric %s. "". 1551 ""Valid metrics are %s, or 'precomputed', or a "". -> 1552 ""callable"" % (metric, _VALID_METRICS)). 1553 . 1554 if metric == ""precomputed"":. ValueError: Unknown metric hellinger. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1011
https://github.com/scverse/scanpy/issues/1011:499,modifiability,modul,module,499,"New UMAP distances like ll_dirichlet and hellinger throw exception with small AnnDatas; If adata.n_obs < 4096 and umap version >= 0.4 and if `metric` is a distance that is not supported by scikit-learn (like ll_dirichlet or hellinger), we get a ValueError:. Code for reproducing with UMAP >= 0.4:. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.neighbors(adata, metric='hellinger'). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-5-e2c66b650fd3> in <module>. 2 . 3 adata = sc.datasets.paul15(). ----> 4 sc.pp.neighbors(adata, metric='hellinger'). ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 109 method=method, metric=metric, metric_kwds=metric_kwds,. --> 110 random_state=random_state,. 111 ). 112 adata.uns['neighbors'] = {}. ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 686 # non-euclidean case and approx nearest neighbors. 687 if X.shape[0] < 4096:. --> 688 X = pairwise_distances(X, metric=metric, **metric_kwds). 689 metric = 'precomputed'. 690 knn_indices, knn_distances, forest = compute_neighbors_umap(. ~/.anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, **kwds). 1550 raise ValueError(""Unknown metric %s. "". 1551 ""Valid metrics are %s, or 'precomputed', or a "". -> 1552 ""callable"" % (metric, _VALID_METRICS)). 1553 . 1554 if metric == ""precomputed"":. ValueError: Unknown metric hellinger. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1011
https://github.com/scverse/scanpy/issues/1011:628,modifiability,pac,packages,628,"New UMAP distances like ll_dirichlet and hellinger throw exception with small AnnDatas; If adata.n_obs < 4096 and umap version >= 0.4 and if `metric` is a distance that is not supported by scikit-learn (like ll_dirichlet or hellinger), we get a ValueError:. Code for reproducing with UMAP >= 0.4:. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.neighbors(adata, metric='hellinger'). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-5-e2c66b650fd3> in <module>. 2 . 3 adata = sc.datasets.paul15(). ----> 4 sc.pp.neighbors(adata, metric='hellinger'). ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 109 method=method, metric=metric, metric_kwds=metric_kwds,. --> 110 random_state=random_state,. 111 ). 112 adata.uns['neighbors'] = {}. ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 686 # non-euclidean case and approx nearest neighbors. 687 if X.shape[0] < 4096:. --> 688 X = pairwise_distances(X, metric=metric, **metric_kwds). 689 metric = 'precomputed'. 690 knn_indices, knn_distances, forest = compute_neighbors_umap(. ~/.anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, **kwds). 1550 raise ValueError(""Unknown metric %s. "". 1551 ""Valid metrics are %s, or 'precomputed', or a "". -> 1552 ""callable"" % (metric, _VALID_METRICS)). 1553 . 1554 if metric == ""precomputed"":. ValueError: Unknown metric hellinger. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1011
https://github.com/scverse/scanpy/issues/1011:1007,modifiability,pac,packages,1007,"stances like ll_dirichlet and hellinger throw exception with small AnnDatas; If adata.n_obs < 4096 and umap version >= 0.4 and if `metric` is a distance that is not supported by scikit-learn (like ll_dirichlet or hellinger), we get a ValueError:. Code for reproducing with UMAP >= 0.4:. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.neighbors(adata, metric='hellinger'). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-5-e2c66b650fd3> in <module>. 2 . 3 adata = sc.datasets.paul15(). ----> 4 sc.pp.neighbors(adata, metric='hellinger'). ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 109 method=method, metric=metric, metric_kwds=metric_kwds,. --> 110 random_state=random_state,. 111 ). 112 adata.uns['neighbors'] = {}. ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 686 # non-euclidean case and approx nearest neighbors. 687 if X.shape[0] < 4096:. --> 688 X = pairwise_distances(X, metric=metric, **metric_kwds). 689 metric = 'precomputed'. 690 knn_indices, knn_distances, forest = compute_neighbors_umap(. ~/.anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, **kwds). 1550 raise ValueError(""Unknown metric %s. "". 1551 ""Valid metrics are %s, or 'precomputed', or a "". -> 1552 ""callable"" % (metric, _VALID_METRICS)). 1553 . 1554 if metric == ""precomputed"":. ValueError: Unknown metric hellinger. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1011
https://github.com/scverse/scanpy/issues/1011:1442,modifiability,pac,packages,1442,".pp.neighbors(adata, metric='hellinger'). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-5-e2c66b650fd3> in <module>. 2 . 3 adata = sc.datasets.paul15(). ----> 4 sc.pp.neighbors(adata, metric='hellinger'). ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 109 method=method, metric=metric, metric_kwds=metric_kwds,. --> 110 random_state=random_state,. 111 ). 112 adata.uns['neighbors'] = {}. ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 686 # non-euclidean case and approx nearest neighbors. 687 if X.shape[0] < 4096:. --> 688 X = pairwise_distances(X, metric=metric, **metric_kwds). 689 metric = 'precomputed'. 690 knn_indices, knn_distances, forest = compute_neighbors_umap(. ~/.anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, **kwds). 1550 raise ValueError(""Unknown metric %s. "". 1551 ""Valid metrics are %s, or 'precomputed', or a "". -> 1552 ""callable"" % (metric, _VALID_METRICS)). 1553 . 1554 if metric == ""precomputed"":. ValueError: Unknown metric hellinger. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'haversine'], or 'precomputed', or a callable. ```. Similar to this code in UMAP (https://github.com/lmcinnes/umap/pull/259/files), we should check if scikit's `pairwise_distances` throws a ValueError and fallback to UMAP's own pairwise `pairwise_special_metric` function.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1011
https://github.com/scverse/scanpy/issues/1011:57,safety,except,exception,57,"New UMAP distances like ll_dirichlet and hellinger throw exception with small AnnDatas; If adata.n_obs < 4096 and umap version >= 0.4 and if `metric` is a distance that is not supported by scikit-learn (like ll_dirichlet or hellinger), we get a ValueError:. Code for reproducing with UMAP >= 0.4:. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.neighbors(adata, metric='hellinger'). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-5-e2c66b650fd3> in <module>. 2 . 3 adata = sc.datasets.paul15(). ----> 4 sc.pp.neighbors(adata, metric='hellinger'). ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 109 method=method, metric=metric, metric_kwds=metric_kwds,. --> 110 random_state=random_state,. 111 ). 112 adata.uns['neighbors'] = {}. ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 686 # non-euclidean case and approx nearest neighbors. 687 if X.shape[0] < 4096:. --> 688 X = pairwise_distances(X, metric=metric, **metric_kwds). 689 metric = 'precomputed'. 690 knn_indices, knn_distances, forest = compute_neighbors_umap(. ~/.anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, **kwds). 1550 raise ValueError(""Unknown metric %s. "". 1551 ""Valid metrics are %s, or 'precomputed', or a "". -> 1552 ""callable"" % (metric, _VALID_METRICS)). 1553 . 1554 if metric == ""precomputed"":. ValueError: Unknown metric hellinger. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1011
https://github.com/scverse/scanpy/issues/1011:473,safety,input,input-,473,"New UMAP distances like ll_dirichlet and hellinger throw exception with small AnnDatas; If adata.n_obs < 4096 and umap version >= 0.4 and if `metric` is a distance that is not supported by scikit-learn (like ll_dirichlet or hellinger), we get a ValueError:. Code for reproducing with UMAP >= 0.4:. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.neighbors(adata, metric='hellinger'). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-5-e2c66b650fd3> in <module>. 2 . 3 adata = sc.datasets.paul15(). ----> 4 sc.pp.neighbors(adata, metric='hellinger'). ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 109 method=method, metric=metric, metric_kwds=metric_kwds,. --> 110 random_state=random_state,. 111 ). 112 adata.uns['neighbors'] = {}. ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 686 # non-euclidean case and approx nearest neighbors. 687 if X.shape[0] < 4096:. --> 688 X = pairwise_distances(X, metric=metric, **metric_kwds). 689 metric = 'precomputed'. 690 knn_indices, knn_distances, forest = compute_neighbors_umap(. ~/.anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, **kwds). 1550 raise ValueError(""Unknown metric %s. "". 1551 ""Valid metrics are %s, or 'precomputed', or a "". -> 1552 ""callable"" % (metric, _VALID_METRICS)). 1553 . 1554 if metric == ""precomputed"":. ValueError: Unknown metric hellinger. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1011
https://github.com/scverse/scanpy/issues/1011:499,safety,modul,module,499,"New UMAP distances like ll_dirichlet and hellinger throw exception with small AnnDatas; If adata.n_obs < 4096 and umap version >= 0.4 and if `metric` is a distance that is not supported by scikit-learn (like ll_dirichlet or hellinger), we get a ValueError:. Code for reproducing with UMAP >= 0.4:. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.neighbors(adata, metric='hellinger'). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-5-e2c66b650fd3> in <module>. 2 . 3 adata = sc.datasets.paul15(). ----> 4 sc.pp.neighbors(adata, metric='hellinger'). ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 109 method=method, metric=metric, metric_kwds=metric_kwds,. --> 110 random_state=random_state,. 111 ). 112 adata.uns['neighbors'] = {}. ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 686 # non-euclidean case and approx nearest neighbors. 687 if X.shape[0] < 4096:. --> 688 X = pairwise_distances(X, metric=metric, **metric_kwds). 689 metric = 'precomputed'. 690 knn_indices, knn_distances, forest = compute_neighbors_umap(. ~/.anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, **kwds). 1550 raise ValueError(""Unknown metric %s. "". 1551 ""Valid metrics are %s, or 'precomputed', or a "". -> 1552 ""callable"" % (metric, _VALID_METRICS)). 1553 . 1554 if metric == ""precomputed"":. ValueError: Unknown metric hellinger. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1011
https://github.com/scverse/scanpy/issues/1011:1583,safety,Valid,Valid,1583,".pp.neighbors(adata, metric='hellinger'). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-5-e2c66b650fd3> in <module>. 2 . 3 adata = sc.datasets.paul15(). ----> 4 sc.pp.neighbors(adata, metric='hellinger'). ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 109 method=method, metric=metric, metric_kwds=metric_kwds,. --> 110 random_state=random_state,. 111 ). 112 adata.uns['neighbors'] = {}. ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 686 # non-euclidean case and approx nearest neighbors. 687 if X.shape[0] < 4096:. --> 688 X = pairwise_distances(X, metric=metric, **metric_kwds). 689 metric = 'precomputed'. 690 knn_indices, knn_distances, forest = compute_neighbors_umap(. ~/.anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, **kwds). 1550 raise ValueError(""Unknown metric %s. "". 1551 ""Valid metrics are %s, or 'precomputed', or a "". -> 1552 ""callable"" % (metric, _VALID_METRICS)). 1553 . 1554 if metric == ""precomputed"":. ValueError: Unknown metric hellinger. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'haversine'], or 'precomputed', or a callable. ```. Similar to this code in UMAP (https://github.com/lmcinnes/umap/pull/259/files), we should check if scikit's `pairwise_distances` throws a ValueError and fallback to UMAP's own pairwise `pairwise_special_metric` function.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1011
https://github.com/scverse/scanpy/issues/1011:1758,safety,Valid,Valid,1758,".pp.neighbors(adata, metric='hellinger'). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-5-e2c66b650fd3> in <module>. 2 . 3 adata = sc.datasets.paul15(). ----> 4 sc.pp.neighbors(adata, metric='hellinger'). ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 109 method=method, metric=metric, metric_kwds=metric_kwds,. --> 110 random_state=random_state,. 111 ). 112 adata.uns['neighbors'] = {}. ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 686 # non-euclidean case and approx nearest neighbors. 687 if X.shape[0] < 4096:. --> 688 X = pairwise_distances(X, metric=metric, **metric_kwds). 689 metric = 'precomputed'. 690 knn_indices, knn_distances, forest = compute_neighbors_umap(. ~/.anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, **kwds). 1550 raise ValueError(""Unknown metric %s. "". 1551 ""Valid metrics are %s, or 'precomputed', or a "". -> 1552 ""callable"" % (metric, _VALID_METRICS)). 1553 . 1554 if metric == ""precomputed"":. ValueError: Unknown metric hellinger. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule', 'wminkowski', 'haversine'], or 'precomputed', or a callable. ```. Similar to this code in UMAP (https://github.com/lmcinnes/umap/pull/259/files), we should check if scikit's `pairwise_distances` throws a ValueError and fallback to UMAP's own pairwise `pairwise_special_metric` function.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1011
https://github.com/scverse/scanpy/issues/1011:429,testability,Trace,Traceback,429,"New UMAP distances like ll_dirichlet and hellinger throw exception with small AnnDatas; If adata.n_obs < 4096 and umap version >= 0.4 and if `metric` is a distance that is not supported by scikit-learn (like ll_dirichlet or hellinger), we get a ValueError:. Code for reproducing with UMAP >= 0.4:. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.neighbors(adata, metric='hellinger'). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-5-e2c66b650fd3> in <module>. 2 . 3 adata = sc.datasets.paul15(). ----> 4 sc.pp.neighbors(adata, metric='hellinger'). ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 109 method=method, metric=metric, metric_kwds=metric_kwds,. --> 110 random_state=random_state,. 111 ). 112 adata.uns['neighbors'] = {}. ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 686 # non-euclidean case and approx nearest neighbors. 687 if X.shape[0] < 4096:. --> 688 X = pairwise_distances(X, metric=metric, **metric_kwds). 689 metric = 'precomputed'. 690 knn_indices, knn_distances, forest = compute_neighbors_umap(. ~/.anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, **kwds). 1550 raise ValueError(""Unknown metric %s. "". 1551 ""Valid metrics are %s, or 'precomputed', or a "". -> 1552 ""callable"" % (metric, _VALID_METRICS)). 1553 . 1554 if metric == ""precomputed"":. ValueError: Unknown metric hellinger. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1011
https://github.com/scverse/scanpy/issues/1011:176,usability,support,supported,176,"New UMAP distances like ll_dirichlet and hellinger throw exception with small AnnDatas; If adata.n_obs < 4096 and umap version >= 0.4 and if `metric` is a distance that is not supported by scikit-learn (like ll_dirichlet or hellinger), we get a ValueError:. Code for reproducing with UMAP >= 0.4:. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.neighbors(adata, metric='hellinger'). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-5-e2c66b650fd3> in <module>. 2 . 3 adata = sc.datasets.paul15(). ----> 4 sc.pp.neighbors(adata, metric='hellinger'). ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 109 method=method, metric=metric, metric_kwds=metric_kwds,. --> 110 random_state=random_state,. 111 ). 112 adata.uns['neighbors'] = {}. ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 686 # non-euclidean case and approx nearest neighbors. 687 if X.shape[0] < 4096:. --> 688 X = pairwise_distances(X, metric=metric, **metric_kwds). 689 metric = 'precomputed'. 690 knn_indices, knn_distances, forest = compute_neighbors_umap(. ~/.anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, **kwds). 1550 raise ValueError(""Unknown metric %s. "". 1551 ""Valid metrics are %s, or 'precomputed', or a "". -> 1552 ""callable"" % (metric, _VALID_METRICS)). 1553 . 1554 if metric == ""precomputed"":. ValueError: Unknown metric hellinger. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1011
https://github.com/scverse/scanpy/issues/1011:196,usability,learn,learn,196,"New UMAP distances like ll_dirichlet and hellinger throw exception with small AnnDatas; If adata.n_obs < 4096 and umap version >= 0.4 and if `metric` is a distance that is not supported by scikit-learn (like ll_dirichlet or hellinger), we get a ValueError:. Code for reproducing with UMAP >= 0.4:. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.neighbors(adata, metric='hellinger'). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-5-e2c66b650fd3> in <module>. 2 . 3 adata = sc.datasets.paul15(). ----> 4 sc.pp.neighbors(adata, metric='hellinger'). ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 109 method=method, metric=metric, metric_kwds=metric_kwds,. --> 110 random_state=random_state,. 111 ). 112 adata.uns['neighbors'] = {}. ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 686 # non-euclidean case and approx nearest neighbors. 687 if X.shape[0] < 4096:. --> 688 X = pairwise_distances(X, metric=metric, **metric_kwds). 689 metric = 'precomputed'. 690 knn_indices, knn_distances, forest = compute_neighbors_umap(. ~/.anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, **kwds). 1550 raise ValueError(""Unknown metric %s. "". 1551 ""Valid metrics are %s, or 'precomputed', or a "". -> 1552 ""callable"" % (metric, _VALID_METRICS)). 1553 . 1554 if metric == ""precomputed"":. ValueError: Unknown metric hellinger. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1011
https://github.com/scverse/scanpy/issues/1011:473,usability,input,input-,473,"New UMAP distances like ll_dirichlet and hellinger throw exception with small AnnDatas; If adata.n_obs < 4096 and umap version >= 0.4 and if `metric` is a distance that is not supported by scikit-learn (like ll_dirichlet or hellinger), we get a ValueError:. Code for reproducing with UMAP >= 0.4:. ```python. import scanpy as sc. adata = sc.datasets.paul15(). sc.pp.neighbors(adata, metric='hellinger'). ```. ```pytb. ValueError Traceback (most recent call last). <ipython-input-5-e2c66b650fd3> in <module>. 2 . 3 adata = sc.datasets.paul15(). ----> 4 sc.pp.neighbors(adata, metric='hellinger'). ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. 109 method=method, metric=metric, metric_kwds=metric_kwds,. --> 110 random_state=random_state,. 111 ). 112 adata.uns['neighbors'] = {}. ~/.anaconda3/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in compute_neighbors(self, n_neighbors, knn, n_pcs, use_rep, method, random_state, write_knn_indices, metric, metric_kwds). 686 # non-euclidean case and approx nearest neighbors. 687 if X.shape[0] < 4096:. --> 688 X = pairwise_distances(X, metric=metric, **metric_kwds). 689 metric = 'precomputed'. 690 knn_indices, knn_distances, forest = compute_neighbors_umap(. ~/.anaconda3/lib/python3.7/site-packages/sklearn/metrics/pairwise.py in pairwise_distances(X, Y, metric, n_jobs, **kwds). 1550 raise ValueError(""Unknown metric %s. "". 1551 ""Valid metrics are %s, or 'precomputed', or a "". -> 1552 ""callable"" % (metric, _VALID_METRICS)). 1553 . 1554 if metric == ""precomputed"":. ValueError: Unknown metric hellinger. Valid metrics are ['euclidean', 'l2', 'l1', 'manhattan', 'cityblock', 'braycurtis', 'canberra', 'chebyshev', 'correlation', 'cosine', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russel",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1011
https://github.com/scverse/scanpy/pull/1012:70,interoperability,coordinat,coordinate,70,Plotting function for spatial data; Support for 10x Visium images and coordinate system,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1012
https://github.com/scverse/scanpy/pull/1012:36,usability,Support,Support,36,Plotting function for spatial data; Support for 10x Visium images and coordinate system,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1012
https://github.com/scverse/scanpy/pull/1013:103,interoperability,format,format,103,Add visium_sge dataset function; 10x Spatial Gene Expression data includes tar files. The files in tar format are checked by `check_presence_download_untar()`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1013
https://github.com/scverse/scanpy/pull/1015:4,safety,test,test,4,Fix test breakages; - [x] leiden/louvain tests are fixed by 71fbae4 circumventing pandas-dev/pandas#31499. - [x] `test_read_10x[mtx_path1-h5_path1]` fixed by theislab/anndata#313. - [x] `test_plotting.test_clustermap` is caused by seaborn mwaskom/seaborn#1953,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1015
https://github.com/scverse/scanpy/pull/1015:41,safety,test,tests,41,Fix test breakages; - [x] leiden/louvain tests are fixed by 71fbae4 circumventing pandas-dev/pandas#31499. - [x] `test_read_10x[mtx_path1-h5_path1]` fixed by theislab/anndata#313. - [x] `test_plotting.test_clustermap` is caused by seaborn mwaskom/seaborn#1953,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1015
https://github.com/scverse/scanpy/pull/1015:4,testability,test,test,4,Fix test breakages; - [x] leiden/louvain tests are fixed by 71fbae4 circumventing pandas-dev/pandas#31499. - [x] `test_read_10x[mtx_path1-h5_path1]` fixed by theislab/anndata#313. - [x] `test_plotting.test_clustermap` is caused by seaborn mwaskom/seaborn#1953,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1015
https://github.com/scverse/scanpy/pull/1015:41,testability,test,tests,41,Fix test breakages; - [x] leiden/louvain tests are fixed by 71fbae4 circumventing pandas-dev/pandas#31499. - [x] `test_read_10x[mtx_path1-h5_path1]` fixed by theislab/anndata#313. - [x] `test_plotting.test_clustermap` is caused by seaborn mwaskom/seaborn#1953,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1015
https://github.com/scverse/scanpy/issues/1016:596,availability,operat,operates,596,"Metacell support; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hello! I would like to use [MetaCell](https://github.com/tanaylab/metacell.py) for some analyses. It (supposdely) operates on the KNN graph. The R documentation is more complete and can be seen [here](https://tanaylab.github.io/metacell/articles/a-basic_pbmc8k.html#building-the-balanced-cell-graph), where it shows how to run the individual libraries on metacell",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1016
https://github.com/scverse/scanpy/issues/1016:748,deployability,build,building-the-balanced-cell-graph,748,"Metacell support; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hello! I would like to use [MetaCell](https://github.com/tanaylab/metacell.py) for some analyses. It (supposdely) operates on the KNN graph. The R documentation is more complete and can be seen [here](https://tanaylab.github.io/metacell/articles/a-basic_pbmc8k.html#building-the-balanced-cell-graph), where it shows how to run the individual libraries on metacell",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1016
https://github.com/scverse/scanpy/issues/1016:102,modifiability,paramet,parameters,102,"Metacell support; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hello! I would like to use [MetaCell](https://github.com/tanaylab/metacell.py) for some analyses. It (supposdely) operates on the KNN graph. The R documentation is more complete and can be seen [here](https://tanaylab.github.io/metacell/articles/a-basic_pbmc8k.html#building-the-balanced-cell-graph), where it shows how to run the individual libraries on metacell",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1016
https://github.com/scverse/scanpy/issues/1016:379,modifiability,pac,package,379,"Metacell support; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hello! I would like to use [MetaCell](https://github.com/tanaylab/metacell.py) for some analyses. It (supposdely) operates on the KNN graph. The R documentation is more complete and can be seen [here](https://tanaylab.github.io/metacell/articles/a-basic_pbmc8k.html#building-the-balanced-cell-graph), where it shows how to run the individual libraries on metacell",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1016
https://github.com/scverse/scanpy/issues/1016:651,safety,compl,complete,651,"Metacell support; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hello! I would like to use [MetaCell](https://github.com/tanaylab/metacell.py) for some analyses. It (supposdely) operates on the KNN graph. The R documentation is more complete and can be seen [here](https://tanaylab.github.io/metacell/articles/a-basic_pbmc8k.html#building-the-balanced-cell-graph), where it shows how to run the individual libraries on metacell",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1016
https://github.com/scverse/scanpy/issues/1016:651,security,compl,complete,651,"Metacell support; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hello! I would like to use [MetaCell](https://github.com/tanaylab/metacell.py) for some analyses. It (supposdely) operates on the KNN graph. The R documentation is more complete and can be seen [here](https://tanaylab.github.io/metacell/articles/a-basic_pbmc8k.html#building-the-balanced-cell-graph), where it shows how to run the individual libraries on metacell",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1016
https://github.com/scverse/scanpy/issues/1016:184,testability,simpl,simple,184,"Metacell support; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hello! I would like to use [MetaCell](https://github.com/tanaylab/metacell.py) for some analyses. It (supposdely) operates on the KNN graph. The R documentation is more complete and can be seen [here](https://tanaylab.github.io/metacell/articles/a-basic_pbmc8k.html#building-the-balanced-cell-graph), where it shows how to run the individual libraries on metacell",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1016
https://github.com/scverse/scanpy/issues/1016:9,usability,support,support,9,"Metacell support; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hello! I would like to use [MetaCell](https://github.com/tanaylab/metacell.py) for some analyses. It (supposdely) operates on the KNN graph. The R documentation is more complete and can be seen [here](https://tanaylab.github.io/metacell/articles/a-basic_pbmc8k.html#building-the-balanced-cell-graph), where it shows how to run the individual libraries on metacell",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1016
https://github.com/scverse/scanpy/issues/1016:176,usability,tool,tool,176,"Metacell support; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hello! I would like to use [MetaCell](https://github.com/tanaylab/metacell.py) for some analyses. It (supposdely) operates on the KNN graph. The R documentation is more complete and can be seen [here](https://tanaylab.github.io/metacell/articles/a-basic_pbmc8k.html#building-the-balanced-cell-graph), where it shows how to run the individual libraries on metacell",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1016
https://github.com/scverse/scanpy/issues/1016:184,usability,simpl,simple,184,"Metacell support; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hello! I would like to use [MetaCell](https://github.com/tanaylab/metacell.py) for some analyses. It (supposdely) operates on the KNN graph. The R documentation is more complete and can be seen [here](https://tanaylab.github.io/metacell/articles/a-basic_pbmc8k.html#building-the-balanced-cell-graph), where it shows how to run the individual libraries on metacell",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1016
https://github.com/scverse/scanpy/issues/1016:200,usability,tool,tool,200,"Metacell support; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hello! I would like to use [MetaCell](https://github.com/tanaylab/metacell.py) for some analyses. It (supposdely) operates on the KNN graph. The R documentation is more complete and can be seen [here](https://tanaylab.github.io/metacell/articles/a-basic_pbmc8k.html#building-the-balanced-cell-graph), where it shows how to run the individual libraries on metacell",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1016
https://github.com/scverse/scanpy/issues/1016:248,usability,tool,tools,248,"Metacell support; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hello! I would like to use [MetaCell](https://github.com/tanaylab/metacell.py) for some analyses. It (supposdely) operates on the KNN graph. The R documentation is more complete and can be seen [here](https://tanaylab.github.io/metacell/articles/a-basic_pbmc8k.html#building-the-balanced-cell-graph), where it shows how to run the individual libraries on metacell",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1016
https://github.com/scverse/scanpy/issues/1016:348,usability,tool,tools,348,"Metacell support; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hello! I would like to use [MetaCell](https://github.com/tanaylab/metacell.py) for some analyses. It (supposdely) operates on the KNN graph. The R documentation is more complete and can be seen [here](https://tanaylab.github.io/metacell/articles/a-basic_pbmc8k.html#building-the-balanced-cell-graph), where it shows how to run the individual libraries on metacell",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1016
https://github.com/scverse/scanpy/issues/1016:629,usability,document,documentation,629,"Metacell support; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [x] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [x] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. Hello! I would like to use [MetaCell](https://github.com/tanaylab/metacell.py) for some analyses. It (supposdely) operates on the KNN graph. The R documentation is more complete and can be seen [here](https://tanaylab.github.io/metacell/articles/a-basic_pbmc8k.html#building-the-balanced-cell-graph), where it shows how to run the individual libraries on metacell",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1016
https://github.com/scverse/scanpy/issues/1017:108,availability,error,error,108,"sc.tl.louvain() function bugged in pandas 1.0.0; sc.tl.louvain() works fine in pandas==0.25.3. but it shows error in new pandas==1.0.0:. TypeError: Expected unicode, got numpy.str_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1017
https://github.com/scverse/scanpy/issues/1017:108,performance,error,error,108,"sc.tl.louvain() function bugged in pandas 1.0.0; sc.tl.louvain() works fine in pandas==0.25.3. but it shows error in new pandas==1.0.0:. TypeError: Expected unicode, got numpy.str_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1017
https://github.com/scverse/scanpy/issues/1017:108,safety,error,error,108,"sc.tl.louvain() function bugged in pandas 1.0.0; sc.tl.louvain() works fine in pandas==0.25.3. but it shows error in new pandas==1.0.0:. TypeError: Expected unicode, got numpy.str_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1017
https://github.com/scverse/scanpy/issues/1017:108,usability,error,error,108,"sc.tl.louvain() function bugged in pandas 1.0.0; sc.tl.louvain() works fine in pandas==0.25.3. but it shows error in new pandas==1.0.0:. TypeError: Expected unicode, got numpy.str_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1017
https://github.com/scverse/scanpy/pull/1020:49,deployability,version,versions,49,"Use matplotlib 3.1 and adapt tests; Now only mpl versions start to break more important stuff than 3d plotting, so let’s update. <details><summary>Outdated</summary>. The umap_with_edges went . | from | to |. | ---- | -- |. | ![grafik](https://user-images.githubusercontent.com/291575/73608411-df447900-45c2-11ea-948f-164ba4204416.png) | ![grafik](https://user-images.githubusercontent.com/291575/73608416-e8354a80-45c2-11ea-9456-82a00cfca79d.png) |. Is the new one correct? If not, what did I do wrong? </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1020
https://github.com/scverse/scanpy/pull/1020:121,deployability,updat,update,121,"Use matplotlib 3.1 and adapt tests; Now only mpl versions start to break more important stuff than 3d plotting, so let’s update. <details><summary>Outdated</summary>. The umap_with_edges went . | from | to |. | ---- | -- |. | ![grafik](https://user-images.githubusercontent.com/291575/73608411-df447900-45c2-11ea-948f-164ba4204416.png) | ![grafik](https://user-images.githubusercontent.com/291575/73608416-e8354a80-45c2-11ea-9456-82a00cfca79d.png) |. Is the new one correct? If not, what did I do wrong? </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1020
https://github.com/scverse/scanpy/pull/1020:23,energy efficiency,adapt,adapt,23,"Use matplotlib 3.1 and adapt tests; Now only mpl versions start to break more important stuff than 3d plotting, so let’s update. <details><summary>Outdated</summary>. The umap_with_edges went . | from | to |. | ---- | -- |. | ![grafik](https://user-images.githubusercontent.com/291575/73608411-df447900-45c2-11ea-948f-164ba4204416.png) | ![grafik](https://user-images.githubusercontent.com/291575/73608416-e8354a80-45c2-11ea-9456-82a00cfca79d.png) |. Is the new one correct? If not, what did I do wrong? </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1020
https://github.com/scverse/scanpy/pull/1020:23,integrability,adapt,adapt,23,"Use matplotlib 3.1 and adapt tests; Now only mpl versions start to break more important stuff than 3d plotting, so let’s update. <details><summary>Outdated</summary>. The umap_with_edges went . | from | to |. | ---- | -- |. | ![grafik](https://user-images.githubusercontent.com/291575/73608411-df447900-45c2-11ea-948f-164ba4204416.png) | ![grafik](https://user-images.githubusercontent.com/291575/73608416-e8354a80-45c2-11ea-9456-82a00cfca79d.png) |. Is the new one correct? If not, what did I do wrong? </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1020
https://github.com/scverse/scanpy/pull/1020:49,integrability,version,versions,49,"Use matplotlib 3.1 and adapt tests; Now only mpl versions start to break more important stuff than 3d plotting, so let’s update. <details><summary>Outdated</summary>. The umap_with_edges went . | from | to |. | ---- | -- |. | ![grafik](https://user-images.githubusercontent.com/291575/73608411-df447900-45c2-11ea-948f-164ba4204416.png) | ![grafik](https://user-images.githubusercontent.com/291575/73608416-e8354a80-45c2-11ea-9456-82a00cfca79d.png) |. Is the new one correct? If not, what did I do wrong? </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1020
https://github.com/scverse/scanpy/pull/1020:23,interoperability,adapt,adapt,23,"Use matplotlib 3.1 and adapt tests; Now only mpl versions start to break more important stuff than 3d plotting, so let’s update. <details><summary>Outdated</summary>. The umap_with_edges went . | from | to |. | ---- | -- |. | ![grafik](https://user-images.githubusercontent.com/291575/73608411-df447900-45c2-11ea-948f-164ba4204416.png) | ![grafik](https://user-images.githubusercontent.com/291575/73608416-e8354a80-45c2-11ea-9456-82a00cfca79d.png) |. Is the new one correct? If not, what did I do wrong? </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1020
https://github.com/scverse/scanpy/pull/1020:23,modifiability,adapt,adapt,23,"Use matplotlib 3.1 and adapt tests; Now only mpl versions start to break more important stuff than 3d plotting, so let’s update. <details><summary>Outdated</summary>. The umap_with_edges went . | from | to |. | ---- | -- |. | ![grafik](https://user-images.githubusercontent.com/291575/73608411-df447900-45c2-11ea-948f-164ba4204416.png) | ![grafik](https://user-images.githubusercontent.com/291575/73608416-e8354a80-45c2-11ea-9456-82a00cfca79d.png) |. Is the new one correct? If not, what did I do wrong? </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1020
https://github.com/scverse/scanpy/pull/1020:49,modifiability,version,versions,49,"Use matplotlib 3.1 and adapt tests; Now only mpl versions start to break more important stuff than 3d plotting, so let’s update. <details><summary>Outdated</summary>. The umap_with_edges went . | from | to |. | ---- | -- |. | ![grafik](https://user-images.githubusercontent.com/291575/73608411-df447900-45c2-11ea-948f-164ba4204416.png) | ![grafik](https://user-images.githubusercontent.com/291575/73608416-e8354a80-45c2-11ea-9456-82a00cfca79d.png) |. Is the new one correct? If not, what did I do wrong? </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1020
https://github.com/scverse/scanpy/pull/1020:29,safety,test,tests,29,"Use matplotlib 3.1 and adapt tests; Now only mpl versions start to break more important stuff than 3d plotting, so let’s update. <details><summary>Outdated</summary>. The umap_with_edges went . | from | to |. | ---- | -- |. | ![grafik](https://user-images.githubusercontent.com/291575/73608411-df447900-45c2-11ea-948f-164ba4204416.png) | ![grafik](https://user-images.githubusercontent.com/291575/73608416-e8354a80-45c2-11ea-9456-82a00cfca79d.png) |. Is the new one correct? If not, what did I do wrong? </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1020
https://github.com/scverse/scanpy/pull/1020:121,safety,updat,update,121,"Use matplotlib 3.1 and adapt tests; Now only mpl versions start to break more important stuff than 3d plotting, so let’s update. <details><summary>Outdated</summary>. The umap_with_edges went . | from | to |. | ---- | -- |. | ![grafik](https://user-images.githubusercontent.com/291575/73608411-df447900-45c2-11ea-948f-164ba4204416.png) | ![grafik](https://user-images.githubusercontent.com/291575/73608416-e8354a80-45c2-11ea-9456-82a00cfca79d.png) |. Is the new one correct? If not, what did I do wrong? </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1020
https://github.com/scverse/scanpy/pull/1020:121,security,updat,update,121,"Use matplotlib 3.1 and adapt tests; Now only mpl versions start to break more important stuff than 3d plotting, so let’s update. <details><summary>Outdated</summary>. The umap_with_edges went . | from | to |. | ---- | -- |. | ![grafik](https://user-images.githubusercontent.com/291575/73608411-df447900-45c2-11ea-948f-164ba4204416.png) | ![grafik](https://user-images.githubusercontent.com/291575/73608416-e8354a80-45c2-11ea-9456-82a00cfca79d.png) |. Is the new one correct? If not, what did I do wrong? </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1020
https://github.com/scverse/scanpy/pull/1020:29,testability,test,tests,29,"Use matplotlib 3.1 and adapt tests; Now only mpl versions start to break more important stuff than 3d plotting, so let’s update. <details><summary>Outdated</summary>. The umap_with_edges went . | from | to |. | ---- | -- |. | ![grafik](https://user-images.githubusercontent.com/291575/73608411-df447900-45c2-11ea-948f-164ba4204416.png) | ![grafik](https://user-images.githubusercontent.com/291575/73608416-e8354a80-45c2-11ea-9456-82a00cfca79d.png) |. Is the new one correct? If not, what did I do wrong? </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1020
https://github.com/scverse/scanpy/pull/1020:244,usability,user,user-images,244,"Use matplotlib 3.1 and adapt tests; Now only mpl versions start to break more important stuff than 3d plotting, so let’s update. <details><summary>Outdated</summary>. The umap_with_edges went . | from | to |. | ---- | -- |. | ![grafik](https://user-images.githubusercontent.com/291575/73608411-df447900-45c2-11ea-948f-164ba4204416.png) | ![grafik](https://user-images.githubusercontent.com/291575/73608416-e8354a80-45c2-11ea-9456-82a00cfca79d.png) |. Is the new one correct? If not, what did I do wrong? </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1020
https://github.com/scverse/scanpy/pull/1020:356,usability,user,user-images,356,"Use matplotlib 3.1 and adapt tests; Now only mpl versions start to break more important stuff than 3d plotting, so let’s update. <details><summary>Outdated</summary>. The umap_with_edges went . | from | to |. | ---- | -- |. | ![grafik](https://user-images.githubusercontent.com/291575/73608411-df447900-45c2-11ea-948f-164ba4204416.png) | ![grafik](https://user-images.githubusercontent.com/291575/73608416-e8354a80-45c2-11ea-9456-82a00cfca79d.png) |. Is the new one correct? If not, what did I do wrong? </details>",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1020
https://github.com/scverse/scanpy/issues/1021:408,availability,avail,available,408,"sc.pp.neighbors throws KeyError: diffmap_evals due to obsm concatenation; Duplicating from https://github.com/theislab/anndata/pull/284:. @Koncopd @falexwolf . There is an issue with the obsm concatenation. When we run `sc.tl.diffmap` with different anndata objects, concatenate them and run sc.pp.neighbors on the concatenated new anndata, we get the following exception. The reason is that `X_diffmap'` is available in `obsm` but `.uns['diffmap_evals']` is not. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <timed exec> in <module>. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 104 if adata.isview: # we shouldn't need this here... 105 adata._init_as_actual(adata.copy()). --> 106 neighbors = Neighbors(adata). 107 neighbors.compute_neighbors(. 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in __init__(self, adata, n_dcs). 527 self._number_connected_components = self._connected_components[0]. 528 if 'X_diffmap' in adata.obsm_keys():. --> 529 self._eigen_values = _backwards_compat_get_full_eval(adata). 530 self._eigen_basis = _backwards_compat_get_full_X_diffmap(adata). 531 if n_dcs is not None:. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in _backwards_compat_get_full_eval(adata). 395 return np.r_[1, adata.uns['diffmap_evals']]. 396 else:. --> 397 return adata.uns['diffmap_evals']. 398 . 399 . KeyError: 'diffmap_evals'. ```. Doesn't it make more sense to make `obsm` concatenation False by default, by the way? Should concatenating `obsm` be the default behaviour?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1021
https://github.com/scverse/scanpy/issues/1021:611,deployability,modul,module,611,"sc.pp.neighbors throws KeyError: diffmap_evals due to obsm concatenation; Duplicating from https://github.com/theislab/anndata/pull/284:. @Koncopd @falexwolf . There is an issue with the obsm concatenation. When we run `sc.tl.diffmap` with different anndata objects, concatenate them and run sc.pp.neighbors on the concatenated new anndata, we get the following exception. The reason is that `X_diffmap'` is available in `obsm` but `.uns['diffmap_evals']` is not. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <timed exec> in <module>. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 104 if adata.isview: # we shouldn't need this here... 105 adata._init_as_actual(adata.copy()). --> 106 neighbors = Neighbors(adata). 107 neighbors.compute_neighbors(. 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in __init__(self, adata, n_dcs). 527 self._number_connected_components = self._connected_components[0]. 528 if 'X_diffmap' in adata.obsm_keys():. --> 529 self._eigen_values = _backwards_compat_get_full_eval(adata). 530 self._eigen_basis = _backwards_compat_get_full_X_diffmap(adata). 531 if n_dcs is not None:. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in _backwards_compat_get_full_eval(adata). 395 return np.r_[1, adata.uns['diffmap_evals']]. 396 else:. --> 397 return adata.uns['diffmap_evals']. 398 . 399 . KeyError: 'diffmap_evals'. ```. Doesn't it make more sense to make `obsm` concatenation False by default, by the way? Should concatenating `obsm` be the default behaviour?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1021
https://github.com/scverse/scanpy/issues/1021:611,modifiability,modul,module,611,"sc.pp.neighbors throws KeyError: diffmap_evals due to obsm concatenation; Duplicating from https://github.com/theislab/anndata/pull/284:. @Koncopd @falexwolf . There is an issue with the obsm concatenation. When we run `sc.tl.diffmap` with different anndata objects, concatenate them and run sc.pp.neighbors on the concatenated new anndata, we get the following exception. The reason is that `X_diffmap'` is available in `obsm` but `.uns['diffmap_evals']` is not. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <timed exec> in <module>. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 104 if adata.isview: # we shouldn't need this here... 105 adata._init_as_actual(adata.copy()). --> 106 neighbors = Neighbors(adata). 107 neighbors.compute_neighbors(. 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in __init__(self, adata, n_dcs). 527 self._number_connected_components = self._connected_components[0]. 528 if 'X_diffmap' in adata.obsm_keys():. --> 529 self._eigen_values = _backwards_compat_get_full_eval(adata). 530 self._eigen_basis = _backwards_compat_get_full_X_diffmap(adata). 531 if n_dcs is not None:. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in _backwards_compat_get_full_eval(adata). 395 return np.r_[1, adata.uns['diffmap_evals']]. 396 else:. --> 397 return adata.uns['diffmap_evals']. 398 . 399 . KeyError: 'diffmap_evals'. ```. Doesn't it make more sense to make `obsm` concatenation False by default, by the way? Should concatenating `obsm` be the default behaviour?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1021
https://github.com/scverse/scanpy/issues/1021:650,modifiability,pac,packages,650,"sc.pp.neighbors throws KeyError: diffmap_evals due to obsm concatenation; Duplicating from https://github.com/theislab/anndata/pull/284:. @Koncopd @falexwolf . There is an issue with the obsm concatenation. When we run `sc.tl.diffmap` with different anndata objects, concatenate them and run sc.pp.neighbors on the concatenated new anndata, we get the following exception. The reason is that `X_diffmap'` is available in `obsm` but `.uns['diffmap_evals']` is not. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <timed exec> in <module>. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 104 if adata.isview: # we shouldn't need this here... 105 adata._init_as_actual(adata.copy()). --> 106 neighbors = Neighbors(adata). 107 neighbors.compute_neighbors(. 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in __init__(self, adata, n_dcs). 527 self._number_connected_components = self._connected_components[0]. 528 if 'X_diffmap' in adata.obsm_keys():. --> 529 self._eigen_values = _backwards_compat_get_full_eval(adata). 530 self._eigen_basis = _backwards_compat_get_full_X_diffmap(adata). 531 if n_dcs is not None:. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in _backwards_compat_get_full_eval(adata). 395 return np.r_[1, adata.uns['diffmap_evals']]. 396 else:. --> 397 return adata.uns['diffmap_evals']. 398 . 399 . KeyError: 'diffmap_evals'. ```. Doesn't it make more sense to make `obsm` concatenation False by default, by the way? Should concatenating `obsm` be the default behaviour?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1021
https://github.com/scverse/scanpy/issues/1021:1058,modifiability,pac,packages,1058,"sc.pp.neighbors throws KeyError: diffmap_evals due to obsm concatenation; Duplicating from https://github.com/theislab/anndata/pull/284:. @Koncopd @falexwolf . There is an issue with the obsm concatenation. When we run `sc.tl.diffmap` with different anndata objects, concatenate them and run sc.pp.neighbors on the concatenated new anndata, we get the following exception. The reason is that `X_diffmap'` is available in `obsm` but `.uns['diffmap_evals']` is not. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <timed exec> in <module>. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 104 if adata.isview: # we shouldn't need this here... 105 adata._init_as_actual(adata.copy()). --> 106 neighbors = Neighbors(adata). 107 neighbors.compute_neighbors(. 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in __init__(self, adata, n_dcs). 527 self._number_connected_components = self._connected_components[0]. 528 if 'X_diffmap' in adata.obsm_keys():. --> 529 self._eigen_values = _backwards_compat_get_full_eval(adata). 530 self._eigen_basis = _backwards_compat_get_full_X_diffmap(adata). 531 if n_dcs is not None:. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in _backwards_compat_get_full_eval(adata). 395 return np.r_[1, adata.uns['diffmap_evals']]. 396 else:. --> 397 return adata.uns['diffmap_evals']. 398 . 399 . KeyError: 'diffmap_evals'. ```. Doesn't it make more sense to make `obsm` concatenation False by default, by the way? Should concatenating `obsm` be the default behaviour?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1021
https://github.com/scverse/scanpy/issues/1021:1437,modifiability,pac,packages,1437,"sc.pp.neighbors throws KeyError: diffmap_evals due to obsm concatenation; Duplicating from https://github.com/theislab/anndata/pull/284:. @Koncopd @falexwolf . There is an issue with the obsm concatenation. When we run `sc.tl.diffmap` with different anndata objects, concatenate them and run sc.pp.neighbors on the concatenated new anndata, we get the following exception. The reason is that `X_diffmap'` is available in `obsm` but `.uns['diffmap_evals']` is not. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <timed exec> in <module>. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 104 if adata.isview: # we shouldn't need this here... 105 adata._init_as_actual(adata.copy()). --> 106 neighbors = Neighbors(adata). 107 neighbors.compute_neighbors(. 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in __init__(self, adata, n_dcs). 527 self._number_connected_components = self._connected_components[0]. 528 if 'X_diffmap' in adata.obsm_keys():. --> 529 self._eigen_values = _backwards_compat_get_full_eval(adata). 530 self._eigen_basis = _backwards_compat_get_full_X_diffmap(adata). 531 if n_dcs is not None:. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in _backwards_compat_get_full_eval(adata). 395 return np.r_[1, adata.uns['diffmap_evals']]. 396 else:. --> 397 return adata.uns['diffmap_evals']. 398 . 399 . KeyError: 'diffmap_evals'. ```. Doesn't it make more sense to make `obsm` concatenation False by default, by the way? Should concatenating `obsm` be the default behaviour?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1021
https://github.com/scverse/scanpy/issues/1021:595,performance,time,timed,595,"sc.pp.neighbors throws KeyError: diffmap_evals due to obsm concatenation; Duplicating from https://github.com/theislab/anndata/pull/284:. @Koncopd @falexwolf . There is an issue with the obsm concatenation. When we run `sc.tl.diffmap` with different anndata objects, concatenate them and run sc.pp.neighbors on the concatenated new anndata, we get the following exception. The reason is that `X_diffmap'` is available in `obsm` but `.uns['diffmap_evals']` is not. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <timed exec> in <module>. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 104 if adata.isview: # we shouldn't need this here... 105 adata._init_as_actual(adata.copy()). --> 106 neighbors = Neighbors(adata). 107 neighbors.compute_neighbors(. 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in __init__(self, adata, n_dcs). 527 self._number_connected_components = self._connected_components[0]. 528 if 'X_diffmap' in adata.obsm_keys():. --> 529 self._eigen_values = _backwards_compat_get_full_eval(adata). 530 self._eigen_basis = _backwards_compat_get_full_X_diffmap(adata). 531 if n_dcs is not None:. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in _backwards_compat_get_full_eval(adata). 395 return np.r_[1, adata.uns['diffmap_evals']]. 396 else:. --> 397 return adata.uns['diffmap_evals']. 398 . 399 . KeyError: 'diffmap_evals'. ```. Doesn't it make more sense to make `obsm` concatenation False by default, by the way? Should concatenating `obsm` be the default behaviour?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1021
https://github.com/scverse/scanpy/issues/1021:408,reliability,availab,available,408,"sc.pp.neighbors throws KeyError: diffmap_evals due to obsm concatenation; Duplicating from https://github.com/theislab/anndata/pull/284:. @Koncopd @falexwolf . There is an issue with the obsm concatenation. When we run `sc.tl.diffmap` with different anndata objects, concatenate them and run sc.pp.neighbors on the concatenated new anndata, we get the following exception. The reason is that `X_diffmap'` is available in `obsm` but `.uns['diffmap_evals']` is not. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <timed exec> in <module>. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 104 if adata.isview: # we shouldn't need this here... 105 adata._init_as_actual(adata.copy()). --> 106 neighbors = Neighbors(adata). 107 neighbors.compute_neighbors(. 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in __init__(self, adata, n_dcs). 527 self._number_connected_components = self._connected_components[0]. 528 if 'X_diffmap' in adata.obsm_keys():. --> 529 self._eigen_values = _backwards_compat_get_full_eval(adata). 530 self._eigen_basis = _backwards_compat_get_full_X_diffmap(adata). 531 if n_dcs is not None:. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in _backwards_compat_get_full_eval(adata). 395 return np.r_[1, adata.uns['diffmap_evals']]. 396 else:. --> 397 return adata.uns['diffmap_evals']. 398 . 399 . KeyError: 'diffmap_evals'. ```. Doesn't it make more sense to make `obsm` concatenation False by default, by the way? Should concatenating `obsm` be the default behaviour?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1021
https://github.com/scverse/scanpy/issues/1021:1665,reliability,Doe,Doesn,1665,"sc.pp.neighbors throws KeyError: diffmap_evals due to obsm concatenation; Duplicating from https://github.com/theislab/anndata/pull/284:. @Koncopd @falexwolf . There is an issue with the obsm concatenation. When we run `sc.tl.diffmap` with different anndata objects, concatenate them and run sc.pp.neighbors on the concatenated new anndata, we get the following exception. The reason is that `X_diffmap'` is available in `obsm` but `.uns['diffmap_evals']` is not. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <timed exec> in <module>. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 104 if adata.isview: # we shouldn't need this here... 105 adata._init_as_actual(adata.copy()). --> 106 neighbors = Neighbors(adata). 107 neighbors.compute_neighbors(. 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in __init__(self, adata, n_dcs). 527 self._number_connected_components = self._connected_components[0]. 528 if 'X_diffmap' in adata.obsm_keys():. --> 529 self._eigen_values = _backwards_compat_get_full_eval(adata). 530 self._eigen_basis = _backwards_compat_get_full_X_diffmap(adata). 531 if n_dcs is not None:. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in _backwards_compat_get_full_eval(adata). 395 return np.r_[1, adata.uns['diffmap_evals']]. 396 else:. --> 397 return adata.uns['diffmap_evals']. 398 . 399 . KeyError: 'diffmap_evals'. ```. Doesn't it make more sense to make `obsm` concatenation False by default, by the way? Should concatenating `obsm` be the default behaviour?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1021
https://github.com/scverse/scanpy/issues/1021:362,safety,except,exception,362,"sc.pp.neighbors throws KeyError: diffmap_evals due to obsm concatenation; Duplicating from https://github.com/theislab/anndata/pull/284:. @Koncopd @falexwolf . There is an issue with the obsm concatenation. When we run `sc.tl.diffmap` with different anndata objects, concatenate them and run sc.pp.neighbors on the concatenated new anndata, we get the following exception. The reason is that `X_diffmap'` is available in `obsm` but `.uns['diffmap_evals']` is not. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <timed exec> in <module>. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 104 if adata.isview: # we shouldn't need this here... 105 adata._init_as_actual(adata.copy()). --> 106 neighbors = Neighbors(adata). 107 neighbors.compute_neighbors(. 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in __init__(self, adata, n_dcs). 527 self._number_connected_components = self._connected_components[0]. 528 if 'X_diffmap' in adata.obsm_keys():. --> 529 self._eigen_values = _backwards_compat_get_full_eval(adata). 530 self._eigen_basis = _backwards_compat_get_full_X_diffmap(adata). 531 if n_dcs is not None:. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in _backwards_compat_get_full_eval(adata). 395 return np.r_[1, adata.uns['diffmap_evals']]. 396 else:. --> 397 return adata.uns['diffmap_evals']. 398 . 399 . KeyError: 'diffmap_evals'. ```. Doesn't it make more sense to make `obsm` concatenation False by default, by the way? Should concatenating `obsm` be the default behaviour?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1021
https://github.com/scverse/scanpy/issues/1021:408,safety,avail,available,408,"sc.pp.neighbors throws KeyError: diffmap_evals due to obsm concatenation; Duplicating from https://github.com/theislab/anndata/pull/284:. @Koncopd @falexwolf . There is an issue with the obsm concatenation. When we run `sc.tl.diffmap` with different anndata objects, concatenate them and run sc.pp.neighbors on the concatenated new anndata, we get the following exception. The reason is that `X_diffmap'` is available in `obsm` but `.uns['diffmap_evals']` is not. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <timed exec> in <module>. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 104 if adata.isview: # we shouldn't need this here... 105 adata._init_as_actual(adata.copy()). --> 106 neighbors = Neighbors(adata). 107 neighbors.compute_neighbors(. 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in __init__(self, adata, n_dcs). 527 self._number_connected_components = self._connected_components[0]. 528 if 'X_diffmap' in adata.obsm_keys():. --> 529 self._eigen_values = _backwards_compat_get_full_eval(adata). 530 self._eigen_basis = _backwards_compat_get_full_X_diffmap(adata). 531 if n_dcs is not None:. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in _backwards_compat_get_full_eval(adata). 395 return np.r_[1, adata.uns['diffmap_evals']]. 396 else:. --> 397 return adata.uns['diffmap_evals']. 398 . 399 . KeyError: 'diffmap_evals'. ```. Doesn't it make more sense to make `obsm` concatenation False by default, by the way? Should concatenating `obsm` be the default behaviour?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1021
https://github.com/scverse/scanpy/issues/1021:611,safety,modul,module,611,"sc.pp.neighbors throws KeyError: diffmap_evals due to obsm concatenation; Duplicating from https://github.com/theislab/anndata/pull/284:. @Koncopd @falexwolf . There is an issue with the obsm concatenation. When we run `sc.tl.diffmap` with different anndata objects, concatenate them and run sc.pp.neighbors on the concatenated new anndata, we get the following exception. The reason is that `X_diffmap'` is available in `obsm` but `.uns['diffmap_evals']` is not. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <timed exec> in <module>. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 104 if adata.isview: # we shouldn't need this here... 105 adata._init_as_actual(adata.copy()). --> 106 neighbors = Neighbors(adata). 107 neighbors.compute_neighbors(. 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in __init__(self, adata, n_dcs). 527 self._number_connected_components = self._connected_components[0]. 528 if 'X_diffmap' in adata.obsm_keys():. --> 529 self._eigen_values = _backwards_compat_get_full_eval(adata). 530 self._eigen_basis = _backwards_compat_get_full_X_diffmap(adata). 531 if n_dcs is not None:. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in _backwards_compat_get_full_eval(adata). 395 return np.r_[1, adata.uns['diffmap_evals']]. 396 else:. --> 397 return adata.uns['diffmap_evals']. 398 . 399 . KeyError: 'diffmap_evals'. ```. Doesn't it make more sense to make `obsm` concatenation False by default, by the way? Should concatenating `obsm` be the default behaviour?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1021
https://github.com/scverse/scanpy/issues/1021:408,security,availab,available,408,"sc.pp.neighbors throws KeyError: diffmap_evals due to obsm concatenation; Duplicating from https://github.com/theislab/anndata/pull/284:. @Koncopd @falexwolf . There is an issue with the obsm concatenation. When we run `sc.tl.diffmap` with different anndata objects, concatenate them and run sc.pp.neighbors on the concatenated new anndata, we get the following exception. The reason is that `X_diffmap'` is available in `obsm` but `.uns['diffmap_evals']` is not. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <timed exec> in <module>. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 104 if adata.isview: # we shouldn't need this here... 105 adata._init_as_actual(adata.copy()). --> 106 neighbors = Neighbors(adata). 107 neighbors.compute_neighbors(. 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in __init__(self, adata, n_dcs). 527 self._number_connected_components = self._connected_components[0]. 528 if 'X_diffmap' in adata.obsm_keys():. --> 529 self._eigen_values = _backwards_compat_get_full_eval(adata). 530 self._eigen_basis = _backwards_compat_get_full_X_diffmap(adata). 531 if n_dcs is not None:. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in _backwards_compat_get_full_eval(adata). 395 return np.r_[1, adata.uns['diffmap_evals']]. 396 else:. --> 397 return adata.uns['diffmap_evals']. 398 . 399 . KeyError: 'diffmap_evals'. ```. Doesn't it make more sense to make `obsm` concatenation False by default, by the way? Should concatenating `obsm` be the default behaviour?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1021
https://github.com/scverse/scanpy/issues/1021:559,testability,Trace,Traceback,559,"sc.pp.neighbors throws KeyError: diffmap_evals due to obsm concatenation; Duplicating from https://github.com/theislab/anndata/pull/284:. @Koncopd @falexwolf . There is an issue with the obsm concatenation. When we run `sc.tl.diffmap` with different anndata objects, concatenate them and run sc.pp.neighbors on the concatenated new anndata, we get the following exception. The reason is that `X_diffmap'` is available in `obsm` but `.uns['diffmap_evals']` is not. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <timed exec> in <module>. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 104 if adata.isview: # we shouldn't need this here... 105 adata._init_as_actual(adata.copy()). --> 106 neighbors = Neighbors(adata). 107 neighbors.compute_neighbors(. 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in __init__(self, adata, n_dcs). 527 self._number_connected_components = self._connected_components[0]. 528 if 'X_diffmap' in adata.obsm_keys():. --> 529 self._eigen_values = _backwards_compat_get_full_eval(adata). 530 self._eigen_basis = _backwards_compat_get_full_X_diffmap(adata). 531 if n_dcs is not None:. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in _backwards_compat_get_full_eval(adata). 395 return np.r_[1, adata.uns['diffmap_evals']]. 396 else:. --> 397 return adata.uns['diffmap_evals']. 398 . 399 . KeyError: 'diffmap_evals'. ```. Doesn't it make more sense to make `obsm` concatenation False by default, by the way? Should concatenating `obsm` be the default behaviour?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1021
https://github.com/scverse/scanpy/issues/1021:1794,usability,behavi,behaviour,1794,"sc.pp.neighbors throws KeyError: diffmap_evals due to obsm concatenation; Duplicating from https://github.com/theislab/anndata/pull/284:. @Koncopd @falexwolf . There is an issue with the obsm concatenation. When we run `sc.tl.diffmap` with different anndata objects, concatenate them and run sc.pp.neighbors on the concatenated new anndata, we get the following exception. The reason is that `X_diffmap'` is available in `obsm` but `.uns['diffmap_evals']` is not. ```pytb. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <timed exec> in <module>. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in neighbors(adata, n_neighbors, n_pcs, use_rep, knn, random_state, method, metric, metric_kwds, copy). 104 if adata.isview: # we shouldn't need this here... 105 adata._init_as_actual(adata.copy()). --> 106 neighbors = Neighbors(adata). 107 neighbors.compute_neighbors(. 108 n_neighbors=n_neighbors, knn=knn, n_pcs=n_pcs, use_rep=use_rep,. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in __init__(self, adata, n_dcs). 527 self._number_connected_components = self._connected_components[0]. 528 if 'X_diffmap' in adata.obsm_keys():. --> 529 self._eigen_values = _backwards_compat_get_full_eval(adata). 530 self._eigen_basis = _backwards_compat_get_full_X_diffmap(adata). 531 if n_dcs is not None:. /opt/conda/lib/python3.7/site-packages/scanpy/neighbors/__init__.py in _backwards_compat_get_full_eval(adata). 395 return np.r_[1, adata.uns['diffmap_evals']]. 396 else:. --> 397 return adata.uns['diffmap_evals']. 398 . 399 . KeyError: 'diffmap_evals'. ```. Doesn't it make more sense to make `obsm` concatenation False by default, by the way? Should concatenating `obsm` be the default behaviour?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1021
https://github.com/scverse/scanpy/pull/1022:506,availability,Ping,Ping,506,"Avoid large copy in subsample; Speed up `subsample` when we copy by not copying the whole thing (which we did for some reason). Example of the speedup (where times are from `sc.pp.subsample(adata, frac=0.5, copy=True)`). Dataset | On a3b71d9113ee14ac0 (this PR) | On a23ad96ea013c7 (current master). --------|--------------------------|--------------. `sc.datasets.pbmc3k_processed()` | 14.9 ms ± 249 µs | 24.3 ms ± 558 µs. 9936 cell x 23000 gene dataset (w/ one layer) | 93.2 ms ± 1.82 ms| 191 ms ± 4 ms. Ping @gokceneraslan, since this touches code you also have a PR for.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1022
https://github.com/scverse/scanpy/pull/1022:283,energy efficiency,current,current,283,"Avoid large copy in subsample; Speed up `subsample` when we copy by not copying the whole thing (which we did for some reason). Example of the speedup (where times are from `sc.pp.subsample(adata, frac=0.5, copy=True)`). Dataset | On a3b71d9113ee14ac0 (this PR) | On a23ad96ea013c7 (current master). --------|--------------------------|--------------. `sc.datasets.pbmc3k_processed()` | 14.9 ms ± 249 µs | 24.3 ms ± 558 µs. 9936 cell x 23000 gene dataset (w/ one layer) | 93.2 ms ± 1.82 ms| 191 ms ± 4 ms. Ping @gokceneraslan, since this touches code you also have a PR for.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1022
https://github.com/scverse/scanpy/pull/1022:20,integrability,sub,subsample,20,"Avoid large copy in subsample; Speed up `subsample` when we copy by not copying the whole thing (which we did for some reason). Example of the speedup (where times are from `sc.pp.subsample(adata, frac=0.5, copy=True)`). Dataset | On a3b71d9113ee14ac0 (this PR) | On a23ad96ea013c7 (current master). --------|--------------------------|--------------. `sc.datasets.pbmc3k_processed()` | 14.9 ms ± 249 µs | 24.3 ms ± 558 µs. 9936 cell x 23000 gene dataset (w/ one layer) | 93.2 ms ± 1.82 ms| 191 ms ± 4 ms. Ping @gokceneraslan, since this touches code you also have a PR for.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1022
https://github.com/scverse/scanpy/pull/1022:41,integrability,sub,subsample,41,"Avoid large copy in subsample; Speed up `subsample` when we copy by not copying the whole thing (which we did for some reason). Example of the speedup (where times are from `sc.pp.subsample(adata, frac=0.5, copy=True)`). Dataset | On a3b71d9113ee14ac0 (this PR) | On a23ad96ea013c7 (current master). --------|--------------------------|--------------. `sc.datasets.pbmc3k_processed()` | 14.9 ms ± 249 µs | 24.3 ms ± 558 µs. 9936 cell x 23000 gene dataset (w/ one layer) | 93.2 ms ± 1.82 ms| 191 ms ± 4 ms. Ping @gokceneraslan, since this touches code you also have a PR for.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1022
https://github.com/scverse/scanpy/pull/1022:180,integrability,sub,subsample,180,"Avoid large copy in subsample; Speed up `subsample` when we copy by not copying the whole thing (which we did for some reason). Example of the speedup (where times are from `sc.pp.subsample(adata, frac=0.5, copy=True)`). Dataset | On a3b71d9113ee14ac0 (this PR) | On a23ad96ea013c7 (current master). --------|--------------------------|--------------. `sc.datasets.pbmc3k_processed()` | 14.9 ms ± 249 µs | 24.3 ms ± 558 µs. 9936 cell x 23000 gene dataset (w/ one layer) | 93.2 ms ± 1.82 ms| 191 ms ± 4 ms. Ping @gokceneraslan, since this touches code you also have a PR for.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1022
https://github.com/scverse/scanpy/pull/1022:463,modifiability,layer,layer,463,"Avoid large copy in subsample; Speed up `subsample` when we copy by not copying the whole thing (which we did for some reason). Example of the speedup (where times are from `sc.pp.subsample(adata, frac=0.5, copy=True)`). Dataset | On a3b71d9113ee14ac0 (this PR) | On a23ad96ea013c7 (current master). --------|--------------------------|--------------. `sc.datasets.pbmc3k_processed()` | 14.9 ms ± 249 µs | 24.3 ms ± 558 µs. 9936 cell x 23000 gene dataset (w/ one layer) | 93.2 ms ± 1.82 ms| 191 ms ± 4 ms. Ping @gokceneraslan, since this touches code you also have a PR for.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1022
https://github.com/scverse/scanpy/pull/1022:158,performance,time,times,158,"Avoid large copy in subsample; Speed up `subsample` when we copy by not copying the whole thing (which we did for some reason). Example of the speedup (where times are from `sc.pp.subsample(adata, frac=0.5, copy=True)`). Dataset | On a3b71d9113ee14ac0 (this PR) | On a23ad96ea013c7 (current master). --------|--------------------------|--------------. `sc.datasets.pbmc3k_processed()` | 14.9 ms ± 249 µs | 24.3 ms ± 558 µs. 9936 cell x 23000 gene dataset (w/ one layer) | 93.2 ms ± 1.82 ms| 191 ms ± 4 ms. Ping @gokceneraslan, since this touches code you also have a PR for.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1022
https://github.com/scverse/scanpy/pull/1022:0,safety,Avoid,Avoid,0,"Avoid large copy in subsample; Speed up `subsample` when we copy by not copying the whole thing (which we did for some reason). Example of the speedup (where times are from `sc.pp.subsample(adata, frac=0.5, copy=True)`). Dataset | On a3b71d9113ee14ac0 (this PR) | On a23ad96ea013c7 (current master). --------|--------------------------|--------------. `sc.datasets.pbmc3k_processed()` | 14.9 ms ± 249 µs | 24.3 ms ± 558 µs. 9936 cell x 23000 gene dataset (w/ one layer) | 93.2 ms ± 1.82 ms| 191 ms ± 4 ms. Ping @gokceneraslan, since this touches code you also have a PR for.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1022
https://github.com/scverse/scanpy/pull/1023:49,interoperability,coordinat,coordinates,49,Small fixes to datasets and plotting; fixed read coordinates and image key in adata.uns,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1023
https://github.com/scverse/scanpy/pull/1024:222,deployability,api,api,222,"Spatial; Draft PR (@ivirshup look, Github has that now!). Once @giovp and @Mirkazemi say it’s ready from their side, we can review and merge this. Docs:. - [read_visium](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.read_visium.html) (new). - [datasets.visium_sge](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.datasets.visium_sge.html) (new). - [pl.spatial](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.spatial.html) (new). - [pl.embedding](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.embedding.html) (new parameters)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1024
https://github.com/scverse/scanpy/pull/1024:334,deployability,api,api,334,"Spatial; Draft PR (@ivirshup look, Github has that now!). Once @giovp and @Mirkazemi say it’s ready from their side, we can review and merge this. Docs:. - [read_visium](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.read_visium.html) (new). - [datasets.visium_sge](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.datasets.visium_sge.html) (new). - [pl.spatial](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.spatial.html) (new). - [pl.embedding](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.embedding.html) (new parameters)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1024
https://github.com/scverse/scanpy/pull/1024:445,deployability,api,api,445,"Spatial; Draft PR (@ivirshup look, Github has that now!). Once @giovp and @Mirkazemi say it’s ready from their side, we can review and merge this. Docs:. - [read_visium](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.read_visium.html) (new). - [datasets.visium_sge](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.datasets.visium_sge.html) (new). - [pl.spatial](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.spatial.html) (new). - [pl.embedding](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.embedding.html) (new parameters)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1024
https://github.com/scverse/scanpy/pull/1024:549,deployability,api,api,549,"Spatial; Draft PR (@ivirshup look, Github has that now!). Once @giovp and @Mirkazemi say it’s ready from their side, we can review and merge this. Docs:. - [read_visium](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.read_visium.html) (new). - [datasets.visium_sge](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.datasets.visium_sge.html) (new). - [pl.spatial](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.spatial.html) (new). - [pl.embedding](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.embedding.html) (new parameters)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1024
https://github.com/scverse/scanpy/pull/1024:222,integrability,api,api,222,"Spatial; Draft PR (@ivirshup look, Github has that now!). Once @giovp and @Mirkazemi say it’s ready from their side, we can review and merge this. Docs:. - [read_visium](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.read_visium.html) (new). - [datasets.visium_sge](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.datasets.visium_sge.html) (new). - [pl.spatial](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.spatial.html) (new). - [pl.embedding](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.embedding.html) (new parameters)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1024
https://github.com/scverse/scanpy/pull/1024:334,integrability,api,api,334,"Spatial; Draft PR (@ivirshup look, Github has that now!). Once @giovp and @Mirkazemi say it’s ready from their side, we can review and merge this. Docs:. - [read_visium](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.read_visium.html) (new). - [datasets.visium_sge](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.datasets.visium_sge.html) (new). - [pl.spatial](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.spatial.html) (new). - [pl.embedding](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.embedding.html) (new parameters)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1024
https://github.com/scverse/scanpy/pull/1024:445,integrability,api,api,445,"Spatial; Draft PR (@ivirshup look, Github has that now!). Once @giovp and @Mirkazemi say it’s ready from their side, we can review and merge this. Docs:. - [read_visium](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.read_visium.html) (new). - [datasets.visium_sge](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.datasets.visium_sge.html) (new). - [pl.spatial](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.spatial.html) (new). - [pl.embedding](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.embedding.html) (new parameters)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1024
https://github.com/scverse/scanpy/pull/1024:549,integrability,api,api,549,"Spatial; Draft PR (@ivirshup look, Github has that now!). Once @giovp and @Mirkazemi say it’s ready from their side, we can review and merge this. Docs:. - [read_visium](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.read_visium.html) (new). - [datasets.visium_sge](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.datasets.visium_sge.html) (new). - [pl.spatial](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.spatial.html) (new). - [pl.embedding](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.embedding.html) (new parameters)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1024
https://github.com/scverse/scanpy/pull/1024:222,interoperability,api,api,222,"Spatial; Draft PR (@ivirshup look, Github has that now!). Once @giovp and @Mirkazemi say it’s ready from their side, we can review and merge this. Docs:. - [read_visium](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.read_visium.html) (new). - [datasets.visium_sge](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.datasets.visium_sge.html) (new). - [pl.spatial](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.spatial.html) (new). - [pl.embedding](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.embedding.html) (new parameters)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1024
https://github.com/scverse/scanpy/pull/1024:334,interoperability,api,api,334,"Spatial; Draft PR (@ivirshup look, Github has that now!). Once @giovp and @Mirkazemi say it’s ready from their side, we can review and merge this. Docs:. - [read_visium](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.read_visium.html) (new). - [datasets.visium_sge](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.datasets.visium_sge.html) (new). - [pl.spatial](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.spatial.html) (new). - [pl.embedding](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.embedding.html) (new parameters)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1024
https://github.com/scverse/scanpy/pull/1024:445,interoperability,api,api,445,"Spatial; Draft PR (@ivirshup look, Github has that now!). Once @giovp and @Mirkazemi say it’s ready from their side, we can review and merge this. Docs:. - [read_visium](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.read_visium.html) (new). - [datasets.visium_sge](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.datasets.visium_sge.html) (new). - [pl.spatial](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.spatial.html) (new). - [pl.embedding](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.embedding.html) (new parameters)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1024
https://github.com/scverse/scanpy/pull/1024:549,interoperability,api,api,549,"Spatial; Draft PR (@ivirshup look, Github has that now!). Once @giovp and @Mirkazemi say it’s ready from their side, we can review and merge this. Docs:. - [read_visium](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.read_visium.html) (new). - [datasets.visium_sge](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.datasets.visium_sge.html) (new). - [pl.spatial](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.spatial.html) (new). - [pl.embedding](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.embedding.html) (new parameters)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1024
https://github.com/scverse/scanpy/pull/1024:584,modifiability,paramet,parameters,584,"Spatial; Draft PR (@ivirshup look, Github has that now!). Once @giovp and @Mirkazemi say it’s ready from their side, we can review and merge this. Docs:. - [read_visium](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.read_visium.html) (new). - [datasets.visium_sge](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.datasets.visium_sge.html) (new). - [pl.spatial](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.spatial.html) (new). - [pl.embedding](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.embedding.html) (new parameters)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1024
https://github.com/scverse/scanpy/pull/1024:124,safety,review,review,124,"Spatial; Draft PR (@ivirshup look, Github has that now!). Once @giovp and @Mirkazemi say it’s ready from their side, we can review and merge this. Docs:. - [read_visium](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.read_visium.html) (new). - [datasets.visium_sge](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.datasets.visium_sge.html) (new). - [pl.spatial](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.spatial.html) (new). - [pl.embedding](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.embedding.html) (new parameters)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1024
https://github.com/scverse/scanpy/pull/1024:124,testability,review,review,124,"Spatial; Draft PR (@ivirshup look, Github has that now!). Once @giovp and @Mirkazemi say it’s ready from their side, we can review and merge this. Docs:. - [read_visium](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.read_visium.html) (new). - [datasets.visium_sge](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.datasets.visium_sge.html) (new). - [pl.spatial](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.spatial.html) (new). - [pl.embedding](https://icb-scanpy.readthedocs-hosted.com/en/latest/api/scanpy.pl.embedding.html) (new parameters)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1024
https://github.com/scverse/scanpy/pull/1025:98,usability,user,users,98,Better check for mpl bug; This way we can just remove our check once mpl fixes it. Also it points users into the right direction.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1025
https://github.com/scverse/scanpy/pull/1026:0,safety,Test,Test,0,Test that the fallback fr layout works; Breaks for me locally…,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1026
https://github.com/scverse/scanpy/pull/1026:0,testability,Test,Test,0,Test that the fallback fr layout works; Breaks for me locally…,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1026
https://github.com/scverse/scanpy/issues/1027:239,availability,error,error,239,"sc.datasets.visium_sge uses adata.is_view (anndata>=0.7rc1); <!-- Please give a clear and concise description of what the bug is: -->. Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Vers",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:924,availability,Error,Error,924,"sc.datasets.visium_sge uses adata.is_view (anndata>=0.7rc1); <!-- Please give a clear and concise description of what the bug is: -->. Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Vers",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:340,deployability,version,version,340,"sc.datasets.visium_sge uses adata.is_view (anndata>=0.7rc1); <!-- Please give a clear and concise description of what the bug is: -->. Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Vers",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:769,deployability,instal,install,769,"sc.datasets.visium_sge uses adata.is_view (anndata>=0.7rc1); <!-- Please give a clear and concise description of what the bug is: -->. Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Vers",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:1255,deployability,modul,module,1255,"Data' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3.dev17+g09b9856 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.5 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:1292,deployability,instal,install,1292,"Data' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3.dev17+g09b9856 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.5 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:1996,deployability,Version,Versions,1996,"Data' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3.dev17+g09b9856 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.5 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:2029,deployability,log,logging,2029,"Data' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3.dev17+g09b9856 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.5 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:135,energy efficiency,Load,Loading,135,"sc.datasets.visium_sge uses adata.is_view (anndata>=0.7rc1); <!-- Please give a clear and concise description of what the bug is: -->. Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Vers",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:340,integrability,version,version,340,"sc.datasets.visium_sge uses adata.is_view (anndata>=0.7rc1); <!-- Please give a clear and concise description of what the bug is: -->. Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Vers",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:1996,integrability,Version,Versions,1996,"Data' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3.dev17+g09b9856 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.5 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:629,interoperability,compatib,compatibility,629,"sc.datasets.visium_sge uses adata.is_view (anndata>=0.7rc1); <!-- Please give a clear and concise description of what the bug is: -->. Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Vers",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:340,modifiability,version,version,340,"sc.datasets.visium_sge uses adata.is_view (anndata>=0.7rc1); <!-- Please give a clear and concise description of what the bug is: -->. Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Vers",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:1010,modifiability,Variab,Variable,1010,"sium_sge uses adata.is_view (anndata>=0.7rc1); <!-- Please give a clear and concise description of what the bug is: -->. Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Ou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:1255,modifiability,modul,module,1255,"Data' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3.dev17+g09b9856 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.5 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:1470,modifiability,pac,packages,1470,"Data' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3.dev17+g09b9856 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.5 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:1676,modifiability,pac,packages,1676,"Data' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3.dev17+g09b9856 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.5 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:1996,modifiability,Version,Versions,1996,"Data' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3.dev17+g09b9856 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.5 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:135,performance,Load,Loading,135,"sc.datasets.visium_sge uses adata.is_view (anndata>=0.7rc1); <!-- Please give a clear and concise description of what the bug is: -->. Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Vers",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:239,performance,error,error,239,"sc.datasets.visium_sge uses adata.is_view (anndata>=0.7rc1); <!-- Please give a clear and concise description of what the bug is: -->. Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Vers",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:924,performance,Error,Error,924,"sc.datasets.visium_sge uses adata.is_view (anndata>=0.7rc1); <!-- Please give a clear and concise description of what the bug is: -->. Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Vers",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:239,safety,error,error,239,"sc.datasets.visium_sge uses adata.is_view (anndata>=0.7rc1); <!-- Please give a clear and concise description of what the bug is: -->. Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Vers",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:924,safety,Error,Error,924,"sc.datasets.visium_sge uses adata.is_view (anndata>=0.7rc1); <!-- Please give a clear and concise description of what the bug is: -->. Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Vers",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:1229,safety,input,input-,1229,"ads to error `'AnnData' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3.dev17+g09b9856 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.5 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:1255,safety,modul,module,1255,"Data' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3.dev17+g09b9856 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.5 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:2029,safety,log,logging,2029,"Data' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3.dev17+g09b9856 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.5 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:2029,security,log,logging,2029,"Data' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3.dev17+g09b9856 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.5 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:1185,testability,Trace,Traceback,1185,"Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3.dev17+g09b9856 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.5 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:2029,testability,log,logging,2029,"Data' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3.dev17+g09b9856 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.5 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:80,usability,clear,clear,80,"sc.datasets.visium_sge uses adata.is_view (anndata>=0.7rc1); <!-- Please give a clear and concise description of what the bug is: -->. Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Vers",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:239,usability,error,error,239,"sc.datasets.visium_sge uses adata.is_view (anndata>=0.7rc1); <!-- Please give a clear and concise description of what the bug is: -->. Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Vers",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:598,usability,prefer,preferable,598,"sc.datasets.visium_sge uses adata.is_view (anndata>=0.7rc1); <!-- Please give a clear and concise description of what the bug is: -->. Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Vers",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:671,usability,minim,minimal,671,"sc.datasets.visium_sge uses adata.is_view (anndata>=0.7rc1); <!-- Please give a clear and concise description of what the bug is: -->. Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Vers",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:924,usability,Error,Error,924,"sc.datasets.visium_sge uses adata.is_view (anndata>=0.7rc1); <!-- Please give a clear and concise description of what the bug is: -->. Loading data using `adata = sc.datasets.visium_sge('V1_Human_Lymph_Node')` with Anndata<0.7rc1 leads to error `'AnnData' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Vers",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:1229,usability,input,input-,1229,"ads to error `'AnnData' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3.dev17+g09b9856 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.5 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1027:2180,usability,learn,learn,2180,"Data' object has no attribute 'is_view'`. The reason is that the function name changed in version 0.7rc1 from `isview` -> `is_view`. I propose two possible solutions:. **Solution A**: Change requirements to `anndata>=0.7rc1`. **Solution B**: Add function to anndata:. ```python. def isview(self):. return self.is_view(). ```. I think solution B is preferable as it provides back-compatibility of anndata. ---. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. import scanpy as sc. adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Variable names are not unique. To make them unique, call `.var_names_make_unique`. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-2-59eff31dcd22> in <module>. 1 get_ipython().system('pip install git+https://github.com/theislab/scanpy.git@spatial'). 2 import scanpy as sc. ----> 3 adata = sc.datasets.visium_sge('V1_Human_Lymph_Node'). /opt/conda/lib/python3.7/site-packages/scanpy/datasets/__init__.py in visium_sge(sample_id). 368 . 369 # read h5 file. --> 370 adata = read_10x_h5(files['counts']). 371 adata.var_names_make_unique(). 372 . /opt/conda/lib/python3.7/site-packages/scanpy/readwrite.py in read_10x_h5(filename, genome, gex_only). 169 if gex_only:. 170 adata = adata[:, list(map(lambda x: x == 'Gene Expression', adata.var['feature_types']))]. --> 171 if adata.is_view:. 172 return adata.copy(). 173 else:. AttributeError: 'AnnData' object has no attribute 'is_view'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post3.dev17+g09b9856 anndata==0.6.22.post1 umap==0.3.10 numpy==1.17.5 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1027
https://github.com/scverse/scanpy/issues/1028:7,availability,cluster,clustering,7,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:119,availability,error,error,119,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:216,availability,error,error,216,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:250,availability,cluster,clustering,250,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:867,availability,cluster,clustering,867,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:7,deployability,cluster,clustering,7,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:18,deployability,fail,fails,18,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:157,deployability,fail,fails,157,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:250,deployability,cluster,clustering,250,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:420,deployability,modul,module,420,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:867,deployability,cluster,clustering,867,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:1607,deployability,Version,Versions,1607,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:1668,deployability,instal,installed,1668,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:948,energy efficiency,core,core,948,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:1211,energy efficiency,core,core,1211,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:1607,integrability,Version,Versions,1607,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:420,modifiability,modul,module,420,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:500,modifiability,pac,packages,500,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:878,modifiability,paramet,parameters,878,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:932,modifiability,pac,packages,932,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:1195,modifiability,pac,packages,1195,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:1607,modifiability,Version,Versions,1607,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:119,performance,error,error,119,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:216,performance,error,error,216,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:18,reliability,fail,fails,18,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:157,reliability,fail,fails,157,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:119,safety,error,error,119,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:216,safety,error,error,216,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:393,safety,input,input-,393,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:420,safety,modul,module,420,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:1509,security,hash,hashtable,1509,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:349,testability,Trace,Traceback,349,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:119,usability,error,error,119,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:216,usability,error,error,216,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:393,usability,input,input-,393,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/issues/1028:516,usability,tool,tools,516,"leiden clustering fails on pbmc3k tutorial; I am trying to follow the pbmc3k tutorial. I pushed through the regres_out error mentioned in #1010 , but now it fails at line: . ```python. sc.tl.leiden(adata). ```. with error : . ```pytb. running Leiden clustering. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-46-a9ad6348435f> in <module>. ----> 1 sc.tl.leiden(adata). ~/miniconda3/envs/i529/lib/python3.7/site-packages/scanpy/tools/_leiden.py in leiden(adata, resolution, restrict_to, random_state, key_added, adjacency, directed, use_weights, n_iterations, partition_type, copy, **partition_kwargs). 138 adata.obs[key_added] = pd.Categorical(. 139 values=groups.astype('U'),. --> 140 categories=natsorted(np.unique(groups).astype('U')),. 141 ). 142 # store information on the clustering parameters. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in __init__(self, values, categories, ordered, dtype, fastpath). 383 . 384 else:. --> 385 codes = _get_codes_for_values(values, dtype.categories). 386 . 387 if null_mask.any():. ~/miniconda3/envs/i529/lib/python3.7/site-packages/pandas/core/arrays/categorical.py in _get_codes_for_values(values, categories). 2574 _, cats = _get_data_algo(categories). 2575 t = hash_klass(len(cats)). -> 2576 t.map_locations(cats). 2577 return coerce_indexer_dtype(t.lookup(vals), cats). 2578 . pandas/_libs/hashtable_class_helper.pxi in pandas._libs.hashtable.StringHashTable.map_locations(). TypeError: Expected unicode, got numpy.str_. ```. #### Versions:. scanpy __version__ is 1.4.4.post1, everything was installed using conda in a freshly created environment. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1028
https://github.com/scverse/scanpy/pull/1029:47,energy efficiency,Current,Currently,47,"Add reading from .uns colors for sc.pl.violin; Currently, `sc.pl.violin` does not support support reading colors from `adata['uns']`, this PR fixes it. Prior to this PR, the below ""works"":. ```python. sc.pl.violin(adata, keys=['initial_size'], stripplot=True, groupby='initial_size'). ```. i.e. takes about ~30 seconds to plot, because `groupby` is not categorical (there's no check), now. it raises `AttributeError: Can only use .cat accessor with a 'category' dtype` because of the color addition.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1029
https://github.com/scverse/scanpy/pull/1029:73,reliability,doe,does,73,"Add reading from .uns colors for sc.pl.violin; Currently, `sc.pl.violin` does not support support reading colors from `adata['uns']`, this PR fixes it. Prior to this PR, the below ""works"":. ```python. sc.pl.violin(adata, keys=['initial_size'], stripplot=True, groupby='initial_size'). ```. i.e. takes about ~30 seconds to plot, because `groupby` is not categorical (there's no check), now. it raises `AttributeError: Can only use .cat accessor with a 'category' dtype` because of the color addition.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1029
https://github.com/scverse/scanpy/pull/1029:435,security,access,accessor,435,"Add reading from .uns colors for sc.pl.violin; Currently, `sc.pl.violin` does not support support reading colors from `adata['uns']`, this PR fixes it. Prior to this PR, the below ""works"":. ```python. sc.pl.violin(adata, keys=['initial_size'], stripplot=True, groupby='initial_size'). ```. i.e. takes about ~30 seconds to plot, because `groupby` is not categorical (there's no check), now. it raises `AttributeError: Can only use .cat accessor with a 'category' dtype` because of the color addition.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1029
https://github.com/scverse/scanpy/pull/1029:82,usability,support,support,82,"Add reading from .uns colors for sc.pl.violin; Currently, `sc.pl.violin` does not support support reading colors from `adata['uns']`, this PR fixes it. Prior to this PR, the below ""works"":. ```python. sc.pl.violin(adata, keys=['initial_size'], stripplot=True, groupby='initial_size'). ```. i.e. takes about ~30 seconds to plot, because `groupby` is not categorical (there's no check), now. it raises `AttributeError: Can only use .cat accessor with a 'category' dtype` because of the color addition.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1029
https://github.com/scverse/scanpy/pull/1029:90,usability,support,support,90,"Add reading from .uns colors for sc.pl.violin; Currently, `sc.pl.violin` does not support support reading colors from `adata['uns']`, this PR fixes it. Prior to this PR, the below ""works"":. ```python. sc.pl.violin(adata, keys=['initial_size'], stripplot=True, groupby='initial_size'). ```. i.e. takes about ~30 seconds to plot, because `groupby` is not categorical (there's no check), now. it raises `AttributeError: Can only use .cat accessor with a 'category' dtype` because of the color addition.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1029
https://github.com/scverse/scanpy/issues/1030:10,availability,cluster,cluster,10,"Returning cluster assignments as str conflicts with matplotlib color sequences; Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python. import numpy as np. import scanpy as sc. import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))). sc.pp.neighbors(adata). sc.tl.louvain(adata). plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']). ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python. plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)). ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward? In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1030:118,availability,cluster,cluster,118,"Returning cluster assignments as str conflicts with matplotlib color sequences; Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python. import numpy as np. import scanpy as sc. import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))). sc.pp.neighbors(adata). sc.tl.louvain(adata). plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']). ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python. plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)). ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward? In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1030:545,availability,error,error,545,"Returning cluster assignments as str conflicts with matplotlib color sequences; Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python. import numpy as np. import scanpy as sc. import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))). sc.pp.neighbors(adata). sc.tl.louvain(adata). plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']). ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python. plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)). ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward? In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1030:963,availability,cluster,cluster,963,"Returning cluster assignments as str conflicts with matplotlib color sequences; Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python. import numpy as np. import scanpy as sc. import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))). sc.pp.neighbors(adata). sc.tl.louvain(adata). plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']). ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python. plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)). ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward? In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1030:1720,availability,cluster,cluster,1720,"Returning cluster assignments as str conflicts with matplotlib color sequences; Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python. import numpy as np. import scanpy as sc. import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))). sc.pp.neighbors(adata). sc.tl.louvain(adata). plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']). ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python. plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)). ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward? In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1030:1785,availability,cluster,cluster,1785,"Returning cluster assignments as str conflicts with matplotlib color sequences; Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python. import numpy as np. import scanpy as sc. import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))). sc.pp.neighbors(adata). sc.tl.louvain(adata). plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']). ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python. plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)). ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward? In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1030:10,deployability,cluster,cluster,10,"Returning cluster assignments as str conflicts with matplotlib color sequences; Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python. import numpy as np. import scanpy as sc. import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))). sc.pp.neighbors(adata). sc.tl.louvain(adata). plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']). ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python. plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)). ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward? In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1030:118,deployability,cluster,cluster,118,"Returning cluster assignments as str conflicts with matplotlib color sequences; Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python. import numpy as np. import scanpy as sc. import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))). sc.pp.neighbors(adata). sc.tl.louvain(adata). plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']). ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python. plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)). ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward? In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1030:963,deployability,cluster,cluster,963,"Returning cluster assignments as str conflicts with matplotlib color sequences; Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python. import numpy as np. import scanpy as sc. import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))). sc.pp.neighbors(adata). sc.tl.louvain(adata). plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']). ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python. plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)). ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward? In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1030:1720,deployability,cluster,cluster,1720,"Returning cluster assignments as str conflicts with matplotlib color sequences; Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python. import numpy as np. import scanpy as sc. import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))). sc.pp.neighbors(adata). sc.tl.louvain(adata). plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']). ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python. plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)). ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward? In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1030:1785,deployability,cluster,cluster,1785,"Returning cluster assignments as str conflicts with matplotlib color sequences; Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python. import numpy as np. import scanpy as sc. import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))). sc.pp.neighbors(adata). sc.tl.louvain(adata). plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']). ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python. plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)). ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward? In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1030:80,energy efficiency,Current,Currently,80,"Returning cluster assignments as str conflicts with matplotlib color sequences; Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python. import numpy as np. import scanpy as sc. import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))). sc.pp.neighbors(adata). sc.tl.louvain(adata). plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']). ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python. plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)). ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward? In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1030:892,integrability,sub,submitted,892,"Returning cluster assignments as str conflicts with matplotlib color sequences; Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python. import numpy as np. import scanpy as sc. import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))). sc.pp.neighbors(adata). sc.tl.louvain(adata). plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']). ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python. plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)). ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward? In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1030:1234,integrability,rout,routinely,1234,"Returning cluster assignments as str conflicts with matplotlib color sequences; Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python. import numpy as np. import scanpy as sc. import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))). sc.pp.neighbors(adata). sc.tl.louvain(adata). plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']). ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python. plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)). ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward? In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1030:37,interoperability,conflict,conflicts,37,"Returning cluster assignments as str conflicts with matplotlib color sequences; Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python. import numpy as np. import scanpy as sc. import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))). sc.pp.neighbors(adata). sc.tl.louvain(adata). plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']). ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python. plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)). ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward? In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1030:185,interoperability,incompatib,incompatibility,185,"Returning cluster assignments as str conflicts with matplotlib color sequences; Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python. import numpy as np. import scanpy as sc. import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))). sc.pp.neighbors(adata). sc.tl.louvain(adata). plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']). ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python. plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)). ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward? In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1030:545,performance,error,error,545,"Returning cluster assignments as str conflicts with matplotlib color sequences; Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python. import numpy as np. import scanpy as sc. import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))). sc.pp.neighbors(adata). sc.tl.louvain(adata). plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']). ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python. plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)). ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward? In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1030:545,safety,error,error,545,"Returning cluster assignments as str conflicts with matplotlib color sequences; Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python. import numpy as np. import scanpy as sc. import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))). sc.pp.neighbors(adata). sc.tl.louvain(adata). plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']). ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python. plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)). ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward? In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1030:1532,safety,avoid,avoid,1532,"Returning cluster assignments as str conflicts with matplotlib color sequences; Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python. import numpy as np. import scanpy as sc. import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))). sc.pp.neighbors(adata). sc.tl.louvain(adata). plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']). ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python. plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)). ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward? In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1030:1864,security,access,accessible,1864,"Returning cluster assignments as str conflicts with matplotlib color sequences; Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python. import numpy as np. import scanpy as sc. import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))). sc.pp.neighbors(adata). sc.tl.louvain(adata). plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']). ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python. plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)). ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward? In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1030:1501,testability,understand,understand,1501,"Returning cluster assignments as str conflicts with matplotlib color sequences; Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python. import numpy as np. import scanpy as sc. import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))). sc.pp.neighbors(adata). sc.tl.louvain(adata). plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']). ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python. plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)). ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward? In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1030:545,usability,error,error,545,"Returning cluster assignments as str conflicts with matplotlib color sequences; Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python. import numpy as np. import scanpy as sc. import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))). sc.pp.neighbors(adata). sc.tl.louvain(adata). plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']). ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python. plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)). ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward? In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1030:921,usability,behavi,behavior,921,"Returning cluster assignments as str conflicts with matplotlib color sequences; Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python. import numpy as np. import scanpy as sc. import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))). sc.pp.neighbors(adata). sc.tl.louvain(adata). plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']). ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python. plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)). ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward? In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1030:1109,usability,tool,tools,1109,"Returning cluster assignments as str conflicts with matplotlib color sequences; Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python. import numpy as np. import scanpy as sc. import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))). sc.pp.neighbors(adata). sc.tl.louvain(adata). plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']). ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python. plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)). ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward? In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/issues/1030:1848,usability,tool,tools,1848,"Returning cluster assignments as str conflicts with matplotlib color sequences; Currently, `sc.tl.louvain` etc return cluster assignments as a Categorical with dtype `str` resulting in incompatibility with matplotlib color sequences. For example, the following code raises a ValueError:. ```python. import numpy as np. import scanpy as sc. import matplotlib.pyplot as plt. adata = sc.AnnData(np.random.normal(size=(100,2))). sc.pp.neighbors(adata). sc.tl.louvain(adata). plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain']). ```. The error is: `ValueError: RGBA values should be within 0-1 range`. Funnily enough, this used to work due to a bug in matplotlib that was fixed in https://github.com/matplotlib/matplotlib/pull/13913. Note, the following code works as intended:. ```python. plt.scatter(adata.X[:,0], adata.X[:,1], c=adata.obs['louvain'].astype(int)). ```. I would have submitted a PR changing this behavior had I not noticed that returning cluster assignments as `str` is explicitly checked here:. https://github.com/theislab/scanpy/blob/78125e6355c0cd2c4ae930495829282eea6f4a52/scanpy/tools/_utils_clustering.py#L11-L23. This brings up a larger design question in scanpy / anndata: *Why are arrays of numerics routinely converted to strings representing numbers?*. In `https://github.com/theislab/anndata/issues/311` I found a case where converting arrays of numerics to strings creates a bug when assigning to AnnData `obsm` with DataFrames with a RangeIndex. In that case, I understand there's a desire to avoid ambiguity in positional vs label indexing, but that issue was solved in pandas with the `.loc` and `.iloc` conventions. Why not carry that forward? In this case, why not just return cluster assignments as arrays of numerics as is done in `sklearn.cluster`? . I think following these conventions will make both tools much more accessible to the general Python data science community.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1030
https://github.com/scverse/scanpy/pull/1031:4,deployability,version,version,4,Fix version type; Discovered in chanzuckerberg/cellxgene#1132,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1031
https://github.com/scverse/scanpy/pull/1031:4,integrability,version,version,4,Fix version type; Discovered in chanzuckerberg/cellxgene#1132,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1031
https://github.com/scverse/scanpy/pull/1031:18,integrability,Discover,Discovered,18,Fix version type; Discovered in chanzuckerberg/cellxgene#1132,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1031
https://github.com/scverse/scanpy/pull/1031:18,interoperability,Discover,Discovered,18,Fix version type; Discovered in chanzuckerberg/cellxgene#1132,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1031
https://github.com/scverse/scanpy/pull/1031:4,modifiability,version,version,4,Fix version type; Discovered in chanzuckerberg/cellxgene#1132,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1031
https://github.com/scverse/scanpy/pull/1031:18,usability,Discov,Discovered,18,Fix version type; Discovered in chanzuckerberg/cellxgene#1132,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1031
https://github.com/scverse/scanpy/issues/1032:187,availability,down,downstream,187,"PCA fails with batch highly-variable gene correction; <!-- Please give a clear and concise description of what the bug is: -->. With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""). adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:839,availability,error,error,839,"PCA fails with batch highly-variable gene correction; <!-- Please give a clear and concise description of what the bug is: -->. With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""). adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:876,availability,Error,Error,876,"PCA fails with batch highly-variable gene correction; <!-- Please give a clear and concise description of what the bug is: -->. With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""). adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:2683,availability,error,error,2683,"ython3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'highly_variable' in adata.var.keys() else False. if use_highly_variable:. logg.info(' on highly variable genes'). adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```. ```pytb. adata.var.keys(). Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',. 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',. 'n_cells', 'highly_variable', 'means', 'dispersions',. 'dispersions_norm', 'highly_variable_nbatches',. 'highly_variable_intersection'],. dtype='object'). ```. #### Versions:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:2982,availability,consist,consists,2982,"tion/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'highly_variable' in adata.var.keys() else False. if use_highly_variable:. logg.info(' on highly variable genes'). adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```. ```pytb. adata.var.keys(). Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',. 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',. 'n_cells', 'highly_variable', 'means', 'dispersions',. 'dispersions_norm', 'highly_variable_nbatches',. 'highly_variable_intersection'],. dtype='object'). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post2 anndata==0.7.1 umap==0.3.10 numpy==1.17.0 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.3 statsmodels==0.11.0dev0+630.g4565348 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:4,deployability,fail,fails,4,"PCA fails with batch highly-variable gene correction; <!-- Please give a clear and concise description of what the bug is: -->. With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""). adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:221,deployability,fail,fail,221,"PCA fails with batch highly-variable gene correction; <!-- Please give a clear and concise description of what the bug is: -->. With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""). adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:1122,deployability,modul,module,1122,">. With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""). adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:3215,deployability,log,logg,3215,"tion/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'highly_variable' in adata.var.keys() else False. if use_highly_variable:. logg.info(' on highly variable genes'). adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```. ```pytb. adata.var.keys(). Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',. 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',. 'n_cells', 'highly_variable', 'means', 'dispersions',. 'dispersions_norm', 'highly_variable_nbatches',. 'highly_variable_intersection'],. dtype='object'). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post2 anndata==0.7.1 umap==0.3.10 numpy==1.17.0 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.3 statsmodels==0.11.0dev0+630.g4565348 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:3676,deployability,Version,Versions,3676,"tion/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'highly_variable' in adata.var.keys() else False. if use_highly_variable:. logg.info(' on highly variable genes'). adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```. ```pytb. adata.var.keys(). Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',. 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',. 'n_cells', 'highly_variable', 'means', 'dispersions',. 'dispersions_norm', 'highly_variable_nbatches',. 'highly_variable_intersection'],. dtype='object'). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post2 anndata==0.7.1 umap==0.3.10 numpy==1.17.0 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.3 statsmodels==0.11.0dev0+630.g4565348 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:3709,deployability,log,logging,3709,"tion/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'highly_variable' in adata.var.keys() else False. if use_highly_variable:. logg.info(' on highly variable genes'). adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```. ```pytb. adata.var.keys(). Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',. 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',. 'n_cells', 'highly_variable', 'means', 'dispersions',. 'dispersions_norm', 'highly_variable_nbatches',. 'highly_variable_intersection'],. dtype='object'). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post2 anndata==0.7.1 umap==0.3.10 numpy==1.17.0 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.3 statsmodels==0.11.0dev0+630.g4565348 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:322,energy efficiency,current,currently,322,"PCA fails with batch highly-variable gene correction; <!-- Please give a clear and concise description of what the bug is: -->. With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""). adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:2350,energy efficiency,estimat,estimator,2350,"ndom_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'highly_variable' in adata.var.keys() else False. if use_highly_variable:. logg.info(' on highly variable genes'). adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```. ```pytb.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:15,integrability,batch,batch,15,"PCA fails with batch highly-variable gene correction; <!-- Please give a clear and concise description of what the bug is: -->. With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""). adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:3676,integrability,Version,Versions,3676,"tion/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'highly_variable' in adata.var.keys() else False. if use_highly_variable:. logg.info(' on highly variable genes'). adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```. ```pytb. adata.var.keys(). Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',. 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',. 'n_cells', 'highly_variable', 'means', 'dispersions',. 'dispersions_norm', 'highly_variable_nbatches',. 'highly_variable_intersection'],. dtype='object'). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post2 anndata==0.7.1 umap==0.3.10 numpy==1.17.0 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.3 statsmodels==0.11.0dev0+630.g4565348 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:28,modifiability,variab,variable,28,"PCA fails with batch highly-variable gene correction; <!-- Please give a clear and concise description of what the bug is: -->. With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""). adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:1122,modifiability,modul,module,1122,">. With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""). adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:1265,modifiability,pac,packages,1265," true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""). adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_fini",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:1700,modifiability,pac,packages,1700,"ction].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:1717,modifiability,deco,decomposition,1717,".pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_inte",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:1899,modifiability,pac,packages,1899,"lock (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:1916,modifiability,deco,decomposition,1916," else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:2140,modifiability,pac,packages,2140,".pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'hig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:3001,modifiability,variab,variable,3001,"tion/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'highly_variable' in adata.var.keys() else False. if use_highly_variable:. logg.info(' on highly variable genes'). adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```. ```pytb. adata.var.keys(). Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',. 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',. 'n_cells', 'highly_variable', 'means', 'dispersions',. 'dispersions_norm', 'highly_variable_nbatches',. 'highly_variable_intersection'],. dtype='object'). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post2 anndata==0.7.1 umap==0.3.10 numpy==1.17.0 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.3 statsmodels==0.11.0dev0+630.g4565348 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:3237,modifiability,variab,variable,3237,"tion/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'highly_variable' in adata.var.keys() else False. if use_highly_variable:. logg.info(' on highly variable genes'). adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```. ```pytb. adata.var.keys(). Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',. 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',. 'n_cells', 'highly_variable', 'means', 'dispersions',. 'dispersions_norm', 'highly_variable_nbatches',. 'highly_variable_intersection'],. dtype='object'). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post2 anndata==0.7.1 umap==0.3.10 numpy==1.17.0 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.3 statsmodels==0.11.0dev0+630.g4565348 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:3676,modifiability,Version,Versions,3676,"tion/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'highly_variable' in adata.var.keys() else False. if use_highly_variable:. logg.info(' on highly variable genes'). adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```. ```pytb. adata.var.keys(). Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',. 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',. 'n_cells', 'highly_variable', 'means', 'dispersions',. 'dispersions_norm', 'highly_variable_nbatches',. 'highly_variable_intersection'],. dtype='object'). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post2 anndata==0.7.1 umap==0.3.10 numpy==1.17.0 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.3 statsmodels==0.11.0dev0+630.g4565348 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:15,performance,batch,batch,15,"PCA fails with batch highly-variable gene correction; <!-- Please give a clear and concise description of what the bug is: -->. With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""). adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:839,performance,error,error,839,"PCA fails with batch highly-variable gene correction; <!-- Please give a clear and concise description of what the bug is: -->. With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""). adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:876,performance,Error,Error,876,"PCA fails with batch highly-variable gene correction; <!-- Please give a clear and concise description of what the bug is: -->. With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""). adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:2683,performance,error,error,2683,"ython3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'highly_variable' in adata.var.keys() else False. if use_highly_variable:. logg.info(' on highly variable genes'). adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```. ```pytb. adata.var.keys(). Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',. 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',. 'n_cells', 'highly_variable', 'means', 'dispersions',. 'dispersions_norm', 'highly_variable_nbatches',. 'highly_variable_intersection'],. dtype='object'). ```. #### Versions:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:4,reliability,fail,fails,4,"PCA fails with batch highly-variable gene correction; <!-- Please give a clear and concise description of what the bug is: -->. With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""). adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:221,reliability,fail,fail,221,"PCA fails with batch highly-variable gene correction; <!-- Please give a clear and concise description of what the bug is: -->. With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""). adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:332,reliability,doe,doesn,332,"PCA fails with batch highly-variable gene correction; <!-- Please give a clear and concise description of what the bug is: -->. With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""). adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:2675,reliability,doe,doesn,2675,"py/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'highly_variable' in adata.var.keys() else False. if use_highly_variable:. logg.info(' on highly variable genes'). adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```. ```pytb. adata.var.keys(). Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',. 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',. 'n_cells', 'highly_variable', 'means', 'dispersions',. 'dispersions_norm', 'highly_variable_nbatches',. 'highly_variable_intersection'],. dtype='object'). ```. #### Ve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:839,safety,error,error,839,"PCA fails with batch highly-variable gene correction; <!-- Please give a clear and concise description of what the bug is: -->. With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""). adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:876,safety,Error,Error,876,"PCA fails with batch highly-variable gene correction; <!-- Please give a clear and concise description of what the bug is: -->. With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""). adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:1094,safety,input,input-,1094,"ption of what the bug is: -->. With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""). adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:1122,safety,modul,module,1122,">. With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""). adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:2163,safety,valid,validation,2163,"er='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'highly_variable' in adata.v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:2683,safety,error,error,2683,"ython3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'highly_variable' in adata.var.keys() else False. if use_highly_variable:. logg.info(' on highly variable genes'). adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```. ```pytb. adata.var.keys(). Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',. 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',. 'n_cells', 'highly_variable', 'means', 'dispersions',. 'dispersions_norm', 'highly_variable_nbatches',. 'highly_variable_intersection'],. dtype='object'). ```. #### Versions:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:3215,safety,log,logg,3215,"tion/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'highly_variable' in adata.var.keys() else False. if use_highly_variable:. logg.info(' on highly variable genes'). adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```. ```pytb. adata.var.keys(). Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',. 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',. 'n_cells', 'highly_variable', 'means', 'dispersions',. 'dispersions_norm', 'highly_variable_nbatches',. 'highly_variable_intersection'],. dtype='object'). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post2 anndata==0.7.1 umap==0.3.10 numpy==1.17.0 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.3 statsmodels==0.11.0dev0+630.g4565348 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:3709,safety,log,logging,3709,"tion/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'highly_variable' in adata.var.keys() else False. if use_highly_variable:. logg.info(' on highly variable genes'). adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```. ```pytb. adata.var.keys(). Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',. 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',. 'n_cells', 'highly_variable', 'means', 'dispersions',. 'dispersions_norm', 'highly_variable_nbatches',. 'highly_variable_intersection'],. dtype='object'). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post2 anndata==0.7.1 umap==0.3.10 numpy==1.17.0 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.3 statsmodels==0.11.0dev0+630.g4565348 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:2163,security,validat,validation,2163,"er='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'highly_variable' in adata.v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:3215,security,log,logg,3215,"tion/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'highly_variable' in adata.var.keys() else False. if use_highly_variable:. logg.info(' on highly variable genes'). adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```. ```pytb. adata.var.keys(). Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',. 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',. 'n_cells', 'highly_variable', 'means', 'dispersions',. 'dispersions_norm', 'highly_variable_nbatches',. 'highly_variable_intersection'],. dtype='object'). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post2 anndata==0.7.1 umap==0.3.10 numpy==1.17.0 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.3 statsmodels==0.11.0dev0+630.g4565348 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:3709,security,log,logging,3709,"tion/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'highly_variable' in adata.var.keys() else False. if use_highly_variable:. logg.info(' on highly variable genes'). adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```. ```pytb. adata.var.keys(). Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',. 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',. 'n_cells', 'highly_variable', 'means', 'dispersions',. 'dispersions_norm', 'highly_variable_nbatches',. 'highly_variable_intersection'],. dtype='object'). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post2 anndata==0.7.1 umap==0.3.10 numpy==1.17.0 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.3 statsmodels==0.11.0dev0+630.g4565348 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:1050,testability,Trace,Traceback,1050,"!-- Please give a clear and concise description of what the bug is: -->. With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""). adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:2463,testability,context,context,2463,"nents=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'highly_variable' in adata.var.keys() else False. if use_highly_variable:. logg.info(' on highly variable genes'). adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```. ```pytb. adata.var.keys(). Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',. 'pct_dropout_by_coun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:3215,testability,log,logg,3215,"tion/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'highly_variable' in adata.var.keys() else False. if use_highly_variable:. logg.info(' on highly variable genes'). adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```. ```pytb. adata.var.keys(). Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',. 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',. 'n_cells', 'highly_variable', 'means', 'dispersions',. 'dispersions_norm', 'highly_variable_nbatches',. 'highly_variable_intersection'],. dtype='object'). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post2 anndata==0.7.1 umap==0.3.10 numpy==1.17.0 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.3 statsmodels==0.11.0dev0+630.g4565348 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:3709,testability,log,logging,3709,"tion/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'highly_variable' in adata.var.keys() else False. if use_highly_variable:. logg.info(' on highly variable genes'). adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```. ```pytb. adata.var.keys(). Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',. 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',. 'n_cells', 'highly_variable', 'means', 'dispersions',. 'dispersions_norm', 'highly_variable_nbatches',. 'highly_variable_intersection'],. dtype='object'). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post2 anndata==0.7.1 umap==0.3.10 numpy==1.17.0 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.3 statsmodels==0.11.0dev0+630.g4565348 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:73,usability,clear,clear,73,"PCA fails with batch highly-variable gene correction; <!-- Please give a clear and concise description of what the bug is: -->. With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""). adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:456,usability,minim,minimal,456,"PCA fails with batch highly-variable gene correction; <!-- Please give a clear and concise description of what the bug is: -->. With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""). adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:839,usability,error,error,839,"PCA fails with batch highly-variable gene correction; <!-- Please give a clear and concise description of what the bug is: -->. With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""). adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:876,usability,Error,Error,876,"PCA fails with batch highly-variable gene correction; <!-- Please give a clear and concise description of what the bug is: -->. With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""). adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float6",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:1094,usability,input,input-,1094,"ption of what the bug is: -->. With the new `batch_key` option in `highly_variable_genes` downstream functions like PCA can fail silently with the old defaults. The same is true for `sc.pl.highly_variable_genes(adata)` which currently doesn't recognize the output key in `adata.var` is `highly_variable_intersection` rather than `highly_variable`. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=10, min_disp=0.1, batch_key=""source""). adata_hvg = adata[:, adata.var.highly_variable_intersection].copy(). sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True) # both the default None and True will error; see below. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-125-322839e541fd> in <module>. ----> 1 sc.tl.pca(adata_hvg, svd_solver='arpack', n_comps = 30, use_highly_variable=True). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:2370,usability,minim,minimum,2370,"info, use_highly_variable, dtype, copy, chunked, chunk_size). 529 pca_ = TruncatedSVD(n_components=n_comps, random_state=random_state). 530 X = adata_comp.X. --> 531 X_pca = pca_.fit_transform(X). 532 . 533 if X_pca.dtype.descr != np.dtype(dtype).descr: X_pca = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'highly_variable' in adata.var.keys() else False. if use_highly_variable:. logg.info(' on highly variable genes'). adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```. ```pytb. adata.var.keys(). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:2629,usability,minim,minimum,2629," = X_pca.astype(dtype). ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'highly_variable' in adata.var.keys() else False. if use_highly_variable:. logg.info(' on highly variable genes'). adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```. ```pytb. adata.var.keys(). Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',. 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',. 'n_cells', 'highly_variable', 'means', 'dispersions',. 'dispersions_norm', 'highly_variable_nbatches',. 'highly_variable_i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:2683,usability,error,error,2683,"ython3.6/site-packages/sklearn/decomposition/pca.py in fit_transform(self, X, y). 358 . 359 """""". --> 360 U, S, V = self._fit(X). 361 U = U[:, :self.n_components_]. 362 . ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/decomposition/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'highly_variable' in adata.var.keys() else False. if use_highly_variable:. logg.info(' on highly variable genes'). adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```. ```pytb. adata.var.keys(). Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',. 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',. 'n_cells', 'highly_variable', 'means', 'dispersions',. 'dispersions_norm', 'highly_variable_nbatches',. 'highly_variable_intersection'],. dtype='object'). ```. #### Versions:.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:2982,usability,consist,consists,2982,"tion/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'highly_variable' in adata.var.keys() else False. if use_highly_variable:. logg.info(' on highly variable genes'). adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```. ```pytb. adata.var.keys(). Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',. 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',. 'n_cells', 'highly_variable', 'means', 'dispersions',. 'dispersions_norm', 'highly_variable_nbatches',. 'highly_variable_intersection'],. dtype='object'). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post2 anndata==0.7.1 umap==0.3.10 numpy==1.17.0 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.3 statsmodels==0.11.0dev0+630.g4565348 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1032:3838,usability,learn,learn,3838,"tion/pca.py in _fit(self, X). 380 . 381 X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,. --> 382 copy=self.copy). 383 . 384 # Handle n_components==None. ~/anaconda2/envs/scanpy/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator). 556 "" a minimum of %d is required%s."". 557 % (n_features, array.shape, ensure_min_features,. --> 558 context)). 559 . 560 if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:. ValueError: Found array with 0 feature(s) (shape=(44495, 0)) while a minimum of 1 is required. ```. The `pca` code doesn't error here, because `highly_variable_intersection` makes `'highly_variable' in adata.var.keys()` evaluate to `True`:. ```. if use_highly_variable is True and 'highly_variable' not in adata.var.keys():. raise ValueError('Did not find adata.var[\'highly_variable\']. '. 'Either your data already only consists of highly-variable genes '. 'or consider running `pp.highly_variable_genes` first.'). if use_highly_variable is None:. use_highly_variable = True if 'highly_variable' in adata.var.keys() else False. if use_highly_variable:. logg.info(' on highly variable genes'). adata_comp = adata[:, adata.var['highly_variable']] if use_highly_variable else adata. ```. ```pytb. adata.var.keys(). Index(['mito', 'n_cells_by_counts', 'mean_counts', 'log1p_mean_counts',. 'pct_dropout_by_counts', 'total_counts', 'log1p_total_counts',. 'n_cells', 'highly_variable', 'means', 'dispersions',. 'dispersions_norm', 'highly_variable_nbatches',. 'highly_variable_intersection'],. dtype='object'). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post2 anndata==0.7.1 umap==0.3.10 numpy==1.17.0 scipy==1.3.0 pandas==0.24.2 scikit-learn==0.21.3 statsmodels==0.11.0dev0+630.g4565348 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1032
https://github.com/scverse/scanpy/issues/1033:22,deployability,fail,fails,22,"highly_variable_genes fails with `batch_key` and `inplace=False`; Came across this while investigating #1032. . ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pp.highly_variable_genes(pbmc, inplace=False). ```. ```pytb. /Users/isaac/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py:58: RuntimeWarning: invalid value encountered in log. dispersion = np.log(dispersion). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-36b7cb4d9c0f> in <module>. 1 import scanpy as sc. 2 pbmc = sc.datasets.pbmc3k_processed(). ----> 3 sc.pp.highly_variable_genes(pbmc, batch_key=""louvain"", inplace=False). ~/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 347 ('highly_variable_intersection', np.bool_),. 348 ]). --> 349 return np.rec.fromarrays(arrays, dtype=dtypes). /usr/local/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 615 . 616 if dtype is not None:. --> 617 descr = sb.dtype(dtype). 618 _names = descr.names. 619 else:. TypeError: data type not understood. ````. Separately, could we return a dataframe here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1033
https://github.com/scverse/scanpy/issues/1033:370,deployability,log,log,370,"highly_variable_genes fails with `batch_key` and `inplace=False`; Came across this while investigating #1032. . ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pp.highly_variable_genes(pbmc, inplace=False). ```. ```pytb. /Users/isaac/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py:58: RuntimeWarning: invalid value encountered in log. dispersion = np.log(dispersion). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-36b7cb4d9c0f> in <module>. 1 import scanpy as sc. 2 pbmc = sc.datasets.pbmc3k_processed(). ----> 3 sc.pp.highly_variable_genes(pbmc, batch_key=""louvain"", inplace=False). ~/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 347 ('highly_variable_intersection', np.bool_),. 348 ]). --> 349 return np.rec.fromarrays(arrays, dtype=dtypes). /usr/local/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 615 . 616 if dtype is not None:. --> 617 descr = sb.dtype(dtype). 618 _names = descr.names. 619 else:. TypeError: data type not understood. ````. Separately, could we return a dataframe here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1033
https://github.com/scverse/scanpy/issues/1033:391,deployability,log,log,391,"highly_variable_genes fails with `batch_key` and `inplace=False`; Came across this while investigating #1032. . ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pp.highly_variable_genes(pbmc, inplace=False). ```. ```pytb. /Users/isaac/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py:58: RuntimeWarning: invalid value encountered in log. dispersion = np.log(dispersion). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-36b7cb4d9c0f> in <module>. 1 import scanpy as sc. 2 pbmc = sc.datasets.pbmc3k_processed(). ----> 3 sc.pp.highly_variable_genes(pbmc, batch_key=""louvain"", inplace=False). ~/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 347 ('highly_variable_intersection', np.bool_),. 348 ]). --> 349 return np.rec.fromarrays(arrays, dtype=dtypes). /usr/local/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 615 . 616 if dtype is not None:. --> 617 descr = sb.dtype(dtype). 618 _names = descr.names. 619 else:. TypeError: data type not understood. ````. Separately, could we return a dataframe here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1033
https://github.com/scverse/scanpy/issues/1033:565,deployability,modul,module,565,"highly_variable_genes fails with `batch_key` and `inplace=False`; Came across this while investigating #1032. . ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pp.highly_variable_genes(pbmc, inplace=False). ```. ```pytb. /Users/isaac/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py:58: RuntimeWarning: invalid value encountered in log. dispersion = np.log(dispersion). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-36b7cb4d9c0f> in <module>. 1 import scanpy as sc. 2 pbmc = sc.datasets.pbmc3k_processed(). ----> 3 sc.pp.highly_variable_genes(pbmc, batch_key=""louvain"", inplace=False). ~/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 347 ('highly_variable_intersection', np.bool_),. 348 ]). --> 349 return np.rec.fromarrays(arrays, dtype=dtypes). /usr/local/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 615 . 616 if dtype is not None:. --> 617 descr = sb.dtype(dtype). 618 _names = descr.names. 619 else:. TypeError: data type not understood. ````. Separately, could we return a dataframe here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1033
https://github.com/scverse/scanpy/issues/1033:1068,energy efficiency,core,core,1068,"highly_variable_genes fails with `batch_key` and `inplace=False`; Came across this while investigating #1032. . ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pp.highly_variable_genes(pbmc, inplace=False). ```. ```pytb. /Users/isaac/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py:58: RuntimeWarning: invalid value encountered in log. dispersion = np.log(dispersion). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-36b7cb4d9c0f> in <module>. 1 import scanpy as sc. 2 pbmc = sc.datasets.pbmc3k_processed(). ----> 3 sc.pp.highly_variable_genes(pbmc, batch_key=""louvain"", inplace=False). ~/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 347 ('highly_variable_intersection', np.bool_),. 348 ]). --> 349 return np.rec.fromarrays(arrays, dtype=dtypes). /usr/local/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 615 . 616 if dtype is not None:. --> 617 descr = sb.dtype(dtype). 618 _names = descr.names. 619 else:. TypeError: data type not understood. ````. Separately, could we return a dataframe here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1033
https://github.com/scverse/scanpy/issues/1033:881,integrability,sub,subset,881,"highly_variable_genes fails with `batch_key` and `inplace=False`; Came across this while investigating #1032. . ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pp.highly_variable_genes(pbmc, inplace=False). ```. ```pytb. /Users/isaac/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py:58: RuntimeWarning: invalid value encountered in log. dispersion = np.log(dispersion). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-36b7cb4d9c0f> in <module>. 1 import scanpy as sc. 2 pbmc = sc.datasets.pbmc3k_processed(). ----> 3 sc.pp.highly_variable_genes(pbmc, batch_key=""louvain"", inplace=False). ~/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 347 ('highly_variable_intersection', np.bool_),. 348 ]). --> 349 return np.rec.fromarrays(arrays, dtype=dtypes). /usr/local/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 615 . 616 if dtype is not None:. --> 617 descr = sb.dtype(dtype). 618 _names = descr.names. 619 else:. TypeError: data type not understood. ````. Separately, could we return a dataframe here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1033
https://github.com/scverse/scanpy/issues/1033:1123,interoperability,format,formats,1123,"highly_variable_genes fails with `batch_key` and `inplace=False`; Came across this while investigating #1032. . ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pp.highly_variable_genes(pbmc, inplace=False). ```. ```pytb. /Users/isaac/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py:58: RuntimeWarning: invalid value encountered in log. dispersion = np.log(dispersion). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-36b7cb4d9c0f> in <module>. 1 import scanpy as sc. 2 pbmc = sc.datasets.pbmc3k_processed(). ----> 3 sc.pp.highly_variable_genes(pbmc, batch_key=""louvain"", inplace=False). ~/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 347 ('highly_variable_intersection', np.bool_),. 348 ]). --> 349 return np.rec.fromarrays(arrays, dtype=dtypes). /usr/local/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 615 . 616 if dtype is not None:. --> 617 descr = sb.dtype(dtype). 618 _names = descr.names. 619 else:. TypeError: data type not understood. ````. Separately, could we return a dataframe here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1033
https://github.com/scverse/scanpy/issues/1033:565,modifiability,modul,module,565,"highly_variable_genes fails with `batch_key` and `inplace=False`; Came across this while investigating #1032. . ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pp.highly_variable_genes(pbmc, inplace=False). ```. ```pytb. /Users/isaac/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py:58: RuntimeWarning: invalid value encountered in log. dispersion = np.log(dispersion). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-36b7cb4d9c0f> in <module>. 1 import scanpy as sc. 2 pbmc = sc.datasets.pbmc3k_processed(). ----> 3 sc.pp.highly_variable_genes(pbmc, batch_key=""louvain"", inplace=False). ~/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 347 ('highly_variable_intersection', np.bool_),. 348 ]). --> 349 return np.rec.fromarrays(arrays, dtype=dtypes). /usr/local/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 615 . 616 if dtype is not None:. --> 617 descr = sb.dtype(dtype). 618 _names = descr.names. 619 else:. TypeError: data type not understood. ````. Separately, could we return a dataframe here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1033
https://github.com/scverse/scanpy/issues/1033:1053,modifiability,pac,packages,1053,"highly_variable_genes fails with `batch_key` and `inplace=False`; Came across this while investigating #1032. . ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pp.highly_variable_genes(pbmc, inplace=False). ```. ```pytb. /Users/isaac/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py:58: RuntimeWarning: invalid value encountered in log. dispersion = np.log(dispersion). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-36b7cb4d9c0f> in <module>. 1 import scanpy as sc. 2 pbmc = sc.datasets.pbmc3k_processed(). ----> 3 sc.pp.highly_variable_genes(pbmc, batch_key=""louvain"", inplace=False). ~/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 347 ('highly_variable_intersection', np.bool_),. 348 ]). --> 349 return np.rec.fromarrays(arrays, dtype=dtypes). /usr/local/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 615 . 616 if dtype is not None:. --> 617 descr = sb.dtype(dtype). 618 _names = descr.names. 619 else:. TypeError: data type not understood. ````. Separately, could we return a dataframe here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1033
https://github.com/scverse/scanpy/issues/1033:22,reliability,fail,fails,22,"highly_variable_genes fails with `batch_key` and `inplace=False`; Came across this while investigating #1032. . ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pp.highly_variable_genes(pbmc, inplace=False). ```. ```pytb. /Users/isaac/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py:58: RuntimeWarning: invalid value encountered in log. dispersion = np.log(dispersion). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-36b7cb4d9c0f> in <module>. 1 import scanpy as sc. 2 pbmc = sc.datasets.pbmc3k_processed(). ----> 3 sc.pp.highly_variable_genes(pbmc, batch_key=""louvain"", inplace=False). ~/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 347 ('highly_variable_intersection', np.bool_),. 348 ]). --> 349 return np.rec.fromarrays(arrays, dtype=dtypes). /usr/local/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 615 . 616 if dtype is not None:. --> 617 descr = sb.dtype(dtype). 618 _names = descr.names. 619 else:. TypeError: data type not understood. ````. Separately, could we return a dataframe here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1033
https://github.com/scverse/scanpy/issues/1033:370,safety,log,log,370,"highly_variable_genes fails with `batch_key` and `inplace=False`; Came across this while investigating #1032. . ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pp.highly_variable_genes(pbmc, inplace=False). ```. ```pytb. /Users/isaac/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py:58: RuntimeWarning: invalid value encountered in log. dispersion = np.log(dispersion). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-36b7cb4d9c0f> in <module>. 1 import scanpy as sc. 2 pbmc = sc.datasets.pbmc3k_processed(). ----> 3 sc.pp.highly_variable_genes(pbmc, batch_key=""louvain"", inplace=False). ~/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 347 ('highly_variable_intersection', np.bool_),. 348 ]). --> 349 return np.rec.fromarrays(arrays, dtype=dtypes). /usr/local/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 615 . 616 if dtype is not None:. --> 617 descr = sb.dtype(dtype). 618 _names = descr.names. 619 else:. TypeError: data type not understood. ````. Separately, could we return a dataframe here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1033
https://github.com/scverse/scanpy/issues/1033:391,safety,log,log,391,"highly_variable_genes fails with `batch_key` and `inplace=False`; Came across this while investigating #1032. . ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pp.highly_variable_genes(pbmc, inplace=False). ```. ```pytb. /Users/isaac/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py:58: RuntimeWarning: invalid value encountered in log. dispersion = np.log(dispersion). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-36b7cb4d9c0f> in <module>. 1 import scanpy as sc. 2 pbmc = sc.datasets.pbmc3k_processed(). ----> 3 sc.pp.highly_variable_genes(pbmc, batch_key=""louvain"", inplace=False). ~/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 347 ('highly_variable_intersection', np.bool_),. 348 ]). --> 349 return np.rec.fromarrays(arrays, dtype=dtypes). /usr/local/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 615 . 616 if dtype is not None:. --> 617 descr = sb.dtype(dtype). 618 _names = descr.names. 619 else:. TypeError: data type not understood. ````. Separately, could we return a dataframe here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1033
https://github.com/scverse/scanpy/issues/1033:539,safety,input,input-,539,"highly_variable_genes fails with `batch_key` and `inplace=False`; Came across this while investigating #1032. . ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pp.highly_variable_genes(pbmc, inplace=False). ```. ```pytb. /Users/isaac/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py:58: RuntimeWarning: invalid value encountered in log. dispersion = np.log(dispersion). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-36b7cb4d9c0f> in <module>. 1 import scanpy as sc. 2 pbmc = sc.datasets.pbmc3k_processed(). ----> 3 sc.pp.highly_variable_genes(pbmc, batch_key=""louvain"", inplace=False). ~/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 347 ('highly_variable_intersection', np.bool_),. 348 ]). --> 349 return np.rec.fromarrays(arrays, dtype=dtypes). /usr/local/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 615 . 616 if dtype is not None:. --> 617 descr = sb.dtype(dtype). 618 _names = descr.names. 619 else:. TypeError: data type not understood. ````. Separately, could we return a dataframe here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1033
https://github.com/scverse/scanpy/issues/1033:565,safety,modul,module,565,"highly_variable_genes fails with `batch_key` and `inplace=False`; Came across this while investigating #1032. . ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pp.highly_variable_genes(pbmc, inplace=False). ```. ```pytb. /Users/isaac/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py:58: RuntimeWarning: invalid value encountered in log. dispersion = np.log(dispersion). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-36b7cb4d9c0f> in <module>. 1 import scanpy as sc. 2 pbmc = sc.datasets.pbmc3k_processed(). ----> 3 sc.pp.highly_variable_genes(pbmc, batch_key=""louvain"", inplace=False). ~/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 347 ('highly_variable_intersection', np.bool_),. 348 ]). --> 349 return np.rec.fromarrays(arrays, dtype=dtypes). /usr/local/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 615 . 616 if dtype is not None:. --> 617 descr = sb.dtype(dtype). 618 _names = descr.names. 619 else:. TypeError: data type not understood. ````. Separately, could we return a dataframe here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1033
https://github.com/scverse/scanpy/issues/1033:370,security,log,log,370,"highly_variable_genes fails with `batch_key` and `inplace=False`; Came across this while investigating #1032. . ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pp.highly_variable_genes(pbmc, inplace=False). ```. ```pytb. /Users/isaac/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py:58: RuntimeWarning: invalid value encountered in log. dispersion = np.log(dispersion). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-36b7cb4d9c0f> in <module>. 1 import scanpy as sc. 2 pbmc = sc.datasets.pbmc3k_processed(). ----> 3 sc.pp.highly_variable_genes(pbmc, batch_key=""louvain"", inplace=False). ~/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 347 ('highly_variable_intersection', np.bool_),. 348 ]). --> 349 return np.rec.fromarrays(arrays, dtype=dtypes). /usr/local/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 615 . 616 if dtype is not None:. --> 617 descr = sb.dtype(dtype). 618 _names = descr.names. 619 else:. TypeError: data type not understood. ````. Separately, could we return a dataframe here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1033
https://github.com/scverse/scanpy/issues/1033:391,security,log,log,391,"highly_variable_genes fails with `batch_key` and `inplace=False`; Came across this while investigating #1032. . ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pp.highly_variable_genes(pbmc, inplace=False). ```. ```pytb. /Users/isaac/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py:58: RuntimeWarning: invalid value encountered in log. dispersion = np.log(dispersion). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-36b7cb4d9c0f> in <module>. 1 import scanpy as sc. 2 pbmc = sc.datasets.pbmc3k_processed(). ----> 3 sc.pp.highly_variable_genes(pbmc, batch_key=""louvain"", inplace=False). ~/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 347 ('highly_variable_intersection', np.bool_),. 348 ]). --> 349 return np.rec.fromarrays(arrays, dtype=dtypes). /usr/local/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 615 . 616 if dtype is not None:. --> 617 descr = sb.dtype(dtype). 618 _names = descr.names. 619 else:. TypeError: data type not understood. ````. Separately, could we return a dataframe here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1033
https://github.com/scverse/scanpy/issues/1033:370,testability,log,log,370,"highly_variable_genes fails with `batch_key` and `inplace=False`; Came across this while investigating #1032. . ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pp.highly_variable_genes(pbmc, inplace=False). ```. ```pytb. /Users/isaac/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py:58: RuntimeWarning: invalid value encountered in log. dispersion = np.log(dispersion). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-36b7cb4d9c0f> in <module>. 1 import scanpy as sc. 2 pbmc = sc.datasets.pbmc3k_processed(). ----> 3 sc.pp.highly_variable_genes(pbmc, batch_key=""louvain"", inplace=False). ~/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 347 ('highly_variable_intersection', np.bool_),. 348 ]). --> 349 return np.rec.fromarrays(arrays, dtype=dtypes). /usr/local/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 615 . 616 if dtype is not None:. --> 617 descr = sb.dtype(dtype). 618 _names = descr.names. 619 else:. TypeError: data type not understood. ````. Separately, could we return a dataframe here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1033
https://github.com/scverse/scanpy/issues/1033:391,testability,log,log,391,"highly_variable_genes fails with `batch_key` and `inplace=False`; Came across this while investigating #1032. . ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pp.highly_variable_genes(pbmc, inplace=False). ```. ```pytb. /Users/isaac/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py:58: RuntimeWarning: invalid value encountered in log. dispersion = np.log(dispersion). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-36b7cb4d9c0f> in <module>. 1 import scanpy as sc. 2 pbmc = sc.datasets.pbmc3k_processed(). ----> 3 sc.pp.highly_variable_genes(pbmc, batch_key=""louvain"", inplace=False). ~/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 347 ('highly_variable_intersection', np.bool_),. 348 ]). --> 349 return np.rec.fromarrays(arrays, dtype=dtypes). /usr/local/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 615 . 616 if dtype is not None:. --> 617 descr = sb.dtype(dtype). 618 _names = descr.names. 619 else:. TypeError: data type not understood. ````. Separately, could we return a dataframe here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1033
https://github.com/scverse/scanpy/issues/1033:495,testability,Trace,Traceback,495,"highly_variable_genes fails with `batch_key` and `inplace=False`; Came across this while investigating #1032. . ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pp.highly_variable_genes(pbmc, inplace=False). ```. ```pytb. /Users/isaac/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py:58: RuntimeWarning: invalid value encountered in log. dispersion = np.log(dispersion). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-36b7cb4d9c0f> in <module>. 1 import scanpy as sc. 2 pbmc = sc.datasets.pbmc3k_processed(). ----> 3 sc.pp.highly_variable_genes(pbmc, batch_key=""louvain"", inplace=False). ~/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 347 ('highly_variable_intersection', np.bool_),. 348 ]). --> 349 return np.rec.fromarrays(arrays, dtype=dtypes). /usr/local/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 615 . 616 if dtype is not None:. --> 617 descr = sb.dtype(dtype). 618 _names = descr.names. 619 else:. TypeError: data type not understood. ````. Separately, could we return a dataframe here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1033
https://github.com/scverse/scanpy/issues/1033:248,usability,User,Users,248,"highly_variable_genes fails with `batch_key` and `inplace=False`; Came across this while investigating #1032. . ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pp.highly_variable_genes(pbmc, inplace=False). ```. ```pytb. /Users/isaac/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py:58: RuntimeWarning: invalid value encountered in log. dispersion = np.log(dispersion). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-36b7cb4d9c0f> in <module>. 1 import scanpy as sc. 2 pbmc = sc.datasets.pbmc3k_processed(). ----> 3 sc.pp.highly_variable_genes(pbmc, batch_key=""louvain"", inplace=False). ~/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 347 ('highly_variable_intersection', np.bool_),. 348 ]). --> 349 return np.rec.fromarrays(arrays, dtype=dtypes). /usr/local/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 615 . 616 if dtype is not None:. --> 617 descr = sb.dtype(dtype). 618 _names = descr.names. 619 else:. TypeError: data type not understood. ````. Separately, could we return a dataframe here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1033
https://github.com/scverse/scanpy/issues/1033:539,usability,input,input-,539,"highly_variable_genes fails with `batch_key` and `inplace=False`; Came across this while investigating #1032. . ```python. import scanpy as sc. pbmc = sc.datasets.pbmc3k_processed(). sc.pp.highly_variable_genes(pbmc, inplace=False). ```. ```pytb. /Users/isaac/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py:58: RuntimeWarning: invalid value encountered in log. dispersion = np.log(dispersion). ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-1-36b7cb4d9c0f> in <module>. 1 import scanpy as sc. 2 pbmc = sc.datasets.pbmc3k_processed(). ----> 3 sc.pp.highly_variable_genes(pbmc, batch_key=""louvain"", inplace=False). ~/github/scanpy/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, min_disp, max_disp, min_mean, max_mean, n_top_genes, n_bins, flavor, subset, inplace, batch_key). 347 ('highly_variable_intersection', np.bool_),. 348 ]). --> 349 return np.rec.fromarrays(arrays, dtype=dtypes). /usr/local/lib/python3.7/site-packages/numpy/core/records.py in fromarrays(arrayList, dtype, shape, formats, names, titles, aligned, byteorder). 615 . 616 if dtype is not None:. --> 617 descr = sb.dtype(dtype). 618 _names = descr.names. 619 else:. TypeError: data type not understood. ````. Separately, could we return a dataframe here?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1033
https://github.com/scverse/scanpy/pull/1034:25,deployability,Updat,Update,25,"read function and fixes; Update:. * Added `read_visium` function, based on [understanding output from 10x](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/overview). * addressed #1027 by changing requirements. * added features to import in `adata.obs`, in addition to coordinates in `adata.obsm`, in `scanpy.datasets`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1034
https://github.com/scverse/scanpy/pull/1034:172,deployability,pipelin,pipelines,172,"read function and fixes; Update:. * Added `read_visium` function, based on [understanding output from 10x](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/overview). * addressed #1027 by changing requirements. * added features to import in `adata.obs`, in addition to coordinates in `adata.obsm`, in `scanpy.datasets`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1034
https://github.com/scverse/scanpy/pull/1034:172,integrability,pipelin,pipelines,172,"read function and fixes; Update:. * Added `read_visium` function, based on [understanding output from 10x](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/overview). * addressed #1027 by changing requirements. * added features to import in `adata.obs`, in addition to coordinates in `adata.obsm`, in `scanpy.datasets`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1034
https://github.com/scverse/scanpy/pull/1034:309,interoperability,coordinat,coordinates,309,"read function and fixes; Update:. * Added `read_visium` function, based on [understanding output from 10x](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/overview). * addressed #1027 by changing requirements. * added features to import in `adata.obs`, in addition to coordinates in `adata.obsm`, in `scanpy.datasets`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1034
https://github.com/scverse/scanpy/pull/1034:25,safety,Updat,Update,25,"read function and fixes; Update:. * Added `read_visium` function, based on [understanding output from 10x](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/overview). * addressed #1027 by changing requirements. * added features to import in `adata.obs`, in addition to coordinates in `adata.obsm`, in `scanpy.datasets`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1034
https://github.com/scverse/scanpy/pull/1034:25,security,Updat,Update,25,"read function and fixes; Update:. * Added `read_visium` function, based on [understanding output from 10x](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/overview). * addressed #1027 by changing requirements. * added features to import in `adata.obs`, in addition to coordinates in `adata.obsm`, in `scanpy.datasets`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1034
https://github.com/scverse/scanpy/pull/1034:76,testability,understand,understanding,76,"read function and fixes; Update:. * Added `read_visium` function, based on [understanding output from 10x](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/overview). * addressed #1027 by changing requirements. * added features to import in `adata.obs`, in addition to coordinates in `adata.obsm`, in `scanpy.datasets`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1034
https://github.com/scverse/scanpy/pull/1034:115,usability,support,support,115,"read function and fixes; Update:. * Added `read_visium` function, based on [understanding output from 10x](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/overview). * addressed #1027 by changing requirements. * added features to import in `adata.obs`, in addition to coordinates in `adata.obsm`, in `scanpy.datasets`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1034
https://github.com/scverse/scanpy/issues/1035:55,availability,cluster,cluster,55,"How to pull out a list of genes of one sample from one cluster; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi,. I'd like to look at the gene expression from WT and the mutant mice from an interesting cluster, I thought I could use . sc.tl.rank_genes_groups(WT_Donuts, 'leiden', method='t-test', use_raw=False). sc.pl.rank_genes_groups(WT_Donuts, n_genes=5, sharey=False),. Then I realized that it's only for getting the marker genes from clusters. . Thank you for helping me with this issue! -Yi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1035
https://github.com/scverse/scanpy/issues/1035:338,availability,cluster,cluster,338,"How to pull out a list of genes of one sample from one cluster; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi,. I'd like to look at the gene expression from WT and the mutant mice from an interesting cluster, I thought I could use . sc.tl.rank_genes_groups(WT_Donuts, 'leiden', method='t-test', use_raw=False). sc.pl.rank_genes_groups(WT_Donuts, n_genes=5, sharey=False),. Then I realized that it's only for getting the marker genes from clusters. . Thank you for helping me with this issue! -Yi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1035
https://github.com/scverse/scanpy/issues/1035:576,availability,cluster,clusters,576,"How to pull out a list of genes of one sample from one cluster; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi,. I'd like to look at the gene expression from WT and the mutant mice from an interesting cluster, I thought I could use . sc.tl.rank_genes_groups(WT_Donuts, 'leiden', method='t-test', use_raw=False). sc.pl.rank_genes_groups(WT_Donuts, n_genes=5, sharey=False),. Then I realized that it's only for getting the marker genes from clusters. . Thank you for helping me with this issue! -Yi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1035
https://github.com/scverse/scanpy/issues/1035:55,deployability,cluster,cluster,55,"How to pull out a list of genes of one sample from one cluster; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi,. I'd like to look at the gene expression from WT and the mutant mice from an interesting cluster, I thought I could use . sc.tl.rank_genes_groups(WT_Donuts, 'leiden', method='t-test', use_raw=False). sc.pl.rank_genes_groups(WT_Donuts, n_genes=5, sharey=False),. Then I realized that it's only for getting the marker genes from clusters. . Thank you for helping me with this issue! -Yi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1035
https://github.com/scverse/scanpy/issues/1035:338,deployability,cluster,cluster,338,"How to pull out a list of genes of one sample from one cluster; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi,. I'd like to look at the gene expression from WT and the mutant mice from an interesting cluster, I thought I could use . sc.tl.rank_genes_groups(WT_Donuts, 'leiden', method='t-test', use_raw=False). sc.pl.rank_genes_groups(WT_Donuts, n_genes=5, sharey=False),. Then I realized that it's only for getting the marker genes from clusters. . Thank you for helping me with this issue! -Yi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1035
https://github.com/scverse/scanpy/issues/1035:576,deployability,cluster,clusters,576,"How to pull out a list of genes of one sample from one cluster; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi,. I'd like to look at the gene expression from WT and the mutant mice from an interesting cluster, I thought I could use . sc.tl.rank_genes_groups(WT_Donuts, 'leiden', method='t-test', use_raw=False). sc.pl.rank_genes_groups(WT_Donuts, n_genes=5, sharey=False),. Then I realized that it's only for getting the marker genes from clusters. . Thank you for helping me with this issue! -Yi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1035
https://github.com/scverse/scanpy/issues/1035:495,interoperability,share,sharey,495,"How to pull out a list of genes of one sample from one cluster; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi,. I'd like to look at the gene expression from WT and the mutant mice from an interesting cluster, I thought I could use . sc.tl.rank_genes_groups(WT_Donuts, 'leiden', method='t-test', use_raw=False). sc.pl.rank_genes_groups(WT_Donuts, n_genes=5, sharey=False),. Then I realized that it's only for getting the marker genes from clusters. . Thank you for helping me with this issue! -Yi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1035
https://github.com/scverse/scanpy/issues/1035:186,modifiability,design decis,design decisions,186,"How to pull out a list of genes of one sample from one cluster; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi,. I'd like to look at the gene expression from WT and the mutant mice from an interesting cluster, I thought I could use . sc.tl.rank_genes_groups(WT_Donuts, 'leiden', method='t-test', use_raw=False). sc.pl.rank_genes_groups(WT_Donuts, n_genes=5, sharey=False),. Then I realized that it's only for getting the marker genes from clusters. . Thank you for helping me with this issue! -Yi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1035
https://github.com/scverse/scanpy/issues/1035:426,safety,test,test,426,"How to pull out a list of genes of one sample from one cluster; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi,. I'd like to look at the gene expression from WT and the mutant mice from an interesting cluster, I thought I could use . sc.tl.rank_genes_groups(WT_Donuts, 'leiden', method='t-test', use_raw=False). sc.pl.rank_genes_groups(WT_Donuts, n_genes=5, sharey=False),. Then I realized that it's only for getting the marker genes from clusters. . Thank you for helping me with this issue! -Yi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1035
https://github.com/scverse/scanpy/issues/1035:426,testability,test,test,426,"How to pull out a list of genes of one sample from one cluster; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi,. I'd like to look at the gene expression from WT and the mutant mice from an interesting cluster, I thought I could use . sc.tl.rank_genes_groups(WT_Donuts, 'leiden', method='t-test', use_raw=False). sc.pl.rank_genes_groups(WT_Donuts, n_genes=5, sharey=False),. Then I realized that it's only for getting the marker genes from clusters. . Thank you for helping me with this issue! -Yi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1035
https://github.com/scverse/scanpy/issues/1035:84,usability,help,help,84,"How to pull out a list of genes of one sample from one cluster; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi,. I'd like to look at the gene expression from WT and the mutant mice from an interesting cluster, I thought I could use . sc.tl.rank_genes_groups(WT_Donuts, 'leiden', method='t-test', use_raw=False). sc.pl.rank_genes_groups(WT_Donuts, n_genes=5, sharey=False),. Then I realized that it's only for getting the marker genes from clusters. . Thank you for helping me with this issue! -Yi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1035
https://github.com/scverse/scanpy/issues/1035:602,usability,help,helping,602,"How to pull out a list of genes of one sample from one cluster; <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ... Hi,. I'd like to look at the gene expression from WT and the mutant mice from an interesting cluster, I thought I could use . sc.tl.rank_genes_groups(WT_Donuts, 'leiden', method='t-test', use_raw=False). sc.pl.rank_genes_groups(WT_Donuts, n_genes=5, sharey=False),. Then I realized that it's only for getting the marker genes from clusters. . Thank you for helping me with this issue! -Yi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1035
https://github.com/scverse/scanpy/issues/1036:115,availability,error,errors,115,"UMAP 0.4.0rc1 doesn't play nice with ingest; @Koncopd, I just tried out the new release candidate for umap and get errors though out the ingest tests. It looks like `umap` now relies on `pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb. ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------. running ingest. ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():. adata_ref = sc.AnnData(X). adata_new = sc.AnnData(T). . sc.pp.neighbors(. adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0. ). sc.tl.umap(adata_ref, random_state=0). . > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/tools/_ingest.py:270: in __init__. self._init_neighbors(adata). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 . uns: 'neighbors', 'umap'. obsm: 'X_umap'. def _init_neighbors(self, adata):. from umap.distances import named_distances. > from umap.nndescent import (. make_initialisations,. make_initialized_nnd_search,. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036
https://github.com/scverse/scanpy/issues/1036:233,availability,avail,available,233,"UMAP 0.4.0rc1 doesn't play nice with ingest; @Koncopd, I just tried out the new release candidate for umap and get errors though out the ingest tests. It looks like `umap` now relies on `pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb. ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------. running ingest. ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():. adata_ref = sc.AnnData(X). adata_new = sc.AnnData(T). . sc.pp.neighbors(. adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0. ). sc.tl.umap(adata_ref, random_state=0). . > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/tools/_ingest.py:270: in __init__. self._init_neighbors(adata). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 . uns: 'neighbors', 'umap'. obsm: 'X_umap'. def _init_neighbors(self, adata):. from umap.distances import named_distances. > from umap.nndescent import (. make_initialisations,. make_initialized_nnd_search,. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036
https://github.com/scverse/scanpy/issues/1036:80,deployability,releas,release,80,"UMAP 0.4.0rc1 doesn't play nice with ingest; @Koncopd, I just tried out the new release candidate for umap and get errors though out the ingest tests. It looks like `umap` now relies on `pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb. ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------. running ingest. ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():. adata_ref = sc.AnnData(X). adata_new = sc.AnnData(T). . sc.pp.neighbors(. adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0. ). sc.tl.umap(adata_ref, random_state=0). . > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/tools/_ingest.py:270: in __init__. self._init_neighbors(adata). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 . uns: 'neighbors', 'umap'. obsm: 'X_umap'. def _init_neighbors(self, adata):. from umap.distances import named_distances. > from umap.nndescent import (. make_initialisations,. make_initialized_nnd_search,. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036
https://github.com/scverse/scanpy/issues/1036:2113,modifiability,pac,packages,2113,"pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb. ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------. running ingest. ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():. adata_ref = sc.AnnData(X). adata_new = sc.AnnData(T). . sc.pp.neighbors(. adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0. ). sc.tl.umap(adata_ref, random_state=0). . > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/tools/_ingest.py:270: in __init__. self._init_neighbors(adata). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 . uns: 'neighbors', 'umap'. obsm: 'X_umap'. def _init_neighbors(self, adata):. from umap.distances import named_distances. > from umap.nndescent import (. make_initialisations,. make_initialized_nnd_search,. ). E ImportError: cannot import name 'make_initialisations' from 'umap.nndescent' (/usr/local/lib/python3.7/site-packages/umap/nndescent.py). scanpy/tools/_ingest.py:210: ImportError. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036
https://github.com/scverse/scanpy/issues/1036:115,performance,error,errors,115,"UMAP 0.4.0rc1 doesn't play nice with ingest; @Koncopd, I just tried out the new release candidate for umap and get errors though out the ingest tests. It looks like `umap` now relies on `pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb. ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------. running ingest. ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():. adata_ref = sc.AnnData(X). adata_new = sc.AnnData(T). . sc.pp.neighbors(. adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0. ). sc.tl.umap(adata_ref, random_state=0). . > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/tools/_ingest.py:270: in __init__. self._init_neighbors(adata). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 . uns: 'neighbors', 'umap'. obsm: 'X_umap'. def _init_neighbors(self, adata):. from umap.distances import named_distances. > from umap.nndescent import (. make_initialisations,. make_initialized_nnd_search,. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036
https://github.com/scverse/scanpy/issues/1036:14,reliability,doe,doesn,14,"UMAP 0.4.0rc1 doesn't play nice with ingest; @Koncopd, I just tried out the new release candidate for umap and get errors though out the ingest tests. It looks like `umap` now relies on `pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb. ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------. running ingest. ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():. adata_ref = sc.AnnData(X). adata_new = sc.AnnData(T). . sc.pp.neighbors(. adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0. ). sc.tl.umap(adata_ref, random_state=0). . > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/tools/_ingest.py:270: in __init__. self._init_neighbors(adata). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 . uns: 'neighbors', 'umap'. obsm: 'X_umap'. def _init_neighbors(self, adata):. from umap.distances import named_distances. > from umap.nndescent import (. make_initialisations,. make_initialized_nnd_search,. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036
https://github.com/scverse/scanpy/issues/1036:233,reliability,availab,available,233,"UMAP 0.4.0rc1 doesn't play nice with ingest; @Koncopd, I just tried out the new release candidate for umap and get errors though out the ingest tests. It looks like `umap` now relies on `pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb. ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------. running ingest. ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():. adata_ref = sc.AnnData(X). adata_new = sc.AnnData(T). . sc.pp.neighbors(. adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0. ). sc.tl.umap(adata_ref, random_state=0). . > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/tools/_ingest.py:270: in __init__. self._init_neighbors(adata). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 . uns: 'neighbors', 'umap'. obsm: 'X_umap'. def _init_neighbors(self, adata):. from umap.distances import named_distances. > from umap.nndescent import (. make_initialisations,. make_initialized_nnd_search,. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036
https://github.com/scverse/scanpy/issues/1036:115,safety,error,errors,115,"UMAP 0.4.0rc1 doesn't play nice with ingest; @Koncopd, I just tried out the new release candidate for umap and get errors though out the ingest tests. It looks like `umap` now relies on `pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb. ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------. running ingest. ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():. adata_ref = sc.AnnData(X). adata_new = sc.AnnData(T). . sc.pp.neighbors(. adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0. ). sc.tl.umap(adata_ref, random_state=0). . > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/tools/_ingest.py:270: in __init__. self._init_neighbors(adata). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 . uns: 'neighbors', 'umap'. obsm: 'X_umap'. def _init_neighbors(self, adata):. from umap.distances import named_distances. > from umap.nndescent import (. make_initialisations,. make_initialized_nnd_search,. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036
https://github.com/scverse/scanpy/issues/1036:144,safety,test,tests,144,"UMAP 0.4.0rc1 doesn't play nice with ingest; @Koncopd, I just tried out the new release candidate for umap and get errors though out the ingest tests. It looks like `umap` now relies on `pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb. ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------. running ingest. ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():. adata_ref = sc.AnnData(X). adata_new = sc.AnnData(T). . sc.pp.neighbors(. adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0. ). sc.tl.umap(adata_ref, random_state=0). . > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/tools/_ingest.py:270: in __init__. self._init_neighbors(adata). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 . uns: 'neighbors', 'umap'. obsm: 'X_umap'. def _init_neighbors(self, adata):. from umap.distances import named_distances. > from umap.nndescent import (. make_initialisations,. make_initialized_nnd_search,. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036
https://github.com/scverse/scanpy/issues/1036:233,safety,avail,available,233,"UMAP 0.4.0rc1 doesn't play nice with ingest; @Koncopd, I just tried out the new release candidate for umap and get errors though out the ingest tests. It looks like `umap` now relies on `pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb. ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------. running ingest. ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():. adata_ref = sc.AnnData(X). adata_new = sc.AnnData(T). . sc.pp.neighbors(. adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0. ). sc.tl.umap(adata_ref, random_state=0). . > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/tools/_ingest.py:270: in __init__. self._init_neighbors(adata). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 . uns: 'neighbors', 'umap'. obsm: 'X_umap'. def _init_neighbors(self, adata):. from umap.distances import named_distances. > from umap.nndescent import (. make_initialisations,. make_initialized_nnd_search,. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036
https://github.com/scverse/scanpy/issues/1036:1074,safety,test,tests,1074,"ew release candidate for umap and get errors though out the ingest tests. It looks like `umap` now relies on `pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb. ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------. running ingest. ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():. adata_ref = sc.AnnData(X). adata_new = sc.AnnData(T). . sc.pp.neighbors(. adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0. ). sc.tl.umap(adata_ref, random_state=0). . > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/tools/_ingest.py:270: in __init__. self._init_neighbors(adata). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 . uns: 'neighbors', 'umap'. obsm: 'X_umap'. def _init_neighbors(self, adata):. from umap.distances import named_distances. > from umap.nndescent import (. make_initialisations,. make_initialized_nnd_search,. ). E ImportError: cannot import name 'make_initialisations' from 'umap.nndesc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036
https://github.com/scverse/scanpy/issues/1036:233,security,availab,available,233,"UMAP 0.4.0rc1 doesn't play nice with ingest; @Koncopd, I just tried out the new release candidate for umap and get errors though out the ingest tests. It looks like `umap` now relies on `pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb. ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------. running ingest. ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():. adata_ref = sc.AnnData(X). adata_new = sc.AnnData(T). . sc.pp.neighbors(. adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0. ). sc.tl.umap(adata_ref, random_state=0). . > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/tools/_ingest.py:270: in __init__. self._init_neighbors(adata). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 . uns: 'neighbors', 'umap'. obsm: 'X_umap'. def _init_neighbors(self, adata):. from umap.distances import named_distances. > from umap.nndescent import (. make_initialisations,. make_initialized_nnd_search,. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036
https://github.com/scverse/scanpy/issues/1036:144,testability,test,tests,144,"UMAP 0.4.0rc1 doesn't play nice with ingest; @Koncopd, I just tried out the new release candidate for umap and get errors though out the ingest tests. It looks like `umap` now relies on `pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb. ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------. running ingest. ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():. adata_ref = sc.AnnData(X). adata_new = sc.AnnData(T). . sc.pp.neighbors(. adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0. ). sc.tl.umap(adata_ref, random_state=0). . > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/tools/_ingest.py:270: in __init__. self._init_neighbors(adata). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 . uns: 'neighbors', 'umap'. obsm: 'X_umap'. def _init_neighbors(self, adata):. from umap.distances import named_distances. > from umap.nndescent import (. make_initialisations,. make_initialized_nnd_search,. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036
https://github.com/scverse/scanpy/issues/1036:262,testability,trace,traceback,262,"UMAP 0.4.0rc1 doesn't play nice with ingest; @Koncopd, I just tried out the new release candidate for umap and get errors though out the ingest tests. It looks like `umap` now relies on `pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb. ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------. running ingest. ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():. adata_ref = sc.AnnData(X). adata_new = sc.AnnData(T). . sc.pp.neighbors(. adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0. ). sc.tl.umap(adata_ref, random_state=0). . > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/tools/_ingest.py:270: in __init__. self._init_neighbors(adata). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 . uns: 'neighbors', 'umap'. obsm: 'X_umap'. def _init_neighbors(self, adata):. from umap.distances import named_distances. > from umap.nndescent import (. make_initialisations,. make_initialized_nnd_search,. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036
https://github.com/scverse/scanpy/issues/1036:1074,testability,test,tests,1074,"ew release candidate for umap and get errors though out the ingest tests. It looks like `umap` now relies on `pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb. ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------. running ingest. ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():. adata_ref = sc.AnnData(X). adata_new = sc.AnnData(T). . sc.pp.neighbors(. adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0. ). sc.tl.umap(adata_ref, random_state=0). . > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/tools/_ingest.py:270: in __init__. self._init_neighbors(adata). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 . uns: 'neighbors', 'umap'. obsm: 'X_umap'. def _init_neighbors(self, adata):. from umap.distances import named_distances. > from umap.nndescent import (. make_initialisations,. make_initialized_nnd_search,. ). E ImportError: cannot import name 'make_initialisations' from 'umap.nndesc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036
https://github.com/scverse/scanpy/issues/1036:115,usability,error,errors,115,"UMAP 0.4.0rc1 doesn't play nice with ingest; @Koncopd, I just tried out the new release candidate for umap and get errors though out the ingest tests. It looks like `umap` now relies on `pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb. ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------. running ingest. ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():. adata_ref = sc.AnnData(X). adata_new = sc.AnnData(T). . sc.pp.neighbors(. adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0. ). sc.tl.umap(adata_ref, random_state=0). . > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/tools/_ingest.py:270: in __init__. self._init_neighbors(adata). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 . uns: 'neighbors', 'umap'. obsm: 'X_umap'. def _init_neighbors(self, adata):. from umap.distances import named_distances. > from umap.nndescent import (. make_initialisations,. make_initialized_nnd_search,. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036
https://github.com/scverse/scanpy/issues/1036:1363,usability,tool,tools,1363,"pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb. ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------. running ingest. ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():. adata_ref = sc.AnnData(X). adata_new = sc.AnnData(T). . sc.pp.neighbors(. adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0. ). sc.tl.umap(adata_ref, random_state=0). . > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/tools/_ingest.py:270: in __init__. self._init_neighbors(adata). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 . uns: 'neighbors', 'umap'. obsm: 'X_umap'. def _init_neighbors(self, adata):. from umap.distances import named_distances. > from umap.nndescent import (. make_initialisations,. make_initialized_nnd_search,. ). E ImportError: cannot import name 'make_initialisations' from 'umap.nndescent' (/usr/local/lib/python3.7/site-packages/umap/nndescent.py). scanpy/tools/_ingest.py:210: ImportError. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036
https://github.com/scverse/scanpy/issues/1036:1696,usability,tool,tools,1696,"pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb. ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------. running ingest. ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():. adata_ref = sc.AnnData(X). adata_new = sc.AnnData(T). . sc.pp.neighbors(. adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0. ). sc.tl.umap(adata_ref, random_state=0). . > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/tools/_ingest.py:270: in __init__. self._init_neighbors(adata). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 . uns: 'neighbors', 'umap'. obsm: 'X_umap'. def _init_neighbors(self, adata):. from umap.distances import named_distances. > from umap.nndescent import (. make_initialisations,. make_initialized_nnd_search,. ). E ImportError: cannot import name 'make_initialisations' from 'umap.nndescent' (/usr/local/lib/python3.7/site-packages/umap/nndescent.py). scanpy/tools/_ingest.py:210: ImportError. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036
https://github.com/scverse/scanpy/issues/1036:2149,usability,tool,tools,2149,"pynndescent` and some functions are no longer available. Here's an example traceback:. ```pytb. ------------------------------------------------------------------------------------------------------------------- Captured stderr call -------------------------------------------------------------------------------------------------------------------. running ingest. ______________________________________________________________________________________________________________ test_ingest_map_embedding_umap ______________________________________________________________________________________________________________. def test_ingest_map_embedding_umap():. adata_ref = sc.AnnData(X). adata_new = sc.AnnData(T). . sc.pp.neighbors(. adata_ref, method='umap', use_rep='X', n_neighbors=4, random_state=0. ). sc.tl.umap(adata_ref, random_state=0). . > ing = sc.tl.Ingest(adata_ref). scanpy/tests/test_ingest.py:132: . _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . scanpy/tools/_ingest.py:270: in __init__. self._init_neighbors(adata). _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <scanpy.tools._ingest.Ingest object at 0x140357550>, adata = AnnData object with n_obs × n_vars = 6 × 5 . uns: 'neighbors', 'umap'. obsm: 'X_umap'. def _init_neighbors(self, adata):. from umap.distances import named_distances. > from umap.nndescent import (. make_initialisations,. make_initialized_nnd_search,. ). E ImportError: cannot import name 'make_initialisations' from 'umap.nndescent' (/usr/local/lib/python3.7/site-packages/umap/nndescent.py). scanpy/tools/_ingest.py:210: ImportError. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1036
https://github.com/scverse/scanpy/pull/1037:33,deployability,version,version,33,Fix paga tests for new igraph(?) version; Some update has flipped the plots…,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1037
https://github.com/scverse/scanpy/pull/1037:47,deployability,updat,update,47,Fix paga tests for new igraph(?) version; Some update has flipped the plots…,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1037
https://github.com/scverse/scanpy/pull/1037:33,integrability,version,version,33,Fix paga tests for new igraph(?) version; Some update has flipped the plots…,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1037
https://github.com/scverse/scanpy/pull/1037:33,modifiability,version,version,33,Fix paga tests for new igraph(?) version; Some update has flipped the plots…,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1037
https://github.com/scverse/scanpy/pull/1037:9,safety,test,tests,9,Fix paga tests for new igraph(?) version; Some update has flipped the plots…,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1037
https://github.com/scverse/scanpy/pull/1037:47,safety,updat,update,47,Fix paga tests for new igraph(?) version; Some update has flipped the plots…,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1037
https://github.com/scverse/scanpy/pull/1037:47,security,updat,update,47,Fix paga tests for new igraph(?) version; Some update has flipped the plots…,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1037
https://github.com/scverse/scanpy/pull/1037:9,testability,test,tests,9,Fix paga tests for new igraph(?) version; Some update has flipped the plots…,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1037
https://github.com/scverse/scanpy/pull/1038:71,deployability,releas,release,71,Fix ingest for the new umap; This should fix the problems with the new release candidate of umap. https://github.com/theislab/scanpy/issues/1036,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1038
https://github.com/scverse/scanpy/issues/1039:236,availability,error,error,236,"showing gene expression on umap not working; <!-- Please give a clear and concise description of what the bug is: -->. When I tried to plot the expression of a particular gene on umap map by the tutorial, it always showed the following error:. ```. >>> sc.pl.umap(post_adata, color=['XKR4']). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 542, in umap. return embedding(adata, 'umap', **kwargs). File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:980,availability,sli,slice,980,"showing gene expression on umap not working; <!-- Please give a clear and concise description of what the bug is: -->. When I tried to plot the expression of a particular gene on umap map by the tutorial, it always showed the following error:. ```. >>> sc.pl.umap(post_adata, color=['XKR4']). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 542, in umap. return embedding(adata, 'umap', **kwargs). File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:1892,availability,cluster,clusters,1892,"C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_indices', 'labels', 'local_means', 'local_vars', 'louvain', 'clusters'. var: 'gene_id'. uns: 'neighbors', 'louvain', 'louvain_colors'. obsm: 'X_scVI', 'X_umap'. >>> sc.pl.umap(post_adata, color=['louvain']). ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. #### Versions:. scanpy==1.4.5.post3 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.3.2 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+5.3b99dbf6 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:2059,availability,cluster,clusters,2059,"C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_indices', 'labels', 'local_means', 'local_vars', 'louvain', 'clusters'. var: 'gene_id'. uns: 'neighbors', 'louvain', 'louvain_colors'. obsm: 'X_scVI', 'X_umap'. >>> sc.pl.umap(post_adata, color=['louvain']). ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. #### Versions:. scanpy==1.4.5.post3 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.3.2 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+5.3b99dbf6 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:357,deployability,modul,module,357,"showing gene expression on umap not working; <!-- Please give a clear and concise description of what the bug is: -->. When I tried to plot the expression of a particular gene on umap map by the tutorial, it always showed the following error:. ```. >>> sc.pl.umap(post_adata, color=['XKR4']). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 542, in umap. return embedding(adata, 'umap', **kwargs). File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:1431,deployability,observ,observation,1431,"s\scatterplots.py"", line 542, in umap. return embedding(adata, 'umap', **kwargs). File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_indices', 'labels', 'local_means', 'local_vars', 'louvain', 'clusters'. var: 'gene_id'. uns: 'neighbors', 'louvain', 'louvain_colors'. obsm: 'X_scVI', 'X_umap'. >>> sc.pl.umap(post_adata, color=['louvain']). ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. #### Versions:. scanpy==1.4.5.post3 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.3.2 pandas==0.25.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:1892,deployability,cluster,clusters,1892,"C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_indices', 'labels', 'local_means', 'local_vars', 'louvain', 'clusters'. var: 'gene_id'. uns: 'neighbors', 'louvain', 'louvain_colors'. obsm: 'X_scVI', 'X_umap'. >>> sc.pl.umap(post_adata, color=['louvain']). ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. #### Versions:. scanpy==1.4.5.post3 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.3.2 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+5.3b99dbf6 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:2059,deployability,cluster,clusters,2059,"C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_indices', 'labels', 'local_means', 'local_vars', 'louvain', 'clusters'. var: 'gene_id'. uns: 'neighbors', 'louvain', 'louvain_colors'. obsm: 'X_scVI', 'X_umap'. >>> sc.pl.umap(post_adata, color=['louvain']). ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. #### Versions:. scanpy==1.4.5.post3 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.3.2 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+5.3b99dbf6 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:2330,deployability,Version,Versions,2330,"C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_indices', 'labels', 'local_means', 'local_vars', 'louvain', 'clusters'. var: 'gene_id'. uns: 'neighbors', 'louvain', 'louvain_colors'. obsm: 'X_scVI', 'X_umap'. >>> sc.pl.umap(post_adata, color=['louvain']). ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. #### Versions:. scanpy==1.4.5.post3 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.3.2 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+5.3b99dbf6 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:906,energy efficiency,core,core,906,"showing gene expression on umap not working; <!-- Please give a clear and concise description of what the bug is: -->. When I tried to plot the expression of a particular gene on umap map by the tutorial, it always showed the following error:. ```. >>> sc.pl.umap(post_adata, color=['XKR4']). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 542, in umap. return embedding(adata, 'umap', **kwargs). File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:1056,energy efficiency,core,core,1056,"ive a clear and concise description of what the bug is: -->. When I tried to plot the expression of a particular gene on umap map by the tutorial, it always showed the following error:. ```. >>> sc.pl.umap(post_adata, color=['XKR4']). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 542, in umap. return embedding(adata, 'umap', **kwargs). File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_indices', 'labels', 'local_means', 'local_vars', 'louvain', ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:1210,energy efficiency,core,core,1210,"ys showed the following error:. ```. >>> sc.pl.umap(post_adata, color=['XKR4']). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 542, in umap. return embedding(adata, 'umap', **kwargs). File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_indices', 'labels', 'local_means', 'local_vars', 'louvain', 'clusters'. var: 'gene_id'. uns: 'neighbors', 'louvain', 'louvain_colors'. obsm: 'X_scVI', 'X_umap'. >>> sc.pl.umap(post_adata, color=['louvain']). ```. <",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:1341,energy efficiency,core,core,1341,", line 1, in <module>. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 542, in umap. return embedding(adata, 'umap', **kwargs). File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_indices', 'labels', 'local_means', 'local_vars', 'louvain', 'clusters'. var: 'gene_id'. uns: 'neighbors', 'louvain', 'louvain_colors'. obsm: 'X_scVI', 'X_umap'. >>> sc.pl.umap(post_adata, color=['louvain']). ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. #### Versions:. sc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:2330,integrability,Version,Versions,2330,"C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_indices', 'labels', 'local_means', 'local_vars', 'louvain', 'clusters'. var: 'gene_id'. uns: 'neighbors', 'louvain', 'louvain_colors'. obsm: 'X_scVI', 'X_umap'. >>> sc.pl.umap(post_adata, color=['louvain']). ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. #### Versions:. scanpy==1.4.5.post3 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.3.2 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+5.3b99dbf6 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:1383,interoperability,format,format,1383,"\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 542, in umap. return embedding(adata, 'umap', **kwargs). File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_indices', 'labels', 'local_means', 'local_vars', 'louvain', 'clusters'. var: 'gene_id'. uns: 'neighbors', 'louvain', 'louvain_colors'. obsm: 'X_scVI', 'X_umap'. >>> sc.pl.umap(post_adata, color=['louvain']). ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. #### Versions:. scanpy==1.4.5.post3 anndata==0.6.22.post1 uma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:357,modifiability,modul,module,357,"showing gene expression on umap not working; <!-- Please give a clear and concise description of what the bug is: -->. When I tried to plot the expression of a particular gene on umap map by the tutorial, it always showed the following error:. ```. >>> sc.pl.umap(post_adata, color=['XKR4']). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 542, in umap. return embedding(adata, 'umap', **kwargs). File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:407,modifiability,pac,packages,407,"showing gene expression on umap not working; <!-- Please give a clear and concise description of what the bug is: -->. When I tried to plot the expression of a particular gene on umap map by the tutorial, it always showed the following error:. ```. >>> sc.pl.umap(post_adata, color=['XKR4']). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 542, in umap. return embedding(adata, 'umap', **kwargs). File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:560,modifiability,pac,packages,560,"showing gene expression on umap not working; <!-- Please give a clear and concise description of what the bug is: -->. When I tried to plot the expression of a particular gene on umap map by the tutorial, it always showed the following error:. ```. >>> sc.pl.umap(post_adata, color=['XKR4']). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 542, in umap. return embedding(adata, 'umap', **kwargs). File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:720,modifiability,pac,packages,720,"showing gene expression on umap not working; <!-- Please give a clear and concise description of what the bug is: -->. When I tried to plot the expression of a particular gene on umap map by the tutorial, it always showed the following error:. ```. >>> sc.pl.umap(post_adata, color=['XKR4']). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 542, in umap. return embedding(adata, 'umap', **kwargs). File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:889,modifiability,pac,packages,889,"showing gene expression on umap not working; <!-- Please give a clear and concise description of what the bug is: -->. When I tried to plot the expression of a particular gene on umap map by the tutorial, it always showed the following error:. ```. >>> sc.pl.umap(post_adata, color=['XKR4']). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 542, in umap. return embedding(adata, 'umap', **kwargs). File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:1039,modifiability,pac,packages,1039,"; <!-- Please give a clear and concise description of what the bug is: -->. When I tried to plot the expression of a particular gene on umap map by the tutorial, it always showed the following error:. ```. >>> sc.pl.umap(post_adata, color=['XKR4']). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 542, in umap. return embedding(adata, 'umap', **kwargs). File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_indices', 'labels', 'local_means', 'local_var",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:1193,modifiability,pac,packages,1193,"torial, it always showed the following error:. ```. >>> sc.pl.umap(post_adata, color=['XKR4']). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 542, in umap. return embedding(adata, 'umap', **kwargs). File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_indices', 'labels', 'local_means', 'local_vars', 'louvain', 'clusters'. var: 'gene_id'. uns: 'neighbors', 'louvain', 'louvain_colors'. obsm: 'X_scVI', 'X_umap'. >>> sc.pl.umap(post_adata, color=['lou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:1324,modifiability,pac,packages,1324," File ""<stdin>"", line 1, in <module>. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 542, in umap. return embedding(adata, 'umap', **kwargs). File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_indices', 'labels', 'local_means', 'local_vars', 'louvain', 'clusters'. var: 'gene_id'. uns: 'neighbors', 'louvain', 'louvain_colors'. obsm: 'X_scVI', 'X_umap'. >>> sc.pl.umap(post_adata, color=['louvain']). ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. ###",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:1443,modifiability,variab,variable,1443,"lots.py"", line 542, in umap. return embedding(adata, 'umap', **kwargs). File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_indices', 'labels', 'local_means', 'local_vars', 'louvain', 'clusters'. var: 'gene_id'. uns: 'neighbors', 'louvain', 'louvain_colors'. obsm: 'X_scVI', 'X_umap'. >>> sc.pl.umap(post_adata, color=['louvain']). ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. #### Versions:. scanpy==1.4.5.post3 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.3.2 pandas==0.25.3 scikit-le",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:2330,modifiability,Version,Versions,2330,"C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_indices', 'labels', 'local_means', 'local_vars', 'louvain', 'clusters'. var: 'gene_id'. uns: 'neighbors', 'louvain', 'louvain_colors'. obsm: 'X_scVI', 'X_umap'. >>> sc.pl.umap(post_adata, color=['louvain']). ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. #### Versions:. scanpy==1.4.5.post3 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.3.2 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+5.3b99dbf6 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:236,performance,error,error,236,"showing gene expression on umap not working; <!-- Please give a clear and concise description of what the bug is: -->. When I tried to plot the expression of a particular gene on umap map by the tutorial, it always showed the following error:. ```. >>> sc.pl.umap(post_adata, color=['XKR4']). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 542, in umap. return embedding(adata, 'umap', **kwargs). File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:980,reliability,sli,slice,980,"showing gene expression on umap not working; <!-- Please give a clear and concise description of what the bug is: -->. When I tried to plot the expression of a particular gene on umap map by the tutorial, it always showed the following error:. ```. >>> sc.pl.umap(post_adata, color=['XKR4']). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 542, in umap. return embedding(adata, 'umap', **kwargs). File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:236,safety,error,error,236,"showing gene expression on umap not working; <!-- Please give a clear and concise description of what the bug is: -->. When I tried to plot the expression of a particular gene on umap map by the tutorial, it always showed the following error:. ```. >>> sc.pl.umap(post_adata, color=['XKR4']). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 542, in umap. return embedding(adata, 'umap', **kwargs). File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:357,safety,modul,module,357,"showing gene expression on umap not working; <!-- Please give a clear and concise description of what the bug is: -->. When I tried to plot the expression of a particular gene on umap map by the tutorial, it always showed the following error:. ```. >>> sc.pl.umap(post_adata, color=['XKR4']). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 542, in umap. return embedding(adata, 'umap', **kwargs). File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:1425,safety,valid,valid,1425,"ing\_tools\scatterplots.py"", line 542, in umap. return embedding(adata, 'umap', **kwargs). File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_indices', 'labels', 'local_means', 'local_vars', 'louvain', 'clusters'. var: 'gene_id'. uns: 'neighbors', 'louvain', 'louvain_colors'. obsm: 'X_scVI', 'X_umap'. >>> sc.pl.umap(post_adata, color=['louvain']). ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. #### Versions:. scanpy==1.4.5.post3 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.3.2 panda",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:293,testability,Trace,Traceback,293,"showing gene expression on umap not working; <!-- Please give a clear and concise description of what the bug is: -->. When I tried to plot the expression of a particular gene on umap map by the tutorial, it always showed the following error:. ```. >>> sc.pl.umap(post_adata, color=['XKR4']). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 542, in umap. return embedding(adata, 'umap', **kwargs). File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:1431,testability,observ,observation,1431,"s\scatterplots.py"", line 542, in umap. return embedding(adata, 'umap', **kwargs). File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_indices', 'labels', 'local_means', 'local_vars', 'louvain', 'clusters'. var: 'gene_id'. uns: 'neighbors', 'louvain', 'louvain_colors'. obsm: 'X_scVI', 'X_umap'. >>> sc.pl.umap(post_adata, color=['louvain']). ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. #### Versions:. scanpy==1.4.5.post3 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.3.2 pandas==0.25.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:64,usability,clear,clear,64,"showing gene expression on umap not working; <!-- Please give a clear and concise description of what the bug is: -->. When I tried to plot the expression of a particular gene on umap map by the tutorial, it always showed the following error:. ```. >>> sc.pl.umap(post_adata, color=['XKR4']). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 542, in umap. return embedding(adata, 'umap', **kwargs). File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:236,usability,error,error,236,"showing gene expression on umap not working; <!-- Please give a clear and concise description of what the bug is: -->. When I tried to plot the expression of a particular gene on umap map by the tutorial, it always showed the following error:. ```. >>> sc.pl.umap(post_adata, color=['XKR4']). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 542, in umap. return embedding(adata, 'umap', **kwargs). File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_in",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:2222,usability,minim,minimal,2222,"C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_indices', 'labels', 'local_means', 'local_vars', 'louvain', 'clusters'. var: 'gene_id'. uns: 'neighbors', 'louvain', 'louvain_colors'. obsm: 'X_scVI', 'X_umap'. >>> sc.pl.umap(post_adata, color=['louvain']). ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. #### Versions:. scanpy==1.4.5.post3 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.3.2 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+5.3b99dbf6 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1039:2445,usability,learn,learn,2445,"C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 207, in embedding. use_raw=use_raw, gene_symbols=gene_symbols,. File ""C:\ProgramData\Miniconda3\lib\site-packages\scanpy\plotting\_tools\scatterplots.py"", line 865, in _get_color_values. values = adata.raw.obs_vector(value_to_plot). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 413, in obs_vector. idx = self._normalize_indices((slice(None), k)). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 364, in _normalize_indices. var = _normalize_index(var, self.var_names). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 155, in _normalize_index. return name_idx(index). File ""C:\ProgramData\Miniconda3\lib\site-packages\anndata\core\anndata.py"", line 142, in name_idx. .format(i)). IndexError: Key ""XKR4"" is not valid observation/variable name/index. ```. However, the gene XKR4 did exist in the var_names:. ```. >>> post_adata.var_names. Index(['XKR4', 'RP1', 'SOX17', 'MRPL15', 'LYPLA1', 'TCEA1', 'RGS20', 'ATP6V1H',. 'OPRK1', 'NPBWR1',. ... '2700089I24RIK', 'RAB11FIP2', 'E330013P04RIK', 'NANOS1', 'EIF3A',. 'FAM45A', 'SFXN4', 'PRDX3', 'GRK5', 'CSF2RA'],. dtype='object', length=16249). ```. The anndata object looked as below and it was fine when I tried to show the louvain clusters:. ```. >>> post_adata. AnnData object with n_obs × n_vars = 88291 × 16249. obs: 'CellID', 'batch_indices', 'labels', 'local_means', 'local_vars', 'louvain', 'clusters'. var: 'gene_id'. uns: 'neighbors', 'louvain', 'louvain_colors'. obsm: 'X_scVI', 'X_umap'. >>> sc.pl.umap(post_adata, color=['louvain']). ```. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. ... ```. #### Versions:. scanpy==1.4.5.post3 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.3.2 pandas==0.25.3 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+5.3b99dbf6 louvain==0.6.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1039
https://github.com/scverse/scanpy/issues/1040:195,availability,cluster,clustering,195,"Violin plot doesn't have option to return figure and doesn't check if the paths is an absolute path; Hi guys, . Would it be possible to amend the behaviour of sc.pl.violin() to act more like the clustering plots, where there is a 'return_fig' option. Alternatively, you could check whether the str provided to the 'save=' arg contains an existing directory path and if so not append to the front of the path. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1040
https://github.com/scverse/scanpy/issues/1040:195,deployability,cluster,clustering,195,"Violin plot doesn't have option to return figure and doesn't check if the paths is an absolute path; Hi guys, . Would it be possible to amend the behaviour of sc.pl.violin() to act more like the clustering plots, where there is a 'return_fig' option. Alternatively, you could check whether the str provided to the 'save=' arg contains an existing directory path and if so not append to the front of the path. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1040
https://github.com/scverse/scanpy/issues/1040:326,deployability,contain,contains,326,"Violin plot doesn't have option to return figure and doesn't check if the paths is an absolute path; Hi guys, . Would it be possible to amend the behaviour of sc.pl.violin() to act more like the clustering plots, where there is a 'return_fig' option. Alternatively, you could check whether the str provided to the 'save=' arg contains an existing directory path and if so not append to the front of the path. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1040
https://github.com/scverse/scanpy/issues/1040:12,reliability,doe,doesn,12,"Violin plot doesn't have option to return figure and doesn't check if the paths is an absolute path; Hi guys, . Would it be possible to amend the behaviour of sc.pl.violin() to act more like the clustering plots, where there is a 'return_fig' option. Alternatively, you could check whether the str provided to the 'save=' arg contains an existing directory path and if so not append to the front of the path. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1040
https://github.com/scverse/scanpy/issues/1040:53,reliability,doe,doesn,53,"Violin plot doesn't have option to return figure and doesn't check if the paths is an absolute path; Hi guys, . Would it be possible to amend the behaviour of sc.pl.violin() to act more like the clustering plots, where there is a 'return_fig' option. Alternatively, you could check whether the str provided to the 'save=' arg contains an existing directory path and if so not append to the front of the path. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1040
https://github.com/scverse/scanpy/issues/1040:146,usability,behavi,behaviour,146,"Violin plot doesn't have option to return figure and doesn't check if the paths is an absolute path; Hi guys, . Would it be possible to amend the behaviour of sc.pl.violin() to act more like the clustering plots, where there is a 'return_fig' option. Alternatively, you could check whether the str provided to the 'save=' arg contains an existing directory path and if so not append to the front of the path. .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1040
https://github.com/scverse/scanpy/pull/1041:0,safety,Test,Tests,0,Tests for spatial functions;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1041
https://github.com/scverse/scanpy/pull/1041:0,testability,Test,Tests,0,Tests for spatial functions;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1041
https://github.com/scverse/scanpy/pull/1042:106,deployability,releas,release,106,"make sure the newest umap is used in a test; @falexwolf @ivirshup we have a lot of fixes on master, let’s release 1.4.5.1 after this one. As an aside I think our versioning is a bit weird: Why did we do a feature release called 1.4.5 and not 1.5? Why not semver-lite like python itself? - major version (x.0) bumps for vast breaking changes. - minor version (1.x) bumps for new features and minor, long-deprecated breaking changes. - patch version (1.4.x) bumps for fixes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1042
https://github.com/scverse/scanpy/pull/1042:162,deployability,version,versioning,162,"make sure the newest umap is used in a test; @falexwolf @ivirshup we have a lot of fixes on master, let’s release 1.4.5.1 after this one. As an aside I think our versioning is a bit weird: Why did we do a feature release called 1.4.5 and not 1.5? Why not semver-lite like python itself? - major version (x.0) bumps for vast breaking changes. - minor version (1.x) bumps for new features and minor, long-deprecated breaking changes. - patch version (1.4.x) bumps for fixes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1042
https://github.com/scverse/scanpy/pull/1042:213,deployability,releas,release,213,"make sure the newest umap is used in a test; @falexwolf @ivirshup we have a lot of fixes on master, let’s release 1.4.5.1 after this one. As an aside I think our versioning is a bit weird: Why did we do a feature release called 1.4.5 and not 1.5? Why not semver-lite like python itself? - major version (x.0) bumps for vast breaking changes. - minor version (1.x) bumps for new features and minor, long-deprecated breaking changes. - patch version (1.4.x) bumps for fixes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1042
https://github.com/scverse/scanpy/pull/1042:295,deployability,version,version,295,"make sure the newest umap is used in a test; @falexwolf @ivirshup we have a lot of fixes on master, let’s release 1.4.5.1 after this one. As an aside I think our versioning is a bit weird: Why did we do a feature release called 1.4.5 and not 1.5? Why not semver-lite like python itself? - major version (x.0) bumps for vast breaking changes. - minor version (1.x) bumps for new features and minor, long-deprecated breaking changes. - patch version (1.4.x) bumps for fixes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1042
https://github.com/scverse/scanpy/pull/1042:350,deployability,version,version,350,"make sure the newest umap is used in a test; @falexwolf @ivirshup we have a lot of fixes on master, let’s release 1.4.5.1 after this one. As an aside I think our versioning is a bit weird: Why did we do a feature release called 1.4.5 and not 1.5? Why not semver-lite like python itself? - major version (x.0) bumps for vast breaking changes. - minor version (1.x) bumps for new features and minor, long-deprecated breaking changes. - patch version (1.4.x) bumps for fixes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1042
https://github.com/scverse/scanpy/pull/1042:434,deployability,patch,patch,434,"make sure the newest umap is used in a test; @falexwolf @ivirshup we have a lot of fixes on master, let’s release 1.4.5.1 after this one. As an aside I think our versioning is a bit weird: Why did we do a feature release called 1.4.5 and not 1.5? Why not semver-lite like python itself? - major version (x.0) bumps for vast breaking changes. - minor version (1.x) bumps for new features and minor, long-deprecated breaking changes. - patch version (1.4.x) bumps for fixes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1042
https://github.com/scverse/scanpy/pull/1042:440,deployability,version,version,440,"make sure the newest umap is used in a test; @falexwolf @ivirshup we have a lot of fixes on master, let’s release 1.4.5.1 after this one. As an aside I think our versioning is a bit weird: Why did we do a feature release called 1.4.5 and not 1.5? Why not semver-lite like python itself? - major version (x.0) bumps for vast breaking changes. - minor version (1.x) bumps for new features and minor, long-deprecated breaking changes. - patch version (1.4.x) bumps for fixes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1042
https://github.com/scverse/scanpy/pull/1042:162,integrability,version,versioning,162,"make sure the newest umap is used in a test; @falexwolf @ivirshup we have a lot of fixes on master, let’s release 1.4.5.1 after this one. As an aside I think our versioning is a bit weird: Why did we do a feature release called 1.4.5 and not 1.5? Why not semver-lite like python itself? - major version (x.0) bumps for vast breaking changes. - minor version (1.x) bumps for new features and minor, long-deprecated breaking changes. - patch version (1.4.x) bumps for fixes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1042
https://github.com/scverse/scanpy/pull/1042:295,integrability,version,version,295,"make sure the newest umap is used in a test; @falexwolf @ivirshup we have a lot of fixes on master, let’s release 1.4.5.1 after this one. As an aside I think our versioning is a bit weird: Why did we do a feature release called 1.4.5 and not 1.5? Why not semver-lite like python itself? - major version (x.0) bumps for vast breaking changes. - minor version (1.x) bumps for new features and minor, long-deprecated breaking changes. - patch version (1.4.x) bumps for fixes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1042
https://github.com/scverse/scanpy/pull/1042:350,integrability,version,version,350,"make sure the newest umap is used in a test; @falexwolf @ivirshup we have a lot of fixes on master, let’s release 1.4.5.1 after this one. As an aside I think our versioning is a bit weird: Why did we do a feature release called 1.4.5 and not 1.5? Why not semver-lite like python itself? - major version (x.0) bumps for vast breaking changes. - minor version (1.x) bumps for new features and minor, long-deprecated breaking changes. - patch version (1.4.x) bumps for fixes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1042
https://github.com/scverse/scanpy/pull/1042:440,integrability,version,version,440,"make sure the newest umap is used in a test; @falexwolf @ivirshup we have a lot of fixes on master, let’s release 1.4.5.1 after this one. As an aside I think our versioning is a bit weird: Why did we do a feature release called 1.4.5 and not 1.5? Why not semver-lite like python itself? - major version (x.0) bumps for vast breaking changes. - minor version (1.x) bumps for new features and minor, long-deprecated breaking changes. - patch version (1.4.x) bumps for fixes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1042
https://github.com/scverse/scanpy/pull/1042:162,modifiability,version,versioning,162,"make sure the newest umap is used in a test; @falexwolf @ivirshup we have a lot of fixes on master, let’s release 1.4.5.1 after this one. As an aside I think our versioning is a bit weird: Why did we do a feature release called 1.4.5 and not 1.5? Why not semver-lite like python itself? - major version (x.0) bumps for vast breaking changes. - minor version (1.x) bumps for new features and minor, long-deprecated breaking changes. - patch version (1.4.x) bumps for fixes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1042
https://github.com/scverse/scanpy/pull/1042:295,modifiability,version,version,295,"make sure the newest umap is used in a test; @falexwolf @ivirshup we have a lot of fixes on master, let’s release 1.4.5.1 after this one. As an aside I think our versioning is a bit weird: Why did we do a feature release called 1.4.5 and not 1.5? Why not semver-lite like python itself? - major version (x.0) bumps for vast breaking changes. - minor version (1.x) bumps for new features and minor, long-deprecated breaking changes. - patch version (1.4.x) bumps for fixes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1042
https://github.com/scverse/scanpy/pull/1042:350,modifiability,version,version,350,"make sure the newest umap is used in a test; @falexwolf @ivirshup we have a lot of fixes on master, let’s release 1.4.5.1 after this one. As an aside I think our versioning is a bit weird: Why did we do a feature release called 1.4.5 and not 1.5? Why not semver-lite like python itself? - major version (x.0) bumps for vast breaking changes. - minor version (1.x) bumps for new features and minor, long-deprecated breaking changes. - patch version (1.4.x) bumps for fixes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1042
https://github.com/scverse/scanpy/pull/1042:440,modifiability,version,version,440,"make sure the newest umap is used in a test; @falexwolf @ivirshup we have a lot of fixes on master, let’s release 1.4.5.1 after this one. As an aside I think our versioning is a bit weird: Why did we do a feature release called 1.4.5 and not 1.5? Why not semver-lite like python itself? - major version (x.0) bumps for vast breaking changes. - minor version (1.x) bumps for new features and minor, long-deprecated breaking changes. - patch version (1.4.x) bumps for fixes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1042
https://github.com/scverse/scanpy/pull/1042:39,safety,test,test,39,"make sure the newest umap is used in a test; @falexwolf @ivirshup we have a lot of fixes on master, let’s release 1.4.5.1 after this one. As an aside I think our versioning is a bit weird: Why did we do a feature release called 1.4.5 and not 1.5? Why not semver-lite like python itself? - major version (x.0) bumps for vast breaking changes. - minor version (1.x) bumps for new features and minor, long-deprecated breaking changes. - patch version (1.4.x) bumps for fixes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1042
https://github.com/scverse/scanpy/pull/1042:434,safety,patch,patch,434,"make sure the newest umap is used in a test; @falexwolf @ivirshup we have a lot of fixes on master, let’s release 1.4.5.1 after this one. As an aside I think our versioning is a bit weird: Why did we do a feature release called 1.4.5 and not 1.5? Why not semver-lite like python itself? - major version (x.0) bumps for vast breaking changes. - minor version (1.x) bumps for new features and minor, long-deprecated breaking changes. - patch version (1.4.x) bumps for fixes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1042
https://github.com/scverse/scanpy/pull/1042:434,security,patch,patch,434,"make sure the newest umap is used in a test; @falexwolf @ivirshup we have a lot of fixes on master, let’s release 1.4.5.1 after this one. As an aside I think our versioning is a bit weird: Why did we do a feature release called 1.4.5 and not 1.5? Why not semver-lite like python itself? - major version (x.0) bumps for vast breaking changes. - minor version (1.x) bumps for new features and minor, long-deprecated breaking changes. - patch version (1.4.x) bumps for fixes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1042
https://github.com/scverse/scanpy/pull/1042:39,testability,test,test,39,"make sure the newest umap is used in a test; @falexwolf @ivirshup we have a lot of fixes on master, let’s release 1.4.5.1 after this one. As an aside I think our versioning is a bit weird: Why did we do a feature release called 1.4.5 and not 1.5? Why not semver-lite like python itself? - major version (x.0) bumps for vast breaking changes. - minor version (1.x) bumps for new features and minor, long-deprecated breaking changes. - patch version (1.4.x) bumps for fixes",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1042
https://github.com/scverse/scanpy/issues/1043:1067,availability,Error,Error,1067,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:1187,availability,error,error,1187,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:1175,deployability,fail,failed,1175,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:1208,deployability,Version,Versions,1208,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:174,integrability,filter,filtering,174,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:334,integrability,filter,filtered,334,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:520,integrability,filter,filter,520,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:1208,integrability,Version,Versions,1208,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:1208,modifiability,Version,Versions,1208,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:1067,performance,Error,Error,1067,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:1187,performance,error,error,1187,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:1175,reliability,fail,failed,1175,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:1067,safety,Error,Error,1067,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:1187,safety,error,error,1187,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:25,testability,Assert,AssertionError,25,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:471,testability,Assert,AssertionError,471,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:510,testability,simpl,simply,510,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:749,testability,simpl,simple,749,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:794,testability,simpl,simply,794,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:1153,testability,Assert,AssertionError,1153,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:72,usability,clear,clear,72,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:510,usability,simpl,simply,510,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:749,usability,simpl,simple,749,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:794,usability,simpl,simply,794,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:916,usability,minim,minimal,916,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:1067,usability,Error,Error,1067,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:1187,usability,error,error,1187,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/issues/1043:1327,usability,learn,learn,1327,"sc.queries.enrich throws AssertionError with floats; <!-- Please give a clear and concise description of what the bug is: -->. I'm trying to run an enrichment analysis after filtering out certain genes via `sc.tl.filter_rank_genes_groups`, so I use `key='rank_genes_groups_filtered'` as an argument for `sc.queries.enrich`. Since the filtered values are replaced with `nan` I hoped they'd by ignored in the enrichment analysis, but it actually leads to an uninformative `AssertionError`. My suggestion here is simply to filter `nan` values from the gene list around here and 2 lines later: https://github.com/theislab/scanpy/blob/249fc572471683357b86b8bbf41d3284118bc8f8/scanpy/queries/_queries.py#L296. I can make a little PR if we agree with this simple fix. Note you can reproduce this very simply without an adata object (but of course the likely use case is with an adata object as outlined above):. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```. sc.queries.enrich([float('nan')]). ```. Output:. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. AssertionError: query failed with error 500. ```. #### Versions:. ```. scanpy==1.4.5.post2 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.2.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.8.0. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1043
https://github.com/scverse/scanpy/pull/1044:4,deployability,patch,patch,4,Add patch notes for 1.4.5.1;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1044
https://github.com/scverse/scanpy/pull/1044:4,safety,patch,patch,4,Add patch notes for 1.4.5.1;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1044
https://github.com/scverse/scanpy/pull/1044:4,security,patch,patch,4,Add patch notes for 1.4.5.1;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1044
https://github.com/scverse/scanpy/pull/1048:6,safety,test,tests,6,Fixed tests and read function;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1048
https://github.com/scverse/scanpy/pull/1048:6,testability,test,tests,6,Fixed tests and read function;,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1048
https://github.com/scverse/scanpy/pull/1050:38,deployability,build,build,38,"Misc fixes; This should make the docs build again, and fix a few things I came across",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1050
https://github.com/scverse/scanpy/issues/1051:424,availability,Error,Error,424,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:14,deployability,fail,fails,14,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:127,deployability,fail,fails,127,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:574,deployability,modul,module,574,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:1281,deployability,Version,Versions,1281,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:1314,deployability,log,logging,1314,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:1281,integrability,Version,Versions,1281,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:574,modifiability,modul,module,574,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:634,modifiability,pac,packages,634,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:756,modifiability,pac,packages,756,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:773,modifiability,deco,decomposition,773,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:879,modifiability,pac,packages,879,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:896,modifiability,deco,decomposition,896,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:1036,modifiability,pac,packages,1036,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:1053,modifiability,deco,decomposition,1053,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:1281,modifiability,Version,Versions,1281,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:424,performance,Error,Error,424,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:14,reliability,fail,fails,14,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:127,reliability,fail,fails,127,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:424,safety,Error,Error,424,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:574,safety,modul,module,574,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:1314,safety,log,logging,1314,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:1314,security,log,logging,1314,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:510,testability,Trace,Traceback,510,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:1314,testability,log,logging,1314,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:58,usability,clear,clear,58,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:176,usability,minim,minimal,176,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:424,usability,Error,Error,424,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/issues/1051:1471,usability,learn,learn,1471,"scanpy.pp.pca fails on small datasets; <!-- Please give a clear and concise description of what the bug is: -->. scanpy.pp.pca fails if n_samples < 50 < n_features. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import numpy as np. import scanpy as sc. import anndata. adata = anndata.AnnData(np.random.normal(0, 1, (40, 100))). sc.pp.pca(adata). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/scottgigante/.local/lib/python3.8/site-packages/scanpy/preprocessing/_simple.py"", line 531, in pca. X_pca = pca_.fit_transform(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 369, in fit_transform. U, S, V = self._fit(X). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 418, in _fit. return self._fit_truncated(X, n_components, self._fit_svd_solver). File ""/usr/lib/python3.8/site-packages/sklearn/decomposition/_pca.py"", line 497, in _fit_truncated. raise ValueError(""n_components=%r must be between 1 and "". ValueError: n_components=50 must be between 1 and min(n_samples, n_features)=40 with svd_solver='arpack'. ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.2.3.dev1409+g7ca201d.d20200112 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.0 scipy==1.4.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.11.0rc1 python-igraph==0.7.1 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1051
https://github.com/scverse/scanpy/pull/1052:14,availability,state,statements,14,Update import statements for SAM; This is in response to [Issue # 26](https://github.com/atarashansky/self-assembling-manifold/issues/26). Just a slight change to the import statements after switching SAM to have a package structure as opposed to using global modules.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1052
https://github.com/scverse/scanpy/pull/1052:146,availability,sli,slight,146,Update import statements for SAM; This is in response to [Issue # 26](https://github.com/atarashansky/self-assembling-manifold/issues/26). Just a slight change to the import statements after switching SAM to have a package structure as opposed to using global modules.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1052
https://github.com/scverse/scanpy/pull/1052:174,availability,state,statements,174,Update import statements for SAM; This is in response to [Issue # 26](https://github.com/atarashansky/self-assembling-manifold/issues/26). Just a slight change to the import statements after switching SAM to have a package structure as opposed to using global modules.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1052
https://github.com/scverse/scanpy/pull/1052:0,deployability,Updat,Update,0,Update import statements for SAM; This is in response to [Issue # 26](https://github.com/atarashansky/self-assembling-manifold/issues/26). Just a slight change to the import statements after switching SAM to have a package structure as opposed to using global modules.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1052
https://github.com/scverse/scanpy/pull/1052:260,deployability,modul,modules,260,Update import statements for SAM; This is in response to [Issue # 26](https://github.com/atarashansky/self-assembling-manifold/issues/26). Just a slight change to the import statements after switching SAM to have a package structure as opposed to using global modules.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1052
https://github.com/scverse/scanpy/pull/1052:14,integrability,state,statements,14,Update import statements for SAM; This is in response to [Issue # 26](https://github.com/atarashansky/self-assembling-manifold/issues/26). Just a slight change to the import statements after switching SAM to have a package structure as opposed to using global modules.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1052
https://github.com/scverse/scanpy/pull/1052:174,integrability,state,statements,174,Update import statements for SAM; This is in response to [Issue # 26](https://github.com/atarashansky/self-assembling-manifold/issues/26). Just a slight change to the import statements after switching SAM to have a package structure as opposed to using global modules.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1052
https://github.com/scverse/scanpy/pull/1052:215,modifiability,pac,package,215,Update import statements for SAM; This is in response to [Issue # 26](https://github.com/atarashansky/self-assembling-manifold/issues/26). Just a slight change to the import statements after switching SAM to have a package structure as opposed to using global modules.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1052
https://github.com/scverse/scanpy/pull/1052:260,modifiability,modul,modules,260,Update import statements for SAM; This is in response to [Issue # 26](https://github.com/atarashansky/self-assembling-manifold/issues/26). Just a slight change to the import statements after switching SAM to have a package structure as opposed to using global modules.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1052
https://github.com/scverse/scanpy/pull/1052:146,reliability,sli,slight,146,Update import statements for SAM; This is in response to [Issue # 26](https://github.com/atarashansky/self-assembling-manifold/issues/26). Just a slight change to the import statements after switching SAM to have a package structure as opposed to using global modules.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1052
https://github.com/scverse/scanpy/pull/1052:0,safety,Updat,Update,0,Update import statements for SAM; This is in response to [Issue # 26](https://github.com/atarashansky/self-assembling-manifold/issues/26). Just a slight change to the import statements after switching SAM to have a package structure as opposed to using global modules.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1052
https://github.com/scverse/scanpy/pull/1052:260,safety,modul,modules,260,Update import statements for SAM; This is in response to [Issue # 26](https://github.com/atarashansky/self-assembling-manifold/issues/26). Just a slight change to the import statements after switching SAM to have a package structure as opposed to using global modules.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1052
https://github.com/scverse/scanpy/pull/1052:0,security,Updat,Update,0,Update import statements for SAM; This is in response to [Issue # 26](https://github.com/atarashansky/self-assembling-manifold/issues/26). Just a slight change to the import statements after switching SAM to have a package structure as opposed to using global modules.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1052
https://github.com/scverse/scanpy/issues/1053:615,availability,avail,available,615,"Leiden now included in python-igraph; The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053
https://github.com/scverse/scanpy/issues/1053:163,deployability,releas,release,163,"Leiden now included in python-igraph; The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053
https://github.com/scverse/scanpy/issues/1053:191,deployability,version,version,191,"Leiden now included in python-igraph; The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053
https://github.com/scverse/scanpy/issues/1053:244,deployability,depend,depend,244,"Leiden now included in python-igraph; The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053
https://github.com/scverse/scanpy/issues/1053:191,integrability,version,version,191,"Leiden now included in python-igraph; The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053
https://github.com/scverse/scanpy/issues/1053:244,integrability,depend,depend,244,"Leiden now included in python-igraph; The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053
https://github.com/scverse/scanpy/issues/1053:332,integrability,sub,substantially,332,"Leiden now included in python-igraph; The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053
https://github.com/scverse/scanpy/issues/1053:191,modifiability,version,version,191,"Leiden now included in python-igraph; The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053
https://github.com/scverse/scanpy/issues/1053:244,modifiability,depend,depend,244,"Leiden now included in python-igraph; The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053
https://github.com/scverse/scanpy/issues/1053:270,modifiability,pac,packages,270,"Leiden now included in python-igraph; The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053
https://github.com/scverse/scanpy/issues/1053:374,modifiability,pac,package,374,"Leiden now included in python-igraph; The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053
https://github.com/scverse/scanpy/issues/1053:453,modifiability,extens,extensive,453,"Leiden now included in python-igraph; The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053
https://github.com/scverse/scanpy/issues/1053:490,modifiability,pac,package,490,"Leiden now included in python-igraph; The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053
https://github.com/scverse/scanpy/issues/1053:615,reliability,availab,available,615,"Leiden now included in python-igraph; The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053
https://github.com/scverse/scanpy/issues/1053:244,safety,depend,depend,244,"Leiden now included in python-igraph; The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053
https://github.com/scverse/scanpy/issues/1053:615,safety,avail,available,615,"Leiden now included in python-igraph; The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053
https://github.com/scverse/scanpy/issues/1053:615,security,availab,available,615,"Leiden now included in python-igraph; The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053
https://github.com/scverse/scanpy/issues/1053:244,testability,depend,depend,244,"Leiden now included in python-igraph; The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053
https://github.com/scverse/scanpy/issues/1053:389,testability,simpl,simpler,389,"Leiden now included in python-igraph; The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053
https://github.com/scverse/scanpy/issues/1053:389,usability,simpl,simpler,389,"Leiden now included in python-igraph; The Leiden algorithm is now [included](https://igraph.org/python/doc/igraph.Graph-class.html#community_leiden) in the latest release of `python-igraph`, version 0.8.0. I believe this alleviates the need to depend on the `leidenalg` packages. The Leiden algorithm provided in `python-igraph` is substantially faster than the `leidenalg` package. It is simpler though, providing fewer options, but I believe the more extensive options of the `leidenalg` package are not necessarily needed for the purposes of `scanpy`. We provide binary wheels on PyPI and binaries for conda are available from the conda-forge channel, also for Windows.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1053
https://github.com/scverse/scanpy/issues/1057:333,availability,avail,available,333,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:656,availability,error,errors,656,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:709,availability,error,errors,709,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:3094,availability,error,errors,3094,".6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings locally with:. ```. make clean. make html. ```. But if I run `make html` again, I don't get the warnings.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:3352,availability,error,error,3352,".6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings locally with:. ```. make clean. make html. ```. But if I run `make html` again, I don't get the warnings.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:5,deployability,fail,failing,5,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:13,deployability,build,builds,13,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:301,deployability,version,version,301,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:888,deployability,build,build,888,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:928,deployability,build,build,928,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:1105,deployability,build,build,1105,"kouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:1117,deployability,build,builder,1117,"docs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:1254,deployability,build,builders,1254,"deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:1433,deployability,build,builders,1433,"dthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:1469,deployability,build,build,1469,"/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:1643,deployability,build,builders,1643,"ay cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:1837,deployability,build,builders,1837,"/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:1946,deployability,version,versions,1946,"filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2147,deployability,log,logging,2147,"e/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.or",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2210,deployability,log,logger,2210,"atest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2337,deployability,log,logging,2337,"kouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2372,deployability,log,logger,2372,"icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/chec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2419,deployability,version,versions,2419,"es/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/che",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2448,deployability,log,logging,2448,"y"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preproce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2543,deployability,version,versions,2543,"checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not foun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2572,deployability,log,logging,2572,"r_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2667,deployability,version,versions,2667,"535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not bei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2696,deployability,log,logging,2696,"rial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2789,deployability,version,versions,2789,"s/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2818,deployability,log,logging,2818,"ackages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:3006,deployability,log,logging,3006,".6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings locally with:. ```. make clean. make html. ```. But if I run `make html` again, I don't get the warnings.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:3622,deployability,fail,failing,3622,".6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings locally with:. ```. make clean. make html. ```. But if I run `make html` again, I don't get the warnings.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:244,energy efficiency,core,core,244,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:383,energy efficiency,core,core,383,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:301,integrability,version,version,301,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:314,integrability,pub,public,314,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:1946,integrability,version,versions,1946,"filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2419,integrability,version,versions,2419,"es/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/che",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2543,integrability,version,versions,2543,"checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not foun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2667,integrability,version,versions,2667,"535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not bei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2749,integrability,filter,filter,2749,"eadthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't ha",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2789,integrability,version,versions,2789,"s/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2853,integrability,filter,filter,2853,"y"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings local",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2872,integrability,filter,filter,2872,"rite_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings locally with:. ```. make",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:3032,integrability,filter,filter,3032,".6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings locally with:. ```. make clean. make html. ```. But if I run `make html` again, I don't get the warnings.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:3077,integrability,messag,message,3077,".6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings locally with:. ```. make clean. make html. ```. But if I run `make html` again, I don't get the warnings.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:3734,integrability,transform,transform,3734,".6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings locally with:. ```. make clean. make html. ```. But if I run `make html` again, I don't get the warnings.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:717,interoperability,format,format,717,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:3077,interoperability,messag,message,3077,".6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings locally with:. ```. make clean. make html. ```. But if I run `make html` again, I don't get the warnings.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:3734,interoperability,transform,transform,3734,".6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings locally with:. ```. make clean. make html. ```. But if I run `make html` again, I don't get the warnings.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:184,modifiability,pac,packages,184,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:301,modifiability,version,version,301,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:504,modifiability,pac,packages,504,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:868,modifiability,pac,packages,868,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:1059,modifiability,pac,packages,1059,"thedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthe",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:1238,modifiability,pac,packages,1238,"s.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checko",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:1417,modifiability,pac,packages,1417,"cs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/ve",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:1627,modifiability,pac,packages,1627,"is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.hand",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:1821,modifiability,pac,packages,1821,"/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:1946,modifiability,version,versions,1946,"filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-sca",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2126,modifiability,pac,packages,2126,"_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/che",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2316,modifiability,pac,packages,2316,"File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.R",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2419,modifiability,version,versions,2419,"es/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/che",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2543,modifiability,version,versions,2543,"checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not foun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2667,modifiability,version,versions,2667,"535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not bei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2789,modifiability,version,versions,2789,"s/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2985,modifiability,pac,packages,2985,".6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings locally with:. ```. make clean. make html. ```. But if I run `make html` again, I don't get the warnings.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:656,performance,error,errors,656,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:709,performance,error,errors,709,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:3094,performance,error,errors,3094,".6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings locally with:. ```. make clean. make html. ```. But if I run `make html` again, I don't get the warnings.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:3352,performance,error,error,3352,".6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings locally with:. ```. make clean. make html. ```. But if I run `make html` again, I don't get the warnings.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:5,reliability,fail,failing,5,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:333,reliability,availab,available,333,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:3622,reliability,fail,failing,3622,".6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings locally with:. ```. make clean. make html. ```. But if I run `make html` again, I don't get the warnings.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:333,safety,avail,available,333,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:656,safety,error,errors,656,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:709,safety,error,errors,709,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2147,safety,log,logging,2147,"e/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.or",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2210,safety,log,logger,2210,"atest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2337,safety,log,logging,2337,"kouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2372,safety,log,logger,2372,"icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/chec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2448,safety,log,logging,2448,"y"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preproce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2572,safety,log,logging,2572,"r_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2696,safety,log,logging,2696,"rial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2818,safety,log,logging,2818,"ackages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:3006,safety,log,logging,3006,".6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings locally with:. ```. make clean. make html. ```. But if I run `make html` again, I don't get the warnings.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:3094,safety,error,errors,3094,".6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings locally with:. ```. make clean. make html. ```. But if I run `make html` again, I don't get the warnings.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:3352,safety,error,error,3352,".6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings locally with:. ```. make clean. make html. ```. But if I run `make html` again, I don't get the warnings.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:333,security,availab,available,333,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2147,security,log,logging,2147,"e/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.or",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2210,security,log,logger,2210,"atest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2337,security,log,logging,2337,"kouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2372,security,log,logger,2372,"icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/chec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2448,security,log,logging,2448,"y"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preproce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2572,security,log,logging,2572,"r_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2696,security,log,logging,2696,"rial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2818,security,log,logging,2818,"ackages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:3006,security,log,logging,3006,".6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings locally with:. ```. make clean. make html. ```. But if I run `make html` again, I don't get the warnings.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:44,testability,Trace,Traceback,44,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:735,testability,Trace,Traceback,735,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:1975,testability,context,contextlib,1975,"heckouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2147,testability,log,logging,2147,"e/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.or",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2210,testability,log,logger,2210,"atest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2337,testability,log,logging,2337,"kouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2372,testability,log,logger,2372,"icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/chec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2448,testability,log,logging,2448,"y"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preproce",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2572,testability,log,logging,2572,"r_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2696,testability,log,logging,2696,"rial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:2818,testability,log,logging,2818,"ackages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:3006,testability,log,logging,3006,".6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings locally with:. ```. make clean. make html. ```. But if I run `make html` again, I don't get the warnings.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:539,usability,User,UserWarning,539,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:656,usability,error,errors,656,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:709,usability,error,errors,709,"Docs failing builds; . <details>. <summary> Traceback from readthedocs: </summary>. ```pytb. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/setuptools_scm/git.py:68: UserWarning: ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest"" is shallow and may cause errors. warnings.warn('""{}"" is shallow and may cause errors'.format(wd.path)). Traceback (most recent call last):. File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/cmd/build.py"", line 276, in build_main. app.build(args.force_all, filenames). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/application.py"", line 349, in build. self.builder.build_update(). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 299, in build_update. len(to_build)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 361, in build. self.write(docnames, list(updated_docnames), method). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 535, in write. self._write_serial(sorted(docnames)). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/builders/__init__.py"", line 545, in _write_serial. self.write_doc(docname, doctree). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/contextlib.py"", line 88, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:3094,usability,error,errors,3094,".6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings locally with:. ```. make clean. make html. ```. But if I run `make html` again, I don't get the warnings.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1057:3352,usability,error,error,3352,".6.8/lib/python3.6/contextlib.py"", line 88, in __exit__. next(self.gen). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 219, in pending_warnings. memhandler.flushTo(logger). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 184, in flushTo. logger.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1454, in handle. self.callHandlers(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 1516, in callHandlers. hdlr.handle(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 861, in handle. rv = self.filter(record). File ""/home/docs/.pyenv/versions/3.6.8/lib/python3.6/logging/__init__.py"", line 720, in filter. result = f.filter(record). File ""/home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/envs/latest/lib/python3.6/site-packages/sphinx/util/logging.py"", line 404, in filter. raise SphinxWarning(location + "":"" + message). sphinx.errors.SphinxWarning: /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. Warning, treated as error:. /home/docs/checkouts/readthedocs.org/user_builds/icb-scanpy/checkouts/latest/scanpy/preprocessing/_simple.py:docstring of scanpy.pp.downsample_counts:17:py:class reference target not found: numpy.random.RandomState. ```. </details>. It looks like readthedocs is failing due to `numpy.random.RandomState` not being rewritten to `numpy.random.mtrand.RandomState`. I think the transform isn't happening in the right order when the docs are built from scratch since I can reproduce the warnings locally with:. ```. make clean. make html. ```. But if I run `make html` again, I don't get the warnings.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1057
https://github.com/scverse/scanpy/issues/1059:291,modifiability,paramet,parameter,291,"Flipped y-axis in sc.pl.spatial without img_key ; <!-- Please give a clear and concise description of what the bug is: -->. Hi. When I use `sc.pl.spatial` to visualize the same data with or without the H&E staining image in the background, the y-axis is flipped if I don't set the `img_key` parameter. Is this expected? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. from matplotlib import rcParams. adata_vis = sc.datasets.visium_sge('V1_Human_Lymph_Node'). rcParams[""figure.figsize""] = [8,8]. sc.pp.calculate_qc_metrics(adata_vis, inplace=True). sc.pl.spatial(adata_vis, img_key = ""hires"",color=['total_counts']). sc.pl.spatial(adata_vis,color=['total_counts'], size=100). ```. ![Screenshot 2020-02-18 at 16 30 56](https://user-images.githubusercontent.com/32264060/74756365-538e4600-526c-11ea-89f7-46409cb03d3d.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1059
https://github.com/scverse/scanpy/issues/1059:69,usability,clear,clear,69,"Flipped y-axis in sc.pl.spatial without img_key ; <!-- Please give a clear and concise description of what the bug is: -->. Hi. When I use `sc.pl.spatial` to visualize the same data with or without the H&E staining image in the background, the y-axis is flipped if I don't set the `img_key` parameter. Is this expected? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. from matplotlib import rcParams. adata_vis = sc.datasets.visium_sge('V1_Human_Lymph_Node'). rcParams[""figure.figsize""] = [8,8]. sc.pp.calculate_qc_metrics(adata_vis, inplace=True). sc.pl.spatial(adata_vis, img_key = ""hires"",color=['total_counts']). sc.pl.spatial(adata_vis,color=['total_counts'], size=100). ```. ![Screenshot 2020-02-18 at 16 30 56](https://user-images.githubusercontent.com/32264060/74756365-538e4600-526c-11ea-89f7-46409cb03d3d.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1059
https://github.com/scverse/scanpy/issues/1059:158,usability,visual,visualize,158,"Flipped y-axis in sc.pl.spatial without img_key ; <!-- Please give a clear and concise description of what the bug is: -->. Hi. When I use `sc.pl.spatial` to visualize the same data with or without the H&E staining image in the background, the y-axis is flipped if I don't set the `img_key` parameter. Is this expected? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. from matplotlib import rcParams. adata_vis = sc.datasets.visium_sge('V1_Human_Lymph_Node'). rcParams[""figure.figsize""] = [8,8]. sc.pp.calculate_qc_metrics(adata_vis, inplace=True). sc.pl.spatial(adata_vis, img_key = ""hires"",color=['total_counts']). sc.pl.spatial(adata_vis,color=['total_counts'], size=100). ```. ![Screenshot 2020-02-18 at 16 30 56](https://user-images.githubusercontent.com/32264060/74756365-538e4600-526c-11ea-89f7-46409cb03d3d.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1059
https://github.com/scverse/scanpy/issues/1059:333,usability,minim,minimal,333,"Flipped y-axis in sc.pl.spatial without img_key ; <!-- Please give a clear and concise description of what the bug is: -->. Hi. When I use `sc.pl.spatial` to visualize the same data with or without the H&E staining image in the background, the y-axis is flipped if I don't set the `img_key` parameter. Is this expected? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. from matplotlib import rcParams. adata_vis = sc.datasets.visium_sge('V1_Human_Lymph_Node'). rcParams[""figure.figsize""] = [8,8]. sc.pp.calculate_qc_metrics(adata_vis, inplace=True). sc.pl.spatial(adata_vis, img_key = ""hires"",color=['total_counts']). sc.pl.spatial(adata_vis,color=['total_counts'], size=100). ```. ![Screenshot 2020-02-18 at 16 30 56](https://user-images.githubusercontent.com/32264060/74756365-538e4600-526c-11ea-89f7-46409cb03d3d.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1059
https://github.com/scverse/scanpy/issues/1059:806,usability,user,user-images,806,"Flipped y-axis in sc.pl.spatial without img_key ; <!-- Please give a clear and concise description of what the bug is: -->. Hi. When I use `sc.pl.spatial` to visualize the same data with or without the H&E staining image in the background, the y-axis is flipped if I don't set the `img_key` parameter. Is this expected? . <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. from matplotlib import rcParams. adata_vis = sc.datasets.visium_sge('V1_Human_Lymph_Node'). rcParams[""figure.figsize""] = [8,8]. sc.pp.calculate_qc_metrics(adata_vis, inplace=True). sc.pl.spatial(adata_vis, img_key = ""hires"",color=['total_counts']). sc.pl.spatial(adata_vis,color=['total_counts'], size=100). ```. ![Screenshot 2020-02-18 at 16 30 56](https://user-images.githubusercontent.com/32264060/74756365-538e4600-526c-11ea-89f7-46409cb03d3d.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1059
https://github.com/scverse/scanpy/issues/1061:22,availability,error,error,22,Rank gene groups math error in windows; Scanpy affecting most versions tested with 1.4.3. Python 3.6 throws `Math error` exception in windows system for in `rank gene_groups`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (n_active + m_active + 1) / 12)). ```. Reason `sqrt` encounters integer overflow in: ` (n_active * m_active * (n_active + m_active + 1) / 12)` for large numbers. Quick fix to avoid overflow: divide by 12 before scaling by ` (n_active + m_active + 1)`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (1/12.0) * (n_active + m_active + 1))). ```. Casting to float could work as well? Behavior in Unix/Linux not tested,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061
https://github.com/scverse/scanpy/issues/1061:114,availability,error,error,114,Rank gene groups math error in windows; Scanpy affecting most versions tested with 1.4.3. Python 3.6 throws `Math error` exception in windows system for in `rank gene_groups`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (n_active + m_active + 1) / 12)). ```. Reason `sqrt` encounters integer overflow in: ` (n_active * m_active * (n_active + m_active + 1) / 12)` for large numbers. Quick fix to avoid overflow: divide by 12 before scaling by ` (n_active + m_active + 1)`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (1/12.0) * (n_active + m_active + 1))). ```. Casting to float could work as well? Behavior in Unix/Linux not tested,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061
https://github.com/scverse/scanpy/issues/1061:62,deployability,version,versions,62,Rank gene groups math error in windows; Scanpy affecting most versions tested with 1.4.3. Python 3.6 throws `Math error` exception in windows system for in `rank gene_groups`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (n_active + m_active + 1) / 12)). ```. Reason `sqrt` encounters integer overflow in: ` (n_active * m_active * (n_active + m_active + 1) / 12)` for large numbers. Quick fix to avoid overflow: divide by 12 before scaling by ` (n_active + m_active + 1)`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (1/12.0) * (n_active + m_active + 1))). ```. Casting to float could work as well? Behavior in Unix/Linux not tested,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061
https://github.com/scverse/scanpy/issues/1061:62,integrability,version,versions,62,Rank gene groups math error in windows; Scanpy affecting most versions tested with 1.4.3. Python 3.6 throws `Math error` exception in windows system for in `rank gene_groups`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (n_active + m_active + 1) / 12)). ```. Reason `sqrt` encounters integer overflow in: ` (n_active * m_active * (n_active + m_active + 1) / 12)` for large numbers. Quick fix to avoid overflow: divide by 12 before scaling by ` (n_active + m_active + 1)`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (1/12.0) * (n_active + m_active + 1))). ```. Casting to float could work as well? Behavior in Unix/Linux not tested,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061
https://github.com/scverse/scanpy/issues/1061:62,modifiability,version,versions,62,Rank gene groups math error in windows; Scanpy affecting most versions tested with 1.4.3. Python 3.6 throws `Math error` exception in windows system for in `rank gene_groups`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (n_active + m_active + 1) / 12)). ```. Reason `sqrt` encounters integer overflow in: ` (n_active * m_active * (n_active + m_active + 1) / 12)` for large numbers. Quick fix to avoid overflow: divide by 12 before scaling by ` (n_active + m_active + 1)`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (1/12.0) * (n_active + m_active + 1))). ```. Casting to float could work as well? Behavior in Unix/Linux not tested,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061
https://github.com/scverse/scanpy/issues/1061:513,modifiability,scal,scaling,513,Rank gene groups math error in windows; Scanpy affecting most versions tested with 1.4.3. Python 3.6 throws `Math error` exception in windows system for in `rank gene_groups`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (n_active + m_active + 1) / 12)). ```. Reason `sqrt` encounters integer overflow in: ` (n_active * m_active * (n_active + m_active + 1) / 12)` for large numbers. Quick fix to avoid overflow: divide by 12 before scaling by ` (n_active + m_active + 1)`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (1/12.0) * (n_active + m_active + 1))). ```. Casting to float could work as well? Behavior in Unix/Linux not tested,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061
https://github.com/scverse/scanpy/issues/1061:22,performance,error,error,22,Rank gene groups math error in windows; Scanpy affecting most versions tested with 1.4.3. Python 3.6 throws `Math error` exception in windows system for in `rank gene_groups`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (n_active + m_active + 1) / 12)). ```. Reason `sqrt` encounters integer overflow in: ` (n_active * m_active * (n_active + m_active + 1) / 12)` for large numbers. Quick fix to avoid overflow: divide by 12 before scaling by ` (n_active + m_active + 1)`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (1/12.0) * (n_active + m_active + 1))). ```. Casting to float could work as well? Behavior in Unix/Linux not tested,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061
https://github.com/scverse/scanpy/issues/1061:114,performance,error,error,114,Rank gene groups math error in windows; Scanpy affecting most versions tested with 1.4.3. Python 3.6 throws `Math error` exception in windows system for in `rank gene_groups`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (n_active + m_active + 1) / 12)). ```. Reason `sqrt` encounters integer overflow in: ` (n_active * m_active * (n_active + m_active + 1) / 12)` for large numbers. Quick fix to avoid overflow: divide by 12 before scaling by ` (n_active + m_active + 1)`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (1/12.0) * (n_active + m_active + 1))). ```. Casting to float could work as well? Behavior in Unix/Linux not tested,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061
https://github.com/scverse/scanpy/issues/1061:22,safety,error,error,22,Rank gene groups math error in windows; Scanpy affecting most versions tested with 1.4.3. Python 3.6 throws `Math error` exception in windows system for in `rank gene_groups`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (n_active + m_active + 1) / 12)). ```. Reason `sqrt` encounters integer overflow in: ` (n_active * m_active * (n_active + m_active + 1) / 12)` for large numbers. Quick fix to avoid overflow: divide by 12 before scaling by ` (n_active + m_active + 1)`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (1/12.0) * (n_active + m_active + 1))). ```. Casting to float could work as well? Behavior in Unix/Linux not tested,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061
https://github.com/scverse/scanpy/issues/1061:71,safety,test,tested,71,Rank gene groups math error in windows; Scanpy affecting most versions tested with 1.4.3. Python 3.6 throws `Math error` exception in windows system for in `rank gene_groups`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (n_active + m_active + 1) / 12)). ```. Reason `sqrt` encounters integer overflow in: ` (n_active * m_active * (n_active + m_active + 1) / 12)` for large numbers. Quick fix to avoid overflow: divide by 12 before scaling by ` (n_active + m_active + 1)`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (1/12.0) * (n_active + m_active + 1))). ```. Casting to float could work as well? Behavior in Unix/Linux not tested,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061
https://github.com/scverse/scanpy/issues/1061:114,safety,error,error,114,Rank gene groups math error in windows; Scanpy affecting most versions tested with 1.4.3. Python 3.6 throws `Math error` exception in windows system for in `rank gene_groups`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (n_active + m_active + 1) / 12)). ```. Reason `sqrt` encounters integer overflow in: ` (n_active * m_active * (n_active + m_active + 1) / 12)` for large numbers. Quick fix to avoid overflow: divide by 12 before scaling by ` (n_active + m_active + 1)`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (1/12.0) * (n_active + m_active + 1))). ```. Casting to float could work as well? Behavior in Unix/Linux not tested,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061
https://github.com/scverse/scanpy/issues/1061:121,safety,except,exception,121,Rank gene groups math error in windows; Scanpy affecting most versions tested with 1.4.3. Python 3.6 throws `Math error` exception in windows system for in `rank gene_groups`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (n_active + m_active + 1) / 12)). ```. Reason `sqrt` encounters integer overflow in: ` (n_active * m_active * (n_active + m_active + 1) / 12)` for large numbers. Quick fix to avoid overflow: divide by 12 before scaling by ` (n_active + m_active + 1)`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (1/12.0) * (n_active + m_active + 1))). ```. Casting to float could work as well? Behavior in Unix/Linux not tested,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061
https://github.com/scverse/scanpy/issues/1061:477,safety,avoid,avoid,477,Rank gene groups math error in windows; Scanpy affecting most versions tested with 1.4.3. Python 3.6 throws `Math error` exception in windows system for in `rank gene_groups`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (n_active + m_active + 1) / 12)). ```. Reason `sqrt` encounters integer overflow in: ` (n_active * m_active * (n_active + m_active + 1) / 12)` for large numbers. Quick fix to avoid overflow: divide by 12 before scaling by ` (n_active + m_active + 1)`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (1/12.0) * (n_active + m_active + 1))). ```. Casting to float could work as well? Behavior in Unix/Linux not tested,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061
https://github.com/scverse/scanpy/issues/1061:789,safety,test,tested,789,Rank gene groups math error in windows; Scanpy affecting most versions tested with 1.4.3. Python 3.6 throws `Math error` exception in windows system for in `rank gene_groups`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (n_active + m_active + 1) / 12)). ```. Reason `sqrt` encounters integer overflow in: ` (n_active * m_active * (n_active + m_active + 1) / 12)` for large numbers. Quick fix to avoid overflow: divide by 12 before scaling by ` (n_active + m_active + 1)`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (1/12.0) * (n_active + m_active + 1))). ```. Casting to float could work as well? Behavior in Unix/Linux not tested,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061
https://github.com/scverse/scanpy/issues/1061:71,testability,test,tested,71,Rank gene groups math error in windows; Scanpy affecting most versions tested with 1.4.3. Python 3.6 throws `Math error` exception in windows system for in `rank gene_groups`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (n_active + m_active + 1) / 12)). ```. Reason `sqrt` encounters integer overflow in: ` (n_active * m_active * (n_active + m_active + 1) / 12)` for large numbers. Quick fix to avoid overflow: divide by 12 before scaling by ` (n_active + m_active + 1)`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (1/12.0) * (n_active + m_active + 1))). ```. Casting to float could work as well? Behavior in Unix/Linux not tested,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061
https://github.com/scverse/scanpy/issues/1061:789,testability,test,tested,789,Rank gene groups math error in windows; Scanpy affecting most versions tested with 1.4.3. Python 3.6 throws `Math error` exception in windows system for in `rank gene_groups`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (n_active + m_active + 1) / 12)). ```. Reason `sqrt` encounters integer overflow in: ` (n_active * m_active * (n_active + m_active + 1) / 12)` for large numbers. Quick fix to avoid overflow: divide by 12 before scaling by ` (n_active + m_active + 1)`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (1/12.0) * (n_active + m_active + 1))). ```. Casting to float could work as well? Behavior in Unix/Linux not tested,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061
https://github.com/scverse/scanpy/issues/1061:22,usability,error,error,22,Rank gene groups math error in windows; Scanpy affecting most versions tested with 1.4.3. Python 3.6 throws `Math error` exception in windows system for in `rank gene_groups`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (n_active + m_active + 1) / 12)). ```. Reason `sqrt` encounters integer overflow in: ` (n_active * m_active * (n_active + m_active + 1) / 12)` for large numbers. Quick fix to avoid overflow: divide by 12 before scaling by ` (n_active + m_active + 1)`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (1/12.0) * (n_active + m_active + 1))). ```. Casting to float could work as well? Behavior in Unix/Linux not tested,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061
https://github.com/scverse/scanpy/issues/1061:114,usability,error,error,114,Rank gene groups math error in windows; Scanpy affecting most versions tested with 1.4.3. Python 3.6 throws `Math error` exception in windows system for in `rank gene_groups`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (n_active + m_active + 1) / 12)). ```. Reason `sqrt` encounters integer overflow in: ` (n_active * m_active * (n_active + m_active + 1) / 12)` for large numbers. Quick fix to avoid overflow: divide by 12 before scaling by ` (n_active + m_active + 1)`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (1/12.0) * (n_active + m_active + 1))). ```. Casting to float could work as well? Behavior in Unix/Linux not tested,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061
https://github.com/scverse/scanpy/issues/1061:762,usability,Behavi,Behavior,762,Rank gene groups math error in windows; Scanpy affecting most versions tested with 1.4.3. Python 3.6 throws `Math error` exception in windows system for in `rank gene_groups`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (n_active + m_active + 1) / 12)). ```. Reason `sqrt` encounters integer overflow in: ` (n_active * m_active * (n_active + m_active + 1) / 12)` for large numbers. Quick fix to avoid overflow: divide by 12 before scaling by ` (n_active + m_active + 1)`. _rank_gene_groups.py:313. ```. scores = (scores - (n_active * (n_active + m_active + 1) / 2)) / sqrt(. (n_active * m_active * (1/12.0) * (n_active + m_active + 1))). ```. Casting to float could work as well? Behavior in Unix/Linux not tested,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1061
https://github.com/scverse/scanpy/pull/1062:51,availability,operat,operations,51,"Fix rank_genes_groups overflow in Windows; Reorder operations to avoid overflows. Behavior Fixed:. ```py. import scanpy as sc. import numpy as np. X = np.random.randint(0,1000, size= (3000,2000)). ann = sc.AnnData(np.log(X+1)). gsize = X.shape [0] / 2. ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). ```. ```pytb. ... storing 'group' as categorical. C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars. (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-bccdb587a644> in <module>. 5 gsize = X.shape [0] / 2. 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). 8. 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). --> 372. 373 scores[np.isnan(scores)] = 0. 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. After the fix, the same code no longer raises an error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:1486,availability,error,error,1486,"Fix rank_genes_groups overflow in Windows; Reorder operations to avoid overflows. Behavior Fixed:. ```py. import scanpy as sc. import numpy as np. X = np.random.randint(0,1000, size= (3000,2000)). ann = sc.AnnData(np.log(X+1)). gsize = X.shape [0] / 2. ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). ```. ```pytb. ... storing 'group' as categorical. C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars. (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-bccdb587a644> in <module>. 5 gsize = X.shape [0] / 2. 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). 8. 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). --> 372. 373 scores[np.isnan(scores)] = 0. 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. After the fix, the same code no longer raises an error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:1547,availability,error,error,1547,"Fix rank_genes_groups overflow in Windows; Reorder operations to avoid overflows. Behavior Fixed:. ```py. import scanpy as sc. import numpy as np. X = np.random.randint(0,1000, size= (3000,2000)). ann = sc.AnnData(np.log(X+1)). gsize = X.shape [0] / 2. ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). ```. ```pytb. ... storing 'group' as categorical. C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars. (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-bccdb587a644> in <module>. 5 gsize = X.shape [0] / 2. 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). 8. 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). --> 372. 373 scores[np.isnan(scores)] = 0. 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. After the fix, the same code no longer raises an error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:217,deployability,log,log,217,"Fix rank_genes_groups overflow in Windows; Reorder operations to avoid overflows. Behavior Fixed:. ```py. import scanpy as sc. import numpy as np. X = np.random.randint(0,1000, size= (3000,2000)). ann = sc.AnnData(np.log(X+1)). gsize = X.shape [0] / 2. ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). ```. ```pytb. ... storing 'group' as categorical. C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars. (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-bccdb587a644> in <module>. 5 gsize = X.shape [0] / 2. 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). 8. 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). --> 372. 373 scores[np.isnan(scores)] = 0. 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. After the fix, the same code no longer raises an error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:804,deployability,modul,module,804,"Fix rank_genes_groups overflow in Windows; Reorder operations to avoid overflows. Behavior Fixed:. ```py. import scanpy as sc. import numpy as np. X = np.random.randint(0,1000, size= (3000,2000)). ann = sc.AnnData(np.log(X+1)). gsize = X.shape [0] / 2. ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). ```. ```pytb. ... storing 'group' as categorical. C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars. (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-bccdb587a644> in <module>. 5 gsize = X.shape [0] / 2. 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). 8. 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). --> 372. 373 scores[np.isnan(scores)] = 0. 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. After the fix, the same code no longer raises an error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:1414,interoperability,distribut,distributions,1414,"Fix rank_genes_groups overflow in Windows; Reorder operations to avoid overflows. Behavior Fixed:. ```py. import scanpy as sc. import numpy as np. X = np.random.randint(0,1000, size= (3000,2000)). ann = sc.AnnData(np.log(X+1)). gsize = X.shape [0] / 2. ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). ```. ```pytb. ... storing 'group' as categorical. C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars. (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-bccdb587a644> in <module>. 5 gsize = X.shape [0] / 2. 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). 8. 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). --> 372. 373 scores[np.isnan(scores)] = 0. 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. After the fix, the same code no longer raises an error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:484,modifiability,pac,packages,484,"Fix rank_genes_groups overflow in Windows; Reorder operations to avoid overflows. Behavior Fixed:. ```py. import scanpy as sc. import numpy as np. X = np.random.randint(0,1000, size= (3000,2000)). ann = sc.AnnData(np.log(X+1)). gsize = X.shape [0] / 2. ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). ```. ```pytb. ... storing 'group' as categorical. C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars. (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-bccdb587a644> in <module>. 5 gsize = X.shape [0] / 2. 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). 8. 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). --> 372. 373 scores[np.isnan(scores)] = 0. 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. After the fix, the same code no longer raises an error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:804,modifiability,modul,module,804,"Fix rank_genes_groups overflow in Windows; Reorder operations to avoid overflows. Behavior Fixed:. ```py. import scanpy as sc. import numpy as np. X = np.random.randint(0,1000, size= (3000,2000)). ann = sc.AnnData(np.log(X+1)). gsize = X.shape [0] / 2. ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). ```. ```pytb. ... storing 'group' as categorical. C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars. (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-bccdb587a644> in <module>. 5 gsize = X.shape [0] / 2. 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). 8. 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). --> 372. 373 scores[np.isnan(scores)] = 0. 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. After the fix, the same code no longer raises an error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:1024,modifiability,pac,packages,1024,"Fix rank_genes_groups overflow in Windows; Reorder operations to avoid overflows. Behavior Fixed:. ```py. import scanpy as sc. import numpy as np. X = np.random.randint(0,1000, size= (3000,2000)). ann = sc.AnnData(np.log(X+1)). gsize = X.shape [0] / 2. ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). ```. ```pytb. ... storing 'group' as categorical. C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars. (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-bccdb587a644> in <module>. 5 gsize = X.shape [0] / 2. 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). 8. 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). --> 372. 373 scores[np.isnan(scores)] = 0. 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. After the fix, the same code no longer raises an error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:1486,performance,error,error,1486,"Fix rank_genes_groups overflow in Windows; Reorder operations to avoid overflows. Behavior Fixed:. ```py. import scanpy as sc. import numpy as np. X = np.random.randint(0,1000, size= (3000,2000)). ann = sc.AnnData(np.log(X+1)). gsize = X.shape [0] / 2. ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). ```. ```pytb. ... storing 'group' as categorical. C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars. (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-bccdb587a644> in <module>. 5 gsize = X.shape [0] / 2. 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). 8. 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). --> 372. 373 scores[np.isnan(scores)] = 0. 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. After the fix, the same code no longer raises an error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:1547,performance,error,error,1547,"Fix rank_genes_groups overflow in Windows; Reorder operations to avoid overflows. Behavior Fixed:. ```py. import scanpy as sc. import numpy as np. X = np.random.randint(0,1000, size= (3000,2000)). ann = sc.AnnData(np.log(X+1)). gsize = X.shape [0] / 2. ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). ```. ```pytb. ... storing 'group' as categorical. C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars. (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-bccdb587a644> in <module>. 5 gsize = X.shape [0] / 2. 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). 8. 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). --> 372. 373 scores[np.isnan(scores)] = 0. 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. After the fix, the same code no longer raises an error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:65,safety,avoid,avoid,65,"Fix rank_genes_groups overflow in Windows; Reorder operations to avoid overflows. Behavior Fixed:. ```py. import scanpy as sc. import numpy as np. X = np.random.randint(0,1000, size= (3000,2000)). ann = sc.AnnData(np.log(X+1)). gsize = X.shape [0] / 2. ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). ```. ```pytb. ... storing 'group' as categorical. C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars. (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-bccdb587a644> in <module>. 5 gsize = X.shape [0] / 2. 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). 8. 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). --> 372. 373 scores[np.isnan(scores)] = 0. 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. After the fix, the same code no longer raises an error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:217,safety,log,log,217,"Fix rank_genes_groups overflow in Windows; Reorder operations to avoid overflows. Behavior Fixed:. ```py. import scanpy as sc. import numpy as np. X = np.random.randint(0,1000, size= (3000,2000)). ann = sc.AnnData(np.log(X+1)). gsize = X.shape [0] / 2. ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). ```. ```pytb. ... storing 'group' as categorical. C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars. (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-bccdb587a644> in <module>. 5 gsize = X.shape [0] / 2. 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). 8. 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). --> 372. 373 scores[np.isnan(scores)] = 0. 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. After the fix, the same code no longer raises an error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:778,safety,input,input-,778,"Fix rank_genes_groups overflow in Windows; Reorder operations to avoid overflows. Behavior Fixed:. ```py. import scanpy as sc. import numpy as np. X = np.random.randint(0,1000, size= (3000,2000)). ann = sc.AnnData(np.log(X+1)). gsize = X.shape [0] / 2. ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). ```. ```pytb. ... storing 'group' as categorical. C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars. (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-bccdb587a644> in <module>. 5 gsize = X.shape [0] / 2. 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). 8. 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). --> 372. 373 scores[np.isnan(scores)] = 0. 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. After the fix, the same code no longer raises an error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:804,safety,modul,module,804,"Fix rank_genes_groups overflow in Windows; Reorder operations to avoid overflows. Behavior Fixed:. ```py. import scanpy as sc. import numpy as np. X = np.random.randint(0,1000, size= (3000,2000)). ann = sc.AnnData(np.log(X+1)). gsize = X.shape [0] / 2. ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). ```. ```pytb. ... storing 'group' as categorical. C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars. (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-bccdb587a644> in <module>. 5 gsize = X.shape [0] / 2. 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). 8. 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). --> 372. 373 scores[np.isnan(scores)] = 0. 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. After the fix, the same code no longer raises an error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:1486,safety,error,error,1486,"Fix rank_genes_groups overflow in Windows; Reorder operations to avoid overflows. Behavior Fixed:. ```py. import scanpy as sc. import numpy as np. X = np.random.randint(0,1000, size= (3000,2000)). ann = sc.AnnData(np.log(X+1)). gsize = X.shape [0] / 2. ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). ```. ```pytb. ... storing 'group' as categorical. C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars. (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-bccdb587a644> in <module>. 5 gsize = X.shape [0] / 2. 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). 8. 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). --> 372. 373 scores[np.isnan(scores)] = 0. 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. After the fix, the same code no longer raises an error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:1547,safety,error,error,1547,"Fix rank_genes_groups overflow in Windows; Reorder operations to avoid overflows. Behavior Fixed:. ```py. import scanpy as sc. import numpy as np. X = np.random.randint(0,1000, size= (3000,2000)). ann = sc.AnnData(np.log(X+1)). gsize = X.shape [0] / 2. ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). ```. ```pytb. ... storing 'group' as categorical. C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars. (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-bccdb587a644> in <module>. 5 gsize = X.shape [0] / 2. 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). 8. 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). --> 372. 373 scores[np.isnan(scores)] = 0. 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. After the fix, the same code no longer raises an error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:217,security,log,log,217,"Fix rank_genes_groups overflow in Windows; Reorder operations to avoid overflows. Behavior Fixed:. ```py. import scanpy as sc. import numpy as np. X = np.random.randint(0,1000, size= (3000,2000)). ann = sc.AnnData(np.log(X+1)). gsize = X.shape [0] / 2. ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). ```. ```pytb. ... storing 'group' as categorical. C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars. (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-bccdb587a644> in <module>. 5 gsize = X.shape [0] / 2. 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). 8. 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). --> 372. 373 scores[np.isnan(scores)] = 0. 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. After the fix, the same code no longer raises an error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:217,testability,log,log,217,"Fix rank_genes_groups overflow in Windows; Reorder operations to avoid overflows. Behavior Fixed:. ```py. import scanpy as sc. import numpy as np. X = np.random.randint(0,1000, size= (3000,2000)). ann = sc.AnnData(np.log(X+1)). gsize = X.shape [0] / 2. ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). ```. ```pytb. ... storing 'group' as categorical. C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars. (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-bccdb587a644> in <module>. 5 gsize = X.shape [0] / 2. 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). 8. 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). --> 372. 373 scores[np.isnan(scores)] = 0. 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. After the fix, the same code no longer raises an error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:734,testability,Trace,Traceback,734,"Fix rank_genes_groups overflow in Windows; Reorder operations to avoid overflows. Behavior Fixed:. ```py. import scanpy as sc. import numpy as np. X = np.random.randint(0,1000, size= (3000,2000)). ann = sc.AnnData(np.log(X+1)). gsize = X.shape [0] / 2. ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). ```. ```pytb. ... storing 'group' as categorical. C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars. (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-bccdb587a644> in <module>. 5 gsize = X.shape [0] / 2. 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). 8. 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). --> 372. 373 scores[np.isnan(scores)] = 0. 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. After the fix, the same code no longer raises an error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:82,usability,Behavi,Behavior,82,"Fix rank_genes_groups overflow in Windows; Reorder operations to avoid overflows. Behavior Fixed:. ```py. import scanpy as sc. import numpy as np. X = np.random.randint(0,1000, size= (3000,2000)). ann = sc.AnnData(np.log(X+1)). gsize = X.shape [0] / 2. ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). ```. ```pytb. ... storing 'group' as categorical. C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars. (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-bccdb587a644> in <module>. 5 gsize = X.shape [0] / 2. 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). 8. 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). --> 372. 373 scores[np.isnan(scores)] = 0. 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. After the fix, the same code no longer raises an error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:439,usability,User,Users,439,"Fix rank_genes_groups overflow in Windows; Reorder operations to avoid overflows. Behavior Fixed:. ```py. import scanpy as sc. import numpy as np. X = np.random.randint(0,1000, size= (3000,2000)). ann = sc.AnnData(np.log(X+1)). gsize = X.shape [0] / 2. ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). ```. ```pytb. ... storing 'group' as categorical. C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars. (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-bccdb587a644> in <module>. 5 gsize = X.shape [0] / 2. 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). 8. 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). --> 372. 373 scores[np.isnan(scores)] = 0. 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. After the fix, the same code no longer raises an error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:500,usability,tool,tools,500,"Fix rank_genes_groups overflow in Windows; Reorder operations to avoid overflows. Behavior Fixed:. ```py. import scanpy as sc. import numpy as np. X = np.random.randint(0,1000, size= (3000,2000)). ann = sc.AnnData(np.log(X+1)). gsize = X.shape [0] / 2. ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). ```. ```pytb. ... storing 'group' as categorical. C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars. (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-bccdb587a644> in <module>. 5 gsize = X.shape [0] / 2. 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). 8. 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). --> 372. 373 scores[np.isnan(scores)] = 0. 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. After the fix, the same code no longer raises an error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:778,usability,input,input-,778,"Fix rank_genes_groups overflow in Windows; Reorder operations to avoid overflows. Behavior Fixed:. ```py. import scanpy as sc. import numpy as np. X = np.random.randint(0,1000, size= (3000,2000)). ann = sc.AnnData(np.log(X+1)). gsize = X.shape [0] / 2. ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). ```. ```pytb. ... storing 'group' as categorical. C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars. (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-bccdb587a644> in <module>. 5 gsize = X.shape [0] / 2. 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). 8. 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). --> 372. 373 scores[np.isnan(scores)] = 0. 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. After the fix, the same code no longer raises an error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:1040,usability,tool,tools,1040,"Fix rank_genes_groups overflow in Windows; Reorder operations to avoid overflows. Behavior Fixed:. ```py. import scanpy as sc. import numpy as np. X = np.random.randint(0,1000, size= (3000,2000)). ann = sc.AnnData(np.log(X+1)). gsize = X.shape [0] / 2. ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). ```. ```pytb. ... storing 'group' as categorical. C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars. (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-bccdb587a644> in <module>. 5 gsize = X.shape [0] / 2. 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). 8. 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). --> 372. 373 scores[np.isnan(scores)] = 0. 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. After the fix, the same code no longer raises an error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:1486,usability,error,error,1486,"Fix rank_genes_groups overflow in Windows; Reorder operations to avoid overflows. Behavior Fixed:. ```py. import scanpy as sc. import numpy as np. X = np.random.randint(0,1000, size= (3000,2000)). ann = sc.AnnData(np.log(X+1)). gsize = X.shape [0] / 2. ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). ```. ```pytb. ... storing 'group' as categorical. C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars. (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-bccdb587a644> in <module>. 5 gsize = X.shape [0] / 2. 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). 8. 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). --> 372. 373 scores[np.isnan(scores)] = 0. 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. After the fix, the same code no longer raises an error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1062:1547,usability,error,error,1547,"Fix rank_genes_groups overflow in Windows; Reorder operations to avoid overflows. Behavior Fixed:. ```py. import scanpy as sc. import numpy as np. X = np.random.randint(0,1000, size= (3000,2000)). ann = sc.AnnData(np.log(X+1)). gsize = X.shape [0] / 2. ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). ```. ```pytb. ... storing 'group' as categorical. C:\Users\patou\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py:372: RuntimeWarning: overflow encountered in long_scalars. (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-7-bccdb587a644> in <module>. 5 gsize = X.shape [0] / 2. 6 ann.obs['group'] = ['a']* int (gsize) + ['b']*int (gsize). ----> 7 sc.tl.rank_genes_groups(ann, 'group', method = 'wilcoxon', n_genes=2000). 8. 9. ~\Anaconda-p3.7\envs\py36\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, **kwds). 370 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. 371 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). --> 372. 373 scores[np.isnan(scores)] = 0. 374 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. After the fix, the same code no longer raises an error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1062
https://github.com/scverse/scanpy/pull/1063:9,deployability,integr,integration,9,Wishbone integration; Wishbone is an algorithm for positioning single cells along bifurcating . developmental trajectories with high resolution.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1063
https://github.com/scverse/scanpy/pull/1063:9,integrability,integr,integration,9,Wishbone integration; Wishbone is an algorithm for positioning single cells along bifurcating . developmental trajectories with high resolution.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1063
https://github.com/scverse/scanpy/pull/1063:9,interoperability,integr,integration,9,Wishbone integration; Wishbone is an algorithm for positioning single cells along bifurcating . developmental trajectories with high resolution.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1063
https://github.com/scverse/scanpy/pull/1063:9,modifiability,integr,integration,9,Wishbone integration; Wishbone is an algorithm for positioning single cells along bifurcating . developmental trajectories with high resolution.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1063
https://github.com/scverse/scanpy/pull/1063:9,reliability,integr,integration,9,Wishbone integration; Wishbone is an algorithm for positioning single cells along bifurcating . developmental trajectories with high resolution.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1063
https://github.com/scverse/scanpy/pull/1063:9,security,integr,integration,9,Wishbone integration; Wishbone is an algorithm for positioning single cells along bifurcating . developmental trajectories with high resolution.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1063
https://github.com/scverse/scanpy/pull/1063:9,testability,integr,integration,9,Wishbone integration; Wishbone is an algorithm for positioning single cells along bifurcating . developmental trajectories with high resolution.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1063
https://github.com/scverse/scanpy/pull/1064:43,security,access,accessible,43,"Make inner keyword argument of violin plot accessible from outside; I noticed that there is no way to plot the ""box"" inside the violins using inner='box' option. This is the main idea of this PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1064
https://github.com/scverse/scanpy/pull/1066:902,availability,slo,slower,902,"PCA for sparse data (v2); I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:171,deployability,integr,integrate,171,"PCA for sparse data (v2); I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:1277,deployability,integr,integrate,1277,"PCA for sparse data (v2); I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:171,integrability,integr,integrate,171,"PCA for sparse data (v2); I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:1277,integrability,integr,integrate,1277,"PCA for sparse data (v2); I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:171,interoperability,integr,integrate,171,"PCA for sparse data (v2); I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:1277,interoperability,integr,integrate,1277,"PCA for sparse data (v2); I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:171,modifiability,integr,integrate,171,"PCA for sparse data (v2); I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:1277,modifiability,integr,integrate,1277,"PCA for sparse data (v2); I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:537,performance,perform,performs,537,"PCA for sparse data (v2); I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:589,performance,perform,performing,589,"PCA for sparse data (v2); I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:171,reliability,integr,integrate,171,"PCA for sparse data (v2); I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:636,reliability,doe,does,636,"PCA for sparse data (v2); I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:902,reliability,slo,slower,902,"PCA for sparse data (v2); I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:1277,reliability,integr,integrate,1277,"PCA for sparse data (v2); I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:477,safety,input,input,477,"PCA for sparse data (v2); I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:171,security,integr,integrate,171,"PCA for sparse data (v2); I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:888,security,sign,significantly,888,"PCA for sparse data (v2); I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:1277,security,integr,integrate,1277,"PCA for sparse data (v2); I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:171,testability,integr,integrate,171,"PCA for sparse data (v2); I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:1277,testability,integr,integrate,1277,"PCA for sparse data (v2); I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:114,usability,statu,status,114,"PCA for sparse data (v2); I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:434,usability,custom,customize,434,"PCA for sparse data (v2); I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:477,usability,input,input,477,"PCA for sparse data (v2); I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:517,usability,custom,custom,517,"PCA for sparse data (v2); I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:537,usability,perform,performs,537,"PCA for sparse data (v2); I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/pull/1066:589,usability,perform,performing,589,"PCA for sparse data (v2); I know this (quite ancient) pull request has been open (#403), but I wasn't sure on its status. I think the consensus was to wait for sklearn to integrate the necessary changes? If that's still the case, then please feel free to remove this PR. Here I make use of scipy's extremely nifty [LinearOperator](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.LinearOperator.html) class to customize the dot product functions for an input sparse matrix. In this case, the 'custom' dot product performs implicit mean centering. In my benchmarks, performing implicit mean centering in this way does not affect the runtime whatsoever. However, this approach has to use [svds](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.svds.html), for which randomized SVD is not implemented. So we have to use 'arpack', which can be significantly slower (but not intractably so.... in my hands, I could still do PCA on datasets of 200k+ cells in minutes, and it sure beats densifying the data, if you want more thorough benchmarks I am happy to generate them!). The way I incorporated this functionality into scanpy/preprocessing/_simple.py might be questionable, and would love any suggestions or advice on how to better integrate this if there is interest in pushing this PR through. Let me know!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1066
https://github.com/scverse/scanpy/issues/1067:1522,availability,error,errors,1522," in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in _type_check(arg, msg). 372 not isinstance(arg, (type, _TypingBase)) and not callable(arg). 373 ):. --> 374 raise TypeError(msg + "" Got %.100r."" % (arg,)). 375 # Bare Union etc. are not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:2682,availability,down,downgrading,2682,"ate, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in _type_check(arg, msg). 372 not isinstance(arg, (type, _TypingBase)) and not callable(arg). 373 ):. --> 374 raise TypeError(msg + "" Got %.100r."" % (arg,)). 375 # Bare Union etc. are not valid as type arguments. 376 if (. TypeError: Callable[[arg, ...], result]: each arg must be a type. Got Ellipsis. ```. Is there any way to fix this, beside downgrading to the older version?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:24,deployability,updat,updating,24,"Problem with tSNE after updating scanpy; Hi all,. I recently installed the newest version of scanpy:. ```. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1. ```. And after this, I could no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb. TypeError Traceback (most recent call last). <ipython-input-54-e62d5f8d460c> in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:61,deployability,instal,installed,61,"Problem with tSNE after updating scanpy; Hi all,. I recently installed the newest version of scanpy:. ```. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1. ```. And after this, I could no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb. TypeError Traceback (most recent call last). <ipython-input-54-e62d5f8d460c> in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:82,deployability,version,version,82,"Problem with tSNE after updating scanpy; Hi all,. I recently installed the newest version of scanpy:. ```. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1. ```. And after this, I could no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb. TypeError Traceback (most recent call last). <ipython-input-54-e62d5f8d460c> in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:530,deployability,modul,module,530,"Problem with tSNE after updating scanpy; Hi all,. I recently installed the newest version of scanpy:. ```. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1. ```. And after this, I could no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb. TypeError Traceback (most recent call last). <ipython-input-54-e62d5f8d460c> in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:1031,deployability,modul,module,1031,"canpy; Hi all,. I recently installed the newest version of scanpy:. ```. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1. ```. And after this, I could no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb. TypeError Traceback (most recent call last). <ipython-input-54-e62d5f8d460c> in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0). 1348",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:2707,deployability,version,version,2707,"ate, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in _type_check(arg, msg). 372 not isinstance(arg, (type, _TypingBase)) and not callable(arg). 373 ):. --> 374 raise TypeError(msg + "" Got %.100r."" % (arg,)). 375 # Bare Union etc. are not valid as type arguments. 376 if (. TypeError: Callable[[arg, ...], result]: each arg must be a type. Got Ellipsis. ```. Is there any way to fix this, beside downgrading to the older version?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:82,integrability,version,version,82,"Problem with tSNE after updating scanpy; Hi all,. I recently installed the newest version of scanpy:. ```. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1. ```. And after this, I could no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb. TypeError Traceback (most recent call last). <ipython-input-54-e62d5f8d460c> in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:2707,integrability,version,version,2707,"ate, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in _type_check(arg, msg). 372 not isinstance(arg, (type, _TypingBase)) and not callable(arg). 373 ):. --> 374 raise TypeError(msg + "" Got %.100r."" % (arg,)). 375 # Bare Union etc. are not valid as type arguments. 376 if (. TypeError: Callable[[arg, ...], result]: each arg must be a type. Got Ellipsis. ```. Is there any way to fix this, beside downgrading to the older version?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:82,modifiability,version,version,82,"Problem with tSNE after updating scanpy; Hi all,. I recently installed the newest version of scanpy:. ```. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1. ```. And after this, I could no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb. TypeError Traceback (most recent call last). <ipython-input-54-e62d5f8d460c> in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:530,modifiability,modul,module,530,"Problem with tSNE after updating scanpy; Hi all,. I recently installed the newest version of scanpy:. ```. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1. ```. And after this, I could no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb. TypeError Traceback (most recent call last). <ipython-input-54-e62d5f8d460c> in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:597,modifiability,pac,packages,597,"Problem with tSNE after updating scanpy; Hi all,. I recently installed the newest version of scanpy:. ```. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1. ```. And after this, I could no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb. TypeError Traceback (most recent call last). <ipython-input-54-e62d5f8d460c> in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:992,modifiability,pac,packages,992,"Problem with tSNE after updating scanpy; Hi all,. I recently installed the newest version of scanpy:. ```. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1. ```. And after this, I could no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb. TypeError Traceback (most recent call last). <ipython-input-54-e62d5f8d460c> in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:1031,modifiability,modul,module,1031,"canpy; Hi all,. I recently installed the newest version of scanpy:. ```. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1. ```. And after this, I could no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb. TypeError Traceback (most recent call last). <ipython-input-54-e62d5f8d460c> in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0). 1348",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:1257,modifiability,paramet,parameters,1257,"d07760 louvain==0.6.1. ```. And after this, I could no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb. TypeError Traceback (most recent call last). <ipython-input-54-e62d5f8d460c> in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:1307,modifiability,paramet,parameters,1307,"d no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb. TypeError Traceback (most recent call last). <ipython-input-54-e62d5f8d460c> in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:1381,modifiability,paramet,parameters,1381,"). I have not changed anything in my data or my code. ```pytb. TypeError Traceback (most recent call last). <ipython-input-54-e62d5f8d460c> in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in _type_check(arg, msg). 372 not isinstance(arg,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:1692,modifiability,paramet,parameters,1692,"ng_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in _type_check(arg, msg). 372 not isinstance(arg, (type, _TypingBase)) and not callable(arg). 373 ):. --> 374 raise TypeError(msg + "" Got %.100r."" % (arg,)). 375 # Bare Union etc. are not valid as type arguments. 376 if (. TypeError: Callable[[arg, ...], result]: each arg must be a type. Got Ellipsis. ```. Is there any way to fix this, beside downgrading to ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:1900,modifiability,paramet,parameters,1900,"ate, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in _type_check(arg, msg). 372 not isinstance(arg, (type, _TypingBase)) and not callable(arg). 373 ):. --> 374 raise TypeError(msg + "" Got %.100r."" % (arg,)). 375 # Bare Union etc. are not valid as type arguments. 376 if (. TypeError: Callable[[arg, ...], result]: each arg must be a type. Got Ellipsis. ```. Is there any way to fix this, beside downgrading to the older version?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:1963,modifiability,paramet,parameters,1963,"ate, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in _type_check(arg, msg). 372 not isinstance(arg, (type, _TypingBase)) and not callable(arg). 373 ):. --> 374 raise TypeError(msg + "" Got %.100r."" % (arg,)). 375 # Bare Union etc. are not valid as type arguments. 376 if (. TypeError: Callable[[arg, ...], result]: each arg must be a type. Got Ellipsis. ```. Is there any way to fix this, beside downgrading to the older version?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:2225,modifiability,paramet,parameters,2225,"ate, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in _type_check(arg, msg). 372 not isinstance(arg, (type, _TypingBase)) and not callable(arg). 373 ):. --> 374 raise TypeError(msg + "" Got %.100r."" % (arg,)). 375 # Bare Union etc. are not valid as type arguments. 376 if (. TypeError: Callable[[arg, ...], result]: each arg must be a type. Got Ellipsis. ```. Is there any way to fix this, beside downgrading to the older version?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:2288,modifiability,paramet,parameters,2288,"ate, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in _type_check(arg, msg). 372 not isinstance(arg, (type, _TypingBase)) and not callable(arg). 373 ):. --> 374 raise TypeError(msg + "" Got %.100r."" % (arg,)). 375 # Bare Union etc. are not valid as type arguments. 376 if (. TypeError: Callable[[arg, ...], result]: each arg must be a type. Got Ellipsis. ```. Is there any way to fix this, beside downgrading to the older version?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:2707,modifiability,version,version,2707,"ate, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in _type_check(arg, msg). 372 not isinstance(arg, (type, _TypingBase)) and not callable(arg). 373 ):. --> 374 raise TypeError(msg + "" Got %.100r."" % (arg,)). 375 # Bare Union etc. are not valid as type arguments. 376 if (. TypeError: Callable[[arg, ...], result]: each arg must be a type. Got Ellipsis. ```. Is there any way to fix this, beside downgrading to the older version?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:1522,performance,error,errors,1522," in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in _type_check(arg, msg). 372 not isinstance(arg, (type, _TypingBase)) and not callable(arg). 373 ):. --> 374 raise TypeError(msg + "" Got %.100r."" % (arg,)). 375 # Bare Union etc. are not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:921,reliability,doe,does,921,"Problem with tSNE after updating scanpy; Hi all,. I recently installed the newest version of scanpy:. ```. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1. ```. And after this, I could no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb. TypeError Traceback (most recent call last). <ipython-input-54-e62d5f8d460c> in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:24,safety,updat,updating,24,"Problem with tSNE after updating scanpy; Hi all,. I recently installed the newest version of scanpy:. ```. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1. ```. And after this, I could no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb. TypeError Traceback (most recent call last). <ipython-input-54-e62d5f8d460c> in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:503,safety,input,input-,503,"Problem with tSNE after updating scanpy; Hi all,. I recently installed the newest version of scanpy:. ```. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1. ```. And after this, I could no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb. TypeError Traceback (most recent call last). <ipython-input-54-e62d5f8d460c> in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:530,safety,modul,module,530,"Problem with tSNE after updating scanpy; Hi all,. I recently installed the newest version of scanpy:. ```. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1. ```. And after this, I could no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb. TypeError Traceback (most recent call last). <ipython-input-54-e62d5f8d460c> in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:1031,safety,modul,module,1031,"canpy; Hi all,. I recently installed the newest version of scanpy:. ```. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1. ```. And after this, I could no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb. TypeError Traceback (most recent call last). <ipython-input-54-e62d5f8d460c> in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0). 1348",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:1483,safety,except,except,1483," last). <ipython-input-54-e62d5f8d460c> in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in _type_check(arg, msg). 372 not isinstance(arg, (type, _TypingBase)) and not callable(arg). 373 ):. --> 374 raise TypeError(msg + "" Got %.100r."" % ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:1522,safety,error,errors,1522," in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in _type_check(arg, msg). 372 not isinstance(arg, (type, _TypingBase)) and not callable(arg). 373 ):. --> 374 raise TypeError(msg + "" Got %.100r."" % (arg,)). 375 # Bare Union etc. are not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:2525,safety,valid,valid,2525,"ate, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in _type_check(arg, msg). 372 not isinstance(arg, (type, _TypingBase)) and not callable(arg). 373 ):. --> 374 raise TypeError(msg + "" Got %.100r."" % (arg,)). 375 # Bare Union etc. are not valid as type arguments. 376 if (. TypeError: Callable[[arg, ...], result]: each arg must be a type. Got Ellipsis. ```. Is there any way to fix this, beside downgrading to the older version?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:24,security,updat,updating,24,"Problem with tSNE after updating scanpy; Hi all,. I recently installed the newest version of scanpy:. ```. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1. ```. And after this, I could no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb. TypeError Traceback (most recent call last). <ipython-input-54-e62d5f8d460c> in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:459,testability,Trace,Traceback,459,"Problem with tSNE after updating scanpy; Hi all,. I recently installed the newest version of scanpy:. ```. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1. ```. And after this, I could no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb. TypeError Traceback (most recent call last). <ipython-input-54-e62d5f8d460c> in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:203,usability,learn,learn,203,"Problem with tSNE after updating scanpy; Hi all,. I recently installed the newest version of scanpy:. ```. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1. ```. And after this, I could no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb. TypeError Traceback (most recent call last). <ipython-input-54-e62d5f8d460c> in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:503,usability,input,input-,503,"Problem with tSNE after updating scanpy; Hi all,. I recently installed the newest version of scanpy:. ```. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1. ```. And after this, I could no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb. TypeError Traceback (most recent call last). <ipython-input-54-e62d5f8d460c> in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:613,usability,tool,tools,613,"Problem with tSNE after updating scanpy; Hi all,. I recently installed the newest version of scanpy:. ```. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1. ```. And after this, I could no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb. TypeError Traceback (most recent call last). <ipython-input-54-e62d5f8d460c> in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:945,usability,minim,minimum,945,"Problem with tSNE after updating scanpy; Hi all,. I recently installed the newest version of scanpy:. ```. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1. ```. And after this, I could no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb. TypeError Traceback (most recent call last). <ipython-input-54-e62d5f8d460c> in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\li",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:1008,usability,tool,tools,1008,"h tSNE after updating scanpy; Hi all,. I recently installed the newest version of scanpy:. ```. scanpy==1.4.5.post1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0 python-igraph==0.7.1+4.bed07760 louvain==0.6.1. ```. And after this, I could no longer run a tSNE, while this worked fine before (scanpy==1.4.4.post1). I have not changed anything in my data or my code. ```pytb. TypeError Traceback (most recent call last). <ipython-input-54-e62d5f8d460c> in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1067:1522,usability,error,errors,1522," in <module>. ----> 1 sc.tl.tsne(adata). ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne.py in tsne(adata, n_pcs, use_rep, perplexity, early_exaggeration, learning_rate, random_state, use_fast_tsne, n_jobs, copy). 108 if X_tsne is None:. 109 from sklearn.manifold import TSNE. --> 110 from . import _tsne_fix # fix by D. DeTomaso for sklearn < 0.19. 111 . 112 # unfortunately, sklearn does not allow to set a minimum number. ~\Anaconda3\envs\UMCU\lib\site-packages\scanpy\tools\_tsne_fix.py in <module>. 32 verbose: int = 0,. 33 args: Iterable[Any] = (),. ---> 34 kwargs: Mapping[str, Any] = MappingProxyType({}),. 35 ) -> Tuple[np.ndarray, float, int]:. 36 """"""\. ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem__(self, parameters). 1338 "" Got %.100r."" % (args,)). 1339 parameters = (tuple(args), result). -> 1340 return self.__getitem_inner__(parameters). 1341 . 1342 @_tp_cache. ~\Anaconda3\envs\UMCU\lib\typing.py in inner(*args, **kwds). 680 except TypeError:. 681 pass # All real errors (not unhashable args) are raised below. --> 682 return func(*args, **kwds). 683 return inner. 684 . ~\Anaconda3\envs\UMCU\lib\typing.py in __getitem_inner__(self, parameters). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in <genexpr>(.0). 1348 return super().__getitem__((_TypingEllipsis, result)). 1349 msg = ""Callable[[arg, ...], result]: each arg must be a type."". -> 1350 args = tuple(_type_check(arg, msg) for arg in args). 1351 parameters = args + (result,). 1352 return super().__getitem__(parameters). ~\Anaconda3\envs\UMCU\lib\typing.py in _type_check(arg, msg). 372 not isinstance(arg, (type, _TypingBase)) and not callable(arg). 373 ):. --> 374 raise TypeError(msg + "" Got %.100r."" % (arg,)). 375 # Bare Union etc. are not ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1067
https://github.com/scverse/scanpy/issues/1068:15,availability,avail,available,15,"Is sctransform available ?; Hi, I would like to use sctransform, but I didn't find it in Python: https://github.com/ChristophH/sctransform",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068
https://github.com/scverse/scanpy/issues/1068:15,reliability,availab,available,15,"Is sctransform available ?; Hi, I would like to use sctransform, but I didn't find it in Python: https://github.com/ChristophH/sctransform",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068
https://github.com/scverse/scanpy/issues/1068:15,safety,avail,available,15,"Is sctransform available ?; Hi, I would like to use sctransform, but I didn't find it in Python: https://github.com/ChristophH/sctransform",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068
https://github.com/scverse/scanpy/issues/1068:15,security,availab,available,15,"Is sctransform available ?; Hi, I would like to use sctransform, but I didn't find it in Python: https://github.com/ChristophH/sctransform",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1068
https://github.com/scverse/scanpy/pull/1069:320,safety,test,test,320,"Changing scanpy.pl.dotplot to return the matplotlib figure instead of GridSpec; Fixes issue #979 . Note that if you wish to modify the figure in the same jupyter notebook cell in which the plotting function is called, you should set `show=False`:. ```. fig,ax = sc.pl.dotplot(adata,var_names,show=False). ax.set_xlabel('test'). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1069
https://github.com/scverse/scanpy/pull/1069:124,security,modif,modify,124,"Changing scanpy.pl.dotplot to return the matplotlib figure instead of GridSpec; Fixes issue #979 . Note that if you wish to modify the figure in the same jupyter notebook cell in which the plotting function is called, you should set `show=False`:. ```. fig,ax = sc.pl.dotplot(adata,var_names,show=False). ax.set_xlabel('test'). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1069
https://github.com/scverse/scanpy/pull/1069:320,testability,test,test,320,"Changing scanpy.pl.dotplot to return the matplotlib figure instead of GridSpec; Fixes issue #979 . Note that if you wish to modify the figure in the same jupyter notebook cell in which the plotting function is called, you should set `show=False`:. ```. fig,ax = sc.pl.dotplot(adata,var_names,show=False). ax.set_xlabel('test'). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1069
https://github.com/scverse/scanpy/pull/1070:28,deployability,fail,failing,28,Fixes highly_variable_genes failing with `batch_key` and `inplace=False`; Fixes issue #1033,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1070
https://github.com/scverse/scanpy/pull/1070:28,reliability,fail,failing,28,Fixes highly_variable_genes failing with `batch_key` and `inplace=False`; Fixes issue #1033,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1070
https://github.com/scverse/scanpy/issues/1072:193,deployability,integr,integration,193,"link to scVI in documentation; Hi, . This is a minor point. Thanks for linking to the scVI repo in your ecosystem page. However, would it be possible to put scVI in another category than ""data integration"" ? Since scVI can also do differential expression for example. . Thanks, . Romain. <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1072
https://github.com/scverse/scanpy/issues/1072:193,integrability,integr,integration,193,"link to scVI in documentation; Hi, . This is a minor point. Thanks for linking to the scVI repo in your ecosystem page. However, would it be possible to put scVI in another category than ""data integration"" ? Since scVI can also do differential expression for example. . Thanks, . Romain. <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1072
https://github.com/scverse/scanpy/issues/1072:193,interoperability,integr,integration,193,"link to scVI in documentation; Hi, . This is a minor point. Thanks for linking to the scVI repo in your ecosystem page. However, would it be possible to put scVI in another category than ""data integration"" ? Since scVI can also do differential expression for example. . Thanks, . Romain. <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1072
https://github.com/scverse/scanpy/issues/1072:193,modifiability,integr,integration,193,"link to scVI in documentation; Hi, . This is a minor point. Thanks for linking to the scVI repo in your ecosystem page. However, would it be possible to put scVI in another category than ""data integration"" ? Since scVI can also do differential expression for example. . Thanks, . Romain. <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1072
https://github.com/scverse/scanpy/issues/1072:410,modifiability,design decis,design decisions,410,"link to scVI in documentation; Hi, . This is a minor point. Thanks for linking to the scVI repo in your ecosystem page. However, would it be possible to put scVI in another category than ""data integration"" ? Since scVI can also do differential expression for example. . Thanks, . Romain. <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1072
https://github.com/scverse/scanpy/issues/1072:193,reliability,integr,integration,193,"link to scVI in documentation; Hi, . This is a minor point. Thanks for linking to the scVI repo in your ecosystem page. However, would it be possible to put scVI in another category than ""data integration"" ? Since scVI can also do differential expression for example. . Thanks, . Romain. <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1072
https://github.com/scverse/scanpy/issues/1072:193,security,integr,integration,193,"link to scVI in documentation; Hi, . This is a minor point. Thanks for linking to the scVI repo in your ecosystem page. However, would it be possible to put scVI in another category than ""data integration"" ? Since scVI can also do differential expression for example. . Thanks, . Romain. <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1072
https://github.com/scverse/scanpy/issues/1072:193,testability,integr,integration,193,"link to scVI in documentation; Hi, . This is a minor point. Thanks for linking to the scVI repo in your ecosystem page. However, would it be possible to put scVI in another category than ""data integration"" ? Since scVI can also do differential expression for example. . Thanks, . Romain. <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1072
https://github.com/scverse/scanpy/issues/1072:16,usability,document,documentation,16,"link to scVI in documentation; Hi, . This is a minor point. Thanks for linking to the scVI repo in your ecosystem page. However, would it be possible to put scVI in another category than ""data integration"" ? Since scVI can also do differential expression for example. . Thanks, . Romain. <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1072
https://github.com/scverse/scanpy/issues/1072:308,usability,help,help,308,"link to scVI in documentation; Hi, . This is a minor point. Thanks for linking to the scVI repo in your ecosystem page. However, would it be possible to put scVI in another category than ""data integration"" ? Since scVI can also do differential expression for example. . Thanks, . Romain. <!--. ⚠ If you need help using Scanpy, please ask in https://scanpy.discourse.group/ instead ⚠. If you want to know about design decisions and the like, please ask below:. -->. ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1072
https://github.com/scverse/scanpy/pull/1073:105,availability,sli,slides,105,"multi-tissue functionality; This is an implementation for the support of anndatas with multiple tissues (slides). It depends on the anndata PR theislab/anndata#329. I made a short notebook to explain how it should work https://github.com/giovp/spatial-scripts/blob/master/multiple_slices_functionality.ipynb. There is a lot of room for improvement in terms of code, but in terms of functionality it should cover most of the use cases",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1073
https://github.com/scverse/scanpy/pull/1073:117,deployability,depend,depends,117,"multi-tissue functionality; This is an implementation for the support of anndatas with multiple tissues (slides). It depends on the anndata PR theislab/anndata#329. I made a short notebook to explain how it should work https://github.com/giovp/spatial-scripts/blob/master/multiple_slices_functionality.ipynb. There is a lot of room for improvement in terms of code, but in terms of functionality it should cover most of the use cases",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1073
https://github.com/scverse/scanpy/pull/1073:117,integrability,depend,depends,117,"multi-tissue functionality; This is an implementation for the support of anndatas with multiple tissues (slides). It depends on the anndata PR theislab/anndata#329. I made a short notebook to explain how it should work https://github.com/giovp/spatial-scripts/blob/master/multiple_slices_functionality.ipynb. There is a lot of room for improvement in terms of code, but in terms of functionality it should cover most of the use cases",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1073
https://github.com/scverse/scanpy/pull/1073:117,modifiability,depend,depends,117,"multi-tissue functionality; This is an implementation for the support of anndatas with multiple tissues (slides). It depends on the anndata PR theislab/anndata#329. I made a short notebook to explain how it should work https://github.com/giovp/spatial-scripts/blob/master/multiple_slices_functionality.ipynb. There is a lot of room for improvement in terms of code, but in terms of functionality it should cover most of the use cases",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1073
https://github.com/scverse/scanpy/pull/1073:105,reliability,sli,slides,105,"multi-tissue functionality; This is an implementation for the support of anndatas with multiple tissues (slides). It depends on the anndata PR theislab/anndata#329. I made a short notebook to explain how it should work https://github.com/giovp/spatial-scripts/blob/master/multiple_slices_functionality.ipynb. There is a lot of room for improvement in terms of code, but in terms of functionality it should cover most of the use cases",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1073
https://github.com/scverse/scanpy/pull/1073:117,safety,depend,depends,117,"multi-tissue functionality; This is an implementation for the support of anndatas with multiple tissues (slides). It depends on the anndata PR theislab/anndata#329. I made a short notebook to explain how it should work https://github.com/giovp/spatial-scripts/blob/master/multiple_slices_functionality.ipynb. There is a lot of room for improvement in terms of code, but in terms of functionality it should cover most of the use cases",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1073
https://github.com/scverse/scanpy/pull/1073:117,testability,depend,depends,117,"multi-tissue functionality; This is an implementation for the support of anndatas with multiple tissues (slides). It depends on the anndata PR theislab/anndata#329. I made a short notebook to explain how it should work https://github.com/giovp/spatial-scripts/blob/master/multiple_slices_functionality.ipynb. There is a lot of room for improvement in terms of code, but in terms of functionality it should cover most of the use cases",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1073
https://github.com/scverse/scanpy/pull/1073:62,usability,support,support,62,"multi-tissue functionality; This is an implementation for the support of anndatas with multiple tissues (slides). It depends on the anndata PR theislab/anndata#329. I made a short notebook to explain how it should work https://github.com/giovp/spatial-scripts/blob/master/multiple_slices_functionality.ipynb. There is a lot of room for improvement in terms of code, but in terms of functionality it should cover most of the use cases",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1073
https://github.com/scverse/scanpy/issues/1074:703,deployability,Version,Versions,703,"Read loom file warning; <!-- Please give a clear and concise description of what the bug is: -->. Hi,. I am new to python and have no idea what this could imply but thought I could report it. I am reading a file convert from `seurat` using `as.loom`. This file works fine if I open it in `scvelo` using `scv.read`, however, when starting from scanpy using. ```. adata = sc.read_loom(""seu.loom""). ```. I get the following:. ```. /Users/rmvl/miniconda3/envs/scanpy_env/lib/python3.7/site-packages/loompy/loom_layer.py:123: RuntimeWarning: invalid value encountered in not_equal. nonzeros = np.where(vals != 0). ```. I have tried closing all kernels, reinstalling loompy, scanpy, but nothing changed. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1074
https://github.com/scverse/scanpy/issues/1074:736,deployability,log,logging,736,"Read loom file warning; <!-- Please give a clear and concise description of what the bug is: -->. Hi,. I am new to python and have no idea what this could imply but thought I could report it. I am reading a file convert from `seurat` using `as.loom`. This file works fine if I open it in `scvelo` using `scv.read`, however, when starting from scanpy using. ```. adata = sc.read_loom(""seu.loom""). ```. I get the following:. ```. /Users/rmvl/miniconda3/envs/scanpy_env/lib/python3.7/site-packages/loompy/loom_layer.py:123: RuntimeWarning: invalid value encountered in not_equal. nonzeros = np.where(vals != 0). ```. I have tried closing all kernels, reinstalling loompy, scanpy, but nothing changed. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1074
https://github.com/scverse/scanpy/issues/1074:703,integrability,Version,Versions,703,"Read loom file warning; <!-- Please give a clear and concise description of what the bug is: -->. Hi,. I am new to python and have no idea what this could imply but thought I could report it. I am reading a file convert from `seurat` using `as.loom`. This file works fine if I open it in `scvelo` using `scv.read`, however, when starting from scanpy using. ```. adata = sc.read_loom(""seu.loom""). ```. I get the following:. ```. /Users/rmvl/miniconda3/envs/scanpy_env/lib/python3.7/site-packages/loompy/loom_layer.py:123: RuntimeWarning: invalid value encountered in not_equal. nonzeros = np.where(vals != 0). ```. I have tried closing all kernels, reinstalling loompy, scanpy, but nothing changed. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1074
https://github.com/scverse/scanpy/issues/1074:486,modifiability,pac,packages,486,"Read loom file warning; <!-- Please give a clear and concise description of what the bug is: -->. Hi,. I am new to python and have no idea what this could imply but thought I could report it. I am reading a file convert from `seurat` using `as.loom`. This file works fine if I open it in `scvelo` using `scv.read`, however, when starting from scanpy using. ```. adata = sc.read_loom(""seu.loom""). ```. I get the following:. ```. /Users/rmvl/miniconda3/envs/scanpy_env/lib/python3.7/site-packages/loompy/loom_layer.py:123: RuntimeWarning: invalid value encountered in not_equal. nonzeros = np.where(vals != 0). ```. I have tried closing all kernels, reinstalling loompy, scanpy, but nothing changed. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1074
https://github.com/scverse/scanpy/issues/1074:703,modifiability,Version,Versions,703,"Read loom file warning; <!-- Please give a clear and concise description of what the bug is: -->. Hi,. I am new to python and have no idea what this could imply but thought I could report it. I am reading a file convert from `seurat` using `as.loom`. This file works fine if I open it in `scvelo` using `scv.read`, however, when starting from scanpy using. ```. adata = sc.read_loom(""seu.loom""). ```. I get the following:. ```. /Users/rmvl/miniconda3/envs/scanpy_env/lib/python3.7/site-packages/loompy/loom_layer.py:123: RuntimeWarning: invalid value encountered in not_equal. nonzeros = np.where(vals != 0). ```. I have tried closing all kernels, reinstalling loompy, scanpy, but nothing changed. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1074
https://github.com/scverse/scanpy/issues/1074:736,safety,log,logging,736,"Read loom file warning; <!-- Please give a clear and concise description of what the bug is: -->. Hi,. I am new to python and have no idea what this could imply but thought I could report it. I am reading a file convert from `seurat` using `as.loom`. This file works fine if I open it in `scvelo` using `scv.read`, however, when starting from scanpy using. ```. adata = sc.read_loom(""seu.loom""). ```. I get the following:. ```. /Users/rmvl/miniconda3/envs/scanpy_env/lib/python3.7/site-packages/loompy/loom_layer.py:123: RuntimeWarning: invalid value encountered in not_equal. nonzeros = np.where(vals != 0). ```. I have tried closing all kernels, reinstalling loompy, scanpy, but nothing changed. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1074
https://github.com/scverse/scanpy/issues/1074:736,security,log,logging,736,"Read loom file warning; <!-- Please give a clear and concise description of what the bug is: -->. Hi,. I am new to python and have no idea what this could imply but thought I could report it. I am reading a file convert from `seurat` using `as.loom`. This file works fine if I open it in `scvelo` using `scv.read`, however, when starting from scanpy using. ```. adata = sc.read_loom(""seu.loom""). ```. I get the following:. ```. /Users/rmvl/miniconda3/envs/scanpy_env/lib/python3.7/site-packages/loompy/loom_layer.py:123: RuntimeWarning: invalid value encountered in not_equal. nonzeros = np.where(vals != 0). ```. I have tried closing all kernels, reinstalling loompy, scanpy, but nothing changed. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1074
https://github.com/scverse/scanpy/issues/1074:736,testability,log,logging,736,"Read loom file warning; <!-- Please give a clear and concise description of what the bug is: -->. Hi,. I am new to python and have no idea what this could imply but thought I could report it. I am reading a file convert from `seurat` using `as.loom`. This file works fine if I open it in `scvelo` using `scv.read`, however, when starting from scanpy using. ```. adata = sc.read_loom(""seu.loom""). ```. I get the following:. ```. /Users/rmvl/miniconda3/envs/scanpy_env/lib/python3.7/site-packages/loompy/loom_layer.py:123: RuntimeWarning: invalid value encountered in not_equal. nonzeros = np.where(vals != 0). ```. I have tried closing all kernels, reinstalling loompy, scanpy, but nothing changed. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1074
https://github.com/scverse/scanpy/issues/1074:43,usability,clear,clear,43,"Read loom file warning; <!-- Please give a clear and concise description of what the bug is: -->. Hi,. I am new to python and have no idea what this could imply but thought I could report it. I am reading a file convert from `seurat` using `as.loom`. This file works fine if I open it in `scvelo` using `scv.read`, however, when starting from scanpy using. ```. adata = sc.read_loom(""seu.loom""). ```. I get the following:. ```. /Users/rmvl/miniconda3/envs/scanpy_env/lib/python3.7/site-packages/loompy/loom_layer.py:123: RuntimeWarning: invalid value encountered in not_equal. nonzeros = np.where(vals != 0). ```. I have tried closing all kernels, reinstalling loompy, scanpy, but nothing changed. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1074
https://github.com/scverse/scanpy/issues/1074:429,usability,User,Users,429,"Read loom file warning; <!-- Please give a clear and concise description of what the bug is: -->. Hi,. I am new to python and have no idea what this could imply but thought I could report it. I am reading a file convert from `seurat` using `as.loom`. This file works fine if I open it in `scvelo` using `scv.read`, however, when starting from scanpy using. ```. adata = sc.read_loom(""seu.loom""). ```. I get the following:. ```. /Users/rmvl/miniconda3/envs/scanpy_env/lib/python3.7/site-packages/loompy/loom_layer.py:123: RuntimeWarning: invalid value encountered in not_equal. nonzeros = np.where(vals != 0). ```. I have tried closing all kernels, reinstalling loompy, scanpy, but nothing changed. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1074
https://github.com/scverse/scanpy/issues/1074:871,usability,learn,learn,871,"Read loom file warning; <!-- Please give a clear and concise description of what the bug is: -->. Hi,. I am new to python and have no idea what this could imply but thought I could report it. I am reading a file convert from `seurat` using `as.loom`. This file works fine if I open it in `scvelo` using `scv.read`, however, when starting from scanpy using. ```. adata = sc.read_loom(""seu.loom""). ```. I get the following:. ```. /Users/rmvl/miniconda3/envs/scanpy_env/lib/python3.7/site-packages/loompy/loom_layer.py:123: RuntimeWarning: invalid value encountered in not_equal. nonzeros = np.where(vals != 0). ```. I have tried closing all kernels, reinstalling loompy, scanpy, but nothing changed. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1074
https://github.com/scverse/scanpy/issues/1077:105,modifiability,paramet,parameters,105,dendrogram by genes; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1077
https://github.com/scverse/scanpy/issues/1077:382,modifiability,pac,package,382,dendrogram by genes; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1077
https://github.com/scverse/scanpy/issues/1077:187,testability,simpl,simple,187,dendrogram by genes; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1077
https://github.com/scverse/scanpy/issues/1077:179,usability,tool,tool,179,dendrogram by genes; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1077
https://github.com/scverse/scanpy/issues/1077:187,usability,simpl,simple,187,dendrogram by genes; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1077
https://github.com/scverse/scanpy/issues/1077:203,usability,tool,tool,203,dendrogram by genes; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1077
https://github.com/scverse/scanpy/issues/1077:251,usability,tool,tools,251,dendrogram by genes; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1077
https://github.com/scverse/scanpy/issues/1077:351,usability,tool,tools,351,dendrogram by genes; <!-- What kind of feature would you like to request? -->. - [ ] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. ...,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1077
https://github.com/scverse/scanpy/pull/1079:46,energy efficiency,GPU,GPU,46,"Fix deprecated louvain rapids method; Hello,. GPU accelerated louvain community method call nvLouvain has been deprecated. Now it should be run as follow: df, mod = cugraph.louvain(G)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1079
https://github.com/scverse/scanpy/pull/1079:46,performance,GPU,GPU,46,"Fix deprecated louvain rapids method; Hello,. GPU accelerated louvain community method call nvLouvain has been deprecated. Now it should be run as follow: df, mod = cugraph.louvain(G)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1079
https://github.com/scverse/scanpy/pull/1080:29,availability,cluster,clustering,29,"Phenograph supporting Leiden clustering; An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/pull/1080:29,deployability,cluster,clustering,29,"Phenograph supporting Leiden clustering; An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/pull/1080:44,deployability,updat,updated,44,"Phenograph supporting Leiden clustering; An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/pull/1080:56,deployability,releas,release,56,"Phenograph supporting Leiden clustering; An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/pull/1080:266,deployability,updat,updates,266,"Phenograph supporting Leiden clustering; An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/pull/1080:407,deployability,updat,updated,407,"Phenograph supporting Leiden clustering; An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/pull/1080:122,modifiability,pac,package,122,"Phenograph supporting Leiden clustering; An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/pull/1080:44,safety,updat,updated,44,"Phenograph supporting Leiden clustering; An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/pull/1080:176,safety,detect,detection,176,"Phenograph supporting Leiden clustering; An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/pull/1080:266,safety,updat,updates,266,"Phenograph supporting Leiden clustering; An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/pull/1080:339,safety,test,testing,339,"Phenograph supporting Leiden clustering; An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/pull/1080:367,safety,test,tests,367,"Phenograph supporting Leiden clustering; An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/pull/1080:407,safety,updat,updated,407,"Phenograph supporting Leiden clustering; An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/pull/1080:44,security,updat,updated,44,"Phenograph supporting Leiden clustering; An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/pull/1080:176,security,detect,detection,176,"Phenograph supporting Leiden clustering; An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/pull/1080:266,security,updat,updates,266,"Phenograph supporting Leiden clustering; An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/pull/1080:407,security,updat,updated,407,"Phenograph supporting Leiden clustering; An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/pull/1080:339,testability,test,testing,339,"Phenograph supporting Leiden clustering; An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/pull/1080:367,testability,test,tests,367,"Phenograph supporting Leiden clustering; An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/pull/1080:11,usability,support,supporting,11,"Phenograph supporting Leiden clustering; An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/pull/1080:134,usability,support,supports,134,"Phenograph supporting Leiden clustering; An updated new release of [`PhenoGraph`](https://github.com/dpeerlab/PhenoGraph) package now supports `Leiden` algorithm for community detection. The suggested changes in `scanpy/external/tl/_phenograph.py` will make the new updates visible in Scanpy as well. Also, the suggested changes include a testing function in `scanpy/tests/external/test_phenograph.py`, and updated docs.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1080
https://github.com/scverse/scanpy/pull/1081:55,usability,help,helper,55,"Split rank_genes_groups; Splits rank_genes_groups into helper functions. Related to 1), 2) of [this](https://github.com/theislab/scanpy/issues/723#issuecomment-526079225). I don't see any point in using dataframe internally (the second point), dict is more convenient here.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1081
https://github.com/scverse/scanpy/issues/1082:33,availability,error,errors,33,"sc.datasets.ebi_expression_atlas errors; I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:. ```python. adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41. 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path). 877 except Exception:. 878 # Make sure file doesn’t exist half-downloaded. --> 879 path.unlink(missing_ok=True). 880 raise. 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ... ```. `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:106,availability,error,error,106,"sc.datasets.ebi_expression_atlas errors; I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:. ```python. adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41. 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path). 877 except Exception:. 878 # Make sure file doesn’t exist half-downloaded. --> 879 path.unlink(missing_ok=True). 880 raise. 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ... ```. `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:176,availability,error,error,176,"sc.datasets.ebi_expression_atlas errors; I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:. ```python. adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41. 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path). 877 except Exception:. 878 # Make sure file doesn’t exist half-downloaded. --> 879 path.unlink(missing_ok=True). 880 raise. 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ... ```. `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:314,availability,Error,Error,314,"sc.datasets.ebi_expression_atlas errors; I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:. ```python. adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41. 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path). 877 except Exception:. 878 # Make sure file doesn’t exist half-downloaded. --> 879 path.unlink(missing_ok=True). 880 raise. 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ... ```. `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:729,availability,down,downloaded,729,"sc.datasets.ebi_expression_atlas errors; I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:. ```python. adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41. 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path). 877 except Exception:. 878 # Make sure file doesn’t exist half-downloaded. --> 879 path.unlink(missing_ok=True). 880 raise. 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ... ```. `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:202,deployability,version,version,202,"sc.datasets.ebi_expression_atlas errors; I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:. ```python. adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41. 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path). 877 except Exception:. 878 # Make sure file doesn’t exist half-downloaded. --> 879 path.unlink(missing_ok=True). 880 raise. 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ... ```. `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:202,integrability,version,version,202,"sc.datasets.ebi_expression_atlas errors; I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:. ```python. adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41. 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path). 877 except Exception:. 878 # Make sure file doesn’t exist half-downloaded. --> 879 path.unlink(missing_ok=True). 880 raise. 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ... ```. `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:202,modifiability,version,version,202,"sc.datasets.ebi_expression_atlas errors; I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:. ```python. adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41. 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path). 877 except Exception:. 878 # Make sure file doesn’t exist half-downloaded. --> 879 path.unlink(missing_ok=True). 880 raise. 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ... ```. `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:33,performance,error,errors,33,"sc.datasets.ebi_expression_atlas errors; I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:. ```python. adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41. 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path). 877 except Exception:. 878 # Make sure file doesn’t exist half-downloaded. --> 879 path.unlink(missing_ok=True). 880 raise. 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ... ```. `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:106,performance,error,error,106,"sc.datasets.ebi_expression_atlas errors; I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:. ```python. adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41. 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path). 877 except Exception:. 878 # Make sure file doesn’t exist half-downloaded. --> 879 path.unlink(missing_ok=True). 880 raise. 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ... ```. `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:176,performance,error,error,176,"sc.datasets.ebi_expression_atlas errors; I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:. ```python. adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41. 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path). 877 except Exception:. 878 # Make sure file doesn’t exist half-downloaded. --> 879 path.unlink(missing_ok=True). 880 raise. 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ... ```. `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:314,performance,Error,Error,314,"sc.datasets.ebi_expression_atlas errors; I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:. ```python. adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41. 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path). 877 except Exception:. 878 # Make sure file doesn’t exist half-downloaded. --> 879 path.unlink(missing_ok=True). 880 raise. 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ... ```. `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:710,reliability,doe,doesn,710,"sc.datasets.ebi_expression_atlas errors; I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:. ```python. adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41. 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path). 877 except Exception:. 878 # Make sure file doesn’t exist half-downloaded. --> 879 path.unlink(missing_ok=True). 880 raise. 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ... ```. `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:33,safety,error,errors,33,"sc.datasets.ebi_expression_atlas errors; I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:. ```python. adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41. 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path). 877 except Exception:. 878 # Make sure file doesn’t exist half-downloaded. --> 879 path.unlink(missing_ok=True). 880 raise. 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ... ```. `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:106,safety,error,error,106,"sc.datasets.ebi_expression_atlas errors; I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:. ```python. adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41. 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path). 877 except Exception:. 878 # Make sure file doesn’t exist half-downloaded. --> 879 path.unlink(missing_ok=True). 880 raise. 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ... ```. `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:150,safety,valid,valid,150,"sc.datasets.ebi_expression_atlas errors; I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:. ```python. adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41. 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path). 877 except Exception:. 878 # Make sure file doesn’t exist half-downloaded. --> 879 path.unlink(missing_ok=True). 880 raise. 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ... ```. `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:176,safety,error,error,176,"sc.datasets.ebi_expression_atlas errors; I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:. ```python. adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41. 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path). 877 except Exception:. 878 # Make sure file doesn’t exist half-downloaded. --> 879 path.unlink(missing_ok=True). 880 raise. 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ... ```. `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:314,safety,Error,Error,314,"sc.datasets.ebi_expression_atlas errors; I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:. ```python. adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41. 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path). 877 except Exception:. 878 # Make sure file doesn’t exist half-downloaded. --> 879 path.unlink(missing_ok=True). 880 raise. 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ... ```. `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:670,safety,except,except,670,"sc.datasets.ebi_expression_atlas errors; I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:. ```python. adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41. 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path). 877 except Exception:. 878 # Make sure file doesn’t exist half-downloaded. --> 879 path.unlink(missing_ok=True). 880 raise. 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ... ```. `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:677,safety,Except,Exception,677,"sc.datasets.ebi_expression_atlas errors; I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:. ```python. adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41. 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path). 877 except Exception:. 878 # Make sure file doesn’t exist half-downloaded. --> 879 path.unlink(missing_ok=True). 880 raise. 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ... ```. `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:472,security,access,accession,472,"sc.datasets.ebi_expression_atlas errors; I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:. ```python. adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41. 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path). 877 except Exception:. 878 # Make sure file doesn’t exist half-downloaded. --> 879 path.unlink(missing_ok=True). 880 raise. 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ... ```. `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:33,usability,error,errors,33,"sc.datasets.ebi_expression_atlas errors; I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:. ```python. adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41. 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path). 877 except Exception:. 878 # Make sure file doesn’t exist half-downloaded. --> 879 path.unlink(missing_ok=True). 880 raise. 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ... ```. `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:106,usability,error,error,106,"sc.datasets.ebi_expression_atlas errors; I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:. ```python. adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41. 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path). 877 except Exception:. 878 # Make sure file doesn’t exist half-downloaded. --> 879 path.unlink(missing_ok=True). 880 raise. 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ... ```. `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:176,usability,error,error,176,"sc.datasets.ebi_expression_atlas errors; I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:. ```python. adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41. 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path). 877 except Exception:. 878 # Make sure file doesn’t exist half-downloaded. --> 879 path.unlink(missing_ok=True). 880 raise. 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ... ```. `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1082:314,usability,Error,Error,314,"sc.datasets.ebi_expression_atlas errors; I wanted to use ` sc.datasets.ebi_expression_atlas` but I get an error that seems to be related to code only valid in python 3.8. This error happens with python version `3.6.7`. Code:. ```python. adata = sc.datasets.ebi_expression_atlas(""E-GEOD-98556""). ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. /scanpy/scanpy/datasets/_ebi_expression_atlas.py in download_experiment(accession). 41. 42 _download(. ---> 43 download_url + ""experiment-design"", experiment_dir / ""experimental_design.tsv"",. 44 ). 45 _download(. /scanpy/scanpy/readwrite.py in _download(url, path). 877 except Exception:. 878 # Make sure file doesn’t exist half-downloaded. --> 879 path.unlink(missing_ok=True). 880 raise. 881. TypeError: unlink() got an unexpected keyword argument 'missing_ok'. ... ```. `missing_ok` was added to python v. 3.8 (https://docs.python.org/3/library/pathlib.html#pathlib.Path.unlink).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1082
https://github.com/scverse/scanpy/issues/1083:739,availability,Error,Error,739,"zero column/rows; <!-- Please give a clear and concise description of what the bug is: -->. I ran filter_cells but still get a zero column. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_cells(adata, min_counts=300). sc.pp.filter_genes(adata, min_counts=1). sc.pp.filter_cells(adata,max_counts=15000). sc.pl.scatter(adata, x='nCount_RNA', y='percent.mt'). sc.pl.scatter(adata, x='nCount_RNA', y='nFeature_RNA'). sc.pl.highest_expr_genes(adata, n_top=20 ). print(np.any(adata.X.sum(axis=0) == 0)) # A gene's total UMI across all cells. print(np.any(adata.X.sum(axis=1) == 0)) # nUMI. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. True. False. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. Running scvelo 0.1.25 (python 3.7.3) on 2020-03-04 08:24. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1083
https://github.com/scverse/scanpy/issues/1083:848,deployability,Version,Versions,848,"zero column/rows; <!-- Please give a clear and concise description of what the bug is: -->. I ran filter_cells but still get a zero column. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_cells(adata, min_counts=300). sc.pp.filter_genes(adata, min_counts=1). sc.pp.filter_cells(adata,max_counts=15000). sc.pl.scatter(adata, x='nCount_RNA', y='percent.mt'). sc.pl.scatter(adata, x='nCount_RNA', y='nFeature_RNA'). sc.pl.highest_expr_genes(adata, n_top=20 ). print(np.any(adata.X.sum(axis=0) == 0)) # A gene's total UMI across all cells. print(np.any(adata.X.sum(axis=1) == 0)) # nUMI. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. True. False. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. Running scvelo 0.1.25 (python 3.7.3) on 2020-03-04 08:24. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1083
https://github.com/scverse/scanpy/issues/1083:881,deployability,log,logging,881,"zero column/rows; <!-- Please give a clear and concise description of what the bug is: -->. I ran filter_cells but still get a zero column. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_cells(adata, min_counts=300). sc.pp.filter_genes(adata, min_counts=1). sc.pp.filter_cells(adata,max_counts=15000). sc.pl.scatter(adata, x='nCount_RNA', y='percent.mt'). sc.pl.scatter(adata, x='nCount_RNA', y='nFeature_RNA'). sc.pl.highest_expr_genes(adata, n_top=20 ). print(np.any(adata.X.sum(axis=0) == 0)) # A gene's total UMI across all cells. print(np.any(adata.X.sum(axis=1) == 0)) # nUMI. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. True. False. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. Running scvelo 0.1.25 (python 3.7.3) on 2020-03-04 08:24. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1083
https://github.com/scverse/scanpy/issues/1083:848,integrability,Version,Versions,848,"zero column/rows; <!-- Please give a clear and concise description of what the bug is: -->. I ran filter_cells but still get a zero column. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_cells(adata, min_counts=300). sc.pp.filter_genes(adata, min_counts=1). sc.pp.filter_cells(adata,max_counts=15000). sc.pl.scatter(adata, x='nCount_RNA', y='percent.mt'). sc.pl.scatter(adata, x='nCount_RNA', y='nFeature_RNA'). sc.pl.highest_expr_genes(adata, n_top=20 ). print(np.any(adata.X.sum(axis=0) == 0)) # A gene's total UMI across all cells. print(np.any(adata.X.sum(axis=1) == 0)) # nUMI. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. True. False. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. Running scvelo 0.1.25 (python 3.7.3) on 2020-03-04 08:24. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1083
https://github.com/scverse/scanpy/issues/1083:848,modifiability,Version,Versions,848,"zero column/rows; <!-- Please give a clear and concise description of what the bug is: -->. I ran filter_cells but still get a zero column. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_cells(adata, min_counts=300). sc.pp.filter_genes(adata, min_counts=1). sc.pp.filter_cells(adata,max_counts=15000). sc.pl.scatter(adata, x='nCount_RNA', y='percent.mt'). sc.pl.scatter(adata, x='nCount_RNA', y='nFeature_RNA'). sc.pl.highest_expr_genes(adata, n_top=20 ). print(np.any(adata.X.sum(axis=0) == 0)) # A gene's total UMI across all cells. print(np.any(adata.X.sum(axis=1) == 0)) # nUMI. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. True. False. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. Running scvelo 0.1.25 (python 3.7.3) on 2020-03-04 08:24. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1083
https://github.com/scverse/scanpy/issues/1083:739,performance,Error,Error,739,"zero column/rows; <!-- Please give a clear and concise description of what the bug is: -->. I ran filter_cells but still get a zero column. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_cells(adata, min_counts=300). sc.pp.filter_genes(adata, min_counts=1). sc.pp.filter_cells(adata,max_counts=15000). sc.pl.scatter(adata, x='nCount_RNA', y='percent.mt'). sc.pl.scatter(adata, x='nCount_RNA', y='nFeature_RNA'). sc.pl.highest_expr_genes(adata, n_top=20 ). print(np.any(adata.X.sum(axis=0) == 0)) # A gene's total UMI across all cells. print(np.any(adata.X.sum(axis=1) == 0)) # nUMI. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. True. False. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. Running scvelo 0.1.25 (python 3.7.3) on 2020-03-04 08:24. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1083
https://github.com/scverse/scanpy/issues/1083:739,safety,Error,Error,739,"zero column/rows; <!-- Please give a clear and concise description of what the bug is: -->. I ran filter_cells but still get a zero column. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_cells(adata, min_counts=300). sc.pp.filter_genes(adata, min_counts=1). sc.pp.filter_cells(adata,max_counts=15000). sc.pl.scatter(adata, x='nCount_RNA', y='percent.mt'). sc.pl.scatter(adata, x='nCount_RNA', y='nFeature_RNA'). sc.pl.highest_expr_genes(adata, n_top=20 ). print(np.any(adata.X.sum(axis=0) == 0)) # A gene's total UMI across all cells. print(np.any(adata.X.sum(axis=1) == 0)) # nUMI. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. True. False. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. Running scvelo 0.1.25 (python 3.7.3) on 2020-03-04 08:24. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1083
https://github.com/scverse/scanpy/issues/1083:881,safety,log,logging,881,"zero column/rows; <!-- Please give a clear and concise description of what the bug is: -->. I ran filter_cells but still get a zero column. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_cells(adata, min_counts=300). sc.pp.filter_genes(adata, min_counts=1). sc.pp.filter_cells(adata,max_counts=15000). sc.pl.scatter(adata, x='nCount_RNA', y='percent.mt'). sc.pl.scatter(adata, x='nCount_RNA', y='nFeature_RNA'). sc.pl.highest_expr_genes(adata, n_top=20 ). print(np.any(adata.X.sum(axis=0) == 0)) # A gene's total UMI across all cells. print(np.any(adata.X.sum(axis=1) == 0)) # nUMI. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. True. False. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. Running scvelo 0.1.25 (python 3.7.3) on 2020-03-04 08:24. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1083
https://github.com/scverse/scanpy/issues/1083:881,security,log,logging,881,"zero column/rows; <!-- Please give a clear and concise description of what the bug is: -->. I ran filter_cells but still get a zero column. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_cells(adata, min_counts=300). sc.pp.filter_genes(adata, min_counts=1). sc.pp.filter_cells(adata,max_counts=15000). sc.pl.scatter(adata, x='nCount_RNA', y='percent.mt'). sc.pl.scatter(adata, x='nCount_RNA', y='nFeature_RNA'). sc.pl.highest_expr_genes(adata, n_top=20 ). print(np.any(adata.X.sum(axis=0) == 0)) # A gene's total UMI across all cells. print(np.any(adata.X.sum(axis=1) == 0)) # nUMI. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. True. False. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. Running scvelo 0.1.25 (python 3.7.3) on 2020-03-04 08:24. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1083
https://github.com/scverse/scanpy/issues/1083:881,testability,log,logging,881,"zero column/rows; <!-- Please give a clear and concise description of what the bug is: -->. I ran filter_cells but still get a zero column. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_cells(adata, min_counts=300). sc.pp.filter_genes(adata, min_counts=1). sc.pp.filter_cells(adata,max_counts=15000). sc.pl.scatter(adata, x='nCount_RNA', y='percent.mt'). sc.pl.scatter(adata, x='nCount_RNA', y='nFeature_RNA'). sc.pl.highest_expr_genes(adata, n_top=20 ). print(np.any(adata.X.sum(axis=0) == 0)) # A gene's total UMI across all cells. print(np.any(adata.X.sum(axis=1) == 0)) # nUMI. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. True. False. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. Running scvelo 0.1.25 (python 3.7.3) on 2020-03-04 08:24. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1083
https://github.com/scverse/scanpy/issues/1083:37,usability,clear,clear,37,"zero column/rows; <!-- Please give a clear and concise description of what the bug is: -->. I ran filter_cells but still get a zero column. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_cells(adata, min_counts=300). sc.pp.filter_genes(adata, min_counts=1). sc.pp.filter_cells(adata,max_counts=15000). sc.pl.scatter(adata, x='nCount_RNA', y='percent.mt'). sc.pl.scatter(adata, x='nCount_RNA', y='nFeature_RNA'). sc.pl.highest_expr_genes(adata, n_top=20 ). print(np.any(adata.X.sum(axis=0) == 0)) # A gene's total UMI across all cells. print(np.any(adata.X.sum(axis=1) == 0)) # nUMI. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. True. False. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. Running scvelo 0.1.25 (python 3.7.3) on 2020-03-04 08:24. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1083
https://github.com/scverse/scanpy/issues/1083:151,usability,minim,minimal,151,"zero column/rows; <!-- Please give a clear and concise description of what the bug is: -->. I ran filter_cells but still get a zero column. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_cells(adata, min_counts=300). sc.pp.filter_genes(adata, min_counts=1). sc.pp.filter_cells(adata,max_counts=15000). sc.pl.scatter(adata, x='nCount_RNA', y='percent.mt'). sc.pl.scatter(adata, x='nCount_RNA', y='nFeature_RNA'). sc.pl.highest_expr_genes(adata, n_top=20 ). print(np.any(adata.X.sum(axis=0) == 0)) # A gene's total UMI across all cells. print(np.any(adata.X.sum(axis=1) == 0)) # nUMI. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. True. False. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. Running scvelo 0.1.25 (python 3.7.3) on 2020-03-04 08:24. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1083
https://github.com/scverse/scanpy/issues/1083:739,usability,Error,Error,739,"zero column/rows; <!-- Please give a clear and concise description of what the bug is: -->. I ran filter_cells but still get a zero column. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.filter_cells(adata, min_counts=300). sc.pp.filter_genes(adata, min_counts=1). sc.pp.filter_cells(adata,max_counts=15000). sc.pl.scatter(adata, x='nCount_RNA', y='percent.mt'). sc.pl.scatter(adata, x='nCount_RNA', y='nFeature_RNA'). sc.pl.highest_expr_genes(adata, n_top=20 ). print(np.any(adata.X.sum(axis=0) == 0)) # A gene's total UMI across all cells. print(np.any(adata.X.sum(axis=1) == 0)) # nUMI. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```. True. False. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. Running scvelo 0.1.25 (python 3.7.3) on 2020-03-04 08:24. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1083
https://github.com/scverse/scanpy/pull/1084:18,integrability,sub,subplot,18,"stacked_violin as subplot; I think it looks great! ```py. fig, axs = plt.subplots(1, 3, figsize=(15, 5)). sc.pl.rank_genes_groups_violin(adata, groups=adata.obs['leiden'].cat.categories[0], n_genes=8, ax=axs[0], show=False). sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90, ax=axs[1], show=False). sc.pl.umap(adata, color='leiden', title='', frameon=False, ax=axs[2], show=False). fig.tight_layout(). ````. ![grafik](https://user-images.githubusercontent.com/291575/75911279-9c8af080-5e4f-11ea-925b-157b350f39db.png). (The huge gap is a problem of `plt.subplots`, not of this)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1084
https://github.com/scverse/scanpy/pull/1084:73,integrability,sub,subplots,73,"stacked_violin as subplot; I think it looks great! ```py. fig, axs = plt.subplots(1, 3, figsize=(15, 5)). sc.pl.rank_genes_groups_violin(adata, groups=adata.obs['leiden'].cat.categories[0], n_genes=8, ax=axs[0], show=False). sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90, ax=axs[1], show=False). sc.pl.umap(adata, color='leiden', title='', frameon=False, ax=axs[2], show=False). fig.tight_layout(). ````. ![grafik](https://user-images.githubusercontent.com/291575/75911279-9c8af080-5e4f-11ea-925b-157b350f39db.png). (The huge gap is a problem of `plt.subplots`, not of this)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1084
https://github.com/scverse/scanpy/pull/1084:577,integrability,sub,subplots,577,"stacked_violin as subplot; I think it looks great! ```py. fig, axs = plt.subplots(1, 3, figsize=(15, 5)). sc.pl.rank_genes_groups_violin(adata, groups=adata.obs['leiden'].cat.categories[0], n_genes=8, ax=axs[0], show=False). sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90, ax=axs[1], show=False). sc.pl.umap(adata, color='leiden', title='', frameon=False, ax=axs[2], show=False). fig.tight_layout(). ````. ![grafik](https://user-images.githubusercontent.com/291575/75911279-9c8af080-5e4f-11ea-925b-157b350f39db.png). (The huge gap is a problem of `plt.subplots`, not of this)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1084
https://github.com/scverse/scanpy/pull/1084:285,security,rotat,rotation,285,"stacked_violin as subplot; I think it looks great! ```py. fig, axs = plt.subplots(1, 3, figsize=(15, 5)). sc.pl.rank_genes_groups_violin(adata, groups=adata.obs['leiden'].cat.categories[0], n_genes=8, ax=axs[0], show=False). sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90, ax=axs[1], show=False). sc.pl.umap(adata, color='leiden', title='', frameon=False, ax=axs[2], show=False). fig.tight_layout(). ````. ![grafik](https://user-images.githubusercontent.com/291575/75911279-9c8af080-5e4f-11ea-925b-157b350f39db.png). (The huge gap is a problem of `plt.subplots`, not of this)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1084
https://github.com/scverse/scanpy/pull/1084:449,usability,user,user-images,449,"stacked_violin as subplot; I think it looks great! ```py. fig, axs = plt.subplots(1, 3, figsize=(15, 5)). sc.pl.rank_genes_groups_violin(adata, groups=adata.obs['leiden'].cat.categories[0], n_genes=8, ax=axs[0], show=False). sc.pl.stacked_violin(adata, marker_genes, groupby='leiden', rotation=90, ax=axs[1], show=False). sc.pl.umap(adata, color='leiden', title='', frameon=False, ax=axs[2], show=False). fig.tight_layout(). ````. ![grafik](https://user-images.githubusercontent.com/291575/75911279-9c8af080-5e4f-11ea-925b-157b350f39db.png). (The huge gap is a problem of `plt.subplots`, not of this)",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1084
https://github.com/scverse/scanpy/pull/1085:107,deployability,API,API,107,"Add scVI to external; Added VAE and LDVAE models from [scVI](https://github.com/YosefLab/scVI) to externel API. . The user passes an anndata object along with model and training arguments to `scvi()` which then runs and returns the learned representation as well as (optionally) the trainer object. . By default the method uses the model described in the scVI [paper](https://www.nature.com/articles/s41592-018-0229-2.epdf?author_access_token=5sMbnZl1iBFitATlpKkddtRgN0jAjWel9jnR3ZoTv0P1-tTjoP-mBfrGiMqpQx63aBtxToJssRfpqQ482otMbBw2GIGGeinWV4cULBLPg4L4DpCg92dEtoMaB1crCRDG7DgtNrM_1j17VfvHfoy1cQ%3D%3D). . If the user wants to use a linear-decoded VAE model, they can set the `linear_decoded` param to True and the method will use the model described in the LDVAE [paper](https://www.biorxiv.org/content/10.1101/737601v1.full.pdf). . This is my first PR so definitely let me know if you need changes!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1085
https://github.com/scverse/scanpy/pull/1085:42,energy efficiency,model,models,42,"Add scVI to external; Added VAE and LDVAE models from [scVI](https://github.com/YosefLab/scVI) to externel API. . The user passes an anndata object along with model and training arguments to `scvi()` which then runs and returns the learned representation as well as (optionally) the trainer object. . By default the method uses the model described in the scVI [paper](https://www.nature.com/articles/s41592-018-0229-2.epdf?author_access_token=5sMbnZl1iBFitATlpKkddtRgN0jAjWel9jnR3ZoTv0P1-tTjoP-mBfrGiMqpQx63aBtxToJssRfpqQ482otMbBw2GIGGeinWV4cULBLPg4L4DpCg92dEtoMaB1crCRDG7DgtNrM_1j17VfvHfoy1cQ%3D%3D). . If the user wants to use a linear-decoded VAE model, they can set the `linear_decoded` param to True and the method will use the model described in the LDVAE [paper](https://www.biorxiv.org/content/10.1101/737601v1.full.pdf). . This is my first PR so definitely let me know if you need changes!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1085
https://github.com/scverse/scanpy/pull/1085:159,energy efficiency,model,model,159,"Add scVI to external; Added VAE and LDVAE models from [scVI](https://github.com/YosefLab/scVI) to externel API. . The user passes an anndata object along with model and training arguments to `scvi()` which then runs and returns the learned representation as well as (optionally) the trainer object. . By default the method uses the model described in the scVI [paper](https://www.nature.com/articles/s41592-018-0229-2.epdf?author_access_token=5sMbnZl1iBFitATlpKkddtRgN0jAjWel9jnR3ZoTv0P1-tTjoP-mBfrGiMqpQx63aBtxToJssRfpqQ482otMbBw2GIGGeinWV4cULBLPg4L4DpCg92dEtoMaB1crCRDG7DgtNrM_1j17VfvHfoy1cQ%3D%3D). . If the user wants to use a linear-decoded VAE model, they can set the `linear_decoded` param to True and the method will use the model described in the LDVAE [paper](https://www.biorxiv.org/content/10.1101/737601v1.full.pdf). . This is my first PR so definitely let me know if you need changes!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1085
https://github.com/scverse/scanpy/pull/1085:332,energy efficiency,model,model,332,"Add scVI to external; Added VAE and LDVAE models from [scVI](https://github.com/YosefLab/scVI) to externel API. . The user passes an anndata object along with model and training arguments to `scvi()` which then runs and returns the learned representation as well as (optionally) the trainer object. . By default the method uses the model described in the scVI [paper](https://www.nature.com/articles/s41592-018-0229-2.epdf?author_access_token=5sMbnZl1iBFitATlpKkddtRgN0jAjWel9jnR3ZoTv0P1-tTjoP-mBfrGiMqpQx63aBtxToJssRfpqQ482otMbBw2GIGGeinWV4cULBLPg4L4DpCg92dEtoMaB1crCRDG7DgtNrM_1j17VfvHfoy1cQ%3D%3D). . If the user wants to use a linear-decoded VAE model, they can set the `linear_decoded` param to True and the method will use the model described in the LDVAE [paper](https://www.biorxiv.org/content/10.1101/737601v1.full.pdf). . This is my first PR so definitely let me know if you need changes!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1085
https://github.com/scverse/scanpy/pull/1085:650,energy efficiency,model,model,650,"Add scVI to external; Added VAE and LDVAE models from [scVI](https://github.com/YosefLab/scVI) to externel API. . The user passes an anndata object along with model and training arguments to `scvi()` which then runs and returns the learned representation as well as (optionally) the trainer object. . By default the method uses the model described in the scVI [paper](https://www.nature.com/articles/s41592-018-0229-2.epdf?author_access_token=5sMbnZl1iBFitATlpKkddtRgN0jAjWel9jnR3ZoTv0P1-tTjoP-mBfrGiMqpQx63aBtxToJssRfpqQ482otMbBw2GIGGeinWV4cULBLPg4L4DpCg92dEtoMaB1crCRDG7DgtNrM_1j17VfvHfoy1cQ%3D%3D). . If the user wants to use a linear-decoded VAE model, they can set the `linear_decoded` param to True and the method will use the model described in the LDVAE [paper](https://www.biorxiv.org/content/10.1101/737601v1.full.pdf). . This is my first PR so definitely let me know if you need changes!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1085
https://github.com/scverse/scanpy/pull/1085:733,energy efficiency,model,model,733,"Add scVI to external; Added VAE and LDVAE models from [scVI](https://github.com/YosefLab/scVI) to externel API. . The user passes an anndata object along with model and training arguments to `scvi()` which then runs and returns the learned representation as well as (optionally) the trainer object. . By default the method uses the model described in the scVI [paper](https://www.nature.com/articles/s41592-018-0229-2.epdf?author_access_token=5sMbnZl1iBFitATlpKkddtRgN0jAjWel9jnR3ZoTv0P1-tTjoP-mBfrGiMqpQx63aBtxToJssRfpqQ482otMbBw2GIGGeinWV4cULBLPg4L4DpCg92dEtoMaB1crCRDG7DgtNrM_1j17VfvHfoy1cQ%3D%3D). . If the user wants to use a linear-decoded VAE model, they can set the `linear_decoded` param to True and the method will use the model described in the LDVAE [paper](https://www.biorxiv.org/content/10.1101/737601v1.full.pdf). . This is my first PR so definitely let me know if you need changes!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1085
https://github.com/scverse/scanpy/pull/1085:107,integrability,API,API,107,"Add scVI to external; Added VAE and LDVAE models from [scVI](https://github.com/YosefLab/scVI) to externel API. . The user passes an anndata object along with model and training arguments to `scvi()` which then runs and returns the learned representation as well as (optionally) the trainer object. . By default the method uses the model described in the scVI [paper](https://www.nature.com/articles/s41592-018-0229-2.epdf?author_access_token=5sMbnZl1iBFitATlpKkddtRgN0jAjWel9jnR3ZoTv0P1-tTjoP-mBfrGiMqpQx63aBtxToJssRfpqQ482otMbBw2GIGGeinWV4cULBLPg4L4DpCg92dEtoMaB1crCRDG7DgtNrM_1j17VfvHfoy1cQ%3D%3D). . If the user wants to use a linear-decoded VAE model, they can set the `linear_decoded` param to True and the method will use the model described in the LDVAE [paper](https://www.biorxiv.org/content/10.1101/737601v1.full.pdf). . This is my first PR so definitely let me know if you need changes!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1085
https://github.com/scverse/scanpy/pull/1085:107,interoperability,API,API,107,"Add scVI to external; Added VAE and LDVAE models from [scVI](https://github.com/YosefLab/scVI) to externel API. . The user passes an anndata object along with model and training arguments to `scvi()` which then runs and returns the learned representation as well as (optionally) the trainer object. . By default the method uses the model described in the scVI [paper](https://www.nature.com/articles/s41592-018-0229-2.epdf?author_access_token=5sMbnZl1iBFitATlpKkddtRgN0jAjWel9jnR3ZoTv0P1-tTjoP-mBfrGiMqpQx63aBtxToJssRfpqQ482otMbBw2GIGGeinWV4cULBLPg4L4DpCg92dEtoMaB1crCRDG7DgtNrM_1j17VfvHfoy1cQ%3D%3D). . If the user wants to use a linear-decoded VAE model, they can set the `linear_decoded` param to True and the method will use the model described in the LDVAE [paper](https://www.biorxiv.org/content/10.1101/737601v1.full.pdf). . This is my first PR so definitely let me know if you need changes!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1085
https://github.com/scverse/scanpy/pull/1085:638,modifiability,deco,decoded,638,"Add scVI to external; Added VAE and LDVAE models from [scVI](https://github.com/YosefLab/scVI) to externel API. . The user passes an anndata object along with model and training arguments to `scvi()` which then runs and returns the learned representation as well as (optionally) the trainer object. . By default the method uses the model described in the scVI [paper](https://www.nature.com/articles/s41592-018-0229-2.epdf?author_access_token=5sMbnZl1iBFitATlpKkddtRgN0jAjWel9jnR3ZoTv0P1-tTjoP-mBfrGiMqpQx63aBtxToJssRfpqQ482otMbBw2GIGGeinWV4cULBLPg4L4DpCg92dEtoMaB1crCRDG7DgtNrM_1j17VfvHfoy1cQ%3D%3D). . If the user wants to use a linear-decoded VAE model, they can set the `linear_decoded` param to True and the method will use the model described in the LDVAE [paper](https://www.biorxiv.org/content/10.1101/737601v1.full.pdf). . This is my first PR so definitely let me know if you need changes!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1085
https://github.com/scverse/scanpy/pull/1085:794,performance,content,content,794,"Add scVI to external; Added VAE and LDVAE models from [scVI](https://github.com/YosefLab/scVI) to externel API. . The user passes an anndata object along with model and training arguments to `scvi()` which then runs and returns the learned representation as well as (optionally) the trainer object. . By default the method uses the model described in the scVI [paper](https://www.nature.com/articles/s41592-018-0229-2.epdf?author_access_token=5sMbnZl1iBFitATlpKkddtRgN0jAjWel9jnR3ZoTv0P1-tTjoP-mBfrGiMqpQx63aBtxToJssRfpqQ482otMbBw2GIGGeinWV4cULBLPg4L4DpCg92dEtoMaB1crCRDG7DgtNrM_1j17VfvHfoy1cQ%3D%3D). . If the user wants to use a linear-decoded VAE model, they can set the `linear_decoded` param to True and the method will use the model described in the LDVAE [paper](https://www.biorxiv.org/content/10.1101/737601v1.full.pdf). . This is my first PR so definitely let me know if you need changes!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1085
https://github.com/scverse/scanpy/pull/1085:42,security,model,models,42,"Add scVI to external; Added VAE and LDVAE models from [scVI](https://github.com/YosefLab/scVI) to externel API. . The user passes an anndata object along with model and training arguments to `scvi()` which then runs and returns the learned representation as well as (optionally) the trainer object. . By default the method uses the model described in the scVI [paper](https://www.nature.com/articles/s41592-018-0229-2.epdf?author_access_token=5sMbnZl1iBFitATlpKkddtRgN0jAjWel9jnR3ZoTv0P1-tTjoP-mBfrGiMqpQx63aBtxToJssRfpqQ482otMbBw2GIGGeinWV4cULBLPg4L4DpCg92dEtoMaB1crCRDG7DgtNrM_1j17VfvHfoy1cQ%3D%3D). . If the user wants to use a linear-decoded VAE model, they can set the `linear_decoded` param to True and the method will use the model described in the LDVAE [paper](https://www.biorxiv.org/content/10.1101/737601v1.full.pdf). . This is my first PR so definitely let me know if you need changes!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1085
https://github.com/scverse/scanpy/pull/1085:159,security,model,model,159,"Add scVI to external; Added VAE and LDVAE models from [scVI](https://github.com/YosefLab/scVI) to externel API. . The user passes an anndata object along with model and training arguments to `scvi()` which then runs and returns the learned representation as well as (optionally) the trainer object. . By default the method uses the model described in the scVI [paper](https://www.nature.com/articles/s41592-018-0229-2.epdf?author_access_token=5sMbnZl1iBFitATlpKkddtRgN0jAjWel9jnR3ZoTv0P1-tTjoP-mBfrGiMqpQx63aBtxToJssRfpqQ482otMbBw2GIGGeinWV4cULBLPg4L4DpCg92dEtoMaB1crCRDG7DgtNrM_1j17VfvHfoy1cQ%3D%3D). . If the user wants to use a linear-decoded VAE model, they can set the `linear_decoded` param to True and the method will use the model described in the LDVAE [paper](https://www.biorxiv.org/content/10.1101/737601v1.full.pdf). . This is my first PR so definitely let me know if you need changes!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1085
https://github.com/scverse/scanpy/pull/1085:332,security,model,model,332,"Add scVI to external; Added VAE and LDVAE models from [scVI](https://github.com/YosefLab/scVI) to externel API. . The user passes an anndata object along with model and training arguments to `scvi()` which then runs and returns the learned representation as well as (optionally) the trainer object. . By default the method uses the model described in the scVI [paper](https://www.nature.com/articles/s41592-018-0229-2.epdf?author_access_token=5sMbnZl1iBFitATlpKkddtRgN0jAjWel9jnR3ZoTv0P1-tTjoP-mBfrGiMqpQx63aBtxToJssRfpqQ482otMbBw2GIGGeinWV4cULBLPg4L4DpCg92dEtoMaB1crCRDG7DgtNrM_1j17VfvHfoy1cQ%3D%3D). . If the user wants to use a linear-decoded VAE model, they can set the `linear_decoded` param to True and the method will use the model described in the LDVAE [paper](https://www.biorxiv.org/content/10.1101/737601v1.full.pdf). . This is my first PR so definitely let me know if you need changes!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1085
https://github.com/scverse/scanpy/pull/1085:650,security,model,model,650,"Add scVI to external; Added VAE and LDVAE models from [scVI](https://github.com/YosefLab/scVI) to externel API. . The user passes an anndata object along with model and training arguments to `scvi()` which then runs and returns the learned representation as well as (optionally) the trainer object. . By default the method uses the model described in the scVI [paper](https://www.nature.com/articles/s41592-018-0229-2.epdf?author_access_token=5sMbnZl1iBFitATlpKkddtRgN0jAjWel9jnR3ZoTv0P1-tTjoP-mBfrGiMqpQx63aBtxToJssRfpqQ482otMbBw2GIGGeinWV4cULBLPg4L4DpCg92dEtoMaB1crCRDG7DgtNrM_1j17VfvHfoy1cQ%3D%3D). . If the user wants to use a linear-decoded VAE model, they can set the `linear_decoded` param to True and the method will use the model described in the LDVAE [paper](https://www.biorxiv.org/content/10.1101/737601v1.full.pdf). . This is my first PR so definitely let me know if you need changes!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1085
https://github.com/scverse/scanpy/pull/1085:733,security,model,model,733,"Add scVI to external; Added VAE and LDVAE models from [scVI](https://github.com/YosefLab/scVI) to externel API. . The user passes an anndata object along with model and training arguments to `scvi()` which then runs and returns the learned representation as well as (optionally) the trainer object. . By default the method uses the model described in the scVI [paper](https://www.nature.com/articles/s41592-018-0229-2.epdf?author_access_token=5sMbnZl1iBFitATlpKkddtRgN0jAjWel9jnR3ZoTv0P1-tTjoP-mBfrGiMqpQx63aBtxToJssRfpqQ482otMbBw2GIGGeinWV4cULBLPg4L4DpCg92dEtoMaB1crCRDG7DgtNrM_1j17VfvHfoy1cQ%3D%3D). . If the user wants to use a linear-decoded VAE model, they can set the `linear_decoded` param to True and the method will use the model described in the LDVAE [paper](https://www.biorxiv.org/content/10.1101/737601v1.full.pdf). . This is my first PR so definitely let me know if you need changes!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1085
https://github.com/scverse/scanpy/pull/1085:118,usability,user,user,118,"Add scVI to external; Added VAE and LDVAE models from [scVI](https://github.com/YosefLab/scVI) to externel API. . The user passes an anndata object along with model and training arguments to `scvi()` which then runs and returns the learned representation as well as (optionally) the trainer object. . By default the method uses the model described in the scVI [paper](https://www.nature.com/articles/s41592-018-0229-2.epdf?author_access_token=5sMbnZl1iBFitATlpKkddtRgN0jAjWel9jnR3ZoTv0P1-tTjoP-mBfrGiMqpQx63aBtxToJssRfpqQ482otMbBw2GIGGeinWV4cULBLPg4L4DpCg92dEtoMaB1crCRDG7DgtNrM_1j17VfvHfoy1cQ%3D%3D). . If the user wants to use a linear-decoded VAE model, they can set the `linear_decoded` param to True and the method will use the model described in the LDVAE [paper](https://www.biorxiv.org/content/10.1101/737601v1.full.pdf). . This is my first PR so definitely let me know if you need changes!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1085
https://github.com/scverse/scanpy/pull/1085:232,usability,learn,learned,232,"Add scVI to external; Added VAE and LDVAE models from [scVI](https://github.com/YosefLab/scVI) to externel API. . The user passes an anndata object along with model and training arguments to `scvi()` which then runs and returns the learned representation as well as (optionally) the trainer object. . By default the method uses the model described in the scVI [paper](https://www.nature.com/articles/s41592-018-0229-2.epdf?author_access_token=5sMbnZl1iBFitATlpKkddtRgN0jAjWel9jnR3ZoTv0P1-tTjoP-mBfrGiMqpQx63aBtxToJssRfpqQ482otMbBw2GIGGeinWV4cULBLPg4L4DpCg92dEtoMaB1crCRDG7DgtNrM_1j17VfvHfoy1cQ%3D%3D). . If the user wants to use a linear-decoded VAE model, they can set the `linear_decoded` param to True and the method will use the model described in the LDVAE [paper](https://www.biorxiv.org/content/10.1101/737601v1.full.pdf). . This is my first PR so definitely let me know if you need changes!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1085
https://github.com/scverse/scanpy/pull/1085:611,usability,user,user,611,"Add scVI to external; Added VAE and LDVAE models from [scVI](https://github.com/YosefLab/scVI) to externel API. . The user passes an anndata object along with model and training arguments to `scvi()` which then runs and returns the learned representation as well as (optionally) the trainer object. . By default the method uses the model described in the scVI [paper](https://www.nature.com/articles/s41592-018-0229-2.epdf?author_access_token=5sMbnZl1iBFitATlpKkddtRgN0jAjWel9jnR3ZoTv0P1-tTjoP-mBfrGiMqpQx63aBtxToJssRfpqQ482otMbBw2GIGGeinWV4cULBLPg4L4DpCg92dEtoMaB1crCRDG7DgtNrM_1j17VfvHfoy1cQ%3D%3D). . If the user wants to use a linear-decoded VAE model, they can set the `linear_decoded` param to True and the method will use the model described in the LDVAE [paper](https://www.biorxiv.org/content/10.1101/737601v1.full.pdf). . This is my first PR so definitely let me know if you need changes!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1085
https://github.com/scverse/scanpy/issues/1086:139,interoperability,distribut,distributions,139,"Is it possible to test for bimodality in scanpy?; Is there a way to test if particular genes of a single-cell-RNA-seq-dataset show bimodal distributions, in order to infer heterogeneity? . e.g. like in: https://www.nature.com/articles/nature13437",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1086
https://github.com/scverse/scanpy/issues/1086:172,interoperability,heterogen,heterogeneity,172,"Is it possible to test for bimodality in scanpy?; Is there a way to test if particular genes of a single-cell-RNA-seq-dataset show bimodal distributions, in order to infer heterogeneity? . e.g. like in: https://www.nature.com/articles/nature13437",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1086
https://github.com/scverse/scanpy/issues/1086:18,safety,test,test,18,"Is it possible to test for bimodality in scanpy?; Is there a way to test if particular genes of a single-cell-RNA-seq-dataset show bimodal distributions, in order to infer heterogeneity? . e.g. like in: https://www.nature.com/articles/nature13437",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1086
https://github.com/scverse/scanpy/issues/1086:68,safety,test,test,68,"Is it possible to test for bimodality in scanpy?; Is there a way to test if particular genes of a single-cell-RNA-seq-dataset show bimodal distributions, in order to infer heterogeneity? . e.g. like in: https://www.nature.com/articles/nature13437",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1086
https://github.com/scverse/scanpy/issues/1086:18,testability,test,test,18,"Is it possible to test for bimodality in scanpy?; Is there a way to test if particular genes of a single-cell-RNA-seq-dataset show bimodal distributions, in order to infer heterogeneity? . e.g. like in: https://www.nature.com/articles/nature13437",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1086
https://github.com/scverse/scanpy/issues/1086:68,testability,test,test,68,"Is it possible to test for bimodality in scanpy?; Is there a way to test if particular genes of a single-cell-RNA-seq-dataset show bimodal distributions, in order to infer heterogeneity? . e.g. like in: https://www.nature.com/articles/nature13437",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1086
https://github.com/scverse/scanpy/pull/1087:33,availability,down,download,33,"Remove python 3.8 only code from download code; Fix (sorta) #1082. Removed a call that required python 3.8 plus. The added test doesn't fully cover this case, since it wouldn't have had the same error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1087
https://github.com/scverse/scanpy/pull/1087:195,availability,error,error,195,"Remove python 3.8 only code from download code; Fix (sorta) #1082. Removed a call that required python 3.8 plus. The added test doesn't fully cover this case, since it wouldn't have had the same error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1087
https://github.com/scverse/scanpy/pull/1087:195,performance,error,error,195,"Remove python 3.8 only code from download code; Fix (sorta) #1082. Removed a call that required python 3.8 plus. The added test doesn't fully cover this case, since it wouldn't have had the same error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1087
https://github.com/scverse/scanpy/pull/1087:128,reliability,doe,doesn,128,"Remove python 3.8 only code from download code; Fix (sorta) #1082. Removed a call that required python 3.8 plus. The added test doesn't fully cover this case, since it wouldn't have had the same error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1087
https://github.com/scverse/scanpy/pull/1087:123,safety,test,test,123,"Remove python 3.8 only code from download code; Fix (sorta) #1082. Removed a call that required python 3.8 plus. The added test doesn't fully cover this case, since it wouldn't have had the same error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1087
https://github.com/scverse/scanpy/pull/1087:195,safety,error,error,195,"Remove python 3.8 only code from download code; Fix (sorta) #1082. Removed a call that required python 3.8 plus. The added test doesn't fully cover this case, since it wouldn't have had the same error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1087
https://github.com/scverse/scanpy/pull/1087:123,testability,test,test,123,"Remove python 3.8 only code from download code; Fix (sorta) #1082. Removed a call that required python 3.8 plus. The added test doesn't fully cover this case, since it wouldn't have had the same error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1087
https://github.com/scverse/scanpy/pull/1087:195,usability,error,error,195,"Remove python 3.8 only code from download code; Fix (sorta) #1082. Removed a call that required python 3.8 plus. The added test doesn't fully cover this case, since it wouldn't have had the same error.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1087
https://github.com/scverse/scanpy/pull/1088:26,availability,Ping,Ping,26,"Fixes for visium reading; Ping @flying-sheep @giovp @Mirkazemi. Turns out that the `sc.datasets.visium_sge` would just read in whatever images were most recently added, not the one that fit the dataset. This fixes that. Additionally, `sc.read_visium` now takes a directory as the first argument. If a reading function assumes a directory structure, that directory should be passed, not a specific path inside of it. This follows our other functions like: `sc.read_10x_mtx`. Similarly, I've rearranged how the example datasets are stored and how the test data is stored to better match the outputs from 10x pipelines. A few more changes I'd like to make:. * Restructure how elements are added to `uns`, as mentioned in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. * Rename `obsm[""X_spatial""]` to `obsm[""coords""]` or `obsm[""spatial""]`. * There is a natural connectivity for the observations from the adjacency of wells. This should be easy to add to obsp, or should just be added to obsp when `read_visum` is called. I'm thinking `""spatial_connectivity""` for the default key name.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1088
https://github.com/scverse/scanpy/pull/1088:606,deployability,pipelin,pipelines,606,"Fixes for visium reading; Ping @flying-sheep @giovp @Mirkazemi. Turns out that the `sc.datasets.visium_sge` would just read in whatever images were most recently added, not the one that fit the dataset. This fixes that. Additionally, `sc.read_visium` now takes a directory as the first argument. If a reading function assumes a directory structure, that directory should be passed, not a specific path inside of it. This follows our other functions like: `sc.read_10x_mtx`. Similarly, I've rearranged how the example datasets are stored and how the test data is stored to better match the outputs from 10x pipelines. A few more changes I'd like to make:. * Restructure how elements are added to `uns`, as mentioned in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. * Rename `obsm[""X_spatial""]` to `obsm[""coords""]` or `obsm[""spatial""]`. * There is a natural connectivity for the observations from the adjacency of wells. This should be easy to add to obsp, or should just be added to obsp when `read_visum` is called. I'm thinking `""spatial_connectivity""` for the default key name.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1088
https://github.com/scverse/scanpy/pull/1088:902,deployability,observ,observations,902,"Fixes for visium reading; Ping @flying-sheep @giovp @Mirkazemi. Turns out that the `sc.datasets.visium_sge` would just read in whatever images were most recently added, not the one that fit the dataset. This fixes that. Additionally, `sc.read_visium` now takes a directory as the first argument. If a reading function assumes a directory structure, that directory should be passed, not a specific path inside of it. This follows our other functions like: `sc.read_10x_mtx`. Similarly, I've rearranged how the example datasets are stored and how the test data is stored to better match the outputs from 10x pipelines. A few more changes I'd like to make:. * Restructure how elements are added to `uns`, as mentioned in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. * Rename `obsm[""X_spatial""]` to `obsm[""coords""]` or `obsm[""spatial""]`. * There is a natural connectivity for the observations from the adjacency of wells. This should be easy to add to obsp, or should just be added to obsp when `read_visum` is called. I'm thinking `""spatial_connectivity""` for the default key name.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1088
https://github.com/scverse/scanpy/pull/1088:606,integrability,pipelin,pipelines,606,"Fixes for visium reading; Ping @flying-sheep @giovp @Mirkazemi. Turns out that the `sc.datasets.visium_sge` would just read in whatever images were most recently added, not the one that fit the dataset. This fixes that. Additionally, `sc.read_visium` now takes a directory as the first argument. If a reading function assumes a directory structure, that directory should be passed, not a specific path inside of it. This follows our other functions like: `sc.read_10x_mtx`. Similarly, I've rearranged how the example datasets are stored and how the test data is stored to better match the outputs from 10x pipelines. A few more changes I'd like to make:. * Restructure how elements are added to `uns`, as mentioned in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. * Rename `obsm[""X_spatial""]` to `obsm[""coords""]` or `obsm[""spatial""]`. * There is a natural connectivity for the observations from the adjacency of wells. This should be easy to add to obsp, or should just be added to obsp when `read_visum` is called. I'm thinking `""spatial_connectivity""` for the default key name.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1088
https://github.com/scverse/scanpy/pull/1088:388,interoperability,specif,specific,388,"Fixes for visium reading; Ping @flying-sheep @giovp @Mirkazemi. Turns out that the `sc.datasets.visium_sge` would just read in whatever images were most recently added, not the one that fit the dataset. This fixes that. Additionally, `sc.read_visium` now takes a directory as the first argument. If a reading function assumes a directory structure, that directory should be passed, not a specific path inside of it. This follows our other functions like: `sc.read_10x_mtx`. Similarly, I've rearranged how the example datasets are stored and how the test data is stored to better match the outputs from 10x pipelines. A few more changes I'd like to make:. * Restructure how elements are added to `uns`, as mentioned in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. * Rename `obsm[""X_spatial""]` to `obsm[""coords""]` or `obsm[""spatial""]`. * There is a natural connectivity for the observations from the adjacency of wells. This should be easy to add to obsp, or should just be added to obsp when `read_visum` is called. I'm thinking `""spatial_connectivity""` for the default key name.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1088
https://github.com/scverse/scanpy/pull/1088:549,safety,test,test,549,"Fixes for visium reading; Ping @flying-sheep @giovp @Mirkazemi. Turns out that the `sc.datasets.visium_sge` would just read in whatever images were most recently added, not the one that fit the dataset. This fixes that. Additionally, `sc.read_visium` now takes a directory as the first argument. If a reading function assumes a directory structure, that directory should be passed, not a specific path inside of it. This follows our other functions like: `sc.read_10x_mtx`. Similarly, I've rearranged how the example datasets are stored and how the test data is stored to better match the outputs from 10x pipelines. A few more changes I'd like to make:. * Restructure how elements are added to `uns`, as mentioned in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. * Rename `obsm[""X_spatial""]` to `obsm[""coords""]` or `obsm[""spatial""]`. * There is a natural connectivity for the observations from the adjacency of wells. This should be easy to add to obsp, or should just be added to obsp when `read_visum` is called. I'm thinking `""spatial_connectivity""` for the default key name.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1088
https://github.com/scverse/scanpy/pull/1088:549,testability,test,test,549,"Fixes for visium reading; Ping @flying-sheep @giovp @Mirkazemi. Turns out that the `sc.datasets.visium_sge` would just read in whatever images were most recently added, not the one that fit the dataset. This fixes that. Additionally, `sc.read_visium` now takes a directory as the first argument. If a reading function assumes a directory structure, that directory should be passed, not a specific path inside of it. This follows our other functions like: `sc.read_10x_mtx`. Similarly, I've rearranged how the example datasets are stored and how the test data is stored to better match the outputs from 10x pipelines. A few more changes I'd like to make:. * Restructure how elements are added to `uns`, as mentioned in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. * Rename `obsm[""X_spatial""]` to `obsm[""coords""]` or `obsm[""spatial""]`. * There is a natural connectivity for the observations from the adjacency of wells. This should be easy to add to obsp, or should just be added to obsp when `read_visum` is called. I'm thinking `""spatial_connectivity""` for the default key name.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1088
https://github.com/scverse/scanpy/pull/1088:902,testability,observ,observations,902,"Fixes for visium reading; Ping @flying-sheep @giovp @Mirkazemi. Turns out that the `sc.datasets.visium_sge` would just read in whatever images were most recently added, not the one that fit the dataset. This fixes that. Additionally, `sc.read_visium` now takes a directory as the first argument. If a reading function assumes a directory structure, that directory should be passed, not a specific path inside of it. This follows our other functions like: `sc.read_10x_mtx`. Similarly, I've rearranged how the example datasets are stored and how the test data is stored to better match the outputs from 10x pipelines. A few more changes I'd like to make:. * Restructure how elements are added to `uns`, as mentioned in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. * Rename `obsm[""X_spatial""]` to `obsm[""coords""]` or `obsm[""spatial""]`. * There is a natural connectivity for the observations from the adjacency of wells. This should be easy to add to obsp, or should just be added to obsp when `read_visum` is called. I'm thinking `""spatial_connectivity""` for the default key name.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1088
https://github.com/scverse/scanpy/issues/1089:175,availability,operat,operations,175,"Subset and Rescale?; We often identify a subset of cells as irrelevant noise cells and hope to discard them during the analysis. I am a bit confused about how to perform such operations in Scanpy. It's a common practice in other analysis tool like Seurat to do ScaleData across cells so that the relative expression level is adjusted without uninteresting cells' influences. . Such operation is supported by Seurat by providing multiple ""Assay"", such as `counts`, `data`, and `scale.data`, which stores the raw UMI counts, column normalized data (across genes, log1p), and row normalized data (across samples, zscores). . I noticed the scaled data are stored in `adata.X` in scanpy. With this design, how can we access the raw UMI count and do re-scaling if I hope to subset the data? Looking forward your reply. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089
https://github.com/scverse/scanpy/issues/1089:382,availability,operat,operation,382,"Subset and Rescale?; We often identify a subset of cells as irrelevant noise cells and hope to discard them during the analysis. I am a bit confused about how to perform such operations in Scanpy. It's a common practice in other analysis tool like Seurat to do ScaleData across cells so that the relative expression level is adjusted without uninteresting cells' influences. . Such operation is supported by Seurat by providing multiple ""Assay"", such as `counts`, `data`, and `scale.data`, which stores the raw UMI counts, column normalized data (across genes, log1p), and row normalized data (across samples, zscores). . I noticed the scaled data are stored in `adata.X` in scanpy. With this design, how can we access the raw UMI count and do re-scaling if I hope to subset the data? Looking forward your reply. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089
https://github.com/scverse/scanpy/issues/1089:261,deployability,Scale,ScaleData,261,"Subset and Rescale?; We often identify a subset of cells as irrelevant noise cells and hope to discard them during the analysis. I am a bit confused about how to perform such operations in Scanpy. It's a common practice in other analysis tool like Seurat to do ScaleData across cells so that the relative expression level is adjusted without uninteresting cells' influences. . Such operation is supported by Seurat by providing multiple ""Assay"", such as `counts`, `data`, and `scale.data`, which stores the raw UMI counts, column normalized data (across genes, log1p), and row normalized data (across samples, zscores). . I noticed the scaled data are stored in `adata.X` in scanpy. With this design, how can we access the raw UMI count and do re-scaling if I hope to subset the data? Looking forward your reply. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089
https://github.com/scverse/scanpy/issues/1089:477,deployability,scale,scale,477,"Subset and Rescale?; We often identify a subset of cells as irrelevant noise cells and hope to discard them during the analysis. I am a bit confused about how to perform such operations in Scanpy. It's a common practice in other analysis tool like Seurat to do ScaleData across cells so that the relative expression level is adjusted without uninteresting cells' influences. . Such operation is supported by Seurat by providing multiple ""Assay"", such as `counts`, `data`, and `scale.data`, which stores the raw UMI counts, column normalized data (across genes, log1p), and row normalized data (across samples, zscores). . I noticed the scaled data are stored in `adata.X` in scanpy. With this design, how can we access the raw UMI count and do re-scaling if I hope to subset the data? Looking forward your reply. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089
https://github.com/scverse/scanpy/issues/1089:636,deployability,scale,scaled,636,"Subset and Rescale?; We often identify a subset of cells as irrelevant noise cells and hope to discard them during the analysis. I am a bit confused about how to perform such operations in Scanpy. It's a common practice in other analysis tool like Seurat to do ScaleData across cells so that the relative expression level is adjusted without uninteresting cells' influences. . Such operation is supported by Seurat by providing multiple ""Assay"", such as `counts`, `data`, and `scale.data`, which stores the raw UMI counts, column normalized data (across genes, log1p), and row normalized data (across samples, zscores). . I noticed the scaled data are stored in `adata.X` in scanpy. With this design, how can we access the raw UMI count and do re-scaling if I hope to subset the data? Looking forward your reply. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089
https://github.com/scverse/scanpy/issues/1089:261,energy efficiency,Scale,ScaleData,261,"Subset and Rescale?; We often identify a subset of cells as irrelevant noise cells and hope to discard them during the analysis. I am a bit confused about how to perform such operations in Scanpy. It's a common practice in other analysis tool like Seurat to do ScaleData across cells so that the relative expression level is adjusted without uninteresting cells' influences. . Such operation is supported by Seurat by providing multiple ""Assay"", such as `counts`, `data`, and `scale.data`, which stores the raw UMI counts, column normalized data (across genes, log1p), and row normalized data (across samples, zscores). . I noticed the scaled data are stored in `adata.X` in scanpy. With this design, how can we access the raw UMI count and do re-scaling if I hope to subset the data? Looking forward your reply. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089
https://github.com/scverse/scanpy/issues/1089:477,energy efficiency,scale,scale,477,"Subset and Rescale?; We often identify a subset of cells as irrelevant noise cells and hope to discard them during the analysis. I am a bit confused about how to perform such operations in Scanpy. It's a common practice in other analysis tool like Seurat to do ScaleData across cells so that the relative expression level is adjusted without uninteresting cells' influences. . Such operation is supported by Seurat by providing multiple ""Assay"", such as `counts`, `data`, and `scale.data`, which stores the raw UMI counts, column normalized data (across genes, log1p), and row normalized data (across samples, zscores). . I noticed the scaled data are stored in `adata.X` in scanpy. With this design, how can we access the raw UMI count and do re-scaling if I hope to subset the data? Looking forward your reply. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089
https://github.com/scverse/scanpy/issues/1089:636,energy efficiency,scale,scaled,636,"Subset and Rescale?; We often identify a subset of cells as irrelevant noise cells and hope to discard them during the analysis. I am a bit confused about how to perform such operations in Scanpy. It's a common practice in other analysis tool like Seurat to do ScaleData across cells so that the relative expression level is adjusted without uninteresting cells' influences. . Such operation is supported by Seurat by providing multiple ""Assay"", such as `counts`, `data`, and `scale.data`, which stores the raw UMI counts, column normalized data (across genes, log1p), and row normalized data (across samples, zscores). . I noticed the scaled data are stored in `adata.X` in scanpy. With this design, how can we access the raw UMI count and do re-scaling if I hope to subset the data? Looking forward your reply. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089
https://github.com/scverse/scanpy/issues/1089:0,integrability,Sub,Subset,0,"Subset and Rescale?; We often identify a subset of cells as irrelevant noise cells and hope to discard them during the analysis. I am a bit confused about how to perform such operations in Scanpy. It's a common practice in other analysis tool like Seurat to do ScaleData across cells so that the relative expression level is adjusted without uninteresting cells' influences. . Such operation is supported by Seurat by providing multiple ""Assay"", such as `counts`, `data`, and `scale.data`, which stores the raw UMI counts, column normalized data (across genes, log1p), and row normalized data (across samples, zscores). . I noticed the scaled data are stored in `adata.X` in scanpy. With this design, how can we access the raw UMI count and do re-scaling if I hope to subset the data? Looking forward your reply. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089
https://github.com/scverse/scanpy/issues/1089:41,integrability,sub,subset,41,"Subset and Rescale?; We often identify a subset of cells as irrelevant noise cells and hope to discard them during the analysis. I am a bit confused about how to perform such operations in Scanpy. It's a common practice in other analysis tool like Seurat to do ScaleData across cells so that the relative expression level is adjusted without uninteresting cells' influences. . Such operation is supported by Seurat by providing multiple ""Assay"", such as `counts`, `data`, and `scale.data`, which stores the raw UMI counts, column normalized data (across genes, log1p), and row normalized data (across samples, zscores). . I noticed the scaled data are stored in `adata.X` in scanpy. With this design, how can we access the raw UMI count and do re-scaling if I hope to subset the data? Looking forward your reply. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089
https://github.com/scverse/scanpy/issues/1089:768,integrability,sub,subset,768,"Subset and Rescale?; We often identify a subset of cells as irrelevant noise cells and hope to discard them during the analysis. I am a bit confused about how to perform such operations in Scanpy. It's a common practice in other analysis tool like Seurat to do ScaleData across cells so that the relative expression level is adjusted without uninteresting cells' influences. . Such operation is supported by Seurat by providing multiple ""Assay"", such as `counts`, `data`, and `scale.data`, which stores the raw UMI counts, column normalized data (across genes, log1p), and row normalized data (across samples, zscores). . I noticed the scaled data are stored in `adata.X` in scanpy. With this design, how can we access the raw UMI count and do re-scaling if I hope to subset the data? Looking forward your reply. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089
https://github.com/scverse/scanpy/issues/1089:261,modifiability,Scal,ScaleData,261,"Subset and Rescale?; We often identify a subset of cells as irrelevant noise cells and hope to discard them during the analysis. I am a bit confused about how to perform such operations in Scanpy. It's a common practice in other analysis tool like Seurat to do ScaleData across cells so that the relative expression level is adjusted without uninteresting cells' influences. . Such operation is supported by Seurat by providing multiple ""Assay"", such as `counts`, `data`, and `scale.data`, which stores the raw UMI counts, column normalized data (across genes, log1p), and row normalized data (across samples, zscores). . I noticed the scaled data are stored in `adata.X` in scanpy. With this design, how can we access the raw UMI count and do re-scaling if I hope to subset the data? Looking forward your reply. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089
https://github.com/scverse/scanpy/issues/1089:477,modifiability,scal,scale,477,"Subset and Rescale?; We often identify a subset of cells as irrelevant noise cells and hope to discard them during the analysis. I am a bit confused about how to perform such operations in Scanpy. It's a common practice in other analysis tool like Seurat to do ScaleData across cells so that the relative expression level is adjusted without uninteresting cells' influences. . Such operation is supported by Seurat by providing multiple ""Assay"", such as `counts`, `data`, and `scale.data`, which stores the raw UMI counts, column normalized data (across genes, log1p), and row normalized data (across samples, zscores). . I noticed the scaled data are stored in `adata.X` in scanpy. With this design, how can we access the raw UMI count and do re-scaling if I hope to subset the data? Looking forward your reply. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089
https://github.com/scverse/scanpy/issues/1089:636,modifiability,scal,scaled,636,"Subset and Rescale?; We often identify a subset of cells as irrelevant noise cells and hope to discard them during the analysis. I am a bit confused about how to perform such operations in Scanpy. It's a common practice in other analysis tool like Seurat to do ScaleData across cells so that the relative expression level is adjusted without uninteresting cells' influences. . Such operation is supported by Seurat by providing multiple ""Assay"", such as `counts`, `data`, and `scale.data`, which stores the raw UMI counts, column normalized data (across genes, log1p), and row normalized data (across samples, zscores). . I noticed the scaled data are stored in `adata.X` in scanpy. With this design, how can we access the raw UMI count and do re-scaling if I hope to subset the data? Looking forward your reply. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089
https://github.com/scverse/scanpy/issues/1089:747,modifiability,scal,scaling,747,"Subset and Rescale?; We often identify a subset of cells as irrelevant noise cells and hope to discard them during the analysis. I am a bit confused about how to perform such operations in Scanpy. It's a common practice in other analysis tool like Seurat to do ScaleData across cells so that the relative expression level is adjusted without uninteresting cells' influences. . Such operation is supported by Seurat by providing multiple ""Assay"", such as `counts`, `data`, and `scale.data`, which stores the raw UMI counts, column normalized data (across genes, log1p), and row normalized data (across samples, zscores). . I noticed the scaled data are stored in `adata.X` in scanpy. With this design, how can we access the raw UMI count and do re-scaling if I hope to subset the data? Looking forward your reply. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089
https://github.com/scverse/scanpy/issues/1089:162,performance,perform,perform,162,"Subset and Rescale?; We often identify a subset of cells as irrelevant noise cells and hope to discard them during the analysis. I am a bit confused about how to perform such operations in Scanpy. It's a common practice in other analysis tool like Seurat to do ScaleData across cells so that the relative expression level is adjusted without uninteresting cells' influences. . Such operation is supported by Seurat by providing multiple ""Assay"", such as `counts`, `data`, and `scale.data`, which stores the raw UMI counts, column normalized data (across genes, log1p), and row normalized data (across samples, zscores). . I noticed the scaled data are stored in `adata.X` in scanpy. With this design, how can we access the raw UMI count and do re-scaling if I hope to subset the data? Looking forward your reply. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089
https://github.com/scverse/scanpy/issues/1089:261,performance,Scale,ScaleData,261,"Subset and Rescale?; We often identify a subset of cells as irrelevant noise cells and hope to discard them during the analysis. I am a bit confused about how to perform such operations in Scanpy. It's a common practice in other analysis tool like Seurat to do ScaleData across cells so that the relative expression level is adjusted without uninteresting cells' influences. . Such operation is supported by Seurat by providing multiple ""Assay"", such as `counts`, `data`, and `scale.data`, which stores the raw UMI counts, column normalized data (across genes, log1p), and row normalized data (across samples, zscores). . I noticed the scaled data are stored in `adata.X` in scanpy. With this design, how can we access the raw UMI count and do re-scaling if I hope to subset the data? Looking forward your reply. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089
https://github.com/scverse/scanpy/issues/1089:477,performance,scale,scale,477,"Subset and Rescale?; We often identify a subset of cells as irrelevant noise cells and hope to discard them during the analysis. I am a bit confused about how to perform such operations in Scanpy. It's a common practice in other analysis tool like Seurat to do ScaleData across cells so that the relative expression level is adjusted without uninteresting cells' influences. . Such operation is supported by Seurat by providing multiple ""Assay"", such as `counts`, `data`, and `scale.data`, which stores the raw UMI counts, column normalized data (across genes, log1p), and row normalized data (across samples, zscores). . I noticed the scaled data are stored in `adata.X` in scanpy. With this design, how can we access the raw UMI count and do re-scaling if I hope to subset the data? Looking forward your reply. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089
https://github.com/scverse/scanpy/issues/1089:636,performance,scale,scaled,636,"Subset and Rescale?; We often identify a subset of cells as irrelevant noise cells and hope to discard them during the analysis. I am a bit confused about how to perform such operations in Scanpy. It's a common practice in other analysis tool like Seurat to do ScaleData across cells so that the relative expression level is adjusted without uninteresting cells' influences. . Such operation is supported by Seurat by providing multiple ""Assay"", such as `counts`, `data`, and `scale.data`, which stores the raw UMI counts, column normalized data (across genes, log1p), and row normalized data (across samples, zscores). . I noticed the scaled data are stored in `adata.X` in scanpy. With this design, how can we access the raw UMI count and do re-scaling if I hope to subset the data? Looking forward your reply. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089
https://github.com/scverse/scanpy/issues/1089:211,reliability,pra,practice,211,"Subset and Rescale?; We often identify a subset of cells as irrelevant noise cells and hope to discard them during the analysis. I am a bit confused about how to perform such operations in Scanpy. It's a common practice in other analysis tool like Seurat to do ScaleData across cells so that the relative expression level is adjusted without uninteresting cells' influences. . Such operation is supported by Seurat by providing multiple ""Assay"", such as `counts`, `data`, and `scale.data`, which stores the raw UMI counts, column normalized data (across genes, log1p), and row normalized data (across samples, zscores). . I noticed the scaled data are stored in `adata.X` in scanpy. With this design, how can we access the raw UMI count and do re-scaling if I hope to subset the data? Looking forward your reply. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089
https://github.com/scverse/scanpy/issues/1089:30,security,ident,identify,30,"Subset and Rescale?; We often identify a subset of cells as irrelevant noise cells and hope to discard them during the analysis. I am a bit confused about how to perform such operations in Scanpy. It's a common practice in other analysis tool like Seurat to do ScaleData across cells so that the relative expression level is adjusted without uninteresting cells' influences. . Such operation is supported by Seurat by providing multiple ""Assay"", such as `counts`, `data`, and `scale.data`, which stores the raw UMI counts, column normalized data (across genes, log1p), and row normalized data (across samples, zscores). . I noticed the scaled data are stored in `adata.X` in scanpy. With this design, how can we access the raw UMI count and do re-scaling if I hope to subset the data? Looking forward your reply. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089
https://github.com/scverse/scanpy/issues/1089:712,security,access,access,712,"Subset and Rescale?; We often identify a subset of cells as irrelevant noise cells and hope to discard them during the analysis. I am a bit confused about how to perform such operations in Scanpy. It's a common practice in other analysis tool like Seurat to do ScaleData across cells so that the relative expression level is adjusted without uninteresting cells' influences. . Such operation is supported by Seurat by providing multiple ""Assay"", such as `counts`, `data`, and `scale.data`, which stores the raw UMI counts, column normalized data (across genes, log1p), and row normalized data (across samples, zscores). . I noticed the scaled data are stored in `adata.X` in scanpy. With this design, how can we access the raw UMI count and do re-scaling if I hope to subset the data? Looking forward your reply. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089
https://github.com/scverse/scanpy/issues/1089:162,usability,perform,perform,162,"Subset and Rescale?; We often identify a subset of cells as irrelevant noise cells and hope to discard them during the analysis. I am a bit confused about how to perform such operations in Scanpy. It's a common practice in other analysis tool like Seurat to do ScaleData across cells so that the relative expression level is adjusted without uninteresting cells' influences. . Such operation is supported by Seurat by providing multiple ""Assay"", such as `counts`, `data`, and `scale.data`, which stores the raw UMI counts, column normalized data (across genes, log1p), and row normalized data (across samples, zscores). . I noticed the scaled data are stored in `adata.X` in scanpy. With this design, how can we access the raw UMI count and do re-scaling if I hope to subset the data? Looking forward your reply. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089
https://github.com/scverse/scanpy/issues/1089:238,usability,tool,tool,238,"Subset and Rescale?; We often identify a subset of cells as irrelevant noise cells and hope to discard them during the analysis. I am a bit confused about how to perform such operations in Scanpy. It's a common practice in other analysis tool like Seurat to do ScaleData across cells so that the relative expression level is adjusted without uninteresting cells' influences. . Such operation is supported by Seurat by providing multiple ""Assay"", such as `counts`, `data`, and `scale.data`, which stores the raw UMI counts, column normalized data (across genes, log1p), and row normalized data (across samples, zscores). . I noticed the scaled data are stored in `adata.X` in scanpy. With this design, how can we access the raw UMI count and do re-scaling if I hope to subset the data? Looking forward your reply. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089
https://github.com/scverse/scanpy/issues/1089:395,usability,support,supported,395,"Subset and Rescale?; We often identify a subset of cells as irrelevant noise cells and hope to discard them during the analysis. I am a bit confused about how to perform such operations in Scanpy. It's a common practice in other analysis tool like Seurat to do ScaleData across cells so that the relative expression level is adjusted without uninteresting cells' influences. . Such operation is supported by Seurat by providing multiple ""Assay"", such as `counts`, `data`, and `scale.data`, which stores the raw UMI counts, column normalized data (across genes, log1p), and row normalized data (across samples, zscores). . I noticed the scaled data are stored in `adata.X` in scanpy. With this design, how can we access the raw UMI count and do re-scaling if I hope to subset the data? Looking forward your reply. Thanks.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1089
https://github.com/scverse/scanpy/pull/1090:865,availability,down,down,865,"Matplotlib v3.2 fixes; Matplotlib 3.2 seems to have broken a number of our tests. This is me trying to update them, though I've had trouble reproducing figures compared with travis in the past. # Heatmaps. For heatmaps, the update was real bad:. ![blurry_heatmap](https://user-images.githubusercontent.com/8238804/76190007-23651200-6230-11ea-9912-d42dbbe76eb9.png). # Violin plots. Violin plots have changed as well, but I think it's for the better. They seem less likely to show density where there are no data points. In practice, where `n_genes` < 1000 was used as a cutoff, this looks like:. ![new_violin](https://user-images.githubusercontent.com/8238804/76190453-1eed2900-6231-11ea-9a6b-880ebda71a88.png). Axis ticks also changed due to this. # Everything else. For everything else that changed, I couldn't tell the difference. I think plots just moved up or down a bit, and that made them report as changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1090
https://github.com/scverse/scanpy/pull/1090:103,deployability,updat,update,103,"Matplotlib v3.2 fixes; Matplotlib 3.2 seems to have broken a number of our tests. This is me trying to update them, though I've had trouble reproducing figures compared with travis in the past. # Heatmaps. For heatmaps, the update was real bad:. ![blurry_heatmap](https://user-images.githubusercontent.com/8238804/76190007-23651200-6230-11ea-9912-d42dbbe76eb9.png). # Violin plots. Violin plots have changed as well, but I think it's for the better. They seem less likely to show density where there are no data points. In practice, where `n_genes` < 1000 was used as a cutoff, this looks like:. ![new_violin](https://user-images.githubusercontent.com/8238804/76190453-1eed2900-6231-11ea-9a6b-880ebda71a88.png). Axis ticks also changed due to this. # Everything else. For everything else that changed, I couldn't tell the difference. I think plots just moved up or down a bit, and that made them report as changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1090
https://github.com/scverse/scanpy/pull/1090:224,deployability,updat,update,224,"Matplotlib v3.2 fixes; Matplotlib 3.2 seems to have broken a number of our tests. This is me trying to update them, though I've had trouble reproducing figures compared with travis in the past. # Heatmaps. For heatmaps, the update was real bad:. ![blurry_heatmap](https://user-images.githubusercontent.com/8238804/76190007-23651200-6230-11ea-9912-d42dbbe76eb9.png). # Violin plots. Violin plots have changed as well, but I think it's for the better. They seem less likely to show density where there are no data points. In practice, where `n_genes` < 1000 was used as a cutoff, this looks like:. ![new_violin](https://user-images.githubusercontent.com/8238804/76190453-1eed2900-6231-11ea-9a6b-880ebda71a88.png). Axis ticks also changed due to this. # Everything else. For everything else that changed, I couldn't tell the difference. I think plots just moved up or down a bit, and that made them report as changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1090
https://github.com/scverse/scanpy/pull/1090:196,energy efficiency,Heat,Heatmaps,196,"Matplotlib v3.2 fixes; Matplotlib 3.2 seems to have broken a number of our tests. This is me trying to update them, though I've had trouble reproducing figures compared with travis in the past. # Heatmaps. For heatmaps, the update was real bad:. ![blurry_heatmap](https://user-images.githubusercontent.com/8238804/76190007-23651200-6230-11ea-9912-d42dbbe76eb9.png). # Violin plots. Violin plots have changed as well, but I think it's for the better. They seem less likely to show density where there are no data points. In practice, where `n_genes` < 1000 was used as a cutoff, this looks like:. ![new_violin](https://user-images.githubusercontent.com/8238804/76190453-1eed2900-6231-11ea-9a6b-880ebda71a88.png). Axis ticks also changed due to this. # Everything else. For everything else that changed, I couldn't tell the difference. I think plots just moved up or down a bit, and that made them report as changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1090
https://github.com/scverse/scanpy/pull/1090:210,energy efficiency,heat,heatmaps,210,"Matplotlib v3.2 fixes; Matplotlib 3.2 seems to have broken a number of our tests. This is me trying to update them, though I've had trouble reproducing figures compared with travis in the past. # Heatmaps. For heatmaps, the update was real bad:. ![blurry_heatmap](https://user-images.githubusercontent.com/8238804/76190007-23651200-6230-11ea-9912-d42dbbe76eb9.png). # Violin plots. Violin plots have changed as well, but I think it's for the better. They seem less likely to show density where there are no data points. In practice, where `n_genes` < 1000 was used as a cutoff, this looks like:. ![new_violin](https://user-images.githubusercontent.com/8238804/76190453-1eed2900-6231-11ea-9a6b-880ebda71a88.png). Axis ticks also changed due to this. # Everything else. For everything else that changed, I couldn't tell the difference. I think plots just moved up or down a bit, and that made them report as changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1090
https://github.com/scverse/scanpy/pull/1090:523,reliability,pra,practice,523,"Matplotlib v3.2 fixes; Matplotlib 3.2 seems to have broken a number of our tests. This is me trying to update them, though I've had trouble reproducing figures compared with travis in the past. # Heatmaps. For heatmaps, the update was real bad:. ![blurry_heatmap](https://user-images.githubusercontent.com/8238804/76190007-23651200-6230-11ea-9912-d42dbbe76eb9.png). # Violin plots. Violin plots have changed as well, but I think it's for the better. They seem less likely to show density where there are no data points. In practice, where `n_genes` < 1000 was used as a cutoff, this looks like:. ![new_violin](https://user-images.githubusercontent.com/8238804/76190453-1eed2900-6231-11ea-9a6b-880ebda71a88.png). Axis ticks also changed due to this. # Everything else. For everything else that changed, I couldn't tell the difference. I think plots just moved up or down a bit, and that made them report as changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1090
https://github.com/scverse/scanpy/pull/1090:75,safety,test,tests,75,"Matplotlib v3.2 fixes; Matplotlib 3.2 seems to have broken a number of our tests. This is me trying to update them, though I've had trouble reproducing figures compared with travis in the past. # Heatmaps. For heatmaps, the update was real bad:. ![blurry_heatmap](https://user-images.githubusercontent.com/8238804/76190007-23651200-6230-11ea-9912-d42dbbe76eb9.png). # Violin plots. Violin plots have changed as well, but I think it's for the better. They seem less likely to show density where there are no data points. In practice, where `n_genes` < 1000 was used as a cutoff, this looks like:. ![new_violin](https://user-images.githubusercontent.com/8238804/76190453-1eed2900-6231-11ea-9a6b-880ebda71a88.png). Axis ticks also changed due to this. # Everything else. For everything else that changed, I couldn't tell the difference. I think plots just moved up or down a bit, and that made them report as changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1090
https://github.com/scverse/scanpy/pull/1090:103,safety,updat,update,103,"Matplotlib v3.2 fixes; Matplotlib 3.2 seems to have broken a number of our tests. This is me trying to update them, though I've had trouble reproducing figures compared with travis in the past. # Heatmaps. For heatmaps, the update was real bad:. ![blurry_heatmap](https://user-images.githubusercontent.com/8238804/76190007-23651200-6230-11ea-9912-d42dbbe76eb9.png). # Violin plots. Violin plots have changed as well, but I think it's for the better. They seem less likely to show density where there are no data points. In practice, where `n_genes` < 1000 was used as a cutoff, this looks like:. ![new_violin](https://user-images.githubusercontent.com/8238804/76190453-1eed2900-6231-11ea-9a6b-880ebda71a88.png). Axis ticks also changed due to this. # Everything else. For everything else that changed, I couldn't tell the difference. I think plots just moved up or down a bit, and that made them report as changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1090
https://github.com/scverse/scanpy/pull/1090:224,safety,updat,update,224,"Matplotlib v3.2 fixes; Matplotlib 3.2 seems to have broken a number of our tests. This is me trying to update them, though I've had trouble reproducing figures compared with travis in the past. # Heatmaps. For heatmaps, the update was real bad:. ![blurry_heatmap](https://user-images.githubusercontent.com/8238804/76190007-23651200-6230-11ea-9912-d42dbbe76eb9.png). # Violin plots. Violin plots have changed as well, but I think it's for the better. They seem less likely to show density where there are no data points. In practice, where `n_genes` < 1000 was used as a cutoff, this looks like:. ![new_violin](https://user-images.githubusercontent.com/8238804/76190453-1eed2900-6231-11ea-9a6b-880ebda71a88.png). Axis ticks also changed due to this. # Everything else. For everything else that changed, I couldn't tell the difference. I think plots just moved up or down a bit, and that made them report as changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1090
https://github.com/scverse/scanpy/pull/1090:103,security,updat,update,103,"Matplotlib v3.2 fixes; Matplotlib 3.2 seems to have broken a number of our tests. This is me trying to update them, though I've had trouble reproducing figures compared with travis in the past. # Heatmaps. For heatmaps, the update was real bad:. ![blurry_heatmap](https://user-images.githubusercontent.com/8238804/76190007-23651200-6230-11ea-9912-d42dbbe76eb9.png). # Violin plots. Violin plots have changed as well, but I think it's for the better. They seem less likely to show density where there are no data points. In practice, where `n_genes` < 1000 was used as a cutoff, this looks like:. ![new_violin](https://user-images.githubusercontent.com/8238804/76190453-1eed2900-6231-11ea-9a6b-880ebda71a88.png). Axis ticks also changed due to this. # Everything else. For everything else that changed, I couldn't tell the difference. I think plots just moved up or down a bit, and that made them report as changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1090
https://github.com/scverse/scanpy/pull/1090:224,security,updat,update,224,"Matplotlib v3.2 fixes; Matplotlib 3.2 seems to have broken a number of our tests. This is me trying to update them, though I've had trouble reproducing figures compared with travis in the past. # Heatmaps. For heatmaps, the update was real bad:. ![blurry_heatmap](https://user-images.githubusercontent.com/8238804/76190007-23651200-6230-11ea-9912-d42dbbe76eb9.png). # Violin plots. Violin plots have changed as well, but I think it's for the better. They seem less likely to show density where there are no data points. In practice, where `n_genes` < 1000 was used as a cutoff, this looks like:. ![new_violin](https://user-images.githubusercontent.com/8238804/76190453-1eed2900-6231-11ea-9a6b-880ebda71a88.png). Axis ticks also changed due to this. # Everything else. For everything else that changed, I couldn't tell the difference. I think plots just moved up or down a bit, and that made them report as changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1090
https://github.com/scverse/scanpy/pull/1090:75,testability,test,tests,75,"Matplotlib v3.2 fixes; Matplotlib 3.2 seems to have broken a number of our tests. This is me trying to update them, though I've had trouble reproducing figures compared with travis in the past. # Heatmaps. For heatmaps, the update was real bad:. ![blurry_heatmap](https://user-images.githubusercontent.com/8238804/76190007-23651200-6230-11ea-9912-d42dbbe76eb9.png). # Violin plots. Violin plots have changed as well, but I think it's for the better. They seem less likely to show density where there are no data points. In practice, where `n_genes` < 1000 was used as a cutoff, this looks like:. ![new_violin](https://user-images.githubusercontent.com/8238804/76190453-1eed2900-6231-11ea-9a6b-880ebda71a88.png). Axis ticks also changed due to this. # Everything else. For everything else that changed, I couldn't tell the difference. I think plots just moved up or down a bit, and that made them report as changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1090
https://github.com/scverse/scanpy/pull/1090:272,usability,user,user-images,272,"Matplotlib v3.2 fixes; Matplotlib 3.2 seems to have broken a number of our tests. This is me trying to update them, though I've had trouble reproducing figures compared with travis in the past. # Heatmaps. For heatmaps, the update was real bad:. ![blurry_heatmap](https://user-images.githubusercontent.com/8238804/76190007-23651200-6230-11ea-9912-d42dbbe76eb9.png). # Violin plots. Violin plots have changed as well, but I think it's for the better. They seem less likely to show density where there are no data points. In practice, where `n_genes` < 1000 was used as a cutoff, this looks like:. ![new_violin](https://user-images.githubusercontent.com/8238804/76190453-1eed2900-6231-11ea-9a6b-880ebda71a88.png). Axis ticks also changed due to this. # Everything else. For everything else that changed, I couldn't tell the difference. I think plots just moved up or down a bit, and that made them report as changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1090
https://github.com/scverse/scanpy/pull/1090:618,usability,user,user-images,618,"Matplotlib v3.2 fixes; Matplotlib 3.2 seems to have broken a number of our tests. This is me trying to update them, though I've had trouble reproducing figures compared with travis in the past. # Heatmaps. For heatmaps, the update was real bad:. ![blurry_heatmap](https://user-images.githubusercontent.com/8238804/76190007-23651200-6230-11ea-9912-d42dbbe76eb9.png). # Violin plots. Violin plots have changed as well, but I think it's for the better. They seem less likely to show density where there are no data points. In practice, where `n_genes` < 1000 was used as a cutoff, this looks like:. ![new_violin](https://user-images.githubusercontent.com/8238804/76190453-1eed2900-6231-11ea-9a6b-880ebda71a88.png). Axis ticks also changed due to this. # Everything else. For everything else that changed, I couldn't tell the difference. I think plots just moved up or down a bit, and that made them report as changed.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1090
https://github.com/scverse/scanpy/pull/1091:21,deployability,Updat,Update,21,Harmony time series; Update to `sce.external.tl._harmony_timeseries.py`. Exposing parameters passed to `harmony.core.augmented_affinity_matrix` function. Linked to issue reported [here](https://github.com/dpeerlab/Harmony/issues/11).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1091
https://github.com/scverse/scanpy/pull/1091:112,energy efficiency,core,core,112,Harmony time series; Update to `sce.external.tl._harmony_timeseries.py`. Exposing parameters passed to `harmony.core.augmented_affinity_matrix` function. Linked to issue reported [here](https://github.com/dpeerlab/Harmony/issues/11).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1091
https://github.com/scverse/scanpy/pull/1091:82,modifiability,paramet,parameters,82,Harmony time series; Update to `sce.external.tl._harmony_timeseries.py`. Exposing parameters passed to `harmony.core.augmented_affinity_matrix` function. Linked to issue reported [here](https://github.com/dpeerlab/Harmony/issues/11).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1091
https://github.com/scverse/scanpy/pull/1091:8,performance,time,time,8,Harmony time series; Update to `sce.external.tl._harmony_timeseries.py`. Exposing parameters passed to `harmony.core.augmented_affinity_matrix` function. Linked to issue reported [here](https://github.com/dpeerlab/Harmony/issues/11).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1091
https://github.com/scverse/scanpy/pull/1091:21,safety,Updat,Update,21,Harmony time series; Update to `sce.external.tl._harmony_timeseries.py`. Exposing parameters passed to `harmony.core.augmented_affinity_matrix` function. Linked to issue reported [here](https://github.com/dpeerlab/Harmony/issues/11).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1091
https://github.com/scverse/scanpy/pull/1091:21,security,Updat,Update,21,Harmony time series; Update to `sce.external.tl._harmony_timeseries.py`. Exposing parameters passed to `harmony.core.augmented_affinity_matrix` function. Linked to issue reported [here](https://github.com/dpeerlab/Harmony/issues/11).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1091
https://github.com/scverse/scanpy/pull/1091:73,security,Expos,Exposing,73,Harmony time series; Update to `sce.external.tl._harmony_timeseries.py`. Exposing parameters passed to `harmony.core.augmented_affinity_matrix` function. Linked to issue reported [here](https://github.com/dpeerlab/Harmony/issues/11).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1091
https://github.com/scverse/scanpy/issues/1092:139,availability,replic,replicates,139,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:474,availability,error,error,474,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:106,deployability,integr,integrate,106,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:650,deployability,modul,module,650,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:734,deployability,modul,module,734,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:987,deployability,instal,installing,987,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:1040,deployability,continu,continue,1040,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:106,integrability,integr,integrate,106,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:106,interoperability,integr,integrate,106,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:60,modifiability,maintain,maintaining,60,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:106,modifiability,integr,integrate,106,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:650,modifiability,modul,module,650,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:734,modifiability,modul,module,734,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:1002,modifiability,pac,package,1002,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:474,performance,error,error,474,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:106,reliability,integr,integrate,106,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:60,safety,maintain,maintaining,60,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:474,safety,error,error,474,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:623,safety,input,input-,623,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:650,safety,modul,module,650,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:734,safety,modul,module,734,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:106,security,integr,integrate,106,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:106,testability,integr,integrate,106,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:579,testability,Trace,Traceback,579,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:86,usability,tool,tool,86,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:474,usability,error,error,474,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:623,usability,input,input-,623,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:749,usability,tool,tools,749,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1092:891,usability,learn,learn,891,"No attribute 'ingest'; Hello,. Thank you for developing and maintaining such a useful tool! I'm trying to integrate two data sets, they're replicates of the same condition. . ```. var_names = adata_002.var_names.intersection(adata_003.var_names). adata_002 = adata_002[:, var_names]. adata_003 = adata_003[:, var_names]. sc.pp.pca(adata_002). sc.pp.neighbors(adata_002). sc.tl.umap(adata_002). sc.tl.ingest(adata_003, adata_002, obs='louvain'). ```. And I got the following error:. ```. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-42-b3f5427509ba> in <module>. ----> 1 sc.tl.ingest(adata_003, adata_002, obs='louvain'). AttributeError: module 'scanpy.tools' has no attribute 'ingest'. ```. scanpy==1.4.4.post1 anndata==0.6.22.post1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. I've already tried installing the package both with conda and pip and I continue having the same issue. . I would really appreciate your comments and suggestions. . Sara.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1092
https://github.com/scverse/scanpy/issues/1094:21,availability,error,error,21,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:99,availability,error,error,99,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:365,availability,error,error,365,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:443,availability,error,error,443,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:1319,availability,Error,Error,1319," the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:123,deployability,modul,module,123,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:467,deployability,modul,module,467,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:1017,deployability,log,logging,1017,"error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:1568,deployability,modul,module,1568,"n is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_siz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:3452,deployability,modul,module,3452,"lor, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. ~/.conda/envs/single_cell/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:3523,deployability,Version,Versions,3523,"lor, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. ~/.conda/envs/single_cell/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:3556,deployability,log,logging,3556,"lor, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. ~/.conda/envs/single_cell/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:2921,energy efficiency,draw,draw,2921,"lor, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. ~/.conda/envs/single_cell/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:3016,energy efficiency,draw,drawing,3016,"lor, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. ~/.conda/envs/single_cell/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:3523,integrability,Version,Versions,3523,"lor, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. ~/.conda/envs/single_cell/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:123,modifiability,modul,module,123,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:467,modifiability,modul,module,467,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:1568,modifiability,modul,module,1568,"n is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_siz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:1692,modifiability,pac,packages,1692,"w: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, col",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:2326,modifiability,pac,packages,2326,"t in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. ~/.conda/envs/single_cell/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it global",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:2998,modifiability,pac,packages,2998,"lor, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. ~/.conda/envs/single_cell/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:3350,modifiability,scal,scalar,3350,"lor, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. ~/.conda/envs/single_cell/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:3452,modifiability,modul,module,3452,"lor, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. ~/.conda/envs/single_cell/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:3523,modifiability,Version,Versions,3523,"lor, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. ~/.conda/envs/single_cell/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:21,performance,error,error,21,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:99,performance,error,error,99,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:365,performance,error,error,365,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:443,performance,error,error,443,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:1319,performance,Error,Error,1319," the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:3007,performance,network,networkx,3007,"lor, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. ~/.conda/envs/single_cell/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:21,safety,error,error,21,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:99,safety,error,error,99,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:123,safety,modul,module,123,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:365,safety,error,error,365,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:443,safety,error,error,443,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:467,safety,modul,module,467,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:1017,safety,log,logging,1017,"error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:1319,safety,Error,Error,1319," the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:1541,safety,input,input-,1541,"ugh matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:1568,safety,modul,module,1568,"n is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_siz",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:3452,safety,modul,module,3452,"lor, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. ~/.conda/envs/single_cell/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:3556,safety,log,logging,3556,"lor, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. ~/.conda/envs/single_cell/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:1017,security,log,logging,1017,"error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:3007,security,network,networkx,3007,"lor, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. ~/.conda/envs/single_cell/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:3556,security,log,logging,3556,"lor, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. ~/.conda/envs/single_cell/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:1017,testability,log,logging,1017,"error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:1497,testability,Trace,Traceback,1497,"tribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:2801,testability,simpl,simplefilter,2801,"lor, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. ~/.conda/envs/single_cell/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:3556,testability,log,logging,3556,"lor, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. ~/.conda/envs/single_cell/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:21,usability,error,error,21,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:99,usability,error,error,99,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:215,usability,document,documentation,215,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:285,usability,clear,clear,285,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:365,usability,error,error,365,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:443,usability,error,error,443,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:559,usability,document,documentation,559,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:621,usability,minim,minimal,621,"I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated; <!-- Please give a clear and concise description of what the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, ar",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:1319,usability,Error,Error,1319," the bug is: -->. ... I am running into an error when I try to create PAGA plots using the pl.paga() function. I get the error: ""AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike' "". After looking through matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/s",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:1541,usability,input,input-,1541,"ugh matplotlib documentation is_numlike appears to be deprecated. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. import scanpy.external as sce. import pandas as pd. import numpy as np. import matplotlib as mpl. import matplotlib.pyplot as pl. from scipy.stats import mode. from collections import Counter. import loompy. sc.settings.verbosity = 3. sc.set_figure_params(color_map='viridis'). sc.logging.print_versions(). adata_sim = sc.tl.sim('krumsiek11'). adata_sim.var_names_make_unique(). sc.pp.neighbors(adata_sim, n_neighbors=7, n_pcs=20). sc.tl.louvain(adata_sim). sc.tl.paga(adata_sim). sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ... ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-10-973f72fa2eb5> in <module>. ----> 1 sc.pl.paga(adata_sim, color=['louvain'], edge_width_scale=0.2, threshold=0.2). ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in paga(adata, threshold, color, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:2801,usability,simpl,simplefilter,2801,"lor, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. ~/.conda/envs/single_cell/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:3259,usability,user,user,3259,"lor, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. ~/.conda/envs/single_cell/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1094:3678,usability,learn,learn,3678,"lor, layout, layout_kwds, init_pos, root, labels, single_component, solid_edges, dashed_edges, transitions, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, min_edge_width, max_edge_width, arrowsize, title, left_margin, random_state, pos, normalize_to_color, cmap, cax, colorbar, cb_kwds, frameon, add_pos, export_to_gexf, use_raw, colors, groups, plot, show, save, ax). 541 single_component=single_component,. 542 arrowsize=arrowsize,. --> 543 pos=pos,. 544 ). 545 if colorbars[icolor]:. ~/.local/lib/python3.6/site-packages/scanpy/plotting/_tools/paga.py in _paga_graph(adata, ax, solid_edges, dashed_edges, adjacency_solid, adjacency_dashed, transitions, threshold, root, colors, labels, fontsize, fontweight, fontoutline, text_kwds, node_size_scale, node_size_power, edge_width_scale, normalize_to_color, title, pos, cmap, frameon, min_edge_width, max_edge_width, export_to_gexf, colorbar, use_raw, cb_kwds, single_component, arrowsize). 756 with warnings.catch_warnings():. 757 warnings.simplefilter(""ignore""). --> 758 nx.draw_networkx_edges(nx_g_solid, pos, ax=ax, width=widths, edge_color='black'). 759 # draw directed edges. 760 else:. ~/.conda/envs/single_cell/lib/python3.6/site-packages/networkx/drawing/nx_pylab.py in draw_networkx_edges(G, pos, edgelist, width, edge_color, style, alpha, arrowstyle, arrowsize, edge_cmap, edge_vmin, edge_vmax, ax, arrows, label, node_size, nodelist, node_shape, **kwds). 609 # value globally, since the user can instead provide per-edge alphas. 610 # now. Only set it globally if provided as a scalar. --> 611 if cb.is_numlike(alpha):. 612 edge_collection.set_alpha(alpha). 613 . AttributeError: module 'matplotlib.cbook' has no attribute 'is_numlike'. ... ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.7.1 louvain==0.6.1. > ...",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1094
https://github.com/scverse/scanpy/issues/1095:124,availability,cluster,clustering,124,"""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca'].""; Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):. File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>. sc.pl.umap(adata). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap. return embedding(adata, 'umap', **kwargs). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding. data_points, components_list = _get_data_points(adata, basis, projection, components). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points. f""Could not find entry in `obsm` for '{basis}'.\n"". KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata. Out[34]: . AnnData object with n_obs × n_vars = 1858 × 366 . obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'log1p', 'pca', 'neighbors', 'leiden'. obsm: 'X_pca'. varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1095:277,availability,error,error,277,"""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca'].""; Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):. File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>. sc.pl.umap(adata). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap. return embedding(adata, 'umap', **kwargs). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding. data_points, components_list = _get_data_points(adata, basis, projection, components). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points. f""Could not find entry in `obsm` for '{basis}'.\n"". KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata. Out[34]: . AnnData object with n_obs × n_vars = 1858 × 366 . obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'log1p', 'pca', 'neighbors', 'leiden'. obsm: 'X_pca'. varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1095:124,deployability,cluster,clustering,124,"""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca'].""; Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):. File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>. sc.pl.umap(adata). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap. return embedding(adata, 'umap', **kwargs). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding. data_points, components_list = _get_data_points(adata, basis, projection, components). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points. f""Could not find entry in `obsm` for '{basis}'.\n"". KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata. Out[34]: . AnnData object with n_obs × n_vars = 1858 × 366 . obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'log1p', 'pca', 'neighbors', 'leiden'. obsm: 'X_pca'. varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1095:143,deployability,pipelin,pipeline,143,"""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca'].""; Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):. File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>. sc.pl.umap(adata). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap. return embedding(adata, 'umap', **kwargs). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding. data_points, components_list = _get_data_points(adata, basis, projection, components). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points. f""Could not find entry in `obsm` for '{basis}'.\n"". KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata. Out[34]: . AnnData object with n_obs × n_vars = 1858 × 366 . obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'log1p', 'pca', 'neighbors', 'leiden'. obsm: 'X_pca'. varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1095:253,deployability,observ,observing,253,"""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca'].""; Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):. File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>. sc.pl.umap(adata). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap. return embedding(adata, 'umap', **kwargs). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding. data_points, components_list = _get_data_points(adata, basis, projection, components). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points. f""Could not find entry in `obsm` for '{basis}'.\n"". KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata. Out[34]: . AnnData object with n_obs × n_vars = 1858 × 366 . obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'log1p', 'pca', 'neighbors', 'leiden'. obsm: 'X_pca'. varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1095:557,deployability,modul,module,557,"""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca'].""; Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):. File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>. sc.pl.umap(adata). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap. return embedding(adata, 'umap', **kwargs). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding. data_points, components_list = _get_data_points(adata, basis, projection, components). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points. f""Could not find entry in `obsm` for '{basis}'.\n"". KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata. Out[34]: . AnnData object with n_obs × n_vars = 1858 × 366 . obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'log1p', 'pca', 'neighbors', 'leiden'. obsm: 'X_pca'. varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1095:403,energy efficiency,core,core,403,"""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca'].""; Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):. File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>. sc.pl.umap(adata). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap. return embedding(adata, 'umap', **kwargs). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding. data_points, components_list = _get_data_points(adata, basis, projection, components). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points. f""Could not find entry in `obsm` for '{basis}'.\n"". KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata. Out[34]: . AnnData object with n_obs × n_vars = 1858 × 366 . obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'log1p', 'pca', 'neighbors', 'leiden'. obsm: 'X_pca'. varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1095:143,integrability,pipelin,pipeline,143,"""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca'].""; Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):. File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>. sc.pl.umap(adata). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap. return embedding(adata, 'umap', **kwargs). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding. data_points, components_list = _get_data_points(adata, basis, projection, components). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points. f""Could not find entry in `obsm` for '{basis}'.\n"". KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata. Out[34]: . AnnData object with n_obs × n_vars = 1858 × 366 . obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'log1p', 'pca', 'neighbors', 'leiden'. obsm: 'X_pca'. varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1095:977,integrability,compon,components,977,"""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca'].""; Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):. File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>. sc.pl.umap(adata). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap. return embedding(adata, 'umap', **kwargs). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding. data_points, components_list = _get_data_points(adata, basis, projection, components). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points. f""Could not find entry in `obsm` for '{basis}'.\n"". KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata. Out[34]: . AnnData object with n_obs × n_vars = 1858 × 366 . obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'log1p', 'pca', 'neighbors', 'leiden'. obsm: 'X_pca'. varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1095:977,interoperability,compon,components,977,"""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca'].""; Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):. File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>. sc.pl.umap(adata). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap. return embedding(adata, 'umap', **kwargs). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding. data_points, components_list = _get_data_points(adata, basis, projection, components). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points. f""Could not find entry in `obsm` for '{basis}'.\n"". KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata. Out[34]: . AnnData object with n_obs × n_vars = 1858 × 366 . obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'log1p', 'pca', 'neighbors', 'leiden'. obsm: 'X_pca'. varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1095:386,modifiability,pac,packages,386,"""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca'].""; Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):. File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>. sc.pl.umap(adata). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap. return embedding(adata, 'umap', **kwargs). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding. data_points, components_list = _get_data_points(adata, basis, projection, components). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points. f""Could not find entry in `obsm` for '{basis}'.\n"". KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata. Out[34]: . AnnData object with n_obs × n_vars = 1858 × 366 . obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'log1p', 'pca', 'neighbors', 'leiden'. obsm: 'X_pca'. varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1095:557,modifiability,modul,module,557,"""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca'].""; Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):. File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>. sc.pl.umap(adata). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap. return embedding(adata, 'umap', **kwargs). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding. data_points, components_list = _get_data_points(adata, basis, projection, components). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points. f""Could not find entry in `obsm` for '{basis}'.\n"". KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata. Out[34]: . AnnData object with n_obs × n_vars = 1858 × 366 . obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'log1p', 'pca', 'neighbors', 'leiden'. obsm: 'X_pca'. varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1095:651,modifiability,pac,packages,651,"""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca'].""; Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):. File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>. sc.pl.umap(adata). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap. return embedding(adata, 'umap', **kwargs). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding. data_points, components_list = _get_data_points(adata, basis, projection, components). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points. f""Could not find entry in `obsm` for '{basis}'.\n"". KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata. Out[34]: . AnnData object with n_obs × n_vars = 1858 × 366 . obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'log1p', 'pca', 'neighbors', 'leiden'. obsm: 'X_pca'. varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1095:829,modifiability,pac,packages,829,"""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca'].""; Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):. File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>. sc.pl.umap(adata). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap. return embedding(adata, 'umap', **kwargs). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding. data_points, components_list = _get_data_points(adata, basis, projection, components). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points. f""Could not find entry in `obsm` for '{basis}'.\n"". KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata. Out[34]: . AnnData object with n_obs × n_vars = 1858 × 366 . obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'log1p', 'pca', 'neighbors', 'leiden'. obsm: 'X_pca'. varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1095:977,modifiability,compon,components,977,"""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca'].""; Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):. File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>. sc.pl.umap(adata). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap. return embedding(adata, 'umap', **kwargs). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding. data_points, components_list = _get_data_points(adata, basis, projection, components). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points. f""Could not find entry in `obsm` for '{basis}'.\n"". KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata. Out[34]: . AnnData object with n_obs × n_vars = 1858 × 366 . obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'log1p', 'pca', 'neighbors', 'leiden'. obsm: 'X_pca'. varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1095:1056,modifiability,pac,packages,1056,"""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca'].""; Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):. File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>. sc.pl.umap(adata). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap. return embedding(adata, 'umap', **kwargs). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding. data_points, components_list = _get_data_points(adata, basis, projection, components). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points. f""Could not find entry in `obsm` for '{basis}'.\n"". KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata. Out[34]: . AnnData object with n_obs × n_vars = 1858 × 366 . obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'log1p', 'pca', 'neighbors', 'leiden'. obsm: 'X_pca'. varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1095:277,performance,error,error,277,"""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca'].""; Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):. File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>. sc.pl.umap(adata). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap. return embedding(adata, 'umap', **kwargs). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding. data_points, components_list = _get_data_points(adata, basis, projection, components). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points. f""Could not find entry in `obsm` for '{basis}'.\n"". KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata. Out[34]: . AnnData object with n_obs × n_vars = 1858 × 366 . obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'log1p', 'pca', 'neighbors', 'leiden'. obsm: 'X_pca'. varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1095:277,safety,error,error,277,"""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca'].""; Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):. File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>. sc.pl.umap(adata). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap. return embedding(adata, 'umap', **kwargs). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding. data_points, components_list = _get_data_points(adata, basis, projection, components). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points. f""Could not find entry in `obsm` for '{basis}'.\n"". KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata. Out[34]: . AnnData object with n_obs × n_vars = 1858 × 366 . obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'log1p', 'pca', 'neighbors', 'leiden'. obsm: 'X_pca'. varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1095:520,safety,input,input-,520,"""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca'].""; Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):. File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>. sc.pl.umap(adata). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap. return embedding(adata, 'umap', **kwargs). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding. data_points, components_list = _get_data_points(adata, basis, projection, components). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points. f""Could not find entry in `obsm` for '{basis}'.\n"". KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata. Out[34]: . AnnData object with n_obs × n_vars = 1858 × 366 . obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'log1p', 'pca', 'neighbors', 'leiden'. obsm: 'X_pca'. varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1095:557,safety,modul,module,557,"""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca'].""; Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):. File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>. sc.pl.umap(adata). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap. return embedding(adata, 'umap', **kwargs). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding. data_points, components_list = _get_data_points(adata, basis, projection, components). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points. f""Could not find entry in `obsm` for '{basis}'.\n"". KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata. Out[34]: . AnnData object with n_obs × n_vars = 1858 × 366 . obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'log1p', 'pca', 'neighbors', 'leiden'. obsm: 'X_pca'. varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1095:253,testability,observ,observing,253,"""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca'].""; Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):. File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>. sc.pl.umap(adata). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap. return embedding(adata, 'umap', **kwargs). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding. data_points, components_list = _get_data_points(adata, basis, projection, components). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points. f""Could not find entry in `obsm` for '{basis}'.\n"". KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata. Out[34]: . AnnData object with n_obs × n_vars = 1858 × 366 . obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'log1p', 'pca', 'neighbors', 'leiden'. obsm: 'X_pca'. varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1095:284,testability,Trace,Traceback,284,"""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca'].""; Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):. File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>. sc.pl.umap(adata). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap. return embedding(adata, 'umap', **kwargs). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding. data_points, components_list = _get_data_points(adata, basis, projection, components). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points. f""Could not find entry in `obsm` for '{basis}'.\n"". KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata. Out[34]: . AnnData object with n_obs × n_vars = 1858 × 366 . obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'log1p', 'pca', 'neighbors', 'leiden'. obsm: 'X_pca'. varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1095:277,usability,error,error,277,"""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca'].""; Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):. File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>. sc.pl.umap(adata). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap. return embedding(adata, 'umap', **kwargs). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding. data_points, components_list = _get_data_points(adata, basis, projection, components). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points. f""Could not find entry in `obsm` for '{basis}'.\n"". KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata. Out[34]: . AnnData object with n_obs × n_vars = 1858 × 366 . obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'log1p', 'pca', 'neighbors', 'leiden'. obsm: 'X_pca'. varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1095:408,usability,interact,interactiveshell,408,"""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca'].""; Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):. File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>. sc.pl.umap(adata). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap. return embedding(adata, 'umap', **kwargs). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding. data_points, components_list = _get_data_points(adata, basis, projection, components). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points. f""Could not find entry in `obsm` for '{basis}'.\n"". KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata. Out[34]: . AnnData object with n_obs × n_vars = 1858 × 366 . obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'log1p', 'pca', 'neighbors', 'leiden'. obsm: 'X_pca'. varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1095:520,usability,input,input-,520,"""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca'].""; Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):. File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>. sc.pl.umap(adata). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap. return embedding(adata, 'umap', **kwargs). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding. data_points, components_list = _get_data_points(adata, basis, projection, components). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points. f""Could not find entry in `obsm` for '{basis}'.\n"". KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata. Out[34]: . AnnData object with n_obs × n_vars = 1858 × 366 . obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'log1p', 'pca', 'neighbors', 'leiden'. obsm: 'X_pca'. varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1095:1634,usability,user,user-images,1634,"""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca'].""; Hi,. I am trying to run the Preprocessing and clustering example pipeline in our 10x dataset and when I reach to the point of plotting the UMAP -> sc.pl.umap(adata) I started observing the following error. Traceback (most recent call last):. File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code. exec(code_obj, self.user_global_ns, self.user_ns). File ""<ipython-input-32-ccd41cdd9550>"", line 3, in <module>. sc.pl.umap(adata). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 524, in umap. return embedding(adata, 'umap', **kwargs). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 133, in embedding. data_points, components_list = _get_data_points(adata, basis, projection, components). File ""/home/jesuspenaloza/anaconda3/envs/pyrna/lib/python3.6/site-packages/scanpy/plotting/_tools/scatterplots.py"", line 646, in _get_data_points. f""Could not find entry in `obsm` for '{basis}'.\n"". KeyError: ""Could not find entry in `obsm` for 'umap'.\nAvailable keys are: ['X_pca']."". our data structure is the following . adata. Out[34]: . AnnData object with n_obs × n_vars = 1858 × 366 . obs: 'n_genes', 'percent_mito', 'n_counts', 'leiden'. var: 'gene_ids', 'feature_types', 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. uns: 'log1p', 'pca', 'neighbors', 'leiden'. obsm: 'X_pca'. varm: 'PCs'. ![image](https://user-images.githubusercontent.com/17010046/76561178-23a41e00-6479-11ea-85d5-ec6982f0bd59.png).",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1095
https://github.com/scverse/scanpy/issues/1096:0,availability,Error,Error,0,"Error calculating neighbors on sparse array with cosine metric; Downstream of https://github.com/lmcinnes/pynndescent/issues/95. Tracking this here since it breaks a multimodal example. ```python. import scanpy as sc. from scipy import sparse. # smaller examples don't replicate (i.e. n_obs < 5000). adata = sc.AnnData(X=sparse.random(5000, 100, density=0.3, format=""csr"")) . sc.pp.neighbors(adata, use_rep=""X"", metric=""cosine""). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1096
https://github.com/scverse/scanpy/issues/1096:64,availability,Down,Downstream,64,"Error calculating neighbors on sparse array with cosine metric; Downstream of https://github.com/lmcinnes/pynndescent/issues/95. Tracking this here since it breaks a multimodal example. ```python. import scanpy as sc. from scipy import sparse. # smaller examples don't replicate (i.e. n_obs < 5000). adata = sc.AnnData(X=sparse.random(5000, 100, density=0.3, format=""csr"")) . sc.pp.neighbors(adata, use_rep=""X"", metric=""cosine""). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1096
https://github.com/scverse/scanpy/issues/1096:269,availability,replic,replicate,269,"Error calculating neighbors on sparse array with cosine metric; Downstream of https://github.com/lmcinnes/pynndescent/issues/95. Tracking this here since it breaks a multimodal example. ```python. import scanpy as sc. from scipy import sparse. # smaller examples don't replicate (i.e. n_obs < 5000). adata = sc.AnnData(X=sparse.random(5000, 100, density=0.3, format=""csr"")) . sc.pp.neighbors(adata, use_rep=""X"", metric=""cosine""). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1096
https://github.com/scverse/scanpy/issues/1096:359,interoperability,format,format,359,"Error calculating neighbors on sparse array with cosine metric; Downstream of https://github.com/lmcinnes/pynndescent/issues/95. Tracking this here since it breaks a multimodal example. ```python. import scanpy as sc. from scipy import sparse. # smaller examples don't replicate (i.e. n_obs < 5000). adata = sc.AnnData(X=sparse.random(5000, 100, density=0.3, format=""csr"")) . sc.pp.neighbors(adata, use_rep=""X"", metric=""cosine""). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1096
https://github.com/scverse/scanpy/issues/1096:0,performance,Error,Error,0,"Error calculating neighbors on sparse array with cosine metric; Downstream of https://github.com/lmcinnes/pynndescent/issues/95. Tracking this here since it breaks a multimodal example. ```python. import scanpy as sc. from scipy import sparse. # smaller examples don't replicate (i.e. n_obs < 5000). adata = sc.AnnData(X=sparse.random(5000, 100, density=0.3, format=""csr"")) . sc.pp.neighbors(adata, use_rep=""X"", metric=""cosine""). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1096
https://github.com/scverse/scanpy/issues/1096:0,safety,Error,Error,0,"Error calculating neighbors on sparse array with cosine metric; Downstream of https://github.com/lmcinnes/pynndescent/issues/95. Tracking this here since it breaks a multimodal example. ```python. import scanpy as sc. from scipy import sparse. # smaller examples don't replicate (i.e. n_obs < 5000). adata = sc.AnnData(X=sparse.random(5000, 100, density=0.3, format=""csr"")) . sc.pp.neighbors(adata, use_rep=""X"", metric=""cosine""). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1096
https://github.com/scverse/scanpy/issues/1096:0,usability,Error,Error,0,"Error calculating neighbors on sparse array with cosine metric; Downstream of https://github.com/lmcinnes/pynndescent/issues/95. Tracking this here since it breaks a multimodal example. ```python. import scanpy as sc. from scipy import sparse. # smaller examples don't replicate (i.e. n_obs < 5000). adata = sc.AnnData(X=sparse.random(5000, 100, density=0.3, format=""csr"")) . sc.pp.neighbors(adata, use_rep=""X"", metric=""cosine""). ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1096
https://github.com/scverse/scanpy/issues/1097:197,integrability,filter,filtered,197,"sc.pl.scatter does not find gene names in adata.raw; When I tried to use `sc.pl.scatter` with `use_raw=True` to plot genes whose names are found in adata.raw, but not adata (because they have been filtered out during processing), I got:. `ValueError: 'x', 'y', and potential 'color' inputs must all come from either '.obs' or '.var'`. Plotting genes found in both adata and adata.raw works. Plotting the troublesome genes with `sc.pl.umap` with `use_raw=True` also works. So it seems like a specific issue with the scatter plot function. Am I overlooking anything? Thanks in advance! .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1097
https://github.com/scverse/scanpy/issues/1097:491,interoperability,specif,specific,491,"sc.pl.scatter does not find gene names in adata.raw; When I tried to use `sc.pl.scatter` with `use_raw=True` to plot genes whose names are found in adata.raw, but not adata (because they have been filtered out during processing), I got:. `ValueError: 'x', 'y', and potential 'color' inputs must all come from either '.obs' or '.var'`. Plotting genes found in both adata and adata.raw works. Plotting the troublesome genes with `sc.pl.umap` with `use_raw=True` also works. So it seems like a specific issue with the scatter plot function. Am I overlooking anything? Thanks in advance! .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1097
https://github.com/scverse/scanpy/issues/1097:14,reliability,doe,does,14,"sc.pl.scatter does not find gene names in adata.raw; When I tried to use `sc.pl.scatter` with `use_raw=True` to plot genes whose names are found in adata.raw, but not adata (because they have been filtered out during processing), I got:. `ValueError: 'x', 'y', and potential 'color' inputs must all come from either '.obs' or '.var'`. Plotting genes found in both adata and adata.raw works. Plotting the troublesome genes with `sc.pl.umap` with `use_raw=True` also works. So it seems like a specific issue with the scatter plot function. Am I overlooking anything? Thanks in advance! .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1097
https://github.com/scverse/scanpy/issues/1097:283,safety,input,inputs,283,"sc.pl.scatter does not find gene names in adata.raw; When I tried to use `sc.pl.scatter` with `use_raw=True` to plot genes whose names are found in adata.raw, but not adata (because they have been filtered out during processing), I got:. `ValueError: 'x', 'y', and potential 'color' inputs must all come from either '.obs' or '.var'`. Plotting genes found in both adata and adata.raw works. Plotting the troublesome genes with `sc.pl.umap` with `use_raw=True` also works. So it seems like a specific issue with the scatter plot function. Am I overlooking anything? Thanks in advance! .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1097
https://github.com/scverse/scanpy/issues/1097:283,usability,input,inputs,283,"sc.pl.scatter does not find gene names in adata.raw; When I tried to use `sc.pl.scatter` with `use_raw=True` to plot genes whose names are found in adata.raw, but not adata (because they have been filtered out during processing), I got:. `ValueError: 'x', 'y', and potential 'color' inputs must all come from either '.obs' or '.var'`. Plotting genes found in both adata and adata.raw works. Plotting the troublesome genes with `sc.pl.umap` with `use_raw=True` also works. So it seems like a specific issue with the scatter plot function. Am I overlooking anything? Thanks in advance! .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1097
https://github.com/scverse/scanpy/issues/1098:247,availability,cluster,cluster,247,"scanpy heatmap groupby leiden colobar not aligning to the heatmap; Hi I did not have problems before till now. when I execute this function in Scanpy:. sc.pl.heatmap(adata, marker_genes_dict, groupby='leiden'). The colorbars for individual leiden cluster do not align to the heatmap.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1098
https://github.com/scverse/scanpy/issues/1098:247,deployability,cluster,cluster,247,"scanpy heatmap groupby leiden colobar not aligning to the heatmap; Hi I did not have problems before till now. when I execute this function in Scanpy:. sc.pl.heatmap(adata, marker_genes_dict, groupby='leiden'). The colorbars for individual leiden cluster do not align to the heatmap.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1098
https://github.com/scverse/scanpy/issues/1098:7,energy efficiency,heat,heatmap,7,"scanpy heatmap groupby leiden colobar not aligning to the heatmap; Hi I did not have problems before till now. when I execute this function in Scanpy:. sc.pl.heatmap(adata, marker_genes_dict, groupby='leiden'). The colorbars for individual leiden cluster do not align to the heatmap.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1098
https://github.com/scverse/scanpy/issues/1098:58,energy efficiency,heat,heatmap,58,"scanpy heatmap groupby leiden colobar not aligning to the heatmap; Hi I did not have problems before till now. when I execute this function in Scanpy:. sc.pl.heatmap(adata, marker_genes_dict, groupby='leiden'). The colorbars for individual leiden cluster do not align to the heatmap.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1098
https://github.com/scverse/scanpy/issues/1098:158,energy efficiency,heat,heatmap,158,"scanpy heatmap groupby leiden colobar not aligning to the heatmap; Hi I did not have problems before till now. when I execute this function in Scanpy:. sc.pl.heatmap(adata, marker_genes_dict, groupby='leiden'). The colorbars for individual leiden cluster do not align to the heatmap.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1098
https://github.com/scverse/scanpy/issues/1098:275,energy efficiency,heat,heatmap,275,"scanpy heatmap groupby leiden colobar not aligning to the heatmap; Hi I did not have problems before till now. when I execute this function in Scanpy:. sc.pl.heatmap(adata, marker_genes_dict, groupby='leiden'). The colorbars for individual leiden cluster do not align to the heatmap.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1098
https://github.com/scverse/scanpy/pull/1099:8,deployability,build,builds,8,Fix doc builds; Fixed wishbone plotting reference,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1099
https://github.com/scverse/scanpy/pull/1100:16,deployability,version,version,16,Bump matplotlib version requirement; Heatmap color bars were being messed up #1098,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1100
https://github.com/scverse/scanpy/pull/1100:37,energy efficiency,Heat,Heatmap,37,Bump matplotlib version requirement; Heatmap color bars were being messed up #1098,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1100
https://github.com/scverse/scanpy/pull/1100:16,integrability,version,version,16,Bump matplotlib version requirement; Heatmap color bars were being messed up #1098,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1100
https://github.com/scverse/scanpy/pull/1100:16,modifiability,version,version,16,Bump matplotlib version requirement; Heatmap color bars were being messed up #1098,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1100
https://github.com/scverse/scanpy/pull/1101:8,availability,mainten,maintenance,8,"Dataset maintenance; This PR does:. * A minor reorganization of datasets, so only datasets are exported. * Fix a default value bug for the visium example datasets",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1101
https://github.com/scverse/scanpy/pull/1101:8,reliability,mainten,maintenance,8,"Dataset maintenance; This PR does:. * A minor reorganization of datasets, so only datasets are exported. * Fix a default value bug for the visium example datasets",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1101
https://github.com/scverse/scanpy/pull/1101:29,reliability,doe,does,29,"Dataset maintenance; This PR does:. * A minor reorganization of datasets, so only datasets are exported. * Fix a default value bug for the visium example datasets",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1101
https://github.com/scverse/scanpy/pull/1102:8,availability,down,downloads,8,"Fix ebi downloads; Should actually fix downloading EBI datasets. URLs for tables and count matrices had changed, and this PR fixes that. This is a bit of a band-aid, since we should probably be accessing these files through the FTP and we should be checking that already downloaded datasets are current. I've also only done a spot check on this, and tested it with a couple datasets. It's probably worth testing with a larger set.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1102
https://github.com/scverse/scanpy/pull/1102:39,availability,down,downloading,39,"Fix ebi downloads; Should actually fix downloading EBI datasets. URLs for tables and count matrices had changed, and this PR fixes that. This is a bit of a band-aid, since we should probably be accessing these files through the FTP and we should be checking that already downloaded datasets are current. I've also only done a spot check on this, and tested it with a couple datasets. It's probably worth testing with a larger set.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1102
https://github.com/scverse/scanpy/pull/1102:271,availability,down,downloaded,271,"Fix ebi downloads; Should actually fix downloading EBI datasets. URLs for tables and count matrices had changed, and this PR fixes that. This is a bit of a band-aid, since we should probably be accessing these files through the FTP and we should be checking that already downloaded datasets are current. I've also only done a spot check on this, and tested it with a couple datasets. It's probably worth testing with a larger set.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1102
https://github.com/scverse/scanpy/pull/1102:295,energy efficiency,current,current,295,"Fix ebi downloads; Should actually fix downloading EBI datasets. URLs for tables and count matrices had changed, and this PR fixes that. This is a bit of a band-aid, since we should probably be accessing these files through the FTP and we should be checking that already downloaded datasets are current. I've also only done a spot check on this, and tested it with a couple datasets. It's probably worth testing with a larger set.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1102
https://github.com/scverse/scanpy/pull/1102:367,integrability,coupl,couple,367,"Fix ebi downloads; Should actually fix downloading EBI datasets. URLs for tables and count matrices had changed, and this PR fixes that. This is a bit of a band-aid, since we should probably be accessing these files through the FTP and we should be checking that already downloaded datasets are current. I've also only done a spot check on this, and tested it with a couple datasets. It's probably worth testing with a larger set.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1102
https://github.com/scverse/scanpy/pull/1102:367,modifiability,coupl,couple,367,"Fix ebi downloads; Should actually fix downloading EBI datasets. URLs for tables and count matrices had changed, and this PR fixes that. This is a bit of a band-aid, since we should probably be accessing these files through the FTP and we should be checking that already downloaded datasets are current. I've also only done a spot check on this, and tested it with a couple datasets. It's probably worth testing with a larger set.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1102
https://github.com/scverse/scanpy/pull/1102:350,safety,test,tested,350,"Fix ebi downloads; Should actually fix downloading EBI datasets. URLs for tables and count matrices had changed, and this PR fixes that. This is a bit of a band-aid, since we should probably be accessing these files through the FTP and we should be checking that already downloaded datasets are current. I've also only done a spot check on this, and tested it with a couple datasets. It's probably worth testing with a larger set.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1102
https://github.com/scverse/scanpy/pull/1102:404,safety,test,testing,404,"Fix ebi downloads; Should actually fix downloading EBI datasets. URLs for tables and count matrices had changed, and this PR fixes that. This is a bit of a band-aid, since we should probably be accessing these files through the FTP and we should be checking that already downloaded datasets are current. I've also only done a spot check on this, and tested it with a couple datasets. It's probably worth testing with a larger set.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1102
https://github.com/scverse/scanpy/pull/1102:194,security,access,accessing,194,"Fix ebi downloads; Should actually fix downloading EBI datasets. URLs for tables and count matrices had changed, and this PR fixes that. This is a bit of a band-aid, since we should probably be accessing these files through the FTP and we should be checking that already downloaded datasets are current. I've also only done a spot check on this, and tested it with a couple datasets. It's probably worth testing with a larger set.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1102
https://github.com/scverse/scanpy/pull/1102:350,testability,test,tested,350,"Fix ebi downloads; Should actually fix downloading EBI datasets. URLs for tables and count matrices had changed, and this PR fixes that. This is a bit of a band-aid, since we should probably be accessing these files through the FTP and we should be checking that already downloaded datasets are current. I've also only done a spot check on this, and tested it with a couple datasets. It's probably worth testing with a larger set.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1102
https://github.com/scverse/scanpy/pull/1102:367,testability,coupl,couple,367,"Fix ebi downloads; Should actually fix downloading EBI datasets. URLs for tables and count matrices had changed, and this PR fixes that. This is a bit of a band-aid, since we should probably be accessing these files through the FTP and we should be checking that already downloaded datasets are current. I've also only done a spot check on this, and tested it with a couple datasets. It's probably worth testing with a larger set.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1102
https://github.com/scverse/scanpy/pull/1102:404,testability,test,testing,404,"Fix ebi downloads; Should actually fix downloading EBI datasets. URLs for tables and count matrices had changed, and this PR fixes that. This is a bit of a band-aid, since we should probably be accessing these files through the FTP and we should be checking that already downloaded datasets are current. I've also only done a spot check on this, and tested it with a couple datasets. It's probably worth testing with a larger set.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1102
https://github.com/scverse/scanpy/issues/1103:995,deployability,Version,Versions,995,"Legend alignment in dotplot; <!-- Please give a clear and concise description of what the bug is: -->. Hey! The color bar and legend don't seem to align well... might be because i'm subsetting the object. Here is what happens (reproducible example and my plot, which is even stranger with legend overlap):. <img width=""623"" alt=""Screenshot 2020-03-15 at 13 09 33"" src=""https://user-images.githubusercontent.com/13019956/76701118-73bff200-66be-11ea-9c99-ee4e0427bbfa.png"">. <img width=""580"" alt=""Screenshot 2020-03-15 at 13 02 52"" src=""https://user-images.githubusercontent.com/13019956/76701119-76224c00-66be-11ea-9b45-b94c1d9a57bd.png"">. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.pl.dotplot(adata[adata.obs.bulk_labels.isin(['Dendritic', 'CD14+ Monocyte', 'CD4+/CD25 T Reg']),], var_names=['HES4', 'TNFRSF4', 'SSU72'], groupby='bulk_labels', figsize=(8,8)). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Also, matplotlib is 3.1.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1103
https://github.com/scverse/scanpy/issues/1103:1028,deployability,log,logging,1028,"Legend alignment in dotplot; <!-- Please give a clear and concise description of what the bug is: -->. Hey! The color bar and legend don't seem to align well... might be because i'm subsetting the object. Here is what happens (reproducible example and my plot, which is even stranger with legend overlap):. <img width=""623"" alt=""Screenshot 2020-03-15 at 13 09 33"" src=""https://user-images.githubusercontent.com/13019956/76701118-73bff200-66be-11ea-9c99-ee4e0427bbfa.png"">. <img width=""580"" alt=""Screenshot 2020-03-15 at 13 02 52"" src=""https://user-images.githubusercontent.com/13019956/76701119-76224c00-66be-11ea-9b45-b94c1d9a57bd.png"">. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.pl.dotplot(adata[adata.obs.bulk_labels.isin(['Dendritic', 'CD14+ Monocyte', 'CD4+/CD25 T Reg']),], var_names=['HES4', 'TNFRSF4', 'SSU72'], groupby='bulk_labels', figsize=(8,8)). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Also, matplotlib is 3.1.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1103
https://github.com/scverse/scanpy/issues/1103:182,integrability,sub,subsetting,182,"Legend alignment in dotplot; <!-- Please give a clear and concise description of what the bug is: -->. Hey! The color bar and legend don't seem to align well... might be because i'm subsetting the object. Here is what happens (reproducible example and my plot, which is even stranger with legend overlap):. <img width=""623"" alt=""Screenshot 2020-03-15 at 13 09 33"" src=""https://user-images.githubusercontent.com/13019956/76701118-73bff200-66be-11ea-9c99-ee4e0427bbfa.png"">. <img width=""580"" alt=""Screenshot 2020-03-15 at 13 02 52"" src=""https://user-images.githubusercontent.com/13019956/76701119-76224c00-66be-11ea-9b45-b94c1d9a57bd.png"">. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.pl.dotplot(adata[adata.obs.bulk_labels.isin(['Dendritic', 'CD14+ Monocyte', 'CD4+/CD25 T Reg']),], var_names=['HES4', 'TNFRSF4', 'SSU72'], groupby='bulk_labels', figsize=(8,8)). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Also, matplotlib is 3.1.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1103
https://github.com/scverse/scanpy/issues/1103:995,integrability,Version,Versions,995,"Legend alignment in dotplot; <!-- Please give a clear and concise description of what the bug is: -->. Hey! The color bar and legend don't seem to align well... might be because i'm subsetting the object. Here is what happens (reproducible example and my plot, which is even stranger with legend overlap):. <img width=""623"" alt=""Screenshot 2020-03-15 at 13 09 33"" src=""https://user-images.githubusercontent.com/13019956/76701118-73bff200-66be-11ea-9c99-ee4e0427bbfa.png"">. <img width=""580"" alt=""Screenshot 2020-03-15 at 13 02 52"" src=""https://user-images.githubusercontent.com/13019956/76701119-76224c00-66be-11ea-9b45-b94c1d9a57bd.png"">. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.pl.dotplot(adata[adata.obs.bulk_labels.isin(['Dendritic', 'CD14+ Monocyte', 'CD4+/CD25 T Reg']),], var_names=['HES4', 'TNFRSF4', 'SSU72'], groupby='bulk_labels', figsize=(8,8)). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Also, matplotlib is 3.1.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1103
https://github.com/scverse/scanpy/issues/1103:995,modifiability,Version,Versions,995,"Legend alignment in dotplot; <!-- Please give a clear and concise description of what the bug is: -->. Hey! The color bar and legend don't seem to align well... might be because i'm subsetting the object. Here is what happens (reproducible example and my plot, which is even stranger with legend overlap):. <img width=""623"" alt=""Screenshot 2020-03-15 at 13 09 33"" src=""https://user-images.githubusercontent.com/13019956/76701118-73bff200-66be-11ea-9c99-ee4e0427bbfa.png"">. <img width=""580"" alt=""Screenshot 2020-03-15 at 13 02 52"" src=""https://user-images.githubusercontent.com/13019956/76701119-76224c00-66be-11ea-9b45-b94c1d9a57bd.png"">. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.pl.dotplot(adata[adata.obs.bulk_labels.isin(['Dendritic', 'CD14+ Monocyte', 'CD4+/CD25 T Reg']),], var_names=['HES4', 'TNFRSF4', 'SSU72'], groupby='bulk_labels', figsize=(8,8)). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Also, matplotlib is 3.1.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1103
https://github.com/scverse/scanpy/issues/1103:1028,safety,log,logging,1028,"Legend alignment in dotplot; <!-- Please give a clear and concise description of what the bug is: -->. Hey! The color bar and legend don't seem to align well... might be because i'm subsetting the object. Here is what happens (reproducible example and my plot, which is even stranger with legend overlap):. <img width=""623"" alt=""Screenshot 2020-03-15 at 13 09 33"" src=""https://user-images.githubusercontent.com/13019956/76701118-73bff200-66be-11ea-9c99-ee4e0427bbfa.png"">. <img width=""580"" alt=""Screenshot 2020-03-15 at 13 02 52"" src=""https://user-images.githubusercontent.com/13019956/76701119-76224c00-66be-11ea-9b45-b94c1d9a57bd.png"">. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.pl.dotplot(adata[adata.obs.bulk_labels.isin(['Dendritic', 'CD14+ Monocyte', 'CD4+/CD25 T Reg']),], var_names=['HES4', 'TNFRSF4', 'SSU72'], groupby='bulk_labels', figsize=(8,8)). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Also, matplotlib is 3.1.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1103
https://github.com/scverse/scanpy/issues/1103:1028,security,log,logging,1028,"Legend alignment in dotplot; <!-- Please give a clear and concise description of what the bug is: -->. Hey! The color bar and legend don't seem to align well... might be because i'm subsetting the object. Here is what happens (reproducible example and my plot, which is even stranger with legend overlap):. <img width=""623"" alt=""Screenshot 2020-03-15 at 13 09 33"" src=""https://user-images.githubusercontent.com/13019956/76701118-73bff200-66be-11ea-9c99-ee4e0427bbfa.png"">. <img width=""580"" alt=""Screenshot 2020-03-15 at 13 02 52"" src=""https://user-images.githubusercontent.com/13019956/76701119-76224c00-66be-11ea-9b45-b94c1d9a57bd.png"">. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.pl.dotplot(adata[adata.obs.bulk_labels.isin(['Dendritic', 'CD14+ Monocyte', 'CD4+/CD25 T Reg']),], var_names=['HES4', 'TNFRSF4', 'SSU72'], groupby='bulk_labels', figsize=(8,8)). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Also, matplotlib is 3.1.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1103
https://github.com/scverse/scanpy/issues/1103:1028,testability,log,logging,1028,"Legend alignment in dotplot; <!-- Please give a clear and concise description of what the bug is: -->. Hey! The color bar and legend don't seem to align well... might be because i'm subsetting the object. Here is what happens (reproducible example and my plot, which is even stranger with legend overlap):. <img width=""623"" alt=""Screenshot 2020-03-15 at 13 09 33"" src=""https://user-images.githubusercontent.com/13019956/76701118-73bff200-66be-11ea-9c99-ee4e0427bbfa.png"">. <img width=""580"" alt=""Screenshot 2020-03-15 at 13 02 52"" src=""https://user-images.githubusercontent.com/13019956/76701119-76224c00-66be-11ea-9b45-b94c1d9a57bd.png"">. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.pl.dotplot(adata[adata.obs.bulk_labels.isin(['Dendritic', 'CD14+ Monocyte', 'CD4+/CD25 T Reg']),], var_names=['HES4', 'TNFRSF4', 'SSU72'], groupby='bulk_labels', figsize=(8,8)). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Also, matplotlib is 3.1.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1103
https://github.com/scverse/scanpy/issues/1103:48,usability,clear,clear,48,"Legend alignment in dotplot; <!-- Please give a clear and concise description of what the bug is: -->. Hey! The color bar and legend don't seem to align well... might be because i'm subsetting the object. Here is what happens (reproducible example and my plot, which is even stranger with legend overlap):. <img width=""623"" alt=""Screenshot 2020-03-15 at 13 09 33"" src=""https://user-images.githubusercontent.com/13019956/76701118-73bff200-66be-11ea-9c99-ee4e0427bbfa.png"">. <img width=""580"" alt=""Screenshot 2020-03-15 at 13 02 52"" src=""https://user-images.githubusercontent.com/13019956/76701119-76224c00-66be-11ea-9b45-b94c1d9a57bd.png"">. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.pl.dotplot(adata[adata.obs.bulk_labels.isin(['Dendritic', 'CD14+ Monocyte', 'CD4+/CD25 T Reg']),], var_names=['HES4', 'TNFRSF4', 'SSU72'], groupby='bulk_labels', figsize=(8,8)). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Also, matplotlib is 3.1.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1103
https://github.com/scverse/scanpy/issues/1103:377,usability,user,user-images,377,"Legend alignment in dotplot; <!-- Please give a clear and concise description of what the bug is: -->. Hey! The color bar and legend don't seem to align well... might be because i'm subsetting the object. Here is what happens (reproducible example and my plot, which is even stranger with legend overlap):. <img width=""623"" alt=""Screenshot 2020-03-15 at 13 09 33"" src=""https://user-images.githubusercontent.com/13019956/76701118-73bff200-66be-11ea-9c99-ee4e0427bbfa.png"">. <img width=""580"" alt=""Screenshot 2020-03-15 at 13 02 52"" src=""https://user-images.githubusercontent.com/13019956/76701119-76224c00-66be-11ea-9b45-b94c1d9a57bd.png"">. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.pl.dotplot(adata[adata.obs.bulk_labels.isin(['Dendritic', 'CD14+ Monocyte', 'CD4+/CD25 T Reg']),], var_names=['HES4', 'TNFRSF4', 'SSU72'], groupby='bulk_labels', figsize=(8,8)). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Also, matplotlib is 3.1.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1103
https://github.com/scverse/scanpy/issues/1103:543,usability,user,user-images,543,"Legend alignment in dotplot; <!-- Please give a clear and concise description of what the bug is: -->. Hey! The color bar and legend don't seem to align well... might be because i'm subsetting the object. Here is what happens (reproducible example and my plot, which is even stranger with legend overlap):. <img width=""623"" alt=""Screenshot 2020-03-15 at 13 09 33"" src=""https://user-images.githubusercontent.com/13019956/76701118-73bff200-66be-11ea-9c99-ee4e0427bbfa.png"">. <img width=""580"" alt=""Screenshot 2020-03-15 at 13 02 52"" src=""https://user-images.githubusercontent.com/13019956/76701119-76224c00-66be-11ea-9b45-b94c1d9a57bd.png"">. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.pl.dotplot(adata[adata.obs.bulk_labels.isin(['Dendritic', 'CD14+ Monocyte', 'CD4+/CD25 T Reg']),], var_names=['HES4', 'TNFRSF4', 'SSU72'], groupby='bulk_labels', figsize=(8,8)). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Also, matplotlib is 3.1.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1103
https://github.com/scverse/scanpy/issues/1103:650,usability,minim,minimal,650,"Legend alignment in dotplot; <!-- Please give a clear and concise description of what the bug is: -->. Hey! The color bar and legend don't seem to align well... might be because i'm subsetting the object. Here is what happens (reproducible example and my plot, which is even stranger with legend overlap):. <img width=""623"" alt=""Screenshot 2020-03-15 at 13 09 33"" src=""https://user-images.githubusercontent.com/13019956/76701118-73bff200-66be-11ea-9c99-ee4e0427bbfa.png"">. <img width=""580"" alt=""Screenshot 2020-03-15 at 13 02 52"" src=""https://user-images.githubusercontent.com/13019956/76701119-76224c00-66be-11ea-9b45-b94c1d9a57bd.png"">. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.pl.dotplot(adata[adata.obs.bulk_labels.isin(['Dendritic', 'CD14+ Monocyte', 'CD4+/CD25 T Reg']),], var_names=['HES4', 'TNFRSF4', 'SSU72'], groupby='bulk_labels', figsize=(8,8)). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Also, matplotlib is 3.1.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1103
https://github.com/scverse/scanpy/issues/1103:1152,usability,learn,learn,1152,"Legend alignment in dotplot; <!-- Please give a clear and concise description of what the bug is: -->. Hey! The color bar and legend don't seem to align well... might be because i'm subsetting the object. Here is what happens (reproducible example and my plot, which is even stranger with legend overlap):. <img width=""623"" alt=""Screenshot 2020-03-15 at 13 09 33"" src=""https://user-images.githubusercontent.com/13019956/76701118-73bff200-66be-11ea-9c99-ee4e0427bbfa.png"">. <img width=""580"" alt=""Screenshot 2020-03-15 at 13 02 52"" src=""https://user-images.githubusercontent.com/13019956/76701119-76224c00-66be-11ea-9b45-b94c1d9a57bd.png"">. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. import scanpy as sc. adata = sc.datasets.pbmc68k_reduced(). sc.pl.dotplot(adata[adata.obs.bulk_labels.isin(['Dendritic', 'CD14+ Monocyte', 'CD4+/CD25 T Reg']),], var_names=['HES4', 'TNFRSF4', 'SSU72'], groupby='bulk_labels', figsize=(8,8)). ```. #### Versions:. <!-- Output of scanpy.logging.print_versions() -->. > scanpy==1.4.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.2 statsmodels==0.11.1 python-igraph==0.8.0 louvain==0.6.1. Also, matplotlib is 3.1.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1103
https://github.com/scverse/scanpy/issues/1104:191,availability,error,error,191,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:392,availability,Error,Error,392,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:853,availability,error,error,853,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:919,availability,ERROR,ERROR,919,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:934,availability,error,errored,934,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:6,deployability,instal,install,6,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:313,deployability,instal,install,313,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:626,deployability,build,build-,626,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:723,deployability,build,build-,723,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:1000,deployability,log,logs,1000,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:141,performance,time,time,141,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:191,performance,error,error,191,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:392,performance,Error,Error,392,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:853,performance,error,error,853,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:919,performance,ERROR,ERROR,919,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:934,performance,error,errored,934,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:191,safety,error,error,191,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:392,safety,Error,Error,392,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:853,safety,error,error,853,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:919,safety,ERROR,ERROR,919,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:934,safety,error,errored,934,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:1000,safety,log,logs,1000,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:1000,security,log,logs,1000,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:1000,testability,log,logs,1000,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:65,usability,clear,clear,65,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:191,usability,error,error,191,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:215,usability,minim,minimal,215,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:392,usability,Error,Error,392,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:650,usability,command,command,650,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:820,usability,command,command,820,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:853,usability,error,error,853,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:919,usability,ERROR,ERROR,919,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:926,usability,Command,Command,926,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:934,usability,error,errored,934,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:956,usability,statu,status,956,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/issues/1104:1014,usability,command,command,1014,"Can't install the spatial branch of `scanpy`; <!-- Please give a clear and concise description of what the bug is: -->. Trying for the first time the tutorial notebook and I stumble onto the error below. <!-- Put a minimal reproducible example that reproduces the bug in the code block below: -->. ```python. pip install git+https://github.com/theislab/scanpy.git@spatial. ```. <!-- Put your Error output in this code block (if applicable, else delete the block): -->. ```pytb. Collecting git+https://github.com/theislab/scanpy.git@spatial. Cloning https://github.com/theislab/scanpy.git (to revision spatial) to /tmp/pip-req-build-1aajpyr3. Running command git clone -q https://github.com/theislab/scanpy.git /tmp/pip-req-build-1aajpyr3. WARNING: Did not find branch or tag 'spatial', assuming revision or ref. Running command git checkout -q spatial. error: pathspec 'spatial' did not match any file(s) known to git. ERROR: Command errored out with exit status 1: git checkout -q spatial Check the logs for full command output. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1104
https://github.com/scverse/scanpy/pull/1105:395,availability,Recov,Recover,395,"change uns structure for spatial; New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:. * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path. * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value). * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter. * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/pull/1105:522,availability,sli,slides,522,"change uns structure for spatial; New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:. * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path. * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value). * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter. * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/pull/1105:546,availability,sli,slice,546,"change uns structure for spatial; New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:. * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path. * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value). * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter. * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/pull/1105:38,deployability,version,version,38,"change uns structure for spatial; New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:. * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path. * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value). * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter. * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/pull/1105:355,deployability,pipelin,pipelines,355,"change uns structure for spatial; New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:. * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path. * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value). * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter. * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/pull/1105:395,deployability,Recov,Recover,395,"change uns structure for spatial; New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:. * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path. * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value). * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter. * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/pull/1105:38,integrability,version,version,38,"change uns structure for spatial; New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:. * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path. * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value). * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter. * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/pull/1105:355,integrability,pipelin,pipelines,355,"change uns structure for spatial; New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:. * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path. * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value). * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter. * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/pull/1105:38,modifiability,version,version,38,"change uns structure for spatial; New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:. * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path. * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value). * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter. * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/pull/1105:1037,modifiability,maintain,maintaining,1037,"change uns structure for spatial; New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:. * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path. * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value). * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter. * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/pull/1105:1175,modifiability,variab,variable,1175,"change uns structure for spatial; New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:. * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path. * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value). * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter. * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/pull/1105:395,reliability,Recov,Recover,395,"change uns structure for spatial; New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:. * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path. * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value). * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter. * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/pull/1105:522,reliability,sli,slides,522,"change uns structure for spatial; New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:. * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path. * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value). * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter. * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/pull/1105:546,reliability,sli,slice,546,"change uns structure for spatial; New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:. * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path. * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value). * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter. * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/pull/1105:680,reliability,doe,does,680,"change uns structure for spatial; New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:. * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path. * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value). * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter. * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/pull/1105:395,safety,Recov,Recover,395,"change uns structure for spatial; New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:. * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path. * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value). * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter. * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/pull/1105:423,safety,input,input,423,"change uns structure for spatial; New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:. * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path. * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value). * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter. * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/pull/1105:1037,safety,maintain,maintaining,1037,"change uns structure for spatial; New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:. * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path. * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value). * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter. * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/pull/1105:395,security,Recov,Recover,395,"change uns structure for spatial; New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:. * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path. * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value). * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter. * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/pull/1105:895,security,modif,modified,895,"change uns structure for spatial; New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:. * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path. * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value). * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter. * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/pull/1105:851,testability,context,context,851,"change uns structure for spatial; New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:. * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path. * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value). * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter. * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/pull/1105:298,usability,support,support,298,"change uns structure for spatial; New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:. * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path. * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value). * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter. * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/pull/1105:423,usability,input,input,423,"change uns structure for spatial; New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:. * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path. * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value). * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter. * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/pull/1105:826,usability,user,user,826,"change uns structure for spatial; New version of `uns` as discussed in https://github.com/theislab/anndata/issues/295#issuecomment-596164456. The reason for setting a dummy `library_id` (as ""0"" for instance) is:. * The `library_id` information is in the molecule_info file [explained here](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/molecule_info). Recover it would require to input an additional file path. * All the 10x data I had a look at, both from the same tissue (so 2 slides from same tissue slice) and from different tissues, have `library_id` entry set to ""0"". So I am not really sure how space ranger set that value but it does not appear to be unique (and therefore not a natural `batch_key` value). * I think it would be more useful if this value is set according to user choice. Only in the context of `adata.concatenate` it should be modified according to `batch_key`. This is also the only point in the analysis where the `library_id` entry matter. * I agree with respect to maintaining the tree structure before and after concatenation, so the reason for keeping the `library_id` entry and setting it to a dummy variable by default. Looking forward to hear what you think @ivirshup and if agree I'll go on with PRs for `anndata.concatenate`. . Also, let's keep this `spatial` branch open until we really have (almost) everything up and running for spatial analysis.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1105
https://github.com/scverse/scanpy/issues/1107:671,deployability,integr,integrative,671,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:671,integrability,integr,integrative,671,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:1106,integrability,configur,configurable,1106,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:671,interoperability,integr,integrative,671,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:107,modifiability,paramet,parameters,107,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:384,modifiability,pac,package,384,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:671,modifiability,integr,integrative,671,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:737,modifiability,layer,layers,737,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:805,modifiability,layer,layers,805,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:1106,modifiability,configur,configurable,1106,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:641,performance,perform,perform,641,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:860,performance,perform,perform,860,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:934,performance,multiplex,multiplex,934,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:1063,performance,multiplex,multiplex,1063,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:671,reliability,integr,integrative,671,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:952,safety,test,tested,952,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:671,security,integr,integrative,671,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:1106,security,configur,configurable,1106,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:189,testability,simpl,simple,189,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:671,testability,integr,integrative,671,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:952,testability,test,tested,952,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:181,usability,tool,tool,181,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:189,usability,simpl,simple,189,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
https://github.com/scverse/scanpy/issues/1107:205,usability,tool,tool,205,"Multiomics partitions; <!-- What kind of feature would you like to request? -->. - [x] Additional function parameters / changed functionality / changed defaults? - [ ] New analysis tool: A simple analysis tool you have been using and are missing in `sc.tools`? - [ ] New plotting function: A kind of plot you would like to seein `sc.pl`? - [ ] External tools: Do you know an existing package that should go into `sc.external.*`? - [ ] Other? <!-- Please describe your wishes below: -->. As more and more technologies allow multimodal characterization of single cells it could be useful to exploit some functionalities of scanpy's toolkit to perform, at least, some rough integrative analysis. Assuming we have to modalities on different layers (say RNA and ATAC), one could create two knn graphs for both layers and use `leidenalg.find_partition_multiplex` to perform a joint call of partitions handling the two (or more) graphs as a multiplex. I have tested myself this approach, described in [leidenalg documentation](https://leidenalg.readthedocs.io/en/latest/multiplex.html), it works and it is highly configurable. . We can take care of the implementation of enhancement (as `leiden_multiplex()` function?), I just want to be sure that it is not already on the development roadmap and that it is ok to have it into scanpy and not as an external tool.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1107
