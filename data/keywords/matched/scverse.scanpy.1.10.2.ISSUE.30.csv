id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/issues/2587:2045,interoperability,specif,specified,2045," data being preserved. In general values should be in the range 2 to 100. If knn is True, number of nearest neighbors to be searched. If knn is False, a Gaussian kernel width is set to the distance of the n_neighbors neighbor. and. > knn: If True, use a hard threshold to restrict the number of neighbors to n_neighbors, that is, consider a knn graph. Otherwise, use a Gaussian Kernel to assign low weights to neighbors more distant than the n_neighbors nearest neighbor. as well as . > Connectivities: Weighted adjacency matrix of the neighborhood graph of data points. Weights should be interpreted as connectivities. Hence I would expect that the number of non-zero elements in `adata.obsp['connectivities']` in an object to which `sc.pp.neighbors(adata, n_neighbors = k, knn = True)` have been applied, would sum to `k` for each row. However, when inspecting these results, it is not true. The number of non-zero elements in a row varies between both higher as well as lower values than the specified `n_neighbors` (obviously, sometimes it's also the expected `n_neighbors` value). Perhaps I'm misunderstanding something, but this behavior is somewhat counterintuitive to me and not what I expect; happy to be corrected though! /Alma. ### Minimal code sample. ```python. # Import packages. import scanpy as sc. import anndata as ad. import numpy as np. # set random seed. np.random.seed(42). # create dummy data. adata = ad.AnnData(shape=(1000,1)). adata.obsm['rep'] = np.random.random(size = (1000,2)). # get spatial connectivities. k = 10. sc.pp.neighbors(adata, n_neighbors=k, use_rep = 'rep', knn = True). # get and count connectivities for each cell. gr = adata.obsp['connectivities']. nn = (np.array(gr.todense()) > 0).sum(axis=1).flatten(). # check if neighbors are equal to k. np.testing.assert_equal(nn,k). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. anyio NA. arrow 1.2.3. asciitree NA. asttokens NA. attr 23",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:3914,interoperability,platform,platformdirs,3914,". <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. anyio NA. arrow 1.2.3. asciitree NA. asttokens NA. attr 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cloudpickle 2.2.1. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dask 2023.5.1. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fasteners 0.18. fastjsonschema NA. fqdn NA. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. isoduration NA. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.6.0. jupyterlab_server 2.22.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. nbformat 5.8.0. numba 0.57.1. numcodecs 0.11.0. numpy 1.23.4. overrides NA. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.1. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pyparsing 3.0.9. pyrsistent NA. pythonjsonlogger NA. pytz 2023.3. requests 2.28.1. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. scipy 1.10.1. send2trash NA. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. sklearn 1.2.2. sniffio 1.3.0. socks 1.7.1. stack_data 0.6.2. tblib 2.0.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. torch 1.13.1. tornado 6.3.2. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. uri_template NA. urllib3 1.26.15. wcwidth 0.2.6. webcolors 1.13. websocket 1.5.2. yaml 6.0. zarr 2.14.2. zipp NA. zmq 25.1.0. zoneinfo NA. -----. IPython 8.13.2. jupyter_client 8.2.0. jupyter_core 5.3.0. jupyterlab 4.0.1. -----. Python 3.10.11 (main, Apr 20 2023, 19:02:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:210,modifiability,version,version,210,"Unexpected behavior of `sc.pp.neighbors`; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hej! Thanks for maintaining such a great package! This issue relates another [issue](https://github.com/scverse/squidpy/issues/735) posted (by me) in the `squidpy` repo, but I think it might be worth bringing up here as well. . The issue in question is how the `sc.pp.neighbors` function returns an inconsistent number of neighbors even when `knn=True`. In the [documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.neighbors.html) of `sc.pp.neighbors` it's stated that :. >n_neighbors: The size of local neighborhood (in terms of number of neighboring data points) used for manifold approximation. Larger values result in more global views of the manifold, while smaller values result in more local data being preserved. In general values should be in the range 2 to 100. If knn is True, number of nearest neighbors to be searched. If knn is False, a Gaussian kernel width is set to the distance of the n_neighbors neighbor. and. > knn: If True, use a hard threshold to restrict the number of neighbors to n_neighbors, that is, consider a knn graph. Otherwise, use a Gaussian Kernel to assign low weights to neighbors more distant than the n_neighbors nearest neighbor. as well as . > Connectivities: Weighted adjacency matrix of the neighborhood graph of data points. Weights should be interpreted as connectivities. Hence I would expect that the number of non-zero elements in `adata.obsp['connectivities']` in an object to which `sc.pp.neighbors(adata, n_neighbors = k, knn = True)` have been applied, would sum to `k` for each row. However, when inspecting these results, it is not true. The number of non-zero elements in a row varies between ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:346,modifiability,maintain,maintaining,346,"Unexpected behavior of `sc.pp.neighbors`; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hej! Thanks for maintaining such a great package! This issue relates another [issue](https://github.com/scverse/squidpy/issues/735) posted (by me) in the `squidpy` repo, but I think it might be worth bringing up here as well. . The issue in question is how the `sc.pp.neighbors` function returns an inconsistent number of neighbors even when `knn=True`. In the [documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.neighbors.html) of `sc.pp.neighbors` it's stated that :. >n_neighbors: The size of local neighborhood (in terms of number of neighboring data points) used for manifold approximation. Larger values result in more global views of the manifold, while smaller values result in more local data being preserved. In general values should be in the range 2 to 100. If knn is True, number of nearest neighbors to be searched. If knn is False, a Gaussian kernel width is set to the distance of the n_neighbors neighbor. and. > knn: If True, use a hard threshold to restrict the number of neighbors to n_neighbors, that is, consider a knn graph. Otherwise, use a Gaussian Kernel to assign low weights to neighbors more distant than the n_neighbors nearest neighbor. as well as . > Connectivities: Weighted adjacency matrix of the neighborhood graph of data points. Weights should be interpreted as connectivities. Hence I would expect that the number of non-zero elements in `adata.obsp['connectivities']` in an object to which `sc.pp.neighbors(adata, n_neighbors = k, knn = True)` have been applied, would sum to `k` for each row. However, when inspecting these results, it is not true. The number of non-zero elements in a row varies between ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:371,modifiability,pac,package,371,"Unexpected behavior of `sc.pp.neighbors`; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hej! Thanks for maintaining such a great package! This issue relates another [issue](https://github.com/scverse/squidpy/issues/735) posted (by me) in the `squidpy` repo, but I think it might be worth bringing up here as well. . The issue in question is how the `sc.pp.neighbors` function returns an inconsistent number of neighbors even when `knn=True`. In the [documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.neighbors.html) of `sc.pp.neighbors` it's stated that :. >n_neighbors: The size of local neighborhood (in terms of number of neighboring data points) used for manifold approximation. Larger values result in more global views of the manifold, while smaller values result in more local data being preserved. In general values should be in the range 2 to 100. If knn is True, number of nearest neighbors to be searched. If knn is False, a Gaussian kernel width is set to the distance of the n_neighbors neighbor. and. > knn: If True, use a hard threshold to restrict the number of neighbors to n_neighbors, that is, consider a knn graph. Otherwise, use a Gaussian Kernel to assign low weights to neighbors more distant than the n_neighbors nearest neighbor. as well as . > Connectivities: Weighted adjacency matrix of the neighborhood graph of data points. Weights should be interpreted as connectivities. Hence I would expect that the number of non-zero elements in `adata.obsp['connectivities']` in an object to which `sc.pp.neighbors(adata, n_neighbors = k, knn = True)` have been applied, would sum to `k` for each row. However, when inspecting these results, it is not true. The number of non-zero elements in a row varies between ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:2334,modifiability,pac,packages,2334,"ber of neighbors to n_neighbors, that is, consider a knn graph. Otherwise, use a Gaussian Kernel to assign low weights to neighbors more distant than the n_neighbors nearest neighbor. as well as . > Connectivities: Weighted adjacency matrix of the neighborhood graph of data points. Weights should be interpreted as connectivities. Hence I would expect that the number of non-zero elements in `adata.obsp['connectivities']` in an object to which `sc.pp.neighbors(adata, n_neighbors = k, knn = True)` have been applied, would sum to `k` for each row. However, when inspecting these results, it is not true. The number of non-zero elements in a row varies between both higher as well as lower values than the specified `n_neighbors` (obviously, sometimes it's also the expected `n_neighbors` value). Perhaps I'm misunderstanding something, but this behavior is somewhat counterintuitive to me and not what I expect; happy to be corrected though! /Alma. ### Minimal code sample. ```python. # Import packages. import scanpy as sc. import anndata as ad. import numpy as np. # set random seed. np.random.seed(42). # create dummy data. adata = ad.AnnData(shape=(1000,1)). adata.obsm['rep'] = np.random.random(size = (1000,2)). # get spatial connectivities. k = 10. sc.pp.neighbors(adata, n_neighbors=k, use_rep = 'rep', knn = True). # get and count connectivities for each cell. gr = adata.obsp['connectivities']. nn = (np.array(gr.todense()) > 0).sum(axis=1).flatten(). # check if neighbors are equal to k. np.testing.assert_equal(nn,k). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. anyio NA. arrow 1.2.3. asciitree NA. asttokens NA. attr 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cloudpickle 2.2.1. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dask 2023.5.1. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:2912,modifiability,Version,Versions,2912,"se results, it is not true. The number of non-zero elements in a row varies between both higher as well as lower values than the specified `n_neighbors` (obviously, sometimes it's also the expected `n_neighbors` value). Perhaps I'm misunderstanding something, but this behavior is somewhat counterintuitive to me and not what I expect; happy to be corrected though! /Alma. ### Minimal code sample. ```python. # Import packages. import scanpy as sc. import anndata as ad. import numpy as np. # set random seed. np.random.seed(42). # create dummy data. adata = ad.AnnData(shape=(1000,1)). adata.obsm['rep'] = np.random.random(size = (1000,2)). # get spatial connectivities. k = 10. sc.pp.neighbors(adata, n_neighbors=k, use_rep = 'rep', knn = True). # get and count connectivities for each cell. gr = adata.obsp['connectivities']. nn = (np.array(gr.todense()) > 0).sum(axis=1).flatten(). # check if neighbors are equal to k. np.testing.assert_equal(nn,k). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. anyio NA. arrow 1.2.3. asciitree NA. asttokens NA. attr 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cloudpickle 2.2.1. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dask 2023.5.1. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fasteners 0.18. fastjsonschema NA. fqdn NA. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. isoduration NA. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.6.0. jupyterlab_server 2.22.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. nbformat 5.8.0. numba 0.57.1. numcodecs 0.11.0. numpy 1.23.4. overrides NA. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. pl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:3267,modifiability,deco,decorator,3267,"d though! /Alma. ### Minimal code sample. ```python. # Import packages. import scanpy as sc. import anndata as ad. import numpy as np. # set random seed. np.random.seed(42). # create dummy data. adata = ad.AnnData(shape=(1000,1)). adata.obsm['rep'] = np.random.random(size = (1000,2)). # get spatial connectivities. k = 10. sc.pp.neighbors(adata, n_neighbors=k, use_rep = 'rep', knn = True). # get and count connectivities for each cell. gr = adata.obsp['connectivities']. nn = (np.array(gr.todense()) > 0).sum(axis=1).flatten(). # check if neighbors are equal to k. np.testing.assert_equal(nn,k). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. anyio NA. arrow 1.2.3. asciitree NA. asttokens NA. attr 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cloudpickle 2.2.1. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dask 2023.5.1. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fasteners 0.18. fastjsonschema NA. fqdn NA. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. isoduration NA. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.6.0. jupyterlab_server 2.22.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. nbformat 5.8.0. numba 0.57.1. numcodecs 0.11.0. numpy 1.23.4. overrides NA. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.1. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pyparsing 3.0.9. pyrsistent NA. pythonjsonlogger NA. pytz 2023.3. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:3819,modifiability,pac,packaging,3819,"re equal to k. np.testing.assert_equal(nn,k). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. anyio NA. arrow 1.2.3. asciitree NA. asttokens NA. attr 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cloudpickle 2.2.1. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dask 2023.5.1. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fasteners 0.18. fastjsonschema NA. fqdn NA. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. isoduration NA. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.6.0. jupyterlab_server 2.22.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. nbformat 5.8.0. numba 0.57.1. numcodecs 0.11.0. numpy 1.23.4. overrides NA. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.1. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pyparsing 3.0.9. pyrsistent NA. pythonjsonlogger NA. pytz 2023.3. requests 2.28.1. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. scipy 1.10.1. send2trash NA. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. sklearn 1.2.2. sniffio 1.3.0. socks 1.7.1. stack_data 0.6.2. tblib 2.0.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. torch 1.13.1. tornado 6.3.2. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. uri_template NA. urllib3 1.26.15. wcwidth 0.2.6. webcolors 1.13. websocket 1.5.2. yaml 6.0. zarr 2.14.2. zipp NA. zmq 25.1.0. zoneinfo NA. -----. IPython 8.13.2. jupyter_clie",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:2879,performance,Error,Error,2879," row. However, when inspecting these results, it is not true. The number of non-zero elements in a row varies between both higher as well as lower values than the specified `n_neighbors` (obviously, sometimes it's also the expected `n_neighbors` value). Perhaps I'm misunderstanding something, but this behavior is somewhat counterintuitive to me and not what I expect; happy to be corrected though! /Alma. ### Minimal code sample. ```python. # Import packages. import scanpy as sc. import anndata as ad. import numpy as np. # set random seed. np.random.seed(42). # create dummy data. adata = ad.AnnData(shape=(1000,1)). adata.obsm['rep'] = np.random.random(size = (1000,2)). # get spatial connectivities. k = 10. sc.pp.neighbors(adata, n_neighbors=k, use_rep = 'rep', knn = True). # get and count connectivities for each cell. gr = adata.obsp['connectivities']. nn = (np.array(gr.todense()) > 0).sum(axis=1).flatten(). # check if neighbors are equal to k. np.testing.assert_equal(nn,k). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. anyio NA. arrow 1.2.3. asciitree NA. asttokens NA. attr 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cloudpickle 2.2.1. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dask 2023.5.1. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fasteners 0.18. fastjsonschema NA. fqdn NA. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. isoduration NA. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.6.0. jupyterlab_server 2.22.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. nbformat 5.8.0. numba 0.57.1. numcodecs 0.11.0. numpy 1.23.4. overrides NA. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:346,safety,maintain,maintaining,346,"Unexpected behavior of `sc.pp.neighbors`; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hej! Thanks for maintaining such a great package! This issue relates another [issue](https://github.com/scverse/squidpy/issues/735) posted (by me) in the `squidpy` repo, but I think it might be worth bringing up here as well. . The issue in question is how the `sc.pp.neighbors` function returns an inconsistent number of neighbors even when `knn=True`. In the [documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.neighbors.html) of `sc.pp.neighbors` it's stated that :. >n_neighbors: The size of local neighborhood (in terms of number of neighboring data points) used for manifold approximation. Larger values result in more global views of the manifold, while smaller values result in more local data being preserved. In general values should be in the range 2 to 100. If knn is True, number of nearest neighbors to be searched. If knn is False, a Gaussian kernel width is set to the distance of the n_neighbors neighbor. and. > knn: If True, use a hard threshold to restrict the number of neighbors to n_neighbors, that is, consider a knn graph. Otherwise, use a Gaussian Kernel to assign low weights to neighbors more distant than the n_neighbors nearest neighbor. as well as . > Connectivities: Weighted adjacency matrix of the neighborhood graph of data points. Weights should be interpreted as connectivities. Hence I would expect that the number of non-zero elements in `adata.obsp['connectivities']` in an object to which `sc.pp.neighbors(adata, n_neighbors = k, knn = True)` have been applied, would sum to `k` for each row. However, when inspecting these results, it is not true. The number of non-zero elements in a row varies between ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:2842,safety,test,testing,2842,"n applied, would sum to `k` for each row. However, when inspecting these results, it is not true. The number of non-zero elements in a row varies between both higher as well as lower values than the specified `n_neighbors` (obviously, sometimes it's also the expected `n_neighbors` value). Perhaps I'm misunderstanding something, but this behavior is somewhat counterintuitive to me and not what I expect; happy to be corrected though! /Alma. ### Minimal code sample. ```python. # Import packages. import scanpy as sc. import anndata as ad. import numpy as np. # set random seed. np.random.seed(42). # create dummy data. adata = ad.AnnData(shape=(1000,1)). adata.obsm['rep'] = np.random.random(size = (1000,2)). # get spatial connectivities. k = 10. sc.pp.neighbors(adata, n_neighbors=k, use_rep = 'rep', knn = True). # get and count connectivities for each cell. gr = adata.obsp['connectivities']. nn = (np.array(gr.todense()) > 0).sum(axis=1).flatten(). # check if neighbors are equal to k. np.testing.assert_equal(nn,k). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. anyio NA. arrow 1.2.3. asciitree NA. asttokens NA. attr 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cloudpickle 2.2.1. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dask 2023.5.1. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fasteners 0.18. fastjsonschema NA. fqdn NA. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. isoduration NA. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.6.0. jupyterlab_server 2.22.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. nbformat 5.8.0. numba 0.57.1. numcodecs 0.11.0. numpy 1.23.4. overrides NA. packaging 23.1. pandas 2.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:2879,safety,Error,Error,2879," row. However, when inspecting these results, it is not true. The number of non-zero elements in a row varies between both higher as well as lower values than the specified `n_neighbors` (obviously, sometimes it's also the expected `n_neighbors` value). Perhaps I'm misunderstanding something, but this behavior is somewhat counterintuitive to me and not what I expect; happy to be corrected though! /Alma. ### Minimal code sample. ```python. # Import packages. import scanpy as sc. import anndata as ad. import numpy as np. # set random seed. np.random.seed(42). # create dummy data. adata = ad.AnnData(shape=(1000,1)). adata.obsm['rep'] = np.random.random(size = (1000,2)). # get spatial connectivities. k = 10. sc.pp.neighbors(adata, n_neighbors=k, use_rep = 'rep', knn = True). # get and count connectivities for each cell. gr = adata.obsp['connectivities']. nn = (np.array(gr.todense()) > 0).sum(axis=1).flatten(). # check if neighbors are equal to k. np.testing.assert_equal(nn,k). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. anyio NA. arrow 1.2.3. asciitree NA. asttokens NA. attr 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cloudpickle 2.2.1. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dask 2023.5.1. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fasteners 0.18. fastjsonschema NA. fqdn NA. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. isoduration NA. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.6.0. jupyterlab_server 2.22.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. nbformat 5.8.0. numba 0.57.1. numcodecs 0.11.0. numpy 1.23.4. overrides NA. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:5022,safety,updat,updated,5022,"1. backcall 0.2.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cloudpickle 2.2.1. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dask 2023.5.1. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fasteners 0.18. fastjsonschema NA. fqdn NA. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. isoduration NA. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.6.0. jupyterlab_server 2.22.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. nbformat 5.8.0. numba 0.57.1. numcodecs 0.11.0. numpy 1.23.4. overrides NA. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.1. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pyparsing 3.0.9. pyrsistent NA. pythonjsonlogger NA. pytz 2023.3. requests 2.28.1. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. scipy 1.10.1. send2trash NA. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. sklearn 1.2.2. sniffio 1.3.0. socks 1.7.1. stack_data 0.6.2. tblib 2.0.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. torch 1.13.1. tornado 6.3.2. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. uri_template NA. urllib3 1.26.15. wcwidth 0.2.6. webcolors 1.13. websocket 1.5.2. yaml 6.0. zarr 2.14.2. zipp NA. zmq 25.1.0. zoneinfo NA. -----. IPython 8.13.2. jupyter_client 8.2.0. jupyter_core 5.3.0. jupyterlab 4.0.1. -----. Python 3.10.11 (main, Apr 20 2023, 19:02:41) [GCC 11.2.0]. Linux-3.10.0-1160.66.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2023-08-02 14:21. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:3097,security,certif,certifi,3097,"the expected `n_neighbors` value). Perhaps I'm misunderstanding something, but this behavior is somewhat counterintuitive to me and not what I expect; happy to be corrected though! /Alma. ### Minimal code sample. ```python. # Import packages. import scanpy as sc. import anndata as ad. import numpy as np. # set random seed. np.random.seed(42). # create dummy data. adata = ad.AnnData(shape=(1000,1)). adata.obsm['rep'] = np.random.random(size = (1000,2)). # get spatial connectivities. k = 10. sc.pp.neighbors(adata, n_neighbors=k, use_rep = 'rep', knn = True). # get and count connectivities for each cell. gr = adata.obsp['connectivities']. nn = (np.array(gr.todense()) > 0).sum(axis=1).flatten(). # check if neighbors are equal to k. np.testing.assert_equal(nn,k). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. anyio NA. arrow 1.2.3. asciitree NA. asttokens NA. attr 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cloudpickle 2.2.1. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dask 2023.5.1. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fasteners 0.18. fastjsonschema NA. fqdn NA. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. isoduration NA. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.6.0. jupyterlab_server 2.22.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. nbformat 5.8.0. numba 0.57.1. numcodecs 0.11.0. numpy 1.23.4. overrides NA. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.1. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:3435,security,iso,isoduration,3435,"42). # create dummy data. adata = ad.AnnData(shape=(1000,1)). adata.obsm['rep'] = np.random.random(size = (1000,2)). # get spatial connectivities. k = 10. sc.pp.neighbors(adata, n_neighbors=k, use_rep = 'rep', knn = True). # get and count connectivities for each cell. gr = adata.obsp['connectivities']. nn = (np.array(gr.todense()) > 0).sum(axis=1).flatten(). # check if neighbors are equal to k. np.testing.assert_equal(nn,k). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. anyio NA. arrow 1.2.3. asciitree NA. asttokens NA. attr 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cloudpickle 2.2.1. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dask 2023.5.1. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fasteners 0.18. fastjsonschema NA. fqdn NA. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. isoduration NA. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.6.0. jupyterlab_server 2.22.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. nbformat 5.8.0. numba 0.57.1. numcodecs 0.11.0. numpy 1.23.4. overrides NA. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.1. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pyparsing 3.0.9. pyrsistent NA. pythonjsonlogger NA. pytz 2023.3. requests 2.28.1. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. scipy 1.10.1. send2trash NA. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. sklearn 1.2.2. sniffio",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:4449,security,soc,socks,4449,"1. backcall 0.2.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cloudpickle 2.2.1. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dask 2023.5.1. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fasteners 0.18. fastjsonschema NA. fqdn NA. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. isoduration NA. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.6.0. jupyterlab_server 2.22.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. nbformat 5.8.0. numba 0.57.1. numcodecs 0.11.0. numpy 1.23.4. overrides NA. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.1. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pyparsing 3.0.9. pyrsistent NA. pythonjsonlogger NA. pytz 2023.3. requests 2.28.1. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. scipy 1.10.1. send2trash NA. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. sklearn 1.2.2. sniffio 1.3.0. socks 1.7.1. stack_data 0.6.2. tblib 2.0.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. torch 1.13.1. tornado 6.3.2. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. uri_template NA. urllib3 1.26.15. wcwidth 0.2.6. webcolors 1.13. websocket 1.5.2. yaml 6.0. zarr 2.14.2. zipp NA. zmq 25.1.0. zoneinfo NA. -----. IPython 8.13.2. jupyter_client 8.2.0. jupyter_core 5.3.0. jupyterlab 4.0.1. -----. Python 3.10.11 (main, Apr 20 2023, 19:02:41) [GCC 11.2.0]. Linux-3.10.0-1160.66.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2023-08-02 14:21. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:5002,security,Session,Session,5002,"1. backcall 0.2.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cloudpickle 2.2.1. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dask 2023.5.1. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fasteners 0.18. fastjsonschema NA. fqdn NA. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. isoduration NA. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.6.0. jupyterlab_server 2.22.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. nbformat 5.8.0. numba 0.57.1. numcodecs 0.11.0. numpy 1.23.4. overrides NA. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.1. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pyparsing 3.0.9. pyrsistent NA. pythonjsonlogger NA. pytz 2023.3. requests 2.28.1. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. scipy 1.10.1. send2trash NA. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. sklearn 1.2.2. sniffio 1.3.0. socks 1.7.1. stack_data 0.6.2. tblib 2.0.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. torch 1.13.1. tornado 6.3.2. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. uri_template NA. urllib3 1.26.15. wcwidth 0.2.6. webcolors 1.13. websocket 1.5.2. yaml 6.0. zarr 2.14.2. zipp NA. zmq 25.1.0. zoneinfo NA. -----. IPython 8.13.2. jupyter_client 8.2.0. jupyter_core 5.3.0. jupyterlab 4.0.1. -----. Python 3.10.11 (main, Apr 20 2023, 19:02:41) [GCC 11.2.0]. Linux-3.10.0-1160.66.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2023-08-02 14:21. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:5022,security,updat,updated,5022,"1. backcall 0.2.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cloudpickle 2.2.1. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dask 2023.5.1. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fasteners 0.18. fastjsonschema NA. fqdn NA. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. isoduration NA. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.6.0. jupyterlab_server 2.22.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. nbformat 5.8.0. numba 0.57.1. numcodecs 0.11.0. numpy 1.23.4. overrides NA. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.1. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pyparsing 3.0.9. pyrsistent NA. pythonjsonlogger NA. pytz 2023.3. requests 2.28.1. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. scipy 1.10.1. send2trash NA. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. sklearn 1.2.2. sniffio 1.3.0. socks 1.7.1. stack_data 0.6.2. tblib 2.0.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. torch 1.13.1. tornado 6.3.2. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. uri_template NA. urllib3 1.26.15. wcwidth 0.2.6. webcolors 1.13. websocket 1.5.2. yaml 6.0. zarr 2.14.2. zipp NA. zmq 25.1.0. zoneinfo NA. -----. IPython 8.13.2. jupyter_client 8.2.0. jupyter_core 5.3.0. jupyterlab 4.0.1. -----. Python 3.10.11 (main, Apr 20 2023, 19:02:41) [GCC 11.2.0]. Linux-3.10.0-1160.66.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2023-08-02 14:21. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:2842,testability,test,testing,2842,"n applied, would sum to `k` for each row. However, when inspecting these results, it is not true. The number of non-zero elements in a row varies between both higher as well as lower values than the specified `n_neighbors` (obviously, sometimes it's also the expected `n_neighbors` value). Perhaps I'm misunderstanding something, but this behavior is somewhat counterintuitive to me and not what I expect; happy to be corrected though! /Alma. ### Minimal code sample. ```python. # Import packages. import scanpy as sc. import anndata as ad. import numpy as np. # set random seed. np.random.seed(42). # create dummy data. adata = ad.AnnData(shape=(1000,1)). adata.obsm['rep'] = np.random.random(size = (1000,2)). # get spatial connectivities. k = 10. sc.pp.neighbors(adata, n_neighbors=k, use_rep = 'rep', knn = True). # get and count connectivities for each cell. gr = adata.obsp['connectivities']. nn = (np.array(gr.todense()) > 0).sum(axis=1).flatten(). # check if neighbors are equal to k. np.testing.assert_equal(nn,k). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. anyio NA. arrow 1.2.3. asciitree NA. asttokens NA. attr 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cloudpickle 2.2.1. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dask 2023.5.1. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fasteners 0.18. fastjsonschema NA. fqdn NA. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. isoduration NA. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.6.0. jupyterlab_server 2.22.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. nbformat 5.8.0. numba 0.57.1. numcodecs 0.11.0. numpy 1.23.4. overrides NA. packaging 23.1. pandas 2.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:11,usability,behavi,behavior,11,"Unexpected behavior of `sc.pp.neighbors`; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hej! Thanks for maintaining such a great package! This issue relates another [issue](https://github.com/scverse/squidpy/issues/735) posted (by me) in the `squidpy` repo, but I think it might be worth bringing up here as well. . The issue in question is how the `sc.pp.neighbors` function returns an inconsistent number of neighbors even when `knn=True`. In the [documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.neighbors.html) of `sc.pp.neighbors` it's stated that :. >n_neighbors: The size of local neighborhood (in terms of number of neighboring data points) used for manifold approximation. Larger values result in more global views of the manifold, while smaller values result in more local data being preserved. In general values should be in the range 2 to 100. If knn is True, number of nearest neighbors to be searched. If knn is False, a Gaussian kernel width is set to the distance of the n_neighbors neighbor. and. > knn: If True, use a hard threshold to restrict the number of neighbors to n_neighbors, that is, consider a knn graph. Otherwise, use a Gaussian Kernel to assign low weights to neighbors more distant than the n_neighbors nearest neighbor. as well as . > Connectivities: Weighted adjacency matrix of the neighborhood graph of data points. Weights should be interpreted as connectivities. Hence I would expect that the number of non-zero elements in `adata.obsp['connectivities']` in an object to which `sc.pp.neighbors(adata, n_neighbors = k, knn = True)` have been applied, would sum to `k` for each row. However, when inspecting these results, it is not true. The number of non-zero elements in a row varies between ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:170,usability,confirm,confirmed,170,"Unexpected behavior of `sc.pp.neighbors`; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hej! Thanks for maintaining such a great package! This issue relates another [issue](https://github.com/scverse/squidpy/issues/735) posted (by me) in the `squidpy` repo, but I think it might be worth bringing up here as well. . The issue in question is how the `sc.pp.neighbors` function returns an inconsistent number of neighbors even when `knn=True`. In the [documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.neighbors.html) of `sc.pp.neighbors` it's stated that :. >n_neighbors: The size of local neighborhood (in terms of number of neighboring data points) used for manifold approximation. Larger values result in more global views of the manifold, while smaller values result in more local data being preserved. In general values should be in the range 2 to 100. If knn is True, number of nearest neighbors to be searched. If knn is False, a Gaussian kernel width is set to the distance of the n_neighbors neighbor. and. > knn: If True, use a hard threshold to restrict the number of neighbors to n_neighbors, that is, consider a knn graph. Otherwise, use a Gaussian Kernel to assign low weights to neighbors more distant than the n_neighbors nearest neighbor. as well as . > Connectivities: Weighted adjacency matrix of the neighborhood graph of data points. Weights should be interpreted as connectivities. Hence I would expect that the number of non-zero elements in `adata.obsp['connectivities']` in an object to which `sc.pp.neighbors(adata, n_neighbors = k, knn = True)` have been applied, would sum to `k` for each row. However, when inspecting these results, it is not true. The number of non-zero elements in a row varies between ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:253,usability,confirm,confirmed,253,"Unexpected behavior of `sc.pp.neighbors`; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hej! Thanks for maintaining such a great package! This issue relates another [issue](https://github.com/scverse/squidpy/issues/735) posted (by me) in the `squidpy` repo, but I think it might be worth bringing up here as well. . The issue in question is how the `sc.pp.neighbors` function returns an inconsistent number of neighbors even when `knn=True`. In the [documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.neighbors.html) of `sc.pp.neighbors` it's stated that :. >n_neighbors: The size of local neighborhood (in terms of number of neighboring data points) used for manifold approximation. Larger values result in more global views of the manifold, while smaller values result in more local data being preserved. In general values should be in the range 2 to 100. If knn is True, number of nearest neighbors to be searched. If knn is False, a Gaussian kernel width is set to the distance of the n_neighbors neighbor. and. > knn: If True, use a hard threshold to restrict the number of neighbors to n_neighbors, that is, consider a knn graph. Otherwise, use a Gaussian Kernel to assign low weights to neighbors more distant than the n_neighbors nearest neighbor. as well as . > Connectivities: Weighted adjacency matrix of the neighborhood graph of data points. Weights should be interpreted as connectivities. Hence I would expect that the number of non-zero elements in `adata.obsp['connectivities']` in an object to which `sc.pp.neighbors(adata, n_neighbors = k, knn = True)` have been applied, would sum to `k` for each row. However, when inspecting these results, it is not true. The number of non-zero elements in a row varies between ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:692,usability,document,documentation,692,"Unexpected behavior of `sc.pp.neighbors`; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hej! Thanks for maintaining such a great package! This issue relates another [issue](https://github.com/scverse/squidpy/issues/735) posted (by me) in the `squidpy` repo, but I think it might be worth bringing up here as well. . The issue in question is how the `sc.pp.neighbors` function returns an inconsistent number of neighbors even when `knn=True`. In the [documentation](https://scanpy.readthedocs.io/en/stable/generated/scanpy.pp.neighbors.html) of `sc.pp.neighbors` it's stated that :. >n_neighbors: The size of local neighborhood (in terms of number of neighboring data points) used for manifold approximation. Larger values result in more global views of the manifold, while smaller values result in more local data being preserved. In general values should be in the range 2 to 100. If knn is True, number of nearest neighbors to be searched. If knn is False, a Gaussian kernel width is set to the distance of the n_neighbors neighbor. and. > knn: If True, use a hard threshold to restrict the number of neighbors to n_neighbors, that is, consider a knn graph. Otherwise, use a Gaussian Kernel to assign low weights to neighbors more distant than the n_neighbors nearest neighbor. as well as . > Connectivities: Weighted adjacency matrix of the neighborhood graph of data points. Weights should be interpreted as connectivities. Hence I would expect that the number of non-zero elements in `adata.obsp['connectivities']` in an object to which `sc.pp.neighbors(adata, n_neighbors = k, knn = True)` have been applied, would sum to `k` for each row. However, when inspecting these results, it is not true. The number of non-zero elements in a row varies between ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:2185,usability,behavi,behavior,2185,"n is False, a Gaussian kernel width is set to the distance of the n_neighbors neighbor. and. > knn: If True, use a hard threshold to restrict the number of neighbors to n_neighbors, that is, consider a knn graph. Otherwise, use a Gaussian Kernel to assign low weights to neighbors more distant than the n_neighbors nearest neighbor. as well as . > Connectivities: Weighted adjacency matrix of the neighborhood graph of data points. Weights should be interpreted as connectivities. Hence I would expect that the number of non-zero elements in `adata.obsp['connectivities']` in an object to which `sc.pp.neighbors(adata, n_neighbors = k, knn = True)` have been applied, would sum to `k` for each row. However, when inspecting these results, it is not true. The number of non-zero elements in a row varies between both higher as well as lower values than the specified `n_neighbors` (obviously, sometimes it's also the expected `n_neighbors` value). Perhaps I'm misunderstanding something, but this behavior is somewhat counterintuitive to me and not what I expect; happy to be corrected though! /Alma. ### Minimal code sample. ```python. # Import packages. import scanpy as sc. import anndata as ad. import numpy as np. # set random seed. np.random.seed(42). # create dummy data. adata = ad.AnnData(shape=(1000,1)). adata.obsm['rep'] = np.random.random(size = (1000,2)). # get spatial connectivities. k = 10. sc.pp.neighbors(adata, n_neighbors=k, use_rep = 'rep', knn = True). # get and count connectivities for each cell. gr = adata.obsp['connectivities']. nn = (np.array(gr.todense()) > 0).sum(axis=1).flatten(). # check if neighbors are equal to k. np.testing.assert_equal(nn,k). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. anyio NA. arrow 1.2.3. asciitree NA. asttokens NA. attr 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cloudpickle 2.2.1. comm 0.1.3. cy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:2293,usability,Minim,Minimal,2293," use a hard threshold to restrict the number of neighbors to n_neighbors, that is, consider a knn graph. Otherwise, use a Gaussian Kernel to assign low weights to neighbors more distant than the n_neighbors nearest neighbor. as well as . > Connectivities: Weighted adjacency matrix of the neighborhood graph of data points. Weights should be interpreted as connectivities. Hence I would expect that the number of non-zero elements in `adata.obsp['connectivities']` in an object to which `sc.pp.neighbors(adata, n_neighbors = k, knn = True)` have been applied, would sum to `k` for each row. However, when inspecting these results, it is not true. The number of non-zero elements in a row varies between both higher as well as lower values than the specified `n_neighbors` (obviously, sometimes it's also the expected `n_neighbors` value). Perhaps I'm misunderstanding something, but this behavior is somewhat counterintuitive to me and not what I expect; happy to be corrected though! /Alma. ### Minimal code sample. ```python. # Import packages. import scanpy as sc. import anndata as ad. import numpy as np. # set random seed. np.random.seed(42). # create dummy data. adata = ad.AnnData(shape=(1000,1)). adata.obsm['rep'] = np.random.random(size = (1000,2)). # get spatial connectivities. k = 10. sc.pp.neighbors(adata, n_neighbors=k, use_rep = 'rep', knn = True). # get and count connectivities for each cell. gr = adata.obsp['connectivities']. nn = (np.array(gr.todense()) > 0).sum(axis=1).flatten(). # check if neighbors are equal to k. np.testing.assert_equal(nn,k). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. anyio NA. arrow 1.2.3. asciitree NA. asttokens NA. attr 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cloudpickle 2.2.1. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dask 2023.5.1. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:2879,usability,Error,Error,2879," row. However, when inspecting these results, it is not true. The number of non-zero elements in a row varies between both higher as well as lower values than the specified `n_neighbors` (obviously, sometimes it's also the expected `n_neighbors` value). Perhaps I'm misunderstanding something, but this behavior is somewhat counterintuitive to me and not what I expect; happy to be corrected though! /Alma. ### Minimal code sample. ```python. # Import packages. import scanpy as sc. import anndata as ad. import numpy as np. # set random seed. np.random.seed(42). # create dummy data. adata = ad.AnnData(shape=(1000,1)). adata.obsm['rep'] = np.random.random(size = (1000,2)). # get spatial connectivities. k = 10. sc.pp.neighbors(adata, n_neighbors=k, use_rep = 'rep', knn = True). # get and count connectivities for each cell. gr = adata.obsp['connectivities']. nn = (np.array(gr.todense()) > 0).sum(axis=1).flatten(). # check if neighbors are equal to k. np.testing.assert_equal(nn,k). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.4.0. anyio NA. arrow 1.2.3. asciitree NA. asttokens NA. attr 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cloudpickle 2.2.1. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dask 2023.5.1. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fasteners 0.18. fastjsonschema NA. fqdn NA. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. isoduration NA. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.6.0. jupyterlab_server 2.22.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. nbformat 5.8.0. numba 0.57.1. numcodecs 0.11.0. numpy 1.23.4. overrides NA. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickl",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/issues/2587:4543,usability,tool,toolz,4543,"1. backcall 0.2.0. brotli NA. certifi 2022.12.07. cffi 1.15.1. charset_normalizer 2.0.4. cloudpickle 2.2.1. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dask 2023.5.1. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fasteners 0.18. fastjsonschema NA. fqdn NA. h5py 3.8.0. idna 3.4. igraph 0.10.4. ipykernel 6.23.1. isoduration NA. jedi 0.18.2. jinja2 3.1.2. joblib 1.2.0. json5 NA. jsonpointer 2.3. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.6.0. jupyterlab_server 2.22.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. markupsafe 2.1.2. matplotlib 3.7.1. mpl_toolkits NA. msgpack 1.0.5. natsort 8.3.1. nbformat 5.8.0. numba 0.57.1. numcodecs 0.11.0. numpy 1.23.4. overrides NA. packaging 23.1. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.5.1. prometheus_client NA. prompt_toolkit 3.0.38. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pyparsing 3.0.9. pyrsistent NA. pythonjsonlogger NA. pytz 2023.3. requests 2.28.1. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. scipy 1.10.1. send2trash NA. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. sklearn 1.2.2. sniffio 1.3.0. socks 1.7.1. stack_data 0.6.2. tblib 2.0.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. torch 1.13.1. tornado 6.3.2. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. uri_template NA. urllib3 1.26.15. wcwidth 0.2.6. webcolors 1.13. websocket 1.5.2. yaml 6.0. zarr 2.14.2. zipp NA. zmq 25.1.0. zoneinfo NA. -----. IPython 8.13.2. jupyter_client 8.2.0. jupyter_core 5.3.0. jupyterlab 4.0.1. -----. Python 3.10.11 (main, Apr 20 2023, 19:02:41) [GCC 11.2.0]. Linux-3.10.0-1160.66.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2023-08-02 14:21. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2587
https://github.com/scverse/scanpy/pull/2588:0,modifiability,Layer,Layers,0,Layers support for PCA and regress_out; This PR adds `.layers` support for PCA and regress_out.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2588
https://github.com/scverse/scanpy/pull/2588:55,modifiability,layer,layers,55,Layers support for PCA and regress_out; This PR adds `.layers` support for PCA and regress_out.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2588
https://github.com/scverse/scanpy/pull/2588:7,usability,support,support,7,Layers support for PCA and regress_out; This PR adds `.layers` support for PCA and regress_out.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2588
https://github.com/scverse/scanpy/pull/2588:63,usability,support,support,63,Layers support for PCA and regress_out; This PR adds `.layers` support for PCA and regress_out.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2588
https://github.com/scverse/scanpy/pull/2589:34,deployability,log,logreg,34,Fixed wrong order for groups with logreg; Fixes a bug where the `groups` argument would return a wrongly sorted list for logreg in rank_gene_groups.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2589
https://github.com/scverse/scanpy/pull/2589:121,deployability,log,logreg,121,Fixed wrong order for groups with logreg; Fixes a bug where the `groups` argument would return a wrongly sorted list for logreg in rank_gene_groups.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2589
https://github.com/scverse/scanpy/pull/2589:34,safety,log,logreg,34,Fixed wrong order for groups with logreg; Fixes a bug where the `groups` argument would return a wrongly sorted list for logreg in rank_gene_groups.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2589
https://github.com/scverse/scanpy/pull/2589:121,safety,log,logreg,121,Fixed wrong order for groups with logreg; Fixes a bug where the `groups` argument would return a wrongly sorted list for logreg in rank_gene_groups.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2589
https://github.com/scverse/scanpy/pull/2589:34,security,log,logreg,34,Fixed wrong order for groups with logreg; Fixes a bug where the `groups` argument would return a wrongly sorted list for logreg in rank_gene_groups.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2589
https://github.com/scverse/scanpy/pull/2589:121,security,log,logreg,121,Fixed wrong order for groups with logreg; Fixes a bug where the `groups` argument would return a wrongly sorted list for logreg in rank_gene_groups.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2589
https://github.com/scverse/scanpy/pull/2589:34,testability,log,logreg,34,Fixed wrong order for groups with logreg; Fixes a bug where the `groups` argument would return a wrongly sorted list for logreg in rank_gene_groups.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2589
https://github.com/scverse/scanpy/pull/2589:121,testability,log,logreg,121,Fixed wrong order for groups with logreg; Fixes a bug where the `groups` argument would return a wrongly sorted list for logreg in rank_gene_groups.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2589
https://github.com/scverse/scanpy/pull/2590:1401,availability,Mask,Mask,1401,"(feat): Aggregation via group-by in `sc.get`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:. 1. No more tuple-indices and related functionality (i.e., scoring pairwise). 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate. 3. Output is `AnnData` object instead of `DataFrame`. 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs. - [x] Aggregate along other axis. - [x] Keep grouping cols in result. - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?). - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?). - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values. - [x] Support for `obsm`, `varm`. - [ ] Directly pass Series to groupby. - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations). - [ ] Mask argument. - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/pull/2590:302,deployability,version,version,302,"(feat): Aggregation via group-by in `sc.get`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:. 1. No more tuple-indices and related functionality (i.e., scoring pairwise). 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate. 3. Output is `AnnData` object instead of `DataFrame`. 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs. - [x] Aggregate along other axis. - [x] Keep grouping cols in result. - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?). - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?). - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values. - [x] Support for `obsm`, `varm`. - [ ] Directly pass Series to groupby. - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations). - [ ] Mask argument. - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/pull/2590:688,deployability,API,API,688,"(feat): Aggregation via group-by in `sc.get`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:. 1. No more tuple-indices and related functionality (i.e., scoring pairwise). 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate. 3. Output is `AnnData` object instead of `DataFrame`. 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs. - [x] Aggregate along other axis. - [x] Keep grouping cols in result. - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?). - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?). - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values. - [x] Support for `obsm`, `varm`. - [ ] Directly pass Series to groupby. - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations). - [ ] Mask argument. - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/pull/2590:829,deployability,API,API,829,"(feat): Aggregation via group-by in `sc.get`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:. 1. No more tuple-indices and related functionality (i.e., scoring pairwise). 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate. 3. Output is `AnnData` object instead of `DataFrame`. 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs. - [x] Aggregate along other axis. - [x] Keep grouping cols in result. - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?). - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?). - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values. - [x] Support for `obsm`, `varm`. - [ ] Directly pass Series to groupby. - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations). - [ ] Mask argument. - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/pull/2590:849,deployability,version,version,849,"(feat): Aggregation via group-by in `sc.get`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:. 1. No more tuple-indices and related functionality (i.e., scoring pairwise). 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate. 3. Output is `AnnData` object instead of `DataFrame`. 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs. - [x] Aggregate along other axis. - [x] Keep grouping cols in result. - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?). - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?). - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values. - [x] Support for `obsm`, `varm`. - [ ] Directly pass Series to groupby. - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations). - [ ] Mask argument. - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/pull/2590:302,integrability,version,version,302,"(feat): Aggregation via group-by in `sc.get`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:. 1. No more tuple-indices and related functionality (i.e., scoring pairwise). 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate. 3. Output is `AnnData` object instead of `DataFrame`. 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs. - [x] Aggregate along other axis. - [x] Keep grouping cols in result. - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?). - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?). - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values. - [x] Support for `obsm`, `varm`. - [ ] Directly pass Series to groupby. - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations). - [ ] Mask argument. - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/pull/2590:681,integrability,pub,public,681,"(feat): Aggregation via group-by in `sc.get`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:. 1. No more tuple-indices and related functionality (i.e., scoring pairwise). 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate. 3. Output is `AnnData` object instead of `DataFrame`. 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs. - [x] Aggregate along other axis. - [x] Keep grouping cols in result. - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?). - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?). - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values. - [x] Support for `obsm`, `varm`. - [ ] Directly pass Series to groupby. - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations). - [ ] Mask argument. - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/pull/2590:688,integrability,API,API,688,"(feat): Aggregation via group-by in `sc.get`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:. 1. No more tuple-indices and related functionality (i.e., scoring pairwise). 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate. 3. Output is `AnnData` object instead of `DataFrame`. 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs. - [x] Aggregate along other axis. - [x] Keep grouping cols in result. - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?). - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?). - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values. - [x] Support for `obsm`, `varm`. - [ ] Directly pass Series to groupby. - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations). - [ ] Mask argument. - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/pull/2590:829,integrability,API,API,829,"(feat): Aggregation via group-by in `sc.get`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:. 1. No more tuple-indices and related functionality (i.e., scoring pairwise). 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate. 3. Output is `AnnData` object instead of `DataFrame`. 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs. - [x] Aggregate along other axis. - [x] Keep grouping cols in result. - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?). - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?). - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values. - [x] Support for `obsm`, `varm`. - [ ] Directly pass Series to groupby. - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations). - [ ] Mask argument. - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/pull/2590:849,integrability,version,version,849,"(feat): Aggregation via group-by in `sc.get`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:. 1. No more tuple-indices and related functionality (i.e., scoring pairwise). 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate. 3. Output is `AnnData` object instead of `DataFrame`. 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs. - [x] Aggregate along other axis. - [x] Keep grouping cols in result. - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?). - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?). - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values. - [x] Support for `obsm`, `varm`. - [ ] Directly pass Series to groupby. - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations). - [ ] Mask argument. - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/pull/2590:688,interoperability,API,API,688,"(feat): Aggregation via group-by in `sc.get`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:. 1. No more tuple-indices and related functionality (i.e., scoring pairwise). 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate. 3. Output is `AnnData` object instead of `DataFrame`. 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs. - [x] Aggregate along other axis. - [x] Keep grouping cols in result. - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?). - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?). - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values. - [x] Support for `obsm`, `varm`. - [ ] Directly pass Series to groupby. - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations). - [ ] Mask argument. - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/pull/2590:829,interoperability,API,API,829,"(feat): Aggregation via group-by in `sc.get`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:. 1. No more tuple-indices and related functionality (i.e., scoring pairwise). 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate. 3. Output is `AnnData` object instead of `DataFrame`. 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs. - [x] Aggregate along other axis. - [x] Keep grouping cols in result. - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?). - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?). - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values. - [x] Support for `obsm`, `varm`. - [ ] Directly pass Series to groupby. - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations). - [ ] Mask argument. - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/pull/2590:302,modifiability,version,version,302,"(feat): Aggregation via group-by in `sc.get`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:. 1. No more tuple-indices and related functionality (i.e., scoring pairwise). 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate. 3. Output is `AnnData` object instead of `DataFrame`. 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs. - [x] Aggregate along other axis. - [x] Keep grouping cols in result. - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?). - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?). - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values. - [x] Support for `obsm`, `varm`. - [ ] Directly pass Series to groupby. - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations). - [ ] Mask argument. - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/pull/2590:567,modifiability,layer,layers,567,"(feat): Aggregation via group-by in `sc.get`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:. 1. No more tuple-indices and related functionality (i.e., scoring pairwise). 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate. 3. Output is `AnnData` object instead of `DataFrame`. 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs. - [x] Aggregate along other axis. - [x] Keep grouping cols in result. - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?). - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?). - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values. - [x] Support for `obsm`, `varm`. - [ ] Directly pass Series to groupby. - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations). - [ ] Mask argument. - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/pull/2590:849,modifiability,version,version,849,"(feat): Aggregation via group-by in `sc.get`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:. 1. No more tuple-indices and related functionality (i.e., scoring pairwise). 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate. 3. Output is `AnnData` object instead of `DataFrame`. 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs. - [x] Aggregate along other axis. - [x] Keep grouping cols in result. - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?). - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?). - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values. - [x] Support for `obsm`, `varm`. - [ ] Directly pass Series to groupby. - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations). - [ ] Mask argument. - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/pull/2590:1096,reliability,Doe,Does,1096,"(feat): Aggregation via group-by in `sc.get`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:. 1. No more tuple-indices and related functionality (i.e., scoring pairwise). 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate. 3. Output is `AnnData` object instead of `DataFrame`. 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs. - [x] Aggregate along other axis. - [x] Keep grouping cols in result. - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?). - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?). - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values. - [x] Support for `obsm`, `varm`. - [ ] Directly pass Series to groupby. - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations). - [ ] Mask argument. - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/pull/2590:265,safety,review,review,265,"(feat): Aggregation via group-by in `sc.get`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:. 1. No more tuple-indices and related functionality (i.e., scoring pairwise). 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate. 3. Output is `AnnData` object instead of `DataFrame`. 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs. - [x] Aggregate along other axis. - [x] Keep grouping cols in result. - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?). - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?). - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values. - [x] Support for `obsm`, `varm`. - [ ] Directly pass Series to groupby. - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations). - [ ] Mask argument. - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/pull/2590:278,security,Modif,Modified,278,"(feat): Aggregation via group-by in `sc.get`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:. 1. No more tuple-indices and related functionality (i.e., scoring pairwise). 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate. 3. Output is `AnnData` object instead of `DataFrame`. 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs. - [x] Aggregate along other axis. - [x] Keep grouping cols in result. - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?). - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?). - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values. - [x] Support for `obsm`, `varm`. - [ ] Directly pass Series to groupby. - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations). - [ ] Mask argument. - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/pull/2590:265,testability,review,review,265,"(feat): Aggregation via group-by in `sc.get`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:. 1. No more tuple-indices and related functionality (i.e., scoring pairwise). 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate. 3. Output is `AnnData` object instead of `DataFrame`. 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs. - [x] Aggregate along other axis. - [x] Keep grouping cols in result. - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?). - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?). - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values. - [x] Support for `obsm`, `varm`. - [ ] Directly pass Series to groupby. - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations). - [ ] Mask argument. - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/pull/2590:116,usability,guid,guidelines,116,"(feat): Aggregation via group-by in `sc.get`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:. 1. No more tuple-indices and related functionality (i.e., scoring pairwise). 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate. 3. Output is `AnnData` object instead of `DataFrame`. 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs. - [x] Aggregate along other axis. - [x] Keep grouping cols in result. - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?). - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?). - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values. - [x] Support for `obsm`, `varm`. - [ ] Directly pass Series to groupby. - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations). - [ ] Mask argument. - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/pull/2590:147,usability,guid,guide,147,"(feat): Aggregation via group-by in `sc.get`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:. 1. No more tuple-indices and related functionality (i.e., scoring pairwise). 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate. 3. Output is `AnnData` object instead of `DataFrame`. 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs. - [x] Aggregate along other axis. - [x] Keep grouping cols in result. - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?). - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?). - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values. - [x] Support for `obsm`, `varm`. - [ ] Directly pass Series to groupby. - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations). - [ ] Mask argument. - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/pull/2590:243,usability,workflow,workflow,243,"(feat): Aggregation via group-by in `sc.get`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:. 1. No more tuple-indices and related functionality (i.e., scoring pairwise). 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate. 3. Output is `AnnData` object instead of `DataFrame`. 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs. - [x] Aggregate along other axis. - [x] Keep grouping cols in result. - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?). - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?). - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values. - [x] Support for `obsm`, `varm`. - [ ] Directly pass Series to groupby. - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations). - [ ] Mask argument. - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/pull/2590:1245,usability,Support,Support,1245,"(feat): Aggregation via group-by in `sc.get`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:. 1. No more tuple-indices and related functionality (i.e., scoring pairwise). 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate. 3. Output is `AnnData` object instead of `DataFrame`. 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs. - [x] Aggregate along other axis. - [x] Keep grouping cols in result. - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?). - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?). - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values. - [x] Support for `obsm`, `varm`. - [ ] Directly pass Series to groupby. - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations). - [ ] Mask argument. - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/pull/2590:1427,usability,support,support,1427,"(feat): Aggregation via group-by in `sc.get`; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Modified (for `scanpy`) version of https://github.com/scverse/anndata/pull/564. Fixes https://github.com/scverse/anndata/issues/556. Big points of change:. 1. No more tuple-indices and related functionality (i.e., scoring pairwise). 2. Allow for `obs` and `var` group-by +`varm`, `obsm`, `layers` as options for data to aggregate. 3. Output is `AnnData` object instead of `DataFrame`. 4. `scanpy`-style public API. ## TODO (by @ivirshup):. Necessary:. - [x] Docs. - [x] Aggregate along other axis. - [x] Keep grouping cols in result. - [x] Reconsider API for non-anndata version (maybe return a dict of arrays?). - [ ] Decide on naming convention for `""nonzero""` variations, should this be `""nonzero_count""` so it's a little like `""nanmean""`. Optional, can do later:. - [ ] Weighted (although.... Idk, maybe can skip. Does ""weights"" affect ""count_nonzero""?). - [ ] Option for keeping around unseen groups, probably needs `fill_value` argument for those values. - [x] Support for `obsm`, `varm`. - [ ] Directly pass Series to groupby. - [ ] More aggregation functions (mean_nonzero, min, max, std, `nan*` variations). - [ ] Mask argument. - [ ] Dask support",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2590
https://github.com/scverse/scanpy/pull/2591:24,deployability,version,versions,24,(chore): run all python versions up to 3.11 in CI; @ivirshup mentioned that `scanpy` should work up to `3.11` so this PR adds it to the CI.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2591
https://github.com/scverse/scanpy/pull/2591:24,integrability,version,versions,24,(chore): run all python versions up to 3.11 in CI; @ivirshup mentioned that `scanpy` should work up to `3.11` so this PR adds it to the CI.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2591
https://github.com/scverse/scanpy/pull/2591:24,modifiability,version,versions,24,(chore): run all python versions up to 3.11 in CI; @ivirshup mentioned that `scanpy` should work up to `3.11` so this PR adds it to the CI.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2591
https://github.com/scverse/scanpy/issues/2592:24,availability,error,error,24,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:407,availability,Error,Error,407,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:453,availability,error,error,453,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:500,availability,error,error,500,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:595,availability,Error,Error,595,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:2005,availability,error,error,2005,"wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised while reading key {elem.name!r} of "". 190 f""type {type(elem)} from {parent}."". 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. PyQt5 NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.7. brotli 1.0.9. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. colorama 0.4.6. comm 0.1.4. cvxopt 1.3.1. cycler 0.10.0. cython_runtime NA. ... Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]. Windows-10-10.0.19045-SP0. -----. Session information updated at 2023-08-04 10:17. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:2135,availability,error,error,2135,"wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised while reading key {elem.name!r} of "". 190 f""type {type(elem)} from {parent}."". 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. PyQt5 NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.7. brotli 1.0.9. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. colorama 0.4.6. comm 0.1.4. cvxopt 1.3.1. cycler 0.10.0. cython_runtime NA. ... Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]. Windows-10-10.0.19045-SP0. -----. Session information updated at 2023-08-04 10:17. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:245,deployability,version,version,245,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:2196,deployability,Version,Versions,2196,"wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised while reading key {elem.name!r} of "". 190 f""type {type(elem)} from {parent}."". 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. PyQt5 NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.7. brotli 1.0.9. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. colorama 0.4.6. comm 0.1.4. cvxopt 1.3.1. cycler 0.10.0. cython_runtime NA. ... Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]. Windows-10-10.0.19045-SP0. -----. Session information updated at 2023-08-04 10:17. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:2739,deployability,updat,updated,2739,"wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised while reading key {elem.name!r} of "". 190 f""type {type(elem)} from {parent}."". 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. PyQt5 NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.7. brotli 1.0.9. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. colorama 0.4.6. comm 0.1.4. cvxopt 1.3.1. cycler 0.10.0. cython_runtime NA. ... Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]. Windows-10-10.0.19045-SP0. -----. Session information updated at 2023-08-04 10:17. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:245,integrability,version,version,245,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:2196,integrability,Version,Versions,2196,"wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised while reading key {elem.name!r} of "". 190 f""type {type(elem)} from {parent}."". 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. PyQt5 NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.7. brotli 1.0.9. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. colorama 0.4.6. comm 0.1.4. cvxopt 1.3.1. cycler 0.10.0. cython_runtime NA. ... Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]. Windows-10-10.0.19045-SP0. -----. Session information updated at 2023-08-04 10:17. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:967,interoperability,registr,registry,967,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:245,modifiability,version,version,245,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:715,modifiability,pac,packages,715,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:940,modifiability,pac,packages,940,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:1209,modifiability,pac,packages,1209,"d this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised while reading key {elem.name!r} of "". 190 f""type {type(elem)} from {parent}."". 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /. ```. ### Versions. <detail",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:1412,modifiability,pac,packages,1412,"ve checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised while reading key {elem.name!r} of "". 190 f""type {type(elem)} from {parent}."". 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. PyQt5 NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bott",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:1909,modifiability,pac,packages,1909,"wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised while reading key {elem.name!r} of "". 190 f""type {type(elem)} from {parent}."". 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. PyQt5 NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.7. brotli 1.0.9. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. colorama 0.4.6. comm 0.1.4. cvxopt 1.3.1. cycler 0.10.0. cython_runtime NA. ... Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]. Windows-10-10.0.19045-SP0. -----. Session information updated at 2023-08-04 10:17. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:2196,modifiability,Version,Versions,2196,"wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised while reading key {elem.name!r} of "". 190 f""type {type(elem)} from {parent}."". 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. PyQt5 NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.7. brotli 1.0.9. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. colorama 0.4.6. comm 0.1.4. cvxopt 1.3.1. cycler 0.10.0. cython_runtime NA. ... Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]. Windows-10-10.0.19045-SP0. -----. Session information updated at 2023-08-04 10:17. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:2600,modifiability,pac,packaged,2600,"wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised while reading key {elem.name!r} of "". 190 f""type {type(elem)} from {parent}."". 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. PyQt5 NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.7. brotli 1.0.9. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. colorama 0.4.6. comm 0.1.4. cvxopt 1.3.1. cycler 0.10.0. cython_runtime NA. ... Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]. Windows-10-10.0.19045-SP0. -----. Session information updated at 2023-08-04 10:17. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:24,performance,error,error,24,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:407,performance,Error,Error,407,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:453,performance,error,error,453,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:500,performance,error,error,500,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:595,performance,Error,Error,595,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:2005,performance,error,error,2005,"wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised while reading key {elem.name!r} of "". 190 f""type {type(elem)} from {parent}."". 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. PyQt5 NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.7. brotli 1.0.9. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. colorama 0.4.6. comm 0.1.4. cvxopt 1.3.1. cycler 0.10.0. cython_runtime NA. ... Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]. Windows-10-10.0.19045-SP0. -----. Session information updated at 2023-08-04 10:17. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:2135,performance,error,error,2135,"wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised while reading key {elem.name!r} of "". 190 f""type {type(elem)} from {parent}."". 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. PyQt5 NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.7. brotli 1.0.9. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. colorama 0.4.6. comm 0.1.4. cvxopt 1.3.1. cycler 0.10.0. cython_runtime NA. ... Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]. Windows-10-10.0.19045-SP0. -----. Session information updated at 2023-08-04 10:17. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:2412,performance,bottleneck,bottleneck,2412,"wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised while reading key {elem.name!r} of "". 190 f""type {type(elem)} from {parent}."". 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. PyQt5 NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.7. brotli 1.0.9. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. colorama 0.4.6. comm 0.1.4. cvxopt 1.3.1. cycler 0.10.0. cython_runtime NA. ... Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]. Windows-10-10.0.19045-SP0. -----. Session information updated at 2023-08-04 10:17. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:24,safety,error,error,24,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:407,safety,Error,Error,407,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:453,safety,error,error,453,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:500,safety,error,error,500,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:595,safety,Error,Error,595,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:862,safety,except,except,862,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:869,safety,Except,Exception,869,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:2005,safety,error,error,2005,"wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised while reading key {elem.name!r} of "". 190 f""type {type(elem)} from {parent}."". 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. PyQt5 NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.7. brotli 1.0.9. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. colorama 0.4.6. comm 0.1.4. cvxopt 1.3.1. cycler 0.10.0. cython_runtime NA. ... Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]. Windows-10-10.0.19045-SP0. -----. Session information updated at 2023-08-04 10:17. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:2135,safety,error,error,2135,"wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised while reading key {elem.name!r} of "". 190 f""type {type(elem)} from {parent}."". 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. PyQt5 NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.7. brotli 1.0.9. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. colorama 0.4.6. comm 0.1.4. cvxopt 1.3.1. cycler 0.10.0. cython_runtime NA. ... Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]. Windows-10-10.0.19045-SP0. -----. Session information updated at 2023-08-04 10:17. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:2739,safety,updat,updated,2739,"wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised while reading key {elem.name!r} of "". 190 f""type {type(elem)} from {parent}."". 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. PyQt5 NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.7. brotli 1.0.9. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. colorama 0.4.6. comm 0.1.4. cvxopt 1.3.1. cycler 0.10.0. cython_runtime NA. ... Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]. Windows-10-10.0.19045-SP0. -----. Session information updated at 2023-08-04 10:17. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:696,security,lineag,lineageOT,696,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:921,security,lineag,lineageOT,921,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:1016,security,modif,modifiers,1016,"ve error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised whi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:1190,security,lineag,lineageOT,1190,"X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised while reading key {elem.name!r} of "". 190 f""type {type(elem)} from {parent}."". 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /. ```. ###",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:1393,security,lineag,lineageOT,1393,"et an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised while reading key {elem.name!r} of "". 190 f""type {type(elem)} from {parent}."". 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. PyQt5 NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. bi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:1890,security,lineag,lineageOT,1890,"wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised while reading key {elem.name!r} of "". 190 f""type {type(elem)} from {parent}."". 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. PyQt5 NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.7. brotli 1.0.9. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. colorama 0.4.6. comm 0.1.4. cvxopt 1.3.1. cycler 0.10.0. cython_runtime NA. ... Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]. Windows-10-10.0.19045-SP0. -----. Session information updated at 2023-08-04 10:17. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:2444,security,certif,certifi,2444,"wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised while reading key {elem.name!r} of "". 190 f""type {type(elem)} from {parent}."". 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. PyQt5 NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.7. brotli 1.0.9. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. colorama 0.4.6. comm 0.1.4. cvxopt 1.3.1. cycler 0.10.0. cython_runtime NA. ... Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]. Windows-10-10.0.19045-SP0. -----. Session information updated at 2023-08-04 10:17. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:2719,security,Session,Session,2719,"wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised while reading key {elem.name!r} of "". 190 f""type {type(elem)} from {parent}."". 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. PyQt5 NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.7. brotli 1.0.9. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. colorama 0.4.6. comm 0.1.4. cvxopt 1.3.1. cycler 0.10.0. cython_runtime NA. ... Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]. Windows-10-10.0.19045-SP0. -----. Session information updated at 2023-08-04 10:17. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:2739,security,updat,updated,2739,"wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised while reading key {elem.name!r} of "". 190 f""type {type(elem)} from {parent}."". 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. PyQt5 NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.7. brotli 1.0.9. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. colorama 0.4.6. comm 0.1.4. cvxopt 1.3.1. cycler 0.10.0. cython_runtime NA. ... Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]. Windows-10-10.0.19045-SP0. -----. Session information updated at 2023-08-04 10:17. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:626,testability,Trace,Traceback,626,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:24,usability,error,error,24,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:205,usability,confirm,confirmed,205,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:288,usability,confirm,confirmed,288,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:407,usability,Error,Error,407,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:453,usability,error,error,453,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:500,usability,error,error,500,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:511,usability,Minim,Minimal,511,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:595,usability,Error,Error,595,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:669,usability,User,Users,669,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:894,usability,User,Users,894,"AnnDataReadError: Above error raised while reading key '/X' of type from /.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""A",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:1163,usability,User,Users,1163,"ot already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Trying to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised while reading key {elem.name!r} of "". 190 f""type {type(elem)} from {parent}."". 191 ) from e. AnnDataReadError: Above error raised while reading key ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:1366,usability,User,Users,1366,"ng to read an anndata file. Get an OS Error. Have checked other posts about similar error, but nothing there seemed to resolve the error. ### Minimal code sample. ```python. adata = sc.read_h5ad('./cis_scanpy.h5ad'). ```. ### Error output. ```pytb. OSError Traceback (most recent call last). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\utils.py:202, in report_read_key_on_error..func_wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised while reading key {elem.name!r} of "". 190 f""type {type(elem)} from {parent}."". 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. PyQt5 NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. back",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:1863,usability,User,Users,1863,"wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised while reading key {elem.name!r} of "". 190 f""type {type(elem)} from {parent}."". 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. PyQt5 NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.7. brotli 1.0.9. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. colorama 0.4.6. comm 0.1.4. cvxopt 1.3.1. cycler 0.10.0. cython_runtime NA. ... Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]. Windows-10-10.0.19045-SP0. -----. Session information updated at 2023-08-04 10:17. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:2005,usability,error,error,2005,"wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised while reading key {elem.name!r} of "". 190 f""type {type(elem)} from {parent}."". 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. PyQt5 NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.7. brotli 1.0.9. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. colorama 0.4.6. comm 0.1.4. cvxopt 1.3.1. cycler 0.10.0. cython_runtime NA. ... Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]. Windows-10-10.0.19045-SP0. -----. Session information updated at 2023-08-04 10:17. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/issues/2592:2135,usability,error,error,2135,"wrapper(*args, **kwargs). 201 try:. --> 202 return func(*args, **kwargs). 203 except Exception as e:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\registry.py:235, in Reader.read_elem(self, elem, modifiers). 234 if self.callback is not None:. --> 235 return self.callback(read_func, elem.name, elem, iospec=get_spec(elem)). 236 else:. File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\h5ad.py:241, in read_h5ad..callback(func, elem_name, elem, iospec). 240 return read_dataframe(elem). --> 241 return func(elem). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_io\specs\methods.py:500, in read_sparse(elem, _reader). 495 @_REGISTRY.register_read(H5Group, IOSpec(""csc_matrix"", ""0.1.0"")). 496 @_REGISTRY.register_read(H5Group, IOSpec(""csr_matrix"", ""0.1.0"")). 497 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csc_matrix"", ""0.1.0"")). 498 @_REGISTRY.register_read(ZarrGroup, IOSpec(""csr_matrix"", ""0.1.0"")). 499 def read_sparse(elem, _reader):. --> 500 return SparseDataset(elem).to_memory(). File c:\Users\echen\Anaconda3\envs\lineageOT\lib\site-packages\anndata\_core\sparse_dataset.py:379, in SparseDataset.to_memory(self). ... 189 f""Above error raised while reading key {elem.name!r} of "". 190 f""type {type(elem)} from {parent}."". 191 ) from e. AnnDataReadError: Above error raised while reading key '/X' of type from /. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. PyQt5 NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.7. brotli 1.0.9. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. colorama 0.4.6. comm 0.1.4. cvxopt 1.3.1. cycler 0.10.0. cython_runtime NA. ... Python 3.10.12 | packaged by conda-forge | (main, Jun 23 2023, 22:34:57) [MSC v.1936 64 bit (AMD64)]. Windows-10-10.0.19045-SP0. -----. Session information updated at 2023-08-04 10:17. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2592
https://github.com/scverse/scanpy/pull/2593:48,safety,test,tests,48,switch to pytestmark; preparation for more dask tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2593
https://github.com/scverse/scanpy/pull/2593:48,testability,test,tests,48,switch to pytestmark; preparation for more dask tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2593
https://github.com/scverse/scanpy/pull/2595:131,availability,avail,available,131,"Make helpers work with dask; Preparation for more thorough testing of dask support. - [x] move `DaskArray` to `_compat` to have it available everywhere. - [x] test everything using `array_type` or similar with the same fixture. - [x] Add Dask support to `is_constant` (which uses above fixture). the code in [scanpy/metrics/_common.py](https://github.com/scverse/scanpy/pull/2595/files#diff-caabb542dafdc95621693d71cb6a514af1457c05926438e307d3f8107bf91401) has been moved from [scanpy/metrics/_gearys_c.py](https://github.com/scverse/scanpy/pull/2595/files#diff-1ff58f43272e7b1451de7df9813a0d20aba57f55b23d38b2d46e309d75c2879b) without changes. the only real meat this has is in [scanpy/_utils/compute/is_constant.py](https://github.com/scverse/scanpy/pull/2595/files#diff-e2c27335c5bfbbfb5ae9ac042c09411bfaca7d22340c257974d5d2bc68aea677):. https://github.com/scverse/scanpy/blob/f4f4185709b438e9cfe56db806a449634e214756/scanpy/_utils/compute/is_constant.py#L127-L134. its not a great implementation since it concatenates everything along an axis, but that makes it trivially correct.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2595
https://github.com/scverse/scanpy/pull/2595:131,reliability,availab,available,131,"Make helpers work with dask; Preparation for more thorough testing of dask support. - [x] move `DaskArray` to `_compat` to have it available everywhere. - [x] test everything using `array_type` or similar with the same fixture. - [x] Add Dask support to `is_constant` (which uses above fixture). the code in [scanpy/metrics/_common.py](https://github.com/scverse/scanpy/pull/2595/files#diff-caabb542dafdc95621693d71cb6a514af1457c05926438e307d3f8107bf91401) has been moved from [scanpy/metrics/_gearys_c.py](https://github.com/scverse/scanpy/pull/2595/files#diff-1ff58f43272e7b1451de7df9813a0d20aba57f55b23d38b2d46e309d75c2879b) without changes. the only real meat this has is in [scanpy/_utils/compute/is_constant.py](https://github.com/scverse/scanpy/pull/2595/files#diff-e2c27335c5bfbbfb5ae9ac042c09411bfaca7d22340c257974d5d2bc68aea677):. https://github.com/scverse/scanpy/blob/f4f4185709b438e9cfe56db806a449634e214756/scanpy/_utils/compute/is_constant.py#L127-L134. its not a great implementation since it concatenates everything along an axis, but that makes it trivially correct.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2595
https://github.com/scverse/scanpy/pull/2595:59,safety,test,testing,59,"Make helpers work with dask; Preparation for more thorough testing of dask support. - [x] move `DaskArray` to `_compat` to have it available everywhere. - [x] test everything using `array_type` or similar with the same fixture. - [x] Add Dask support to `is_constant` (which uses above fixture). the code in [scanpy/metrics/_common.py](https://github.com/scverse/scanpy/pull/2595/files#diff-caabb542dafdc95621693d71cb6a514af1457c05926438e307d3f8107bf91401) has been moved from [scanpy/metrics/_gearys_c.py](https://github.com/scverse/scanpy/pull/2595/files#diff-1ff58f43272e7b1451de7df9813a0d20aba57f55b23d38b2d46e309d75c2879b) without changes. the only real meat this has is in [scanpy/_utils/compute/is_constant.py](https://github.com/scverse/scanpy/pull/2595/files#diff-e2c27335c5bfbbfb5ae9ac042c09411bfaca7d22340c257974d5d2bc68aea677):. https://github.com/scverse/scanpy/blob/f4f4185709b438e9cfe56db806a449634e214756/scanpy/_utils/compute/is_constant.py#L127-L134. its not a great implementation since it concatenates everything along an axis, but that makes it trivially correct.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2595
https://github.com/scverse/scanpy/pull/2595:131,safety,avail,available,131,"Make helpers work with dask; Preparation for more thorough testing of dask support. - [x] move `DaskArray` to `_compat` to have it available everywhere. - [x] test everything using `array_type` or similar with the same fixture. - [x] Add Dask support to `is_constant` (which uses above fixture). the code in [scanpy/metrics/_common.py](https://github.com/scverse/scanpy/pull/2595/files#diff-caabb542dafdc95621693d71cb6a514af1457c05926438e307d3f8107bf91401) has been moved from [scanpy/metrics/_gearys_c.py](https://github.com/scverse/scanpy/pull/2595/files#diff-1ff58f43272e7b1451de7df9813a0d20aba57f55b23d38b2d46e309d75c2879b) without changes. the only real meat this has is in [scanpy/_utils/compute/is_constant.py](https://github.com/scverse/scanpy/pull/2595/files#diff-e2c27335c5bfbbfb5ae9ac042c09411bfaca7d22340c257974d5d2bc68aea677):. https://github.com/scverse/scanpy/blob/f4f4185709b438e9cfe56db806a449634e214756/scanpy/_utils/compute/is_constant.py#L127-L134. its not a great implementation since it concatenates everything along an axis, but that makes it trivially correct.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2595
https://github.com/scverse/scanpy/pull/2595:159,safety,test,test,159,"Make helpers work with dask; Preparation for more thorough testing of dask support. - [x] move `DaskArray` to `_compat` to have it available everywhere. - [x] test everything using `array_type` or similar with the same fixture. - [x] Add Dask support to `is_constant` (which uses above fixture). the code in [scanpy/metrics/_common.py](https://github.com/scverse/scanpy/pull/2595/files#diff-caabb542dafdc95621693d71cb6a514af1457c05926438e307d3f8107bf91401) has been moved from [scanpy/metrics/_gearys_c.py](https://github.com/scverse/scanpy/pull/2595/files#diff-1ff58f43272e7b1451de7df9813a0d20aba57f55b23d38b2d46e309d75c2879b) without changes. the only real meat this has is in [scanpy/_utils/compute/is_constant.py](https://github.com/scverse/scanpy/pull/2595/files#diff-e2c27335c5bfbbfb5ae9ac042c09411bfaca7d22340c257974d5d2bc68aea677):. https://github.com/scverse/scanpy/blob/f4f4185709b438e9cfe56db806a449634e214756/scanpy/_utils/compute/is_constant.py#L127-L134. its not a great implementation since it concatenates everything along an axis, but that makes it trivially correct.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2595
https://github.com/scverse/scanpy/pull/2595:131,security,availab,available,131,"Make helpers work with dask; Preparation for more thorough testing of dask support. - [x] move `DaskArray` to `_compat` to have it available everywhere. - [x] test everything using `array_type` or similar with the same fixture. - [x] Add Dask support to `is_constant` (which uses above fixture). the code in [scanpy/metrics/_common.py](https://github.com/scverse/scanpy/pull/2595/files#diff-caabb542dafdc95621693d71cb6a514af1457c05926438e307d3f8107bf91401) has been moved from [scanpy/metrics/_gearys_c.py](https://github.com/scverse/scanpy/pull/2595/files#diff-1ff58f43272e7b1451de7df9813a0d20aba57f55b23d38b2d46e309d75c2879b) without changes. the only real meat this has is in [scanpy/_utils/compute/is_constant.py](https://github.com/scverse/scanpy/pull/2595/files#diff-e2c27335c5bfbbfb5ae9ac042c09411bfaca7d22340c257974d5d2bc68aea677):. https://github.com/scverse/scanpy/blob/f4f4185709b438e9cfe56db806a449634e214756/scanpy/_utils/compute/is_constant.py#L127-L134. its not a great implementation since it concatenates everything along an axis, but that makes it trivially correct.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2595
https://github.com/scverse/scanpy/pull/2595:59,testability,test,testing,59,"Make helpers work with dask; Preparation for more thorough testing of dask support. - [x] move `DaskArray` to `_compat` to have it available everywhere. - [x] test everything using `array_type` or similar with the same fixture. - [x] Add Dask support to `is_constant` (which uses above fixture). the code in [scanpy/metrics/_common.py](https://github.com/scverse/scanpy/pull/2595/files#diff-caabb542dafdc95621693d71cb6a514af1457c05926438e307d3f8107bf91401) has been moved from [scanpy/metrics/_gearys_c.py](https://github.com/scverse/scanpy/pull/2595/files#diff-1ff58f43272e7b1451de7df9813a0d20aba57f55b23d38b2d46e309d75c2879b) without changes. the only real meat this has is in [scanpy/_utils/compute/is_constant.py](https://github.com/scverse/scanpy/pull/2595/files#diff-e2c27335c5bfbbfb5ae9ac042c09411bfaca7d22340c257974d5d2bc68aea677):. https://github.com/scverse/scanpy/blob/f4f4185709b438e9cfe56db806a449634e214756/scanpy/_utils/compute/is_constant.py#L127-L134. its not a great implementation since it concatenates everything along an axis, but that makes it trivially correct.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2595
https://github.com/scverse/scanpy/pull/2595:159,testability,test,test,159,"Make helpers work with dask; Preparation for more thorough testing of dask support. - [x] move `DaskArray` to `_compat` to have it available everywhere. - [x] test everything using `array_type` or similar with the same fixture. - [x] Add Dask support to `is_constant` (which uses above fixture). the code in [scanpy/metrics/_common.py](https://github.com/scverse/scanpy/pull/2595/files#diff-caabb542dafdc95621693d71cb6a514af1457c05926438e307d3f8107bf91401) has been moved from [scanpy/metrics/_gearys_c.py](https://github.com/scverse/scanpy/pull/2595/files#diff-1ff58f43272e7b1451de7df9813a0d20aba57f55b23d38b2d46e309d75c2879b) without changes. the only real meat this has is in [scanpy/_utils/compute/is_constant.py](https://github.com/scverse/scanpy/pull/2595/files#diff-e2c27335c5bfbbfb5ae9ac042c09411bfaca7d22340c257974d5d2bc68aea677):. https://github.com/scverse/scanpy/blob/f4f4185709b438e9cfe56db806a449634e214756/scanpy/_utils/compute/is_constant.py#L127-L134. its not a great implementation since it concatenates everything along an axis, but that makes it trivially correct.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2595
https://github.com/scverse/scanpy/pull/2595:5,usability,help,helpers,5,"Make helpers work with dask; Preparation for more thorough testing of dask support. - [x] move `DaskArray` to `_compat` to have it available everywhere. - [x] test everything using `array_type` or similar with the same fixture. - [x] Add Dask support to `is_constant` (which uses above fixture). the code in [scanpy/metrics/_common.py](https://github.com/scverse/scanpy/pull/2595/files#diff-caabb542dafdc95621693d71cb6a514af1457c05926438e307d3f8107bf91401) has been moved from [scanpy/metrics/_gearys_c.py](https://github.com/scverse/scanpy/pull/2595/files#diff-1ff58f43272e7b1451de7df9813a0d20aba57f55b23d38b2d46e309d75c2879b) without changes. the only real meat this has is in [scanpy/_utils/compute/is_constant.py](https://github.com/scverse/scanpy/pull/2595/files#diff-e2c27335c5bfbbfb5ae9ac042c09411bfaca7d22340c257974d5d2bc68aea677):. https://github.com/scverse/scanpy/blob/f4f4185709b438e9cfe56db806a449634e214756/scanpy/_utils/compute/is_constant.py#L127-L134. its not a great implementation since it concatenates everything along an axis, but that makes it trivially correct.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2595
https://github.com/scverse/scanpy/pull/2595:75,usability,support,support,75,"Make helpers work with dask; Preparation for more thorough testing of dask support. - [x] move `DaskArray` to `_compat` to have it available everywhere. - [x] test everything using `array_type` or similar with the same fixture. - [x] Add Dask support to `is_constant` (which uses above fixture). the code in [scanpy/metrics/_common.py](https://github.com/scverse/scanpy/pull/2595/files#diff-caabb542dafdc95621693d71cb6a514af1457c05926438e307d3f8107bf91401) has been moved from [scanpy/metrics/_gearys_c.py](https://github.com/scverse/scanpy/pull/2595/files#diff-1ff58f43272e7b1451de7df9813a0d20aba57f55b23d38b2d46e309d75c2879b) without changes. the only real meat this has is in [scanpy/_utils/compute/is_constant.py](https://github.com/scverse/scanpy/pull/2595/files#diff-e2c27335c5bfbbfb5ae9ac042c09411bfaca7d22340c257974d5d2bc68aea677):. https://github.com/scverse/scanpy/blob/f4f4185709b438e9cfe56db806a449634e214756/scanpy/_utils/compute/is_constant.py#L127-L134. its not a great implementation since it concatenates everything along an axis, but that makes it trivially correct.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2595
https://github.com/scverse/scanpy/pull/2595:243,usability,support,support,243,"Make helpers work with dask; Preparation for more thorough testing of dask support. - [x] move `DaskArray` to `_compat` to have it available everywhere. - [x] test everything using `array_type` or similar with the same fixture. - [x] Add Dask support to `is_constant` (which uses above fixture). the code in [scanpy/metrics/_common.py](https://github.com/scverse/scanpy/pull/2595/files#diff-caabb542dafdc95621693d71cb6a514af1457c05926438e307d3f8107bf91401) has been moved from [scanpy/metrics/_gearys_c.py](https://github.com/scverse/scanpy/pull/2595/files#diff-1ff58f43272e7b1451de7df9813a0d20aba57f55b23d38b2d46e309d75c2879b) without changes. the only real meat this has is in [scanpy/_utils/compute/is_constant.py](https://github.com/scverse/scanpy/pull/2595/files#diff-e2c27335c5bfbbfb5ae9ac042c09411bfaca7d22340c257974d5d2bc68aea677):. https://github.com/scverse/scanpy/blob/f4f4185709b438e9cfe56db806a449634e214756/scanpy/_utils/compute/is_constant.py#L127-L134. its not a great implementation since it concatenates everything along an axis, but that makes it trivially correct.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2595
https://github.com/scverse/scanpy/pull/2596:26,deployability,version,version,26,Use faster default Python version for jobs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2596
https://github.com/scverse/scanpy/pull/2596:26,integrability,version,version,26,Use faster default Python version for jobs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2596
https://github.com/scverse/scanpy/pull/2596:26,modifiability,version,version,26,Use faster default Python version for jobs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2596
https://github.com/scverse/scanpy/pull/2596:263,safety,review,review,263,Use faster default Python version for jobs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2596
https://github.com/scverse/scanpy/pull/2596:263,testability,review,review,263,Use faster default Python version for jobs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2596
https://github.com/scverse/scanpy/pull/2596:114,usability,guid,guidelines,114,Use faster default Python version for jobs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2596
https://github.com/scverse/scanpy/pull/2596:145,usability,guid,guide,145,Use faster default Python version for jobs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2596
https://github.com/scverse/scanpy/pull/2596:241,usability,workflow,workflow,241,Use faster default Python version for jobs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2596
https://github.com/scverse/scanpy/pull/2597:41,deployability,releas,release,41,Backport PR #2594 on branch 1.9.x (1.9.4 release notes); Backport PR #2594: 1.9.4 release notes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2597
https://github.com/scverse/scanpy/pull/2597:82,deployability,releas,release,82,Backport PR #2594 on branch 1.9.x (1.9.4 release notes); Backport PR #2594: 1.9.4 release notes,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2597
https://github.com/scverse/scanpy/issues/2598:36,deployability,version,versions,36,"read_visium() for newer SpaceRanger versions; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. When using SpaceRanger Versions 2.0 and higher, the output no longer contains a tissue_positions_list.csv file. Instead, this file is named tissue_positions.csv. Therefore, it is no longer compatible with scanpy's read_visium() function. Currently, the issue can be fixed by manually renaming the SpaceRanger Output before running the read_visium() function. However, in the long term, I would love for scanpy to be up to date with current SpaceRanger Outputs or to give the user the opportunity to define the name of their tissue positions file. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2598
https://github.com/scverse/scanpy/issues/2598:229,deployability,Version,Versions,229,"read_visium() for newer SpaceRanger versions; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. When using SpaceRanger Versions 2.0 and higher, the output no longer contains a tissue_positions_list.csv file. Instead, this file is named tissue_positions.csv. Therefore, it is no longer compatible with scanpy's read_visium() function. Currently, the issue can be fixed by manually renaming the SpaceRanger Output before running the read_visium() function. However, in the long term, I would love for scanpy to be up to date with current SpaceRanger Outputs or to give the user the opportunity to define the name of their tissue positions file. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2598
https://github.com/scverse/scanpy/issues/2598:275,deployability,contain,contains,275,"read_visium() for newer SpaceRanger versions; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. When using SpaceRanger Versions 2.0 and higher, the output no longer contains a tissue_positions_list.csv file. Instead, this file is named tissue_positions.csv. Therefore, it is no longer compatible with scanpy's read_visium() function. Currently, the issue can be fixed by manually renaming the SpaceRanger Output before running the read_visium() function. However, in the long term, I would love for scanpy to be up to date with current SpaceRanger Outputs or to give the user the opportunity to define the name of their tissue positions file. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2598
https://github.com/scverse/scanpy/issues/2598:444,energy efficiency,Current,Currently,444,"read_visium() for newer SpaceRanger versions; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. When using SpaceRanger Versions 2.0 and higher, the output no longer contains a tissue_positions_list.csv file. Instead, this file is named tissue_positions.csv. Therefore, it is no longer compatible with scanpy's read_visium() function. Currently, the issue can be fixed by manually renaming the SpaceRanger Output before running the read_visium() function. However, in the long term, I would love for scanpy to be up to date with current SpaceRanger Outputs or to give the user the opportunity to define the name of their tissue positions file. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2598
https://github.com/scverse/scanpy/issues/2598:638,energy efficiency,current,current,638,"read_visium() for newer SpaceRanger versions; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. When using SpaceRanger Versions 2.0 and higher, the output no longer contains a tissue_positions_list.csv file. Instead, this file is named tissue_positions.csv. Therefore, it is no longer compatible with scanpy's read_visium() function. Currently, the issue can be fixed by manually renaming the SpaceRanger Output before running the read_visium() function. However, in the long term, I would love for scanpy to be up to date with current SpaceRanger Outputs or to give the user the opportunity to define the name of their tissue positions file. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2598
https://github.com/scverse/scanpy/issues/2598:36,integrability,version,versions,36,"read_visium() for newer SpaceRanger versions; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. When using SpaceRanger Versions 2.0 and higher, the output no longer contains a tissue_positions_list.csv file. Instead, this file is named tissue_positions.csv. Therefore, it is no longer compatible with scanpy's read_visium() function. Currently, the issue can be fixed by manually renaming the SpaceRanger Output before running the read_visium() function. However, in the long term, I would love for scanpy to be up to date with current SpaceRanger Outputs or to give the user the opportunity to define the name of their tissue positions file. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2598
https://github.com/scverse/scanpy/issues/2598:229,integrability,Version,Versions,229,"read_visium() for newer SpaceRanger versions; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. When using SpaceRanger Versions 2.0 and higher, the output no longer contains a tissue_positions_list.csv file. Instead, this file is named tissue_positions.csv. Therefore, it is no longer compatible with scanpy's read_visium() function. Currently, the issue can be fixed by manually renaming the SpaceRanger Output before running the read_visium() function. However, in the long term, I would love for scanpy to be up to date with current SpaceRanger Outputs or to give the user the opportunity to define the name of their tissue positions file. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2598
https://github.com/scverse/scanpy/issues/2598:395,interoperability,compatib,compatible,395,"read_visium() for newer SpaceRanger versions; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. When using SpaceRanger Versions 2.0 and higher, the output no longer contains a tissue_positions_list.csv file. Instead, this file is named tissue_positions.csv. Therefore, it is no longer compatible with scanpy's read_visium() function. Currently, the issue can be fixed by manually renaming the SpaceRanger Output before running the read_visium() function. However, in the long term, I would love for scanpy to be up to date with current SpaceRanger Outputs or to give the user the opportunity to define the name of their tissue positions file. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2598
https://github.com/scverse/scanpy/issues/2598:36,modifiability,version,versions,36,"read_visium() for newer SpaceRanger versions; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. When using SpaceRanger Versions 2.0 and higher, the output no longer contains a tissue_positions_list.csv file. Instead, this file is named tissue_positions.csv. Therefore, it is no longer compatible with scanpy's read_visium() function. Currently, the issue can be fixed by manually renaming the SpaceRanger Output before running the read_visium() function. However, in the long term, I would love for scanpy to be up to date with current SpaceRanger Outputs or to give the user the opportunity to define the name of their tissue positions file. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2598
https://github.com/scverse/scanpy/issues/2598:118,modifiability,paramet,parameters,118,"read_visium() for newer SpaceRanger versions; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. When using SpaceRanger Versions 2.0 and higher, the output no longer contains a tissue_positions_list.csv file. Instead, this file is named tissue_positions.csv. Therefore, it is no longer compatible with scanpy's read_visium() function. Currently, the issue can be fixed by manually renaming the SpaceRanger Output before running the read_visium() function. However, in the long term, I would love for scanpy to be up to date with current SpaceRanger Outputs or to give the user the opportunity to define the name of their tissue positions file. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2598
https://github.com/scverse/scanpy/issues/2598:229,modifiability,Version,Versions,229,"read_visium() for newer SpaceRanger versions; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. When using SpaceRanger Versions 2.0 and higher, the output no longer contains a tissue_positions_list.csv file. Instead, this file is named tissue_positions.csv. Therefore, it is no longer compatible with scanpy's read_visium() function. Currently, the issue can be fixed by manually renaming the SpaceRanger Output before running the read_visium() function. However, in the long term, I would love for scanpy to be up to date with current SpaceRanger Outputs or to give the user the opportunity to define the name of their tissue positions file. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2598
https://github.com/scverse/scanpy/issues/2598:681,usability,user,user,681,"read_visium() for newer SpaceRanger versions; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. When using SpaceRanger Versions 2.0 and higher, the output no longer contains a tissue_positions_list.csv file. Instead, this file is named tissue_positions.csv. Therefore, it is no longer compatible with scanpy's read_visium() function. Currently, the issue can be fixed by manually renaming the SpaceRanger Output before running the read_visium() function. However, in the long term, I would love for scanpy to be up to date with current SpaceRanger Outputs or to give the user the opportunity to define the name of their tissue positions file. Thank you!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2598
https://github.com/scverse/scanpy/pull/2599:44,safety,test,tests,44,Backport PR #2575 on branch 1.9.x (Simplify tests); Backport PR #2575: Simplify tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2599
https://github.com/scverse/scanpy/pull/2599:80,safety,test,tests,80,Backport PR #2575 on branch 1.9.x (Simplify tests); Backport PR #2575: Simplify tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2599
https://github.com/scverse/scanpy/pull/2599:35,testability,Simpl,Simplify,35,Backport PR #2575 on branch 1.9.x (Simplify tests); Backport PR #2575: Simplify tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2599
https://github.com/scverse/scanpy/pull/2599:44,testability,test,tests,44,Backport PR #2575 on branch 1.9.x (Simplify tests); Backport PR #2575: Simplify tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2599
https://github.com/scverse/scanpy/pull/2599:71,testability,Simpl,Simplify,71,Backport PR #2575 on branch 1.9.x (Simplify tests); Backport PR #2575: Simplify tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2599
https://github.com/scverse/scanpy/pull/2599:80,testability,test,tests,80,Backport PR #2575 on branch 1.9.x (Simplify tests); Backport PR #2575: Simplify tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2599
https://github.com/scverse/scanpy/pull/2599:35,usability,Simpl,Simplify,35,Backport PR #2575 on branch 1.9.x (Simplify tests); Backport PR #2575: Simplify tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2599
https://github.com/scverse/scanpy/pull/2599:71,usability,Simpl,Simplify,71,Backport PR #2575 on branch 1.9.x (Simplify tests); Backport PR #2575: Simplify tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2599
https://github.com/scverse/scanpy/pull/2600:69,deployability,log,logreg,69,Backport PR #2589 on branch 1.9.x (Fixed wrong order for groups with logreg); Backport PR #2589: Fixed wrong order for groups with logreg,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2600
https://github.com/scverse/scanpy/pull/2600:131,deployability,log,logreg,131,Backport PR #2589 on branch 1.9.x (Fixed wrong order for groups with logreg); Backport PR #2589: Fixed wrong order for groups with logreg,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2600
https://github.com/scverse/scanpy/pull/2600:69,safety,log,logreg,69,Backport PR #2589 on branch 1.9.x (Fixed wrong order for groups with logreg); Backport PR #2589: Fixed wrong order for groups with logreg,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2600
https://github.com/scverse/scanpy/pull/2600:131,safety,log,logreg,131,Backport PR #2589 on branch 1.9.x (Fixed wrong order for groups with logreg); Backport PR #2589: Fixed wrong order for groups with logreg,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2600
https://github.com/scverse/scanpy/pull/2600:69,security,log,logreg,69,Backport PR #2589 on branch 1.9.x (Fixed wrong order for groups with logreg); Backport PR #2589: Fixed wrong order for groups with logreg,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2600
https://github.com/scverse/scanpy/pull/2600:131,security,log,logreg,131,Backport PR #2589 on branch 1.9.x (Fixed wrong order for groups with logreg); Backport PR #2589: Fixed wrong order for groups with logreg,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2600
https://github.com/scverse/scanpy/pull/2600:69,testability,log,logreg,69,Backport PR #2589 on branch 1.9.x (Fixed wrong order for groups with logreg); Backport PR #2589: Fixed wrong order for groups with logreg,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2600
https://github.com/scverse/scanpy/pull/2600:131,testability,log,logreg,131,Backport PR #2589 on branch 1.9.x (Fixed wrong order for groups with logreg); Backport PR #2589: Fixed wrong order for groups with logreg,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2600
https://github.com/scverse/scanpy/pull/2601:38,deployability,log,logreg,38,"fixed `get.rank_genes_groups_df` with logreg; `get.rank_genes_groups_df` didn't work when the method was ""logreg"". Now it works as intended",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2601
https://github.com/scverse/scanpy/pull/2601:106,deployability,log,logreg,106,"fixed `get.rank_genes_groups_df` with logreg; `get.rank_genes_groups_df` didn't work when the method was ""logreg"". Now it works as intended",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2601
https://github.com/scverse/scanpy/pull/2601:38,safety,log,logreg,38,"fixed `get.rank_genes_groups_df` with logreg; `get.rank_genes_groups_df` didn't work when the method was ""logreg"". Now it works as intended",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2601
https://github.com/scverse/scanpy/pull/2601:106,safety,log,logreg,106,"fixed `get.rank_genes_groups_df` with logreg; `get.rank_genes_groups_df` didn't work when the method was ""logreg"". Now it works as intended",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2601
https://github.com/scverse/scanpy/pull/2601:38,security,log,logreg,38,"fixed `get.rank_genes_groups_df` with logreg; `get.rank_genes_groups_df` didn't work when the method was ""logreg"". Now it works as intended",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2601
https://github.com/scverse/scanpy/pull/2601:106,security,log,logreg,106,"fixed `get.rank_genes_groups_df` with logreg; `get.rank_genes_groups_df` didn't work when the method was ""logreg"". Now it works as intended",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2601
https://github.com/scverse/scanpy/pull/2601:38,testability,log,logreg,38,"fixed `get.rank_genes_groups_df` with logreg; `get.rank_genes_groups_df` didn't work when the method was ""logreg"". Now it works as intended",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2601
https://github.com/scverse/scanpy/pull/2601:106,testability,log,logreg,106,"fixed `get.rank_genes_groups_df` with logreg; `get.rank_genes_groups_df` didn't work when the method was ""logreg"". Now it works as intended",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2601
https://github.com/scverse/scanpy/pull/2605:42,deployability,modul,modules,42,run doctests; This PR adds the `--doctest-modules` flag to pytest and makes changes necessary to allow the doctests to run. Those changes include:. - Fixing verbosity. - using [pytest-doctestplus](https://github.com/scientific-python/pytest-doctestplus) to skip doctests entirely or when their dependencies are absent. - fixing broken doctests (the bulk of the changes),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2605
https://github.com/scverse/scanpy/pull/2605:294,deployability,depend,dependencies,294,run doctests; This PR adds the `--doctest-modules` flag to pytest and makes changes necessary to allow the doctests to run. Those changes include:. - Fixing verbosity. - using [pytest-doctestplus](https://github.com/scientific-python/pytest-doctestplus) to skip doctests entirely or when their dependencies are absent. - fixing broken doctests (the bulk of the changes),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2605
https://github.com/scverse/scanpy/pull/2605:294,integrability,depend,dependencies,294,run doctests; This PR adds the `--doctest-modules` flag to pytest and makes changes necessary to allow the doctests to run. Those changes include:. - Fixing verbosity. - using [pytest-doctestplus](https://github.com/scientific-python/pytest-doctestplus) to skip doctests entirely or when their dependencies are absent. - fixing broken doctests (the bulk of the changes),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2605
https://github.com/scverse/scanpy/pull/2605:42,modifiability,modul,modules,42,run doctests; This PR adds the `--doctest-modules` flag to pytest and makes changes necessary to allow the doctests to run. Those changes include:. - Fixing verbosity. - using [pytest-doctestplus](https://github.com/scientific-python/pytest-doctestplus) to skip doctests entirely or when their dependencies are absent. - fixing broken doctests (the bulk of the changes),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2605
https://github.com/scverse/scanpy/pull/2605:294,modifiability,depend,dependencies,294,run doctests; This PR adds the `--doctest-modules` flag to pytest and makes changes necessary to allow the doctests to run. Those changes include:. - Fixing verbosity. - using [pytest-doctestplus](https://github.com/scientific-python/pytest-doctestplus) to skip doctests entirely or when their dependencies are absent. - fixing broken doctests (the bulk of the changes),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2605
https://github.com/scverse/scanpy/pull/2605:42,safety,modul,modules,42,run doctests; This PR adds the `--doctest-modules` flag to pytest and makes changes necessary to allow the doctests to run. Those changes include:. - Fixing verbosity. - using [pytest-doctestplus](https://github.com/scientific-python/pytest-doctestplus) to skip doctests entirely or when their dependencies are absent. - fixing broken doctests (the bulk of the changes),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2605
https://github.com/scverse/scanpy/pull/2605:294,safety,depend,dependencies,294,run doctests; This PR adds the `--doctest-modules` flag to pytest and makes changes necessary to allow the doctests to run. Those changes include:. - Fixing verbosity. - using [pytest-doctestplus](https://github.com/scientific-python/pytest-doctestplus) to skip doctests entirely or when their dependencies are absent. - fixing broken doctests (the bulk of the changes),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2605
https://github.com/scverse/scanpy/pull/2605:294,testability,depend,dependencies,294,run doctests; This PR adds the `--doctest-modules` flag to pytest and makes changes necessary to allow the doctests to run. Those changes include:. - Fixing verbosity. - using [pytest-doctestplus](https://github.com/scientific-python/pytest-doctestplus) to skip doctests entirely or when their dependencies are absent. - fixing broken doctests (the bulk of the changes),MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2605
https://github.com/scverse/scanpy/pull/2606:73,deployability,log,logreg,73,Backport PR #2601 on branch 1.9.x (fixed `get.rank_genes_groups_df` with logreg); Backport PR #2601: fixed `get.rank_genes_groups_df` with logreg,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2606
https://github.com/scverse/scanpy/pull/2606:139,deployability,log,logreg,139,Backport PR #2601 on branch 1.9.x (fixed `get.rank_genes_groups_df` with logreg); Backport PR #2601: fixed `get.rank_genes_groups_df` with logreg,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2606
https://github.com/scverse/scanpy/pull/2606:73,safety,log,logreg,73,Backport PR #2601 on branch 1.9.x (fixed `get.rank_genes_groups_df` with logreg); Backport PR #2601: fixed `get.rank_genes_groups_df` with logreg,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2606
https://github.com/scverse/scanpy/pull/2606:139,safety,log,logreg,139,Backport PR #2601 on branch 1.9.x (fixed `get.rank_genes_groups_df` with logreg); Backport PR #2601: fixed `get.rank_genes_groups_df` with logreg,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2606
https://github.com/scverse/scanpy/pull/2606:73,security,log,logreg,73,Backport PR #2601 on branch 1.9.x (fixed `get.rank_genes_groups_df` with logreg); Backport PR #2601: fixed `get.rank_genes_groups_df` with logreg,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2606
https://github.com/scverse/scanpy/pull/2606:139,security,log,logreg,139,Backport PR #2601 on branch 1.9.x (fixed `get.rank_genes_groups_df` with logreg); Backport PR #2601: fixed `get.rank_genes_groups_df` with logreg,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2606
https://github.com/scverse/scanpy/pull/2606:73,testability,log,logreg,73,Backport PR #2601 on branch 1.9.x (fixed `get.rank_genes_groups_df` with logreg); Backport PR #2601: fixed `get.rank_genes_groups_df` with logreg,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2606
https://github.com/scverse/scanpy/pull/2606:139,testability,log,logreg,139,Backport PR #2601 on branch 1.9.x (fixed `get.rank_genes_groups_df` with logreg); Backport PR #2601: fixed `get.rank_genes_groups_df` with logreg,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2606
https://github.com/scverse/scanpy/issues/2607:12,deployability,version,version,12,Rapids-UMAP version outdated; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. The version of the UMAP rapids is outdated and need improvement. I'll create a Rapids based UMAP implementation for rapids-singlecell.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2607
https://github.com/scverse/scanpy/issues/2607:194,deployability,version,version,194,Rapids-UMAP version outdated; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. The version of the UMAP rapids is outdated and need improvement. I'll create a Rapids based UMAP implementation for rapids-singlecell.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2607
https://github.com/scverse/scanpy/issues/2607:12,integrability,version,version,12,Rapids-UMAP version outdated; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. The version of the UMAP rapids is outdated and need improvement. I'll create a Rapids based UMAP implementation for rapids-singlecell.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2607
https://github.com/scverse/scanpy/issues/2607:194,integrability,version,version,194,Rapids-UMAP version outdated; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. The version of the UMAP rapids is outdated and need improvement. I'll create a Rapids based UMAP implementation for rapids-singlecell.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2607
https://github.com/scverse/scanpy/issues/2607:12,modifiability,version,version,12,Rapids-UMAP version outdated; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. The version of the UMAP rapids is outdated and need improvement. I'll create a Rapids based UMAP implementation for rapids-singlecell.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2607
https://github.com/scverse/scanpy/issues/2607:102,modifiability,paramet,parameters,102,Rapids-UMAP version outdated; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. The version of the UMAP rapids is outdated and need improvement. I'll create a Rapids based UMAP implementation for rapids-singlecell.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2607
https://github.com/scverse/scanpy/issues/2607:194,modifiability,version,version,194,Rapids-UMAP version outdated; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. The version of the UMAP rapids is outdated and need improvement. I'll create a Rapids based UMAP implementation for rapids-singlecell.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2607
https://github.com/scverse/scanpy/issues/2608:1462,availability,error,error,1462,"argument 'data_df'`. This seems to be a bug in `scanpy/external/tl/_palantir.py` which [uses the keyword data_df](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:1490,availability,Error,Error,1490,"ems to be a bug in `scanpy/external/tl/_palantir.py` which [uses the keyword data_df](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:238,deployability,version,version,238,"sc.external.tl.palantir uses invalid keywork in run_diffusion_maps(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Running `sc.external.tl.palantir(adata)` raises `TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'`. This seems to be a bug in `scanpy/external/tl/_palantir.py` which [uses the keyword data_df](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:740,deployability,version,version,740,"sc.external.tl.palantir uses invalid keywork in run_diffusion_maps(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Running `sc.external.tl.palantir(adata)` raises `TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'`. This seems to be a bug in `scanpy/external/tl/_palantir.py` which [uses the keyword data_df](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:1575,deployability,modul,module,1575,"(https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. gmpy2 2.1.2. h5py 3.9.0. igraph 0.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:1599,deployability,API,API,1599,"erse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. gmpy2 2.1.2. h5py 3.9.0. igraph 0.10.6. importlib_resource",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:1603,deployability,version,version,1603,"canpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. gmpy2 2.1.2. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:1624,deployability,version,version,1624,"npy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. gmpy2 2.1.2. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. joblib 1.3.2. kiwisol",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:2383,deployability,Version,Versions,2383,".normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. gmpy2 2.1.2. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.10.1. llvmlite 0.40.1. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.5. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 1.5.3. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.1. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.6.7. threadpoolctl 3.2.0. torch 2.0.0. tqdm 4.65.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zipp NA. zoneinfo NA. -----. Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:39:03) [GCC 11.3.0]. Linux-4.18.0-477.15.1.el8_8.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2023-08-09 17:08. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:3257,deployability,updat,updated,3257,".normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. gmpy2 2.1.2. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.10.1. llvmlite 0.40.1. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.5. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 1.5.3. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.1. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.6.7. threadpoolctl 3.2.0. torch 2.0.0. tqdm 4.65.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zipp NA. zoneinfo NA. -----. Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:39:03) [GCC 11.3.0]. Linux-4.18.0-477.15.1.el8_8.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2023-08-09 17:08. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:238,integrability,version,version,238,"sc.external.tl.palantir uses invalid keywork in run_diffusion_maps(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Running `sc.external.tl.palantir(adata)` raises `TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'`. This seems to be a bug in `scanpy/external/tl/_palantir.py` which [uses the keyword data_df](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:740,integrability,version,version,740,"sc.external.tl.palantir uses invalid keywork in run_diffusion_maps(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Running `sc.external.tl.palantir(adata)` raises `TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'`. This seems to be a bug in `scanpy/external/tl/_palantir.py` which [uses the keyword data_df](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:1599,integrability,API,API,1599,"erse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. gmpy2 2.1.2. h5py 3.9.0. igraph 0.10.6. importlib_resource",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:1603,integrability,version,version,1603,"canpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. gmpy2 2.1.2. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:1624,integrability,version,version,1624,"npy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. gmpy2 2.1.2. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. joblib 1.3.2. kiwisol",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:2383,integrability,Version,Versions,2383,".normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. gmpy2 2.1.2. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.10.1. llvmlite 0.40.1. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.5. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 1.5.3. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.1. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.6.7. threadpoolctl 3.2.0. torch 2.0.0. tqdm 4.65.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zipp NA. zoneinfo NA. -----. Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:39:03) [GCC 11.3.0]. Linux-4.18.0-477.15.1.el8_8.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2023-08-09 17:08. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:1599,interoperability,API,API,1599,"erse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. gmpy2 2.1.2. h5py 3.9.0. igraph 0.10.6. importlib_resource",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:238,modifiability,version,version,238,"sc.external.tl.palantir uses invalid keywork in run_diffusion_maps(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Running `sc.external.tl.palantir(adata)` raises `TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'`. This seems to be a bug in `scanpy/external/tl/_palantir.py` which [uses the keyword data_df](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:740,modifiability,version,version,740,"sc.external.tl.palantir uses invalid keywork in run_diffusion_maps(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Running `sc.external.tl.palantir(adata)` raises `TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'`. This seems to be a bug in `scanpy/external/tl/_palantir.py` which [uses the keyword data_df](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:1575,modifiability,modul,module,1575,"(https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. gmpy2 2.1.2. h5py 3.9.0. igraph 0.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:1603,modifiability,version,version,1603,"canpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. gmpy2 2.1.2. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:1624,modifiability,version,version,1624,"npy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. gmpy2 2.1.2. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. joblib 1.3.2. kiwisol",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:2021,modifiability,pac,packages,2021,"palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. gmpy2 2.1.2. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.10.1. llvmlite 0.40.1. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.5. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 1.5.3. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.1. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.6.7. threadpoolctl 3.2.0. torch 2.0.0. tqdm 4.65.2. typing_extensi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:2383,modifiability,Version,Versions,2383,".normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. gmpy2 2.1.2. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.10.1. llvmlite 0.40.1. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.5. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 1.5.3. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.1. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.6.7. threadpoolctl 3.2.0. torch 2.0.0. tqdm 4.65.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zipp NA. zoneinfo NA. -----. Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:39:03) [GCC 11.3.0]. Linux-4.18.0-477.15.1.el8_8.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2023-08-09 17:08. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:2800,modifiability,pac,packaging,2800,".normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. gmpy2 2.1.2. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.10.1. llvmlite 0.40.1. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.5. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 1.5.3. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.1. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.6.7. threadpoolctl 3.2.0. torch 2.0.0. tqdm 4.65.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zipp NA. zoneinfo NA. -----. Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:39:03) [GCC 11.3.0]. Linux-4.18.0-477.15.1.el8_8.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2023-08-09 17:08. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:3103,modifiability,pac,packaged,3103,".normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. gmpy2 2.1.2. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.10.1. llvmlite 0.40.1. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.5. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 1.5.3. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.1. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.6.7. threadpoolctl 3.2.0. torch 2.0.0. tqdm 4.65.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zipp NA. zoneinfo NA. -----. Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:39:03) [GCC 11.3.0]. Linux-4.18.0-477.15.1.el8_8.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2023-08-09 17:08. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:1462,performance,error,error,1462,"argument 'data_df'`. This seems to be a bug in `scanpy/external/tl/_palantir.py` which [uses the keyword data_df](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:1490,performance,Error,Error,1490,"ems to be a bug in `scanpy/external/tl/_palantir.py` which [uses the keyword data_df](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:1462,safety,error,error,1462,"argument 'data_df'`. This seems to be a bug in `scanpy/external/tl/_palantir.py` which [uses the keyword data_df](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:1490,safety,Error,Error,1490,"ems to be a bug in `scanpy/external/tl/_palantir.py` which [uses the keyword data_df](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:1575,safety,modul,module,1575,"(https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. gmpy2 2.1.2. h5py 3.9.0. igraph 0.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:3257,safety,updat,updated,3257,".normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. gmpy2 2.1.2. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.10.1. llvmlite 0.40.1. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.5. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 1.5.3. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.1. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.6.7. threadpoolctl 3.2.0. torch 2.0.0. tqdm 4.65.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zipp NA. zoneinfo NA. -----. Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:39:03) [GCC 11.3.0]. Linux-4.18.0-477.15.1.el8_8.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2023-08-09 17:08. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:3237,security,Session,Session,3237,".normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. gmpy2 2.1.2. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.10.1. llvmlite 0.40.1. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.5. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 1.5.3. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.1. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.6.7. threadpoolctl 3.2.0. torch 2.0.0. tqdm 4.65.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zipp NA. zoneinfo NA. -----. Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:39:03) [GCC 11.3.0]. Linux-4.18.0-477.15.1.el8_8.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2023-08-09 17:08. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:3257,security,updat,updated,3257,".normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. gmpy2 2.1.2. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.10.1. llvmlite 0.40.1. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. numba 0.57.1. numexpr 2.8.5. numpy 1.24.4. opt_einsum v3.3.0. packaging 23.1. pandas 1.5.3. psutil 5.9.5. pyparsing 3.0.9. pytz 2023.3. scipy 1.11.1. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. sympy 1.12. texttable 1.6.7. threadpoolctl 3.2.0. torch 2.0.0. tqdm 4.65.2. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zipp NA. zoneinfo NA. -----. Python 3.9.16 | packaged by conda-forge | (main, Feb 1 2023, 21:39:03) [GCC 11.3.0]. Linux-4.18.0-477.15.1.el8_8.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2023-08-09 17:08. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:1526,testability,Trace,Traceback,1526,"/_palantir.py` which [uses the keyword data_df](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. date",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:1736,testability,Trace,Traceback,1736,"ersion](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. gmpy2 2.1.2. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.10.1. llvmlite 0.40.1. matplotlib 3.7.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. num",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:198,usability,confirm,confirmed,198,"sc.external.tl.palantir uses invalid keywork in run_diffusion_maps(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Running `sc.external.tl.palantir(adata)` raises `TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'`. This seems to be a bug in `scanpy/external/tl/_palantir.py` which [uses the keyword data_df](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:281,usability,confirm,confirmed,281,"sc.external.tl.palantir uses invalid keywork in run_diffusion_maps(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Running `sc.external.tl.palantir(adata)` raises `TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'`. This seems to be a bug in `scanpy/external/tl/_palantir.py` which [uses the keyword data_df](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:865,usability,Minim,Minimal,865,"sc.external.tl.palantir uses invalid keywork in run_diffusion_maps(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Running `sc.external.tl.palantir(adata)` raises `TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'`. This seems to be a bug in `scanpy/external/tl/_palantir.py` which [uses the keyword data_df](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:908,usability,document,documentation,908,"sc.external.tl.palantir uses invalid keywork in run_diffusion_maps(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Running `sc.external.tl.palantir(adata)` raises `TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'`. This seems to be a bug in `scanpy/external/tl/_palantir.py` which [uses the keyword data_df](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:1462,usability,error,error,1462,"argument 'data_df'`. This seems to be a bug in `scanpy/external/tl/_palantir.py` which [uses the keyword data_df](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2608:1490,usability,Error,Error,1490,"ems to be a bug in `scanpy/external/tl/_palantir.py` which [uses the keyword data_df](https://github.com/scverse/scanpy/blob/master/scanpy/external/tl/_palantir.py#L210) which seems to have changed from `data_df` to `data` in the [latest palantir version](https://github.com/dpeerlab/Palantir/blob/cf196adaa1bd02b552f7f0b72f21e3928c2a0649/src/palantir/utils.py#L297). ### Minimal code sample. ```python. # from the documentation: https://scanpy.readthedocs.io/en/stable/generated/scanpy.external.tl.palantir.html#scanpy.external.tl.palantir. # (the data comes with the palantir repo). import scanpy.external as sce. import scanpy as sc. adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). sc.pp.filter_cells(adata, min_counts=1000). sc.pp.filter_genes(adata, min_counts=10). sc.pp.normalize_per_cell(adata). sc.pp.log1p(adata). sc.tl.pca(adata, n_comps=300). sc.pp.neighbors(adata, knn=30). sce.tl.palantir(adata, n_components=5, knn=30) # error occurs here. ```. ### Error output. ```pytb. RuntimeError Traceback (most recent call last). RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). /tmp/ipykernel_5717/3469234522.py in <cell line: 7>(). 5 sc.tl.pca(adata, n_comps=300). 6 sc.pp.neighbors(adata, knn=30). ----> 7 sce.tl.palantir(adata, n_components=5, knn=30). /p/project/hai_microbio/sb/miniconda3/envs/cellrank2/lib/python3.9/site-packages/scanpy/external/tl/_palantir.py in palantir(adata, n_components, knn, alpha, use_adjacency_matrix, distances_key, n_eigs, impute_data, n_steps, copy). 207 . 208 # Diffusion maps. --> 209 dm_res = run_diffusion_maps(. 210 data_df=df,. 211 n_components=n_components,. TypeError: run_diffusion_maps() got an unexpected keyword argument 'data_df'. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 10.0.0. cffi 1.15.1. colorama 0.4.6. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2608
https://github.com/scverse/scanpy/issues/2609:737,availability,Error,Error,737,"Incorrect reference for `score_genes` in documentation; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I believe that the reference for the `score_genes` function is incorrect. It looks to be listed as Satija et al. (2015), which is this paper: [https://doi.org/10.1038/nbt.3192](https://doi.org/10.1038/nbt.3192). If I am not mistaken the correct reference is this paper: [DOI: 10.1126/science.aad0501](https://doi.org/10.1126/science.aad0501). ### Minimal code sample. ```python. N/A. ```. ### Error output. _No response_. ### Versions. N/A.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2609
https://github.com/scverse/scanpy/issues/2609:224,deployability,version,version,224,"Incorrect reference for `score_genes` in documentation; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I believe that the reference for the `score_genes` function is incorrect. It looks to be listed as Satija et al. (2015), which is this paper: [https://doi.org/10.1038/nbt.3192](https://doi.org/10.1038/nbt.3192). If I am not mistaken the correct reference is this paper: [DOI: 10.1126/science.aad0501](https://doi.org/10.1126/science.aad0501). ### Minimal code sample. ```python. N/A. ```. ### Error output. _No response_. ### Versions. N/A.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2609
https://github.com/scverse/scanpy/issues/2609:770,deployability,Version,Versions,770,"Incorrect reference for `score_genes` in documentation; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I believe that the reference for the `score_genes` function is incorrect. It looks to be listed as Satija et al. (2015), which is this paper: [https://doi.org/10.1038/nbt.3192](https://doi.org/10.1038/nbt.3192). If I am not mistaken the correct reference is this paper: [DOI: 10.1126/science.aad0501](https://doi.org/10.1126/science.aad0501). ### Minimal code sample. ```python. N/A. ```. ### Error output. _No response_. ### Versions. N/A.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2609
https://github.com/scverse/scanpy/issues/2609:224,integrability,version,version,224,"Incorrect reference for `score_genes` in documentation; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I believe that the reference for the `score_genes` function is incorrect. It looks to be listed as Satija et al. (2015), which is this paper: [https://doi.org/10.1038/nbt.3192](https://doi.org/10.1038/nbt.3192). If I am not mistaken the correct reference is this paper: [DOI: 10.1126/science.aad0501](https://doi.org/10.1126/science.aad0501). ### Minimal code sample. ```python. N/A. ```. ### Error output. _No response_. ### Versions. N/A.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2609
https://github.com/scverse/scanpy/issues/2609:770,integrability,Version,Versions,770,"Incorrect reference for `score_genes` in documentation; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I believe that the reference for the `score_genes` function is incorrect. It looks to be listed as Satija et al. (2015), which is this paper: [https://doi.org/10.1038/nbt.3192](https://doi.org/10.1038/nbt.3192). If I am not mistaken the correct reference is this paper: [DOI: 10.1126/science.aad0501](https://doi.org/10.1126/science.aad0501). ### Minimal code sample. ```python. N/A. ```. ### Error output. _No response_. ### Versions. N/A.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2609
https://github.com/scverse/scanpy/issues/2609:224,modifiability,version,version,224,"Incorrect reference for `score_genes` in documentation; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I believe that the reference for the `score_genes` function is incorrect. It looks to be listed as Satija et al. (2015), which is this paper: [https://doi.org/10.1038/nbt.3192](https://doi.org/10.1038/nbt.3192). If I am not mistaken the correct reference is this paper: [DOI: 10.1126/science.aad0501](https://doi.org/10.1126/science.aad0501). ### Minimal code sample. ```python. N/A. ```. ### Error output. _No response_. ### Versions. N/A.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2609
https://github.com/scverse/scanpy/issues/2609:770,modifiability,Version,Versions,770,"Incorrect reference for `score_genes` in documentation; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I believe that the reference for the `score_genes` function is incorrect. It looks to be listed as Satija et al. (2015), which is this paper: [https://doi.org/10.1038/nbt.3192](https://doi.org/10.1038/nbt.3192). If I am not mistaken the correct reference is this paper: [DOI: 10.1126/science.aad0501](https://doi.org/10.1126/science.aad0501). ### Minimal code sample. ```python. N/A. ```. ### Error output. _No response_. ### Versions. N/A.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2609
https://github.com/scverse/scanpy/issues/2609:737,performance,Error,Error,737,"Incorrect reference for `score_genes` in documentation; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I believe that the reference for the `score_genes` function is incorrect. It looks to be listed as Satija et al. (2015), which is this paper: [https://doi.org/10.1038/nbt.3192](https://doi.org/10.1038/nbt.3192). If I am not mistaken the correct reference is this paper: [DOI: 10.1126/science.aad0501](https://doi.org/10.1126/science.aad0501). ### Minimal code sample. ```python. N/A. ```. ### Error output. _No response_. ### Versions. N/A.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2609
https://github.com/scverse/scanpy/issues/2609:737,safety,Error,Error,737,"Incorrect reference for `score_genes` in documentation; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I believe that the reference for the `score_genes` function is incorrect. It looks to be listed as Satija et al. (2015), which is this paper: [https://doi.org/10.1038/nbt.3192](https://doi.org/10.1038/nbt.3192). If I am not mistaken the correct reference is this paper: [DOI: 10.1126/science.aad0501](https://doi.org/10.1126/science.aad0501). ### Minimal code sample. ```python. N/A. ```. ### Error output. _No response_. ### Versions. N/A.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2609
https://github.com/scverse/scanpy/issues/2609:41,usability,document,documentation,41,"Incorrect reference for `score_genes` in documentation; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I believe that the reference for the `score_genes` function is incorrect. It looks to be listed as Satija et al. (2015), which is this paper: [https://doi.org/10.1038/nbt.3192](https://doi.org/10.1038/nbt.3192). If I am not mistaken the correct reference is this paper: [DOI: 10.1126/science.aad0501](https://doi.org/10.1126/science.aad0501). ### Minimal code sample. ```python. N/A. ```. ### Error output. _No response_. ### Versions. N/A.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2609
https://github.com/scverse/scanpy/issues/2609:184,usability,confirm,confirmed,184,"Incorrect reference for `score_genes` in documentation; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I believe that the reference for the `score_genes` function is incorrect. It looks to be listed as Satija et al. (2015), which is this paper: [https://doi.org/10.1038/nbt.3192](https://doi.org/10.1038/nbt.3192). If I am not mistaken the correct reference is this paper: [DOI: 10.1126/science.aad0501](https://doi.org/10.1126/science.aad0501). ### Minimal code sample. ```python. N/A. ```. ### Error output. _No response_. ### Versions. N/A.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2609
https://github.com/scverse/scanpy/issues/2609:267,usability,confirm,confirmed,267,"Incorrect reference for `score_genes` in documentation; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I believe that the reference for the `score_genes` function is incorrect. It looks to be listed as Satija et al. (2015), which is this paper: [https://doi.org/10.1038/nbt.3192](https://doi.org/10.1038/nbt.3192). If I am not mistaken the correct reference is this paper: [DOI: 10.1126/science.aad0501](https://doi.org/10.1126/science.aad0501). ### Minimal code sample. ```python. N/A. ```. ### Error output. _No response_. ### Versions. N/A.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2609
https://github.com/scverse/scanpy/issues/2609:691,usability,Minim,Minimal,691,"Incorrect reference for `score_genes` in documentation; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I believe that the reference for the `score_genes` function is incorrect. It looks to be listed as Satija et al. (2015), which is this paper: [https://doi.org/10.1038/nbt.3192](https://doi.org/10.1038/nbt.3192). If I am not mistaken the correct reference is this paper: [DOI: 10.1126/science.aad0501](https://doi.org/10.1126/science.aad0501). ### Minimal code sample. ```python. N/A. ```. ### Error output. _No response_. ### Versions. N/A.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2609
https://github.com/scverse/scanpy/issues/2609:737,usability,Error,Error,737,"Incorrect reference for `score_genes` in documentation; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I believe that the reference for the `score_genes` function is incorrect. It looks to be listed as Satija et al. (2015), which is this paper: [https://doi.org/10.1038/nbt.3192](https://doi.org/10.1038/nbt.3192). If I am not mistaken the correct reference is this paper: [DOI: 10.1126/science.aad0501](https://doi.org/10.1126/science.aad0501). ### Minimal code sample. ```python. N/A. ```. ### Error output. _No response_. ### Versions. N/A.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2609
https://github.com/scverse/scanpy/pull/2610:69,safety,prevent,prevent,69,Improve support for n_pcs if bigger than settings.N_PCS; This should prevent an unexpected behaviour when `n_pcs` is bigger than `settings.N_PCS`. Fixes some parts of the doc strings for neighbours and tsne,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2610
https://github.com/scverse/scanpy/pull/2610:69,security,preven,prevent,69,Improve support for n_pcs if bigger than settings.N_PCS; This should prevent an unexpected behaviour when `n_pcs` is bigger than `settings.N_PCS`. Fixes some parts of the doc strings for neighbours and tsne,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2610
https://github.com/scverse/scanpy/pull/2610:8,usability,support,support,8,Improve support for n_pcs if bigger than settings.N_PCS; This should prevent an unexpected behaviour when `n_pcs` is bigger than `settings.N_PCS`. Fixes some parts of the doc strings for neighbours and tsne,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2610
https://github.com/scverse/scanpy/pull/2610:91,usability,behavi,behaviour,91,Improve support for n_pcs if bigger than settings.N_PCS; This should prevent an unexpected behaviour when `n_pcs` is bigger than `settings.N_PCS`. Fixes some parts of the doc strings for neighbours and tsne,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2610
https://github.com/scverse/scanpy/issues/2611:1150,availability,Error,Error,1150,"reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . Thank you so much for the beautiful tool that is Scanpy. I am trying to generate stacked violin plots with a particular order for the groups, but the option 'order' does not seem to work. . I find this issue really weird because categories_order works just fine when I am generating a dotplot. Maybe I am missing something fundamental. ### Minimal code sample. ```python. ##code that does not reorder ( I tried both options 'order' and 'categories_order'. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', categories_order=new_order). ##Code that reorders. sc.pl.dotplot(adata,['GATA3','CD8A','CD4'],groupby='sample_id',categories_order=new_order,cmap='PuRd' ). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. parso 0.8.2. patsy 0.5.3. pexpect 4.6.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.15.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pyarro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:0,deployability,stack,stackedviolin,0,"stackedviolin not taking 'order' specification; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . Thank you so much for the beautiful tool that is Scanpy. I am trying to generate stacked violin plots with a particular order for the groups, but the option 'order' does not seem to work. . I find this issue really weird because categories_order works just fine when I am generating a dotplot. Maybe I am missing something fundamental. ### Minimal code sample. ```python. ##code that does not reorder ( I tried both options 'order' and 'categories_order'. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', categories_order=new_order). ##Code that reorders. sc.pl.dotplot(adata,['GATA3','CD8A','CD4'],groupby='sample_id',categories_order=new_order,cmap='PuRd' ). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:216,deployability,version,version,216,"stackedviolin not taking 'order' specification; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . Thank you so much for the beautiful tool that is Scanpy. I am trying to generate stacked violin plots with a particular order for the groups, but the option 'order' does not seem to work. . I find this issue really weird because categories_order works just fine when I am generating a dotplot. Maybe I am missing something fundamental. ### Minimal code sample. ```python. ##code that does not reorder ( I tried both options 'order' and 'categories_order'. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', categories_order=new_order). ##Code that reorders. sc.pl.dotplot(adata,['GATA3','CD8A','CD4'],groupby='sample_id',categories_order=new_order,cmap='PuRd' ). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:426,deployability,stack,stacked,426,"stackedviolin not taking 'order' specification; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . Thank you so much for the beautiful tool that is Scanpy. I am trying to generate stacked violin plots with a particular order for the groups, but the option 'order' does not seem to work. . I find this issue really weird because categories_order works just fine when I am generating a dotplot. Maybe I am missing something fundamental. ### Minimal code sample. ```python. ##code that does not reorder ( I tried both options 'order' and 'categories_order'. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', categories_order=new_order). ##Code that reorders. sc.pl.dotplot(adata,['GATA3','CD8A','CD4'],groupby='sample_id',categories_order=new_order,cmap='PuRd' ). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:1183,deployability,Version,Versions,1183,"his bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . Thank you so much for the beautiful tool that is Scanpy. I am trying to generate stacked violin plots with a particular order for the groups, but the option 'order' does not seem to work. . I find this issue really weird because categories_order works just fine when I am generating a dotplot. Maybe I am missing something fundamental. ### Minimal code sample. ```python. ##code that does not reorder ( I tried both options 'order' and 'categories_order'. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', categories_order=new_order). ##Code that reorders. sc.pl.dotplot(adata,['GATA3','CD8A','CD4'],groupby='sample_id',categories_order=new_order,cmap='PuRd' ). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. parso 0.8.2. patsy 0.5.3. pexpect 4.6.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.15.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pyarrow 12.0.1. pydev_ipython NA. pydevc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:2971,deployability,updat,updated,2971,"No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. parso 0.8.2. patsy 0.5.3. pexpect 4.6.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.15.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pyarrow 12.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.10.0. pyparsing 2.4.7. pytz 2022.4. requests 2.22.0. scipy 1.10.1. seaborn 0.12.0. session_info 1.0.0. setuptools 68.0.0. simplejson 3.16.0. sitecustomize NA. six 1.14.0. sklearn 1.3.0. socks 1.7.1. statsmodels 0.14.0. storemagic NA. tblib 2.0.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.1. toolz 0.12.0. tornado 6.1. traitlets 5.1.0. typing_extensions NA. urllib3 1.25.8. wcwidth 0.2.5. yaml 5.3.1. zipp NA. zmq 22.3.0. zope NA. -----. IPython 7.28.0. jupyter_client 7.0.6. jupyter_core 4.8.1. notebook 6.4.5. -----. Python 3.8.10 (default, May 26 2023, 14:05:08) [GCC 9.4.0]. Linux-5.15.0-1040-aws-x86_64-with-glibc2.29. -----. Session information updated at 2023-08-11 23:46. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:1367,energy efficiency,cloud,cloudpickle,1367,"autiful tool that is Scanpy. I am trying to generate stacked violin plots with a particular order for the groups, but the option 'order' does not seem to work. . I find this issue really weird because categories_order works just fine when I am generating a dotplot. Maybe I am missing something fundamental. ### Minimal code sample. ```python. ##code that does not reorder ( I tried both options 'order' and 'categories_order'. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', categories_order=new_order). ##Code that reorders. sc.pl.dotplot(adata,['GATA3','CD8A','CD4'],groupby='sample_id',categories_order=new_order,cmap='PuRd' ). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. parso 0.8.2. patsy 0.5.3. pexpect 4.6.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.15.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pyarrow 12.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.10.0. pyparsing 2.4.7. pytz 2022.4. requests 2.22.0. scipy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:216,integrability,version,version,216,"stackedviolin not taking 'order' specification; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . Thank you so much for the beautiful tool that is Scanpy. I am trying to generate stacked violin plots with a particular order for the groups, but the option 'order' does not seem to work. . I find this issue really weird because categories_order works just fine when I am generating a dotplot. Maybe I am missing something fundamental. ### Minimal code sample. ```python. ##code that does not reorder ( I tried both options 'order' and 'categories_order'. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', categories_order=new_order). ##Code that reorders. sc.pl.dotplot(adata,['GATA3','CD8A','CD4'],groupby='sample_id',categories_order=new_order,cmap='PuRd' ). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:1183,integrability,Version,Versions,1183,"his bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . Thank you so much for the beautiful tool that is Scanpy. I am trying to generate stacked violin plots with a particular order for the groups, but the option 'order' does not seem to work. . I find this issue really weird because categories_order works just fine when I am generating a dotplot. Maybe I am missing something fundamental. ### Minimal code sample. ```python. ##code that does not reorder ( I tried both options 'order' and 'categories_order'. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', categories_order=new_order). ##Code that reorders. sc.pl.dotplot(adata,['GATA3','CD8A','CD4'],groupby='sample_id',categories_order=new_order,cmap='PuRd' ). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. parso 0.8.2. patsy 0.5.3. pexpect 4.6.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.15.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pyarrow 12.0.1. pydev_ipython NA. pydevc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:33,interoperability,specif,specification,33,"stackedviolin not taking 'order' specification; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . Thank you so much for the beautiful tool that is Scanpy. I am trying to generate stacked violin plots with a particular order for the groups, but the option 'order' does not seem to work. . I find this issue really weird because categories_order works just fine when I am generating a dotplot. Maybe I am missing something fundamental. ### Minimal code sample. ```python. ##code that does not reorder ( I tried both options 'order' and 'categories_order'. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', categories_order=new_order). ##Code that reorders. sc.pl.dotplot(adata,['GATA3','CD8A','CD4'],groupby='sample_id',categories_order=new_order,cmap='PuRd' ). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:216,modifiability,version,version,216,"stackedviolin not taking 'order' specification; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . Thank you so much for the beautiful tool that is Scanpy. I am trying to generate stacked violin plots with a particular order for the groups, but the option 'order' does not seem to work. . I find this issue really weird because categories_order works just fine when I am generating a dotplot. Maybe I am missing something fundamental. ### Minimal code sample. ```python. ##code that does not reorder ( I tried both options 'order' and 'categories_order'. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', categories_order=new_order). ##Code that reorders. sc.pl.dotplot(adata,['GATA3','CD8A','CD4'],groupby='sample_id',categories_order=new_order,cmap='PuRd' ). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:1183,modifiability,Version,Versions,1183,"his bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . Thank you so much for the beautiful tool that is Scanpy. I am trying to generate stacked violin plots with a particular order for the groups, but the option 'order' does not seem to work. . I find this issue really weird because categories_order works just fine when I am generating a dotplot. Maybe I am missing something fundamental. ### Minimal code sample. ```python. ##code that does not reorder ( I tried both options 'order' and 'categories_order'. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', categories_order=new_order). ##Code that reorders. sc.pl.dotplot(adata,['GATA3','CD8A','CD4'],groupby='sample_id',categories_order=new_order,cmap='PuRd' ). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. parso 0.8.2. patsy 0.5.3. pexpect 4.6.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.15.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pyarrow 12.0.1. pydev_ipython NA. pydevc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:1532,modifiability,deco,decorator,1532,"find this issue really weird because categories_order works just fine when I am generating a dotplot. Maybe I am missing something fundamental. ### Minimal code sample. ```python. ##code that does not reorder ( I tried both options 'order' and 'categories_order'. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', categories_order=new_order). ##Code that reorders. sc.pl.dotplot(adata,['GATA3','CD8A','CD4'],groupby='sample_id',categories_order=new_order,cmap='PuRd' ). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. parso 0.8.2. patsy 0.5.3. pexpect 4.6.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.15.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pyarrow 12.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.10.0. pyparsing 2.4.7. pytz 2022.4. requests 2.22.0. scipy 1.10.1. seaborn 0.12.0. session_info 1.0.0. setuptools 68.0.0. simplejson 3.16.0. sitecustomize NA. six 1.14.0. sklearn 1.3.0. socks 1.7.1. statsmodels 0.14.0. sto",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:1969,modifiability,pac,packaging,1969,"ap='PuRd', categories_order=new_order). ##Code that reorders. sc.pl.dotplot(adata,['GATA3','CD8A','CD4'],groupby='sample_id',categories_order=new_order,cmap='PuRd' ). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. parso 0.8.2. patsy 0.5.3. pexpect 4.6.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.15.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pyarrow 12.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.10.0. pyparsing 2.4.7. pytz 2022.4. requests 2.22.0. scipy 1.10.1. seaborn 0.12.0. session_info 1.0.0. setuptools 68.0.0. simplejson 3.16.0. sitecustomize NA. six 1.14.0. sklearn 1.3.0. socks 1.7.1. statsmodels 0.14.0. storemagic NA. tblib 2.0.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.1. toolz 0.12.0. tornado 6.1. traitlets 5.1.0. typing_extensions NA. urllib3 1.25.8. wcwidth 0.2.5. yaml 5.3.1. zipp NA. zmq 22.3.0. zope NA. -----. IPython 7.28.0. jupyter_client 7.0.6. jupyter_core 4.8.1. notebook 6.4.5. -----. Python 3.8.10 (default, May 26 2023, 14:05:08) [GCC 9.4.0]. Linux-5.15.0-1040-aws-x86_64-with-glibc2.29. -----. Session information upd",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:1150,performance,Error,Error,1150,"reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . Thank you so much for the beautiful tool that is Scanpy. I am trying to generate stacked violin plots with a particular order for the groups, but the option 'order' does not seem to work. . I find this issue really weird because categories_order works just fine when I am generating a dotplot. Maybe I am missing something fundamental. ### Minimal code sample. ```python. ##code that does not reorder ( I tried both options 'order' and 'categories_order'. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', categories_order=new_order). ##Code that reorders. sc.pl.dotplot(adata,['GATA3','CD8A','CD4'],groupby='sample_id',categories_order=new_order,cmap='PuRd' ). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. parso 0.8.2. patsy 0.5.3. pexpect 4.6.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.15.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pyarro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:510,reliability,doe,does,510,"stackedviolin not taking 'order' specification; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . Thank you so much for the beautiful tool that is Scanpy. I am trying to generate stacked violin plots with a particular order for the groups, but the option 'order' does not seem to work. . I find this issue really weird because categories_order works just fine when I am generating a dotplot. Maybe I am missing something fundamental. ### Minimal code sample. ```python. ##code that does not reorder ( I tried both options 'order' and 'categories_order'. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', categories_order=new_order). ##Code that reorders. sc.pl.dotplot(adata,['GATA3','CD8A','CD4'],groupby='sample_id',categories_order=new_order,cmap='PuRd' ). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:729,reliability,doe,does,729,"stackedviolin not taking 'order' specification; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . Thank you so much for the beautiful tool that is Scanpy. I am trying to generate stacked violin plots with a particular order for the groups, but the option 'order' does not seem to work. . I find this issue really weird because categories_order works just fine when I am generating a dotplot. Maybe I am missing something fundamental. ### Minimal code sample. ```python. ##code that does not reorder ( I tried both options 'order' and 'categories_order'. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', categories_order=new_order). ##Code that reorders. sc.pl.dotplot(adata,['GATA3','CD8A','CD4'],groupby='sample_id',categories_order=new_order,cmap='PuRd' ). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:1150,safety,Error,Error,1150,"reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . Thank you so much for the beautiful tool that is Scanpy. I am trying to generate stacked violin plots with a particular order for the groups, but the option 'order' does not seem to work. . I find this issue really weird because categories_order works just fine when I am generating a dotplot. Maybe I am missing something fundamental. ### Minimal code sample. ```python. ##code that does not reorder ( I tried both options 'order' and 'categories_order'. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', categories_order=new_order). ##Code that reorders. sc.pl.dotplot(adata,['GATA3','CD8A','CD4'],groupby='sample_id',categories_order=new_order,cmap='PuRd' ). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. parso 0.8.2. patsy 0.5.3. pexpect 4.6.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.15.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pyarro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:2971,safety,updat,updated,2971,"No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. parso 0.8.2. patsy 0.5.3. pexpect 4.6.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.15.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pyarrow 12.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.10.0. pyparsing 2.4.7. pytz 2022.4. requests 2.22.0. scipy 1.10.1. seaborn 0.12.0. session_info 1.0.0. setuptools 68.0.0. simplejson 3.16.0. sitecustomize NA. six 1.14.0. sklearn 1.3.0. socks 1.7.1. statsmodels 0.14.0. storemagic NA. tblib 2.0.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.1. toolz 0.12.0. tornado 6.1. traitlets 5.1.0. typing_extensions NA. urllib3 1.25.8. wcwidth 0.2.5. yaml 5.3.1. zipp NA. zmq 22.3.0. zope NA. -----. IPython 7.28.0. jupyter_client 7.0.6. jupyter_core 4.8.1. notebook 6.4.5. -----. Python 3.8.10 (default, May 26 2023, 14:05:08) [GCC 9.4.0]. Linux-5.15.0-1040-aws-x86_64-with-glibc2.29. -----. Session information updated at 2023-08-11 23:46. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:1319,security,certif,certifi,1319,"at happened? Hello, . Thank you so much for the beautiful tool that is Scanpy. I am trying to generate stacked violin plots with a particular order for the groups, but the option 'order' does not seem to work. . I find this issue really weird because categories_order works just fine when I am generating a dotplot. Maybe I am missing something fundamental. ### Minimal code sample. ```python. ##code that does not reorder ( I tried both options 'order' and 'categories_order'. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', categories_order=new_order). ##Code that reorders. sc.pl.dotplot(adata,['GATA3','CD8A','CD4'],groupby='sample_id',categories_order=new_order,cmap='PuRd' ). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. parso 0.8.2. patsy 0.5.3. pexpect 4.6.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.15.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pyarrow 12.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.10.0. py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:1418,security,cryptograph,cryptography,1418,"e stacked violin plots with a particular order for the groups, but the option 'order' does not seem to work. . I find this issue really weird because categories_order works just fine when I am generating a dotplot. Maybe I am missing something fundamental. ### Minimal code sample. ```python. ##code that does not reorder ( I tried both options 'order' and 'categories_order'. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', categories_order=new_order). ##Code that reorders. sc.pl.dotplot(adata,['GATA3','CD8A','CD4'],groupby='sample_id',categories_order=new_order,cmap='PuRd' ). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. parso 0.8.2. patsy 0.5.3. pexpect 4.6.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.15.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pyarrow 12.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.10.0. pyparsing 2.4.7. pytz 2022.4. requests 2.22.0. scipy 1.10.1. seaborn 0.12.0. session_info 1.0.0. setupt",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:2501,security,soc,socks,2501,"No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. parso 0.8.2. patsy 0.5.3. pexpect 4.6.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.15.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pyarrow 12.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.10.0. pyparsing 2.4.7. pytz 2022.4. requests 2.22.0. scipy 1.10.1. seaborn 0.12.0. session_info 1.0.0. setuptools 68.0.0. simplejson 3.16.0. sitecustomize NA. six 1.14.0. sklearn 1.3.0. socks 1.7.1. statsmodels 0.14.0. storemagic NA. tblib 2.0.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.1. toolz 0.12.0. tornado 6.1. traitlets 5.1.0. typing_extensions NA. urllib3 1.25.8. wcwidth 0.2.5. yaml 5.3.1. zipp NA. zmq 22.3.0. zope NA. -----. IPython 7.28.0. jupyter_client 7.0.6. jupyter_core 4.8.1. notebook 6.4.5. -----. Python 3.8.10 (default, May 26 2023, 14:05:08) [GCC 9.4.0]. Linux-5.15.0-1040-aws-x86_64-with-glibc2.29. -----. Session information updated at 2023-08-11 23:46. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:2951,security,Session,Session,2951,"No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. parso 0.8.2. patsy 0.5.3. pexpect 4.6.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.15.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pyarrow 12.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.10.0. pyparsing 2.4.7. pytz 2022.4. requests 2.22.0. scipy 1.10.1. seaborn 0.12.0. session_info 1.0.0. setuptools 68.0.0. simplejson 3.16.0. sitecustomize NA. six 1.14.0. sklearn 1.3.0. socks 1.7.1. statsmodels 0.14.0. storemagic NA. tblib 2.0.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.1. toolz 0.12.0. tornado 6.1. traitlets 5.1.0. typing_extensions NA. urllib3 1.25.8. wcwidth 0.2.5. yaml 5.3.1. zipp NA. zmq 22.3.0. zope NA. -----. IPython 7.28.0. jupyter_client 7.0.6. jupyter_core 4.8.1. notebook 6.4.5. -----. Python 3.8.10 (default, May 26 2023, 14:05:08) [GCC 9.4.0]. Linux-5.15.0-1040-aws-x86_64-with-glibc2.29. -----. Session information updated at 2023-08-11 23:46. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:2971,security,updat,updated,2971,"No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. parso 0.8.2. patsy 0.5.3. pexpect 4.6.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.15.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pyarrow 12.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.10.0. pyparsing 2.4.7. pytz 2022.4. requests 2.22.0. scipy 1.10.1. seaborn 0.12.0. session_info 1.0.0. setuptools 68.0.0. simplejson 3.16.0. sitecustomize NA. six 1.14.0. sklearn 1.3.0. socks 1.7.1. statsmodels 0.14.0. storemagic NA. tblib 2.0.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.1. toolz 0.12.0. tornado 6.1. traitlets 5.1.0. typing_extensions NA. urllib3 1.25.8. wcwidth 0.2.5. yaml 5.3.1. zipp NA. zmq 22.3.0. zope NA. -----. IPython 7.28.0. jupyter_client 7.0.6. jupyter_core 4.8.1. notebook 6.4.5. -----. Python 3.8.10 (default, May 26 2023, 14:05:08) [GCC 9.4.0]. Linux-5.15.0-1040-aws-x86_64-with-glibc2.29. -----. Session information updated at 2023-08-11 23:46. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:2437,testability,simpl,simplejson,2437,"No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. parso 0.8.2. patsy 0.5.3. pexpect 4.6.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.15.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pyarrow 12.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.10.0. pyparsing 2.4.7. pytz 2022.4. requests 2.22.0. scipy 1.10.1. seaborn 0.12.0. session_info 1.0.0. setuptools 68.0.0. simplejson 3.16.0. sitecustomize NA. six 1.14.0. sklearn 1.3.0. socks 1.7.1. statsmodels 0.14.0. storemagic NA. tblib 2.0.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.1. toolz 0.12.0. tornado 6.1. traitlets 5.1.0. typing_extensions NA. urllib3 1.25.8. wcwidth 0.2.5. yaml 5.3.1. zipp NA. zmq 22.3.0. zope NA. -----. IPython 7.28.0. jupyter_client 7.0.6. jupyter_core 4.8.1. notebook 6.4.5. -----. Python 3.8.10 (default, May 26 2023, 14:05:08) [GCC 9.4.0]. Linux-5.15.0-1040-aws-x86_64-with-glibc2.29. -----. Session information updated at 2023-08-11 23:46. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:176,usability,confirm,confirmed,176,"stackedviolin not taking 'order' specification; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . Thank you so much for the beautiful tool that is Scanpy. I am trying to generate stacked violin plots with a particular order for the groups, but the option 'order' does not seem to work. . I find this issue really weird because categories_order works just fine when I am generating a dotplot. Maybe I am missing something fundamental. ### Minimal code sample. ```python. ##code that does not reorder ( I tried both options 'order' and 'categories_order'. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', categories_order=new_order). ##Code that reorders. sc.pl.dotplot(adata,['GATA3','CD8A','CD4'],groupby='sample_id',categories_order=new_order,cmap='PuRd' ). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:259,usability,confirm,confirmed,259,"stackedviolin not taking 'order' specification; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . Thank you so much for the beautiful tool that is Scanpy. I am trying to generate stacked violin plots with a particular order for the groups, but the option 'order' does not seem to work. . I find this issue really weird because categories_order works just fine when I am generating a dotplot. Maybe I am missing something fundamental. ### Minimal code sample. ```python. ##code that does not reorder ( I tried both options 'order' and 'categories_order'. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', categories_order=new_order). ##Code that reorders. sc.pl.dotplot(adata,['GATA3','CD8A','CD4'],groupby='sample_id',categories_order=new_order,cmap='PuRd' ). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:381,usability,tool,tool,381,"stackedviolin not taking 'order' specification; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . Thank you so much for the beautiful tool that is Scanpy. I am trying to generate stacked violin plots with a particular order for the groups, but the option 'order' does not seem to work. . I find this issue really weird because categories_order works just fine when I am generating a dotplot. Maybe I am missing something fundamental. ### Minimal code sample. ```python. ##code that does not reorder ( I tried both options 'order' and 'categories_order'. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', categories_order=new_order). ##Code that reorders. sc.pl.dotplot(adata,['GATA3','CD8A','CD4'],groupby='sample_id',categories_order=new_order,cmap='PuRd' ). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:685,usability,Minim,Minimal,685,"stackedviolin not taking 'order' specification; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . Thank you so much for the beautiful tool that is Scanpy. I am trying to generate stacked violin plots with a particular order for the groups, but the option 'order' does not seem to work. . I find this issue really weird because categories_order works just fine when I am generating a dotplot. Maybe I am missing something fundamental. ### Minimal code sample. ```python. ##code that does not reorder ( I tried both options 'order' and 'categories_order'. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', categories_order=new_order). ##Code that reorders. sc.pl.dotplot(adata,['GATA3','CD8A','CD4'],groupby='sample_id',categories_order=new_order,cmap='PuRd' ). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:1150,usability,Error,Error,1150,"reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . Thank you so much for the beautiful tool that is Scanpy. I am trying to generate stacked violin plots with a particular order for the groups, but the option 'order' does not seem to work. . I find this issue really weird because categories_order works just fine when I am generating a dotplot. Maybe I am missing something fundamental. ### Minimal code sample. ```python. ##code that does not reorder ( I tried both options 'order' and 'categories_order'. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', categories_order=new_order). ##Code that reorders. sc.pl.dotplot(adata,['GATA3','CD8A','CD4'],groupby='sample_id',categories_order=new_order,cmap='PuRd' ). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. parso 0.8.2. patsy 0.5.3. pexpect 4.6.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.15.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pyarro",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:2437,usability,simpl,simplejson,2437,"No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. parso 0.8.2. patsy 0.5.3. pexpect 4.6.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.15.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pyarrow 12.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.10.0. pyparsing 2.4.7. pytz 2022.4. requests 2.22.0. scipy 1.10.1. seaborn 0.12.0. session_info 1.0.0. setuptools 68.0.0. simplejson 3.16.0. sitecustomize NA. six 1.14.0. sklearn 1.3.0. socks 1.7.1. statsmodels 0.14.0. storemagic NA. tblib 2.0.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.1. toolz 0.12.0. tornado 6.1. traitlets 5.1.0. typing_extensions NA. urllib3 1.25.8. wcwidth 0.2.5. yaml 5.3.1. zipp NA. zmq 22.3.0. zope NA. -----. IPython 7.28.0. jupyter_client 7.0.6. jupyter_core 4.8.1. notebook 6.4.5. -----. Python 3.8.10 (default, May 26 2023, 14:05:08) [GCC 9.4.0]. Linux-5.15.0-1040-aws-x86_64-with-glibc2.29. -----. Session information updated at 2023-08-11 23:46. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/issues/2611:2612,usability,tool,toolz,2612,"No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.3. -----. OpenSSL 19.0.0. PIL 10.0.0. apport_python_hook NA. backcall 0.2.0. certifi 2019.11.28. cffi 1.15.0. chardet 3.0.4. cloudpickle 2.2.1. colorama 0.4.3. colorcet 3.0.1. cryptography 2.8. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.0. defusedxml 0.7.1. entrypoints 0.3. gseapy 1.0.5. h5py 3.7.0. idna 2.8. igraph 0.10.6. ipykernel 6.4.1. ipython_genutils 0.2.0. ipywidgets 7.6.5. jedi 0.18.0. jinja2 3.1.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.0. llvmlite 0.39.1. lz4 4.3.2. markupsafe 2.1.3. matplotlib 3.6.1. matplotlib_inline NA. more_itertools NA. mpl_toolkits NA. natsort 8.2.0. netifaces 0.10.4. numba 0.56.3. numexpr 2.8.4. numpy 1.23.5. packaging 21.3. pandas 1.5.3. parso 0.8.2. patsy 0.5.3. pexpect 4.6.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.15.0. prompt_toolkit 3.0.20. psutil 5.9.4. ptyprocess 0.7.0. pyarrow 12.0.1. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.10.0. pyparsing 2.4.7. pytz 2022.4. requests 2.22.0. scipy 1.10.1. seaborn 0.12.0. session_info 1.0.0. setuptools 68.0.0. simplejson 3.16.0. sitecustomize NA. six 1.14.0. sklearn 1.3.0. socks 1.7.1. statsmodels 0.14.0. storemagic NA. tblib 2.0.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.1. toolz 0.12.0. tornado 6.1. traitlets 5.1.0. typing_extensions NA. urllib3 1.25.8. wcwidth 0.2.5. yaml 5.3.1. zipp NA. zmq 22.3.0. zope NA. -----. IPython 7.28.0. jupyter_client 7.0.6. jupyter_core 4.8.1. notebook 6.4.5. -----. Python 3.8.10 (default, May 26 2023, 14:05:08) [GCC 9.4.0]. Linux-5.15.0-1040-aws-x86_64-with-glibc2.29. -----. Session information updated at 2023-08-11 23:46. sc.pl.stacked_violin(adata,['GATA3','CD8A','CD4'],groupby='sample_id',cmap='PuRd', order=new_order). sc.pl.stacked_violin(adata,['GATA3','CD8A','CD. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2611
https://github.com/scverse/scanpy/pull/2612:103,availability,slo,slow,103,changed hvg with PR to work with numba; The pearson residuals implementation for hvg is currently very slow and memory inefficient. I switched it to a numba kernel for csc and dense F-continous arrays. It's based on the cuda-kernel in [rapids-singlecell](https://github.com/scverse/rapids_singlecell/blob/main/src/rapids_singlecell/cunnData_funcs/_hvg.py#L14-L258). For 90000 cells we go from 24 seconds to less than 5 with the new implementation. For smaller datasets we don't see a speedup.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2612
https://github.com/scverse/scanpy/pull/2612:88,energy efficiency,current,currently,88,changed hvg with PR to work with numba; The pearson residuals implementation for hvg is currently very slow and memory inefficient. I switched it to a numba kernel for csc and dense F-continous arrays. It's based on the cuda-kernel in [rapids-singlecell](https://github.com/scverse/rapids_singlecell/blob/main/src/rapids_singlecell/cunnData_funcs/_hvg.py#L14-L258). For 90000 cells we go from 24 seconds to less than 5 with the new implementation. For smaller datasets we don't see a speedup.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2612
https://github.com/scverse/scanpy/pull/2612:112,performance,memor,memory,112,changed hvg with PR to work with numba; The pearson residuals implementation for hvg is currently very slow and memory inefficient. I switched it to a numba kernel for csc and dense F-continous arrays. It's based on the cuda-kernel in [rapids-singlecell](https://github.com/scverse/rapids_singlecell/blob/main/src/rapids_singlecell/cunnData_funcs/_hvg.py#L14-L258). For 90000 cells we go from 24 seconds to less than 5 with the new implementation. For smaller datasets we don't see a speedup.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2612
https://github.com/scverse/scanpy/pull/2612:103,reliability,slo,slow,103,changed hvg with PR to work with numba; The pearson residuals implementation for hvg is currently very slow and memory inefficient. I switched it to a numba kernel for csc and dense F-continous arrays. It's based on the cuda-kernel in [rapids-singlecell](https://github.com/scverse/rapids_singlecell/blob/main/src/rapids_singlecell/cunnData_funcs/_hvg.py#L14-L258). For 90000 cells we go from 24 seconds to less than 5 with the new implementation. For smaller datasets we don't see a speedup.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2612
https://github.com/scverse/scanpy/pull/2612:112,usability,memor,memory,112,changed hvg with PR to work with numba; The pearson residuals implementation for hvg is currently very slow and memory inefficient. I switched it to a numba kernel for csc and dense F-continous arrays. It's based on the cuda-kernel in [rapids-singlecell](https://github.com/scverse/rapids_singlecell/blob/main/src/rapids_singlecell/cunnData_funcs/_hvg.py#L14-L258). For 90000 cells we go from 24 seconds to less than 5 with the new implementation. For smaller datasets we don't see a speedup.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2612
https://github.com/scverse/scanpy/pull/2613:43,usability,support,support,43,Backport PR #2610 on branch 1.9.x (Improve support for n_pcs if bigger than settings.N_PCS); Backport PR #2610: Improve support for n_pcs if bigger than settings.N_PCS,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2613
https://github.com/scverse/scanpy/pull/2613:120,usability,support,support,120,Backport PR #2610 on branch 1.9.x (Improve support for n_pcs if bigger than settings.N_PCS); Backport PR #2610: Improve support for n_pcs if bigger than settings.N_PCS,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2613
https://github.com/scverse/scanpy/pull/2614:0,availability,Restor,Restore,0,"Restore link checking in docs (partially reverts #2220); Partially reverts #2220 to restore CI to a functional state. I will skip the review since this is a revert of a breakage. - broken links are banned again. - the tutorial links are just links again, but using intersphinx and therefore still not broken. A follow up PR can make the tutorials a submodule again if we go that route, but we wont disable link checking again. Not for a PR like this, and not for anything else. PS: one of the `{tutorial}` links wasnt converted to a ``{doc}`/tutorials/` `` link in #2220. Fixed that too.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2614
https://github.com/scverse/scanpy/pull/2614:84,availability,restor,restore,84,"Restore link checking in docs (partially reverts #2220); Partially reverts #2220 to restore CI to a functional state. I will skip the review since this is a revert of a breakage. - broken links are banned again. - the tutorial links are just links again, but using intersphinx and therefore still not broken. A follow up PR can make the tutorials a submodule again if we go that route, but we wont disable link checking again. Not for a PR like this, and not for anything else. PS: one of the `{tutorial}` links wasnt converted to a ``{doc}`/tutorials/` `` link in #2220. Fixed that too.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2614
https://github.com/scverse/scanpy/pull/2614:111,availability,state,state,111,"Restore link checking in docs (partially reverts #2220); Partially reverts #2220 to restore CI to a functional state. I will skip the review since this is a revert of a breakage. - broken links are banned again. - the tutorial links are just links again, but using intersphinx and therefore still not broken. A follow up PR can make the tutorials a submodule again if we go that route, but we wont disable link checking again. Not for a PR like this, and not for anything else. PS: one of the `{tutorial}` links wasnt converted to a ``{doc}`/tutorials/` `` link in #2220. Fixed that too.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2614
https://github.com/scverse/scanpy/pull/2614:111,integrability,state,state,111,"Restore link checking in docs (partially reverts #2220); Partially reverts #2220 to restore CI to a functional state. I will skip the review since this is a revert of a breakage. - broken links are banned again. - the tutorial links are just links again, but using intersphinx and therefore still not broken. A follow up PR can make the tutorials a submodule again if we go that route, but we wont disable link checking again. Not for a PR like this, and not for anything else. PS: one of the `{tutorial}` links wasnt converted to a ``{doc}`/tutorials/` `` link in #2220. Fixed that too.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2614
https://github.com/scverse/scanpy/pull/2614:349,integrability,sub,submodule,349,"Restore link checking in docs (partially reverts #2220); Partially reverts #2220 to restore CI to a functional state. I will skip the review since this is a revert of a breakage. - broken links are banned again. - the tutorial links are just links again, but using intersphinx and therefore still not broken. A follow up PR can make the tutorials a submodule again if we go that route, but we wont disable link checking again. Not for a PR like this, and not for anything else. PS: one of the `{tutorial}` links wasnt converted to a ``{doc}`/tutorials/` `` link in #2220. Fixed that too.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2614
https://github.com/scverse/scanpy/pull/2614:379,integrability,rout,route,379,"Restore link checking in docs (partially reverts #2220); Partially reverts #2220 to restore CI to a functional state. I will skip the review since this is a revert of a breakage. - broken links are banned again. - the tutorial links are just links again, but using intersphinx and therefore still not broken. A follow up PR can make the tutorials a submodule again if we go that route, but we wont disable link checking again. Not for a PR like this, and not for anything else. PS: one of the `{tutorial}` links wasnt converted to a ``{doc}`/tutorials/` `` link in #2220. Fixed that too.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2614
https://github.com/scverse/scanpy/pull/2614:0,reliability,Restor,Restore,0,"Restore link checking in docs (partially reverts #2220); Partially reverts #2220 to restore CI to a functional state. I will skip the review since this is a revert of a breakage. - broken links are banned again. - the tutorial links are just links again, but using intersphinx and therefore still not broken. A follow up PR can make the tutorials a submodule again if we go that route, but we wont disable link checking again. Not for a PR like this, and not for anything else. PS: one of the `{tutorial}` links wasnt converted to a ``{doc}`/tutorials/` `` link in #2220. Fixed that too.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2614
https://github.com/scverse/scanpy/pull/2614:84,reliability,restor,restore,84,"Restore link checking in docs (partially reverts #2220); Partially reverts #2220 to restore CI to a functional state. I will skip the review since this is a revert of a breakage. - broken links are banned again. - the tutorial links are just links again, but using intersphinx and therefore still not broken. A follow up PR can make the tutorials a submodule again if we go that route, but we wont disable link checking again. Not for a PR like this, and not for anything else. PS: one of the `{tutorial}` links wasnt converted to a ``{doc}`/tutorials/` `` link in #2220. Fixed that too.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2614
https://github.com/scverse/scanpy/pull/2614:134,safety,review,review,134,"Restore link checking in docs (partially reverts #2220); Partially reverts #2220 to restore CI to a functional state. I will skip the review since this is a revert of a breakage. - broken links are banned again. - the tutorial links are just links again, but using intersphinx and therefore still not broken. A follow up PR can make the tutorials a submodule again if we go that route, but we wont disable link checking again. Not for a PR like this, and not for anything else. PS: one of the `{tutorial}` links wasnt converted to a ``{doc}`/tutorials/` `` link in #2220. Fixed that too.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2614
https://github.com/scverse/scanpy/pull/2614:134,testability,review,review,134,"Restore link checking in docs (partially reverts #2220); Partially reverts #2220 to restore CI to a functional state. I will skip the review since this is a revert of a breakage. - broken links are banned again. - the tutorial links are just links again, but using intersphinx and therefore still not broken. A follow up PR can make the tutorials a submodule again if we go that route, but we wont disable link checking again. Not for a PR like this, and not for anything else. PS: one of the `{tutorial}` links wasnt converted to a ``{doc}`/tutorials/` `` link in #2220. Fixed that too.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2614
https://github.com/scverse/scanpy/pull/2615:250,safety,review,review,250,Fix key name in documentation; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This PR fixes a typo in the docstring of `scanpy.external.pp.scrublet()`: The `obs` column is actually called `predicted_doublet` instead of `predicted_doublets`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2615
https://github.com/scverse/scanpy/pull/2615:250,testability,review,review,250,Fix key name in documentation; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This PR fixes a typo in the docstring of `scanpy.external.pp.scrublet()`: The `obs` column is actually called `predicted_doublet` instead of `predicted_doublets`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2615
https://github.com/scverse/scanpy/pull/2615:16,usability,document,documentation,16,Fix key name in documentation; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This PR fixes a typo in the docstring of `scanpy.external.pp.scrublet()`: The `obs` column is actually called `predicted_doublet` instead of `predicted_doublets`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2615
https://github.com/scverse/scanpy/pull/2615:101,usability,guid,guidelines,101,Fix key name in documentation; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This PR fixes a typo in the docstring of `scanpy.external.pp.scrublet()`: The `obs` column is actually called `predicted_doublet` instead of `predicted_doublets`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2615
https://github.com/scverse/scanpy/pull/2615:132,usability,guid,guide,132,Fix key name in documentation; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This PR fixes a typo in the docstring of `scanpy.external.pp.scrublet()`: The `obs` column is actually called `predicted_doublet` instead of `predicted_doublets`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2615
https://github.com/scverse/scanpy/pull/2615:228,usability,workflow,workflow,228,Fix key name in documentation; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. This PR fixes a typo in the docstring of `scanpy.external.pp.scrublet()`: The `obs` column is actually called `predicted_doublet` instead of `predicted_doublets`.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2615
https://github.com/scverse/scanpy/pull/2616:51,usability,document,documentation,51,Backport PR #2615 on branch 1.9.x (Fix key name in documentation); Backport PR #2615: Fix key name in documentation,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2616
https://github.com/scverse/scanpy/pull/2616:102,usability,document,documentation,102,Backport PR #2615 on branch 1.9.x (Fix key name in documentation); Backport PR #2615: Fix key name in documentation,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2616
https://github.com/scverse/scanpy/pull/2618:35,integrability,batch,batch,35,changed pepy badge; Fixes the pepy batch,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2618
https://github.com/scverse/scanpy/pull/2618:35,performance,batch,batch,35,changed pepy badge; Fixes the pepy batch,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2618
https://github.com/scverse/scanpy/pull/2621:224,deployability,API,APIs,224,"Handle Dask arrays in some utilities; This PR. - makes `_utils.check_nonnegative_integers` work with Dask arrays and with that also `rank_genes_groups`. - Adds type hints that I added while re-familiarizing myself with some APIs. - adds a function pair `lazy_{and,or}` that make it possible to delay checks with dask:. ```py. >>> def fail():. ... raise AssertionError(). >>> # rhs can be a function or dask array. >>> lazy_and(False, fail). False. >>> lazy_and(False, da.array(True).map_blocks(lambda _: fail(), meta=np.bool_(True))). False. >>> # lhs can be a function or dask array for nested use. >>> # when not nested, a lhs function will be called eagerly like in `a() and b`. >>> lazy_and(False, lazy_and(fail, _)). False. >>> # will not create a recursive dask array. >>> lazy_and(da.array(True), da.array(False)).compute(). False. >>> # will complain on invalid use. >>> lazy_and(True, lambda: da.array(...)). 'AssertionError: Use lazy_*(_, da.array(...)) instead of lazy_*(_, lambda: da.array(...)).'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2621
https://github.com/scverse/scanpy/pull/2621:334,deployability,fail,fail,334,"Handle Dask arrays in some utilities; This PR. - makes `_utils.check_nonnegative_integers` work with Dask arrays and with that also `rank_genes_groups`. - Adds type hints that I added while re-familiarizing myself with some APIs. - adds a function pair `lazy_{and,or}` that make it possible to delay checks with dask:. ```py. >>> def fail():. ... raise AssertionError(). >>> # rhs can be a function or dask array. >>> lazy_and(False, fail). False. >>> lazy_and(False, da.array(True).map_blocks(lambda _: fail(), meta=np.bool_(True))). False. >>> # lhs can be a function or dask array for nested use. >>> # when not nested, a lhs function will be called eagerly like in `a() and b`. >>> lazy_and(False, lazy_and(fail, _)). False. >>> # will not create a recursive dask array. >>> lazy_and(da.array(True), da.array(False)).compute(). False. >>> # will complain on invalid use. >>> lazy_and(True, lambda: da.array(...)). 'AssertionError: Use lazy_*(_, da.array(...)) instead of lazy_*(_, lambda: da.array(...)).'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2621
https://github.com/scverse/scanpy/pull/2621:434,deployability,fail,fail,434,"Handle Dask arrays in some utilities; This PR. - makes `_utils.check_nonnegative_integers` work with Dask arrays and with that also `rank_genes_groups`. - Adds type hints that I added while re-familiarizing myself with some APIs. - adds a function pair `lazy_{and,or}` that make it possible to delay checks with dask:. ```py. >>> def fail():. ... raise AssertionError(). >>> # rhs can be a function or dask array. >>> lazy_and(False, fail). False. >>> lazy_and(False, da.array(True).map_blocks(lambda _: fail(), meta=np.bool_(True))). False. >>> # lhs can be a function or dask array for nested use. >>> # when not nested, a lhs function will be called eagerly like in `a() and b`. >>> lazy_and(False, lazy_and(fail, _)). False. >>> # will not create a recursive dask array. >>> lazy_and(da.array(True), da.array(False)).compute(). False. >>> # will complain on invalid use. >>> lazy_and(True, lambda: da.array(...)). 'AssertionError: Use lazy_*(_, da.array(...)) instead of lazy_*(_, lambda: da.array(...)).'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2621
https://github.com/scverse/scanpy/pull/2621:504,deployability,fail,fail,504,"Handle Dask arrays in some utilities; This PR. - makes `_utils.check_nonnegative_integers` work with Dask arrays and with that also `rank_genes_groups`. - Adds type hints that I added while re-familiarizing myself with some APIs. - adds a function pair `lazy_{and,or}` that make it possible to delay checks with dask:. ```py. >>> def fail():. ... raise AssertionError(). >>> # rhs can be a function or dask array. >>> lazy_and(False, fail). False. >>> lazy_and(False, da.array(True).map_blocks(lambda _: fail(), meta=np.bool_(True))). False. >>> # lhs can be a function or dask array for nested use. >>> # when not nested, a lhs function will be called eagerly like in `a() and b`. >>> lazy_and(False, lazy_and(fail, _)). False. >>> # will not create a recursive dask array. >>> lazy_and(da.array(True), da.array(False)).compute(). False. >>> # will complain on invalid use. >>> lazy_and(True, lambda: da.array(...)). 'AssertionError: Use lazy_*(_, da.array(...)) instead of lazy_*(_, lambda: da.array(...)).'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2621
https://github.com/scverse/scanpy/pull/2621:711,deployability,fail,fail,711,"Handle Dask arrays in some utilities; This PR. - makes `_utils.check_nonnegative_integers` work with Dask arrays and with that also `rank_genes_groups`. - Adds type hints that I added while re-familiarizing myself with some APIs. - adds a function pair `lazy_{and,or}` that make it possible to delay checks with dask:. ```py. >>> def fail():. ... raise AssertionError(). >>> # rhs can be a function or dask array. >>> lazy_and(False, fail). False. >>> lazy_and(False, da.array(True).map_blocks(lambda _: fail(), meta=np.bool_(True))). False. >>> # lhs can be a function or dask array for nested use. >>> # when not nested, a lhs function will be called eagerly like in `a() and b`. >>> lazy_and(False, lazy_and(fail, _)). False. >>> # will not create a recursive dask array. >>> lazy_and(da.array(True), da.array(False)).compute(). False. >>> # will complain on invalid use. >>> lazy_and(True, lambda: da.array(...)). 'AssertionError: Use lazy_*(_, da.array(...)) instead of lazy_*(_, lambda: da.array(...)).'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2621
https://github.com/scverse/scanpy/pull/2621:224,integrability,API,APIs,224,"Handle Dask arrays in some utilities; This PR. - makes `_utils.check_nonnegative_integers` work with Dask arrays and with that also `rank_genes_groups`. - Adds type hints that I added while re-familiarizing myself with some APIs. - adds a function pair `lazy_{and,or}` that make it possible to delay checks with dask:. ```py. >>> def fail():. ... raise AssertionError(). >>> # rhs can be a function or dask array. >>> lazy_and(False, fail). False. >>> lazy_and(False, da.array(True).map_blocks(lambda _: fail(), meta=np.bool_(True))). False. >>> # lhs can be a function or dask array for nested use. >>> # when not nested, a lhs function will be called eagerly like in `a() and b`. >>> lazy_and(False, lazy_and(fail, _)). False. >>> # will not create a recursive dask array. >>> lazy_and(da.array(True), da.array(False)).compute(). False. >>> # will complain on invalid use. >>> lazy_and(True, lambda: da.array(...)). 'AssertionError: Use lazy_*(_, da.array(...)) instead of lazy_*(_, lambda: da.array(...)).'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2621
https://github.com/scverse/scanpy/pull/2621:224,interoperability,API,APIs,224,"Handle Dask arrays in some utilities; This PR. - makes `_utils.check_nonnegative_integers` work with Dask arrays and with that also `rank_genes_groups`. - Adds type hints that I added while re-familiarizing myself with some APIs. - adds a function pair `lazy_{and,or}` that make it possible to delay checks with dask:. ```py. >>> def fail():. ... raise AssertionError(). >>> # rhs can be a function or dask array. >>> lazy_and(False, fail). False. >>> lazy_and(False, da.array(True).map_blocks(lambda _: fail(), meta=np.bool_(True))). False. >>> # lhs can be a function or dask array for nested use. >>> # when not nested, a lhs function will be called eagerly like in `a() and b`. >>> lazy_and(False, lazy_and(fail, _)). False. >>> # will not create a recursive dask array. >>> lazy_and(da.array(True), da.array(False)).compute(). False. >>> # will complain on invalid use. >>> lazy_and(True, lambda: da.array(...)). 'AssertionError: Use lazy_*(_, da.array(...)) instead of lazy_*(_, lambda: da.array(...)).'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2621
https://github.com/scverse/scanpy/pull/2621:334,reliability,fail,fail,334,"Handle Dask arrays in some utilities; This PR. - makes `_utils.check_nonnegative_integers` work with Dask arrays and with that also `rank_genes_groups`. - Adds type hints that I added while re-familiarizing myself with some APIs. - adds a function pair `lazy_{and,or}` that make it possible to delay checks with dask:. ```py. >>> def fail():. ... raise AssertionError(). >>> # rhs can be a function or dask array. >>> lazy_and(False, fail). False. >>> lazy_and(False, da.array(True).map_blocks(lambda _: fail(), meta=np.bool_(True))). False. >>> # lhs can be a function or dask array for nested use. >>> # when not nested, a lhs function will be called eagerly like in `a() and b`. >>> lazy_and(False, lazy_and(fail, _)). False. >>> # will not create a recursive dask array. >>> lazy_and(da.array(True), da.array(False)).compute(). False. >>> # will complain on invalid use. >>> lazy_and(True, lambda: da.array(...)). 'AssertionError: Use lazy_*(_, da.array(...)) instead of lazy_*(_, lambda: da.array(...)).'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2621
https://github.com/scverse/scanpy/pull/2621:434,reliability,fail,fail,434,"Handle Dask arrays in some utilities; This PR. - makes `_utils.check_nonnegative_integers` work with Dask arrays and with that also `rank_genes_groups`. - Adds type hints that I added while re-familiarizing myself with some APIs. - adds a function pair `lazy_{and,or}` that make it possible to delay checks with dask:. ```py. >>> def fail():. ... raise AssertionError(). >>> # rhs can be a function or dask array. >>> lazy_and(False, fail). False. >>> lazy_and(False, da.array(True).map_blocks(lambda _: fail(), meta=np.bool_(True))). False. >>> # lhs can be a function or dask array for nested use. >>> # when not nested, a lhs function will be called eagerly like in `a() and b`. >>> lazy_and(False, lazy_and(fail, _)). False. >>> # will not create a recursive dask array. >>> lazy_and(da.array(True), da.array(False)).compute(). False. >>> # will complain on invalid use. >>> lazy_and(True, lambda: da.array(...)). 'AssertionError: Use lazy_*(_, da.array(...)) instead of lazy_*(_, lambda: da.array(...)).'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2621
https://github.com/scverse/scanpy/pull/2621:504,reliability,fail,fail,504,"Handle Dask arrays in some utilities; This PR. - makes `_utils.check_nonnegative_integers` work with Dask arrays and with that also `rank_genes_groups`. - Adds type hints that I added while re-familiarizing myself with some APIs. - adds a function pair `lazy_{and,or}` that make it possible to delay checks with dask:. ```py. >>> def fail():. ... raise AssertionError(). >>> # rhs can be a function or dask array. >>> lazy_and(False, fail). False. >>> lazy_and(False, da.array(True).map_blocks(lambda _: fail(), meta=np.bool_(True))). False. >>> # lhs can be a function or dask array for nested use. >>> # when not nested, a lhs function will be called eagerly like in `a() and b`. >>> lazy_and(False, lazy_and(fail, _)). False. >>> # will not create a recursive dask array. >>> lazy_and(da.array(True), da.array(False)).compute(). False. >>> # will complain on invalid use. >>> lazy_and(True, lambda: da.array(...)). 'AssertionError: Use lazy_*(_, da.array(...)) instead of lazy_*(_, lambda: da.array(...)).'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2621
https://github.com/scverse/scanpy/pull/2621:711,reliability,fail,fail,711,"Handle Dask arrays in some utilities; This PR. - makes `_utils.check_nonnegative_integers` work with Dask arrays and with that also `rank_genes_groups`. - Adds type hints that I added while re-familiarizing myself with some APIs. - adds a function pair `lazy_{and,or}` that make it possible to delay checks with dask:. ```py. >>> def fail():. ... raise AssertionError(). >>> # rhs can be a function or dask array. >>> lazy_and(False, fail). False. >>> lazy_and(False, da.array(True).map_blocks(lambda _: fail(), meta=np.bool_(True))). False. >>> # lhs can be a function or dask array for nested use. >>> # when not nested, a lhs function will be called eagerly like in `a() and b`. >>> lazy_and(False, lazy_and(fail, _)). False. >>> # will not create a recursive dask array. >>> lazy_and(da.array(True), da.array(False)).compute(). False. >>> # will complain on invalid use. >>> lazy_and(True, lambda: da.array(...)). 'AssertionError: Use lazy_*(_, da.array(...)) instead of lazy_*(_, lambda: da.array(...)).'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2621
https://github.com/scverse/scanpy/pull/2621:850,safety,compl,complain,850,"Handle Dask arrays in some utilities; This PR. - makes `_utils.check_nonnegative_integers` work with Dask arrays and with that also `rank_genes_groups`. - Adds type hints that I added while re-familiarizing myself with some APIs. - adds a function pair `lazy_{and,or}` that make it possible to delay checks with dask:. ```py. >>> def fail():. ... raise AssertionError(). >>> # rhs can be a function or dask array. >>> lazy_and(False, fail). False. >>> lazy_and(False, da.array(True).map_blocks(lambda _: fail(), meta=np.bool_(True))). False. >>> # lhs can be a function or dask array for nested use. >>> # when not nested, a lhs function will be called eagerly like in `a() and b`. >>> lazy_and(False, lazy_and(fail, _)). False. >>> # will not create a recursive dask array. >>> lazy_and(da.array(True), da.array(False)).compute(). False. >>> # will complain on invalid use. >>> lazy_and(True, lambda: da.array(...)). 'AssertionError: Use lazy_*(_, da.array(...)) instead of lazy_*(_, lambda: da.array(...)).'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2621
https://github.com/scverse/scanpy/pull/2621:850,security,compl,complain,850,"Handle Dask arrays in some utilities; This PR. - makes `_utils.check_nonnegative_integers` work with Dask arrays and with that also `rank_genes_groups`. - Adds type hints that I added while re-familiarizing myself with some APIs. - adds a function pair `lazy_{and,or}` that make it possible to delay checks with dask:. ```py. >>> def fail():. ... raise AssertionError(). >>> # rhs can be a function or dask array. >>> lazy_and(False, fail). False. >>> lazy_and(False, da.array(True).map_blocks(lambda _: fail(), meta=np.bool_(True))). False. >>> # lhs can be a function or dask array for nested use. >>> # when not nested, a lhs function will be called eagerly like in `a() and b`. >>> lazy_and(False, lazy_and(fail, _)). False. >>> # will not create a recursive dask array. >>> lazy_and(da.array(True), da.array(False)).compute(). False. >>> # will complain on invalid use. >>> lazy_and(True, lambda: da.array(...)). 'AssertionError: Use lazy_*(_, da.array(...)) instead of lazy_*(_, lambda: da.array(...)).'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2621
https://github.com/scverse/scanpy/pull/2621:353,testability,Assert,AssertionError,353,"Handle Dask arrays in some utilities; This PR. - makes `_utils.check_nonnegative_integers` work with Dask arrays and with that also `rank_genes_groups`. - Adds type hints that I added while re-familiarizing myself with some APIs. - adds a function pair `lazy_{and,or}` that make it possible to delay checks with dask:. ```py. >>> def fail():. ... raise AssertionError(). >>> # rhs can be a function or dask array. >>> lazy_and(False, fail). False. >>> lazy_and(False, da.array(True).map_blocks(lambda _: fail(), meta=np.bool_(True))). False. >>> # lhs can be a function or dask array for nested use. >>> # when not nested, a lhs function will be called eagerly like in `a() and b`. >>> lazy_and(False, lazy_and(fail, _)). False. >>> # will not create a recursive dask array. >>> lazy_and(da.array(True), da.array(False)).compute(). False. >>> # will complain on invalid use. >>> lazy_and(True, lambda: da.array(...)). 'AssertionError: Use lazy_*(_, da.array(...)) instead of lazy_*(_, lambda: da.array(...)).'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2621
https://github.com/scverse/scanpy/pull/2621:919,testability,Assert,AssertionError,919,"Handle Dask arrays in some utilities; This PR. - makes `_utils.check_nonnegative_integers` work with Dask arrays and with that also `rank_genes_groups`. - Adds type hints that I added while re-familiarizing myself with some APIs. - adds a function pair `lazy_{and,or}` that make it possible to delay checks with dask:. ```py. >>> def fail():. ... raise AssertionError(). >>> # rhs can be a function or dask array. >>> lazy_and(False, fail). False. >>> lazy_and(False, da.array(True).map_blocks(lambda _: fail(), meta=np.bool_(True))). False. >>> # lhs can be a function or dask array for nested use. >>> # when not nested, a lhs function will be called eagerly like in `a() and b`. >>> lazy_and(False, lazy_and(fail, _)). False. >>> # will not create a recursive dask array. >>> lazy_and(da.array(True), da.array(False)).compute(). False. >>> # will complain on invalid use. >>> lazy_and(True, lambda: da.array(...)). 'AssertionError: Use lazy_*(_, da.array(...)) instead of lazy_*(_, lambda: da.array(...)).'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2621
https://github.com/scverse/scanpy/pull/2621:165,usability,hint,hints,165,"Handle Dask arrays in some utilities; This PR. - makes `_utils.check_nonnegative_integers` work with Dask arrays and with that also `rank_genes_groups`. - Adds type hints that I added while re-familiarizing myself with some APIs. - adds a function pair `lazy_{and,or}` that make it possible to delay checks with dask:. ```py. >>> def fail():. ... raise AssertionError(). >>> # rhs can be a function or dask array. >>> lazy_and(False, fail). False. >>> lazy_and(False, da.array(True).map_blocks(lambda _: fail(), meta=np.bool_(True))). False. >>> # lhs can be a function or dask array for nested use. >>> # when not nested, a lhs function will be called eagerly like in `a() and b`. >>> lazy_and(False, lazy_and(fail, _)). False. >>> # will not create a recursive dask array. >>> lazy_and(da.array(True), da.array(False)).compute(). False. >>> # will complain on invalid use. >>> lazy_and(True, lambda: da.array(...)). 'AssertionError: Use lazy_*(_, da.array(...)) instead of lazy_*(_, lambda: da.array(...)).'. ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2621
https://github.com/scverse/scanpy/issues/2622:10,modifiability,paramet,parameter,10,key_added parameter for bbknn; . The scanpy.pp.neighbors function has a neat parameter called key_added. Can we have that for the bbknn function too?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2622
https://github.com/scverse/scanpy/issues/2622:77,modifiability,paramet,parameter,77,key_added parameter for bbknn; . The scanpy.pp.neighbors function has a neat parameter called key_added. Can we have that for the bbknn function too?,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2622
https://github.com/scverse/scanpy/issues/2623:226,usability,UI,UI,226,"Enable pre-commit autofix; ### What kind of feature would you like to request? Other? ### Please describe your wishes. In #2076, it was disabled for some unstated reason. That makes it harder to contribute by using the GitHub UI: People either need to set up a dev environment or painstakingly make changes by hand while thats not necessary at all. Lets revert that PR.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2623
https://github.com/scverse/scanpy/pull/2624:12,integrability,sub,subsample,12,"allow sc.pp.subsample in backed mode when returning a copy; Adresses issue #2495. Suggested change to allow `sc.pp.subsample` in backed mode of AnnData, when `copy=True` in `sc.pp.subsample`. ```. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. Tagging @ivirshup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2624
https://github.com/scverse/scanpy/pull/2624:115,integrability,sub,subsample,115,"allow sc.pp.subsample in backed mode when returning a copy; Adresses issue #2495. Suggested change to allow `sc.pp.subsample` in backed mode of AnnData, when `copy=True` in `sc.pp.subsample`. ```. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. Tagging @ivirshup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2624
https://github.com/scverse/scanpy/pull/2624:180,integrability,sub,subsample,180,"allow sc.pp.subsample in backed mode when returning a copy; Adresses issue #2495. Suggested change to allow `sc.pp.subsample` in backed mode of AnnData, when `copy=True` in `sc.pp.subsample`. ```. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. Tagging @ivirshup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2624
https://github.com/scverse/scanpy/pull/2624:296,integrability,sub,subsample,296,"allow sc.pp.subsample in backed mode when returning a copy; Adresses issue #2495. Suggested change to allow `sc.pp.subsample` in backed mode of AnnData, when `copy=True` in `sc.pp.subsample`. ```. import scanpy as sc. adata = sc.read_h5ad(""matrix/scatlas.h5ad"", backed=""r""). adata_sample = sc.pp.subsample(adata, fraction=0.01, copy=True). ```. Tagging @ivirshup.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2624
https://github.com/scverse/scanpy/issues/2625:27,availability,Cluster,Cluster,27,"Customizing Dendrogram and Cluster Names Placement in sc.pl.matrixplot; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Dear Scanpy Team,. Ive been working with the sc.pl.matrixplot function to visualize my data. I have a specific requirement regarding the placement of the dendrogram and cluster names in the matrix plot, both on the same side. In my current usage of sc.pl.matrixplot, I would like to customize the positioning of the dendrogram and the cluster names. Could you kindly guide me on how to achieve the placement of the dendrogram and cluster names on one side of the matrix plot for reading the plot easier? I would greatly appreciate any insights or suggestions you could provide. Thank you for your time and assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2625
https://github.com/scverse/scanpy/issues/2625:334,availability,cluster,cluster,334,"Customizing Dendrogram and Cluster Names Placement in sc.pl.matrixplot; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Dear Scanpy Team,. Ive been working with the sc.pl.matrixplot function to visualize my data. I have a specific requirement regarding the placement of the dendrogram and cluster names in the matrix plot, both on the same side. In my current usage of sc.pl.matrixplot, I would like to customize the positioning of the dendrogram and the cluster names. Could you kindly guide me on how to achieve the placement of the dendrogram and cluster names on one side of the matrix plot for reading the plot easier? I would greatly appreciate any insights or suggestions you could provide. Thank you for your time and assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2625
https://github.com/scverse/scanpy/issues/2625:500,availability,cluster,cluster,500,"Customizing Dendrogram and Cluster Names Placement in sc.pl.matrixplot; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Dear Scanpy Team,. Ive been working with the sc.pl.matrixplot function to visualize my data. I have a specific requirement regarding the placement of the dendrogram and cluster names in the matrix plot, both on the same side. In my current usage of sc.pl.matrixplot, I would like to customize the positioning of the dendrogram and the cluster names. Could you kindly guide me on how to achieve the placement of the dendrogram and cluster names on one side of the matrix plot for reading the plot easier? I would greatly appreciate any insights or suggestions you could provide. Thank you for your time and assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2625
https://github.com/scverse/scanpy/issues/2625:595,availability,cluster,cluster,595,"Customizing Dendrogram and Cluster Names Placement in sc.pl.matrixplot; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Dear Scanpy Team,. Ive been working with the sc.pl.matrixplot function to visualize my data. I have a specific requirement regarding the placement of the dendrogram and cluster names in the matrix plot, both on the same side. In my current usage of sc.pl.matrixplot, I would like to customize the positioning of the dendrogram and the cluster names. Could you kindly guide me on how to achieve the placement of the dendrogram and cluster names on one side of the matrix plot for reading the plot easier? I would greatly appreciate any insights or suggestions you could provide. Thank you for your time and assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2625
https://github.com/scverse/scanpy/issues/2625:27,deployability,Cluster,Cluster,27,"Customizing Dendrogram and Cluster Names Placement in sc.pl.matrixplot; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Dear Scanpy Team,. Ive been working with the sc.pl.matrixplot function to visualize my data. I have a specific requirement regarding the placement of the dendrogram and cluster names in the matrix plot, both on the same side. In my current usage of sc.pl.matrixplot, I would like to customize the positioning of the dendrogram and the cluster names. Could you kindly guide me on how to achieve the placement of the dendrogram and cluster names on one side of the matrix plot for reading the plot easier? I would greatly appreciate any insights or suggestions you could provide. Thank you for your time and assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2625
https://github.com/scverse/scanpy/issues/2625:334,deployability,cluster,cluster,334,"Customizing Dendrogram and Cluster Names Placement in sc.pl.matrixplot; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Dear Scanpy Team,. Ive been working with the sc.pl.matrixplot function to visualize my data. I have a specific requirement regarding the placement of the dendrogram and cluster names in the matrix plot, both on the same side. In my current usage of sc.pl.matrixplot, I would like to customize the positioning of the dendrogram and the cluster names. Could you kindly guide me on how to achieve the placement of the dendrogram and cluster names on one side of the matrix plot for reading the plot easier? I would greatly appreciate any insights or suggestions you could provide. Thank you for your time and assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2625
https://github.com/scverse/scanpy/issues/2625:500,deployability,cluster,cluster,500,"Customizing Dendrogram and Cluster Names Placement in sc.pl.matrixplot; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Dear Scanpy Team,. Ive been working with the sc.pl.matrixplot function to visualize my data. I have a specific requirement regarding the placement of the dendrogram and cluster names in the matrix plot, both on the same side. In my current usage of sc.pl.matrixplot, I would like to customize the positioning of the dendrogram and the cluster names. Could you kindly guide me on how to achieve the placement of the dendrogram and cluster names on one side of the matrix plot for reading the plot easier? I would greatly appreciate any insights or suggestions you could provide. Thank you for your time and assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2625
https://github.com/scverse/scanpy/issues/2625:595,deployability,cluster,cluster,595,"Customizing Dendrogram and Cluster Names Placement in sc.pl.matrixplot; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Dear Scanpy Team,. Ive been working with the sc.pl.matrixplot function to visualize my data. I have a specific requirement regarding the placement of the dendrogram and cluster names in the matrix plot, both on the same side. In my current usage of sc.pl.matrixplot, I would like to customize the positioning of the dendrogram and the cluster names. Could you kindly guide me on how to achieve the placement of the dendrogram and cluster names on one side of the matrix plot for reading the plot easier? I would greatly appreciate any insights or suggestions you could provide. Thank you for your time and assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2625
https://github.com/scverse/scanpy/issues/2625:397,energy efficiency,current,current,397,"Customizing Dendrogram and Cluster Names Placement in sc.pl.matrixplot; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Dear Scanpy Team,. Ive been working with the sc.pl.matrixplot function to visualize my data. I have a specific requirement regarding the placement of the dendrogram and cluster names in the matrix plot, both on the same side. In my current usage of sc.pl.matrixplot, I would like to customize the positioning of the dendrogram and the cluster names. Could you kindly guide me on how to achieve the placement of the dendrogram and cluster names on one side of the matrix plot for reading the plot easier? I would greatly appreciate any insights or suggestions you could provide. Thank you for your time and assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2625
https://github.com/scverse/scanpy/issues/2625:267,interoperability,specif,specific,267,"Customizing Dendrogram and Cluster Names Placement in sc.pl.matrixplot; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Dear Scanpy Team,. Ive been working with the sc.pl.matrixplot function to visualize my data. I have a specific requirement regarding the placement of the dendrogram and cluster names in the matrix plot, both on the same side. In my current usage of sc.pl.matrixplot, I would like to customize the positioning of the dendrogram and the cluster names. Could you kindly guide me on how to achieve the placement of the dendrogram and cluster names on one side of the matrix plot for reading the plot easier? I would greatly appreciate any insights or suggestions you could provide. Thank you for your time and assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2625
https://github.com/scverse/scanpy/issues/2625:762,performance,time,time,762,"Customizing Dendrogram and Cluster Names Placement in sc.pl.matrixplot; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Dear Scanpy Team,. Ive been working with the sc.pl.matrixplot function to visualize my data. I have a specific requirement regarding the placement of the dendrogram and cluster names in the matrix plot, both on the same side. In my current usage of sc.pl.matrixplot, I would like to customize the positioning of the dendrogram and the cluster names. Could you kindly guide me on how to achieve the placement of the dendrogram and cluster names on one side of the matrix plot for reading the plot easier? I would greatly appreciate any insights or suggestions you could provide. Thank you for your time and assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2625
https://github.com/scverse/scanpy/issues/2625:176,security,Team,Team,176,"Customizing Dendrogram and Cluster Names Placement in sc.pl.matrixplot; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Dear Scanpy Team,. Ive been working with the sc.pl.matrixplot function to visualize my data. I have a specific requirement regarding the placement of the dendrogram and cluster names in the matrix plot, both on the same side. In my current usage of sc.pl.matrixplot, I would like to customize the positioning of the dendrogram and the cluster names. Could you kindly guide me on how to achieve the placement of the dendrogram and cluster names on one side of the matrix plot for reading the plot easier? I would greatly appreciate any insights or suggestions you could provide. Thank you for your time and assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2625
https://github.com/scverse/scanpy/issues/2625:0,usability,Custom,Customizing,0,"Customizing Dendrogram and Cluster Names Placement in sc.pl.matrixplot; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Dear Scanpy Team,. Ive been working with the sc.pl.matrixplot function to visualize my data. I have a specific requirement regarding the placement of the dendrogram and cluster names in the matrix plot, both on the same side. In my current usage of sc.pl.matrixplot, I would like to customize the positioning of the dendrogram and the cluster names. Could you kindly guide me on how to achieve the placement of the dendrogram and cluster names on one side of the matrix plot for reading the plot easier? I would greatly appreciate any insights or suggestions you could provide. Thank you for your time and assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2625
https://github.com/scverse/scanpy/issues/2625:239,usability,visual,visualize,239,"Customizing Dendrogram and Cluster Names Placement in sc.pl.matrixplot; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Dear Scanpy Team,. Ive been working with the sc.pl.matrixplot function to visualize my data. I have a specific requirement regarding the placement of the dendrogram and cluster names in the matrix plot, both on the same side. In my current usage of sc.pl.matrixplot, I would like to customize the positioning of the dendrogram and the cluster names. Could you kindly guide me on how to achieve the placement of the dendrogram and cluster names on one side of the matrix plot for reading the plot easier? I would greatly appreciate any insights or suggestions you could provide. Thank you for your time and assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2625
https://github.com/scverse/scanpy/issues/2625:448,usability,custom,customize,448,"Customizing Dendrogram and Cluster Names Placement in sc.pl.matrixplot; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Dear Scanpy Team,. Ive been working with the sc.pl.matrixplot function to visualize my data. I have a specific requirement regarding the placement of the dendrogram and cluster names in the matrix plot, both on the same side. In my current usage of sc.pl.matrixplot, I would like to customize the positioning of the dendrogram and the cluster names. Could you kindly guide me on how to achieve the placement of the dendrogram and cluster names on one side of the matrix plot for reading the plot easier? I would greatly appreciate any insights or suggestions you could provide. Thank you for your time and assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2625
https://github.com/scverse/scanpy/issues/2625:532,usability,guid,guide,532,"Customizing Dendrogram and Cluster Names Placement in sc.pl.matrixplot; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Dear Scanpy Team,. Ive been working with the sc.pl.matrixplot function to visualize my data. I have a specific requirement regarding the placement of the dendrogram and cluster names in the matrix plot, both on the same side. In my current usage of sc.pl.matrixplot, I would like to customize the positioning of the dendrogram and the cluster names. Could you kindly guide me on how to achieve the placement of the dendrogram and cluster names on one side of the matrix plot for reading the plot easier? I would greatly appreciate any insights or suggestions you could provide. Thank you for your time and assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2625
https://github.com/scverse/scanpy/issues/2626:52,deployability,scale,scale,52,"scanpy.external.pp.dca results still need normolize,scale,and log1p ?; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. If I run scanpy.external.pp.dca with default parameters, do I still need to perform normalization, scaling, and log1p afterward? How can I obtain the non-normalized values? ```py. scanpy.external.pp.dca(adata, mode='denoise', ae_type='nb-conddisp', normalize_per_cell=True, scale=True, log1p=True, hidden_size=(64, 32, 64), hidden_dropout=0.0, batchnorm=True, activation='relu', init='glorot_uniform', network_kwds=mappingproxy({}), epochs=300, reduce_lr=10, early_stop=15, batch_size=32, optimizer='RMSprop', random_state=0, threads=None, learning_rate=None, verbose=False, training_kwds=mappingproxy({}), return_model=False, return_info=False, copy=False). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2626
https://github.com/scverse/scanpy/issues/2626:505,deployability,scale,scale,505,"scanpy.external.pp.dca results still need normolize,scale,and log1p ?; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. If I run scanpy.external.pp.dca with default parameters, do I still need to perform normalization, scaling, and log1p afterward? How can I obtain the non-normalized values? ```py. scanpy.external.pp.dca(adata, mode='denoise', ae_type='nb-conddisp', normalize_per_cell=True, scale=True, log1p=True, hidden_size=(64, 32, 64), hidden_dropout=0.0, batchnorm=True, activation='relu', init='glorot_uniform', network_kwds=mappingproxy({}), epochs=300, reduce_lr=10, early_stop=15, batch_size=32, optimizer='RMSprop', random_state=0, threads=None, learning_rate=None, verbose=False, training_kwds=mappingproxy({}), return_model=False, return_info=False, copy=False). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2626
https://github.com/scverse/scanpy/issues/2626:52,energy efficiency,scale,scale,52,"scanpy.external.pp.dca results still need normolize,scale,and log1p ?; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. If I run scanpy.external.pp.dca with default parameters, do I still need to perform normalization, scaling, and log1p afterward? How can I obtain the non-normalized values? ```py. scanpy.external.pp.dca(adata, mode='denoise', ae_type='nb-conddisp', normalize_per_cell=True, scale=True, log1p=True, hidden_size=(64, 32, 64), hidden_dropout=0.0, batchnorm=True, activation='relu', init='glorot_uniform', network_kwds=mappingproxy({}), epochs=300, reduce_lr=10, early_stop=15, batch_size=32, optimizer='RMSprop', random_state=0, threads=None, learning_rate=None, verbose=False, training_kwds=mappingproxy({}), return_model=False, return_info=False, copy=False). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2626
https://github.com/scverse/scanpy/issues/2626:505,energy efficiency,scale,scale,505,"scanpy.external.pp.dca results still need normolize,scale,and log1p ?; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. If I run scanpy.external.pp.dca with default parameters, do I still need to perform normalization, scaling, and log1p afterward? How can I obtain the non-normalized values? ```py. scanpy.external.pp.dca(adata, mode='denoise', ae_type='nb-conddisp', normalize_per_cell=True, scale=True, log1p=True, hidden_size=(64, 32, 64), hidden_dropout=0.0, batchnorm=True, activation='relu', init='glorot_uniform', network_kwds=mappingproxy({}), epochs=300, reduce_lr=10, early_stop=15, batch_size=32, optimizer='RMSprop', random_state=0, threads=None, learning_rate=None, verbose=False, training_kwds=mappingproxy({}), return_model=False, return_info=False, copy=False). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2626
https://github.com/scverse/scanpy/issues/2626:720,energy efficiency,optim,optimizer,720,"scanpy.external.pp.dca results still need normolize,scale,and log1p ?; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. If I run scanpy.external.pp.dca with default parameters, do I still need to perform normalization, scaling, and log1p afterward? How can I obtain the non-normalized values? ```py. scanpy.external.pp.dca(adata, mode='denoise', ae_type='nb-conddisp', normalize_per_cell=True, scale=True, log1p=True, hidden_size=(64, 32, 64), hidden_dropout=0.0, batchnorm=True, activation='relu', init='glorot_uniform', network_kwds=mappingproxy({}), epochs=300, reduce_lr=10, early_stop=15, batch_size=32, optimizer='RMSprop', random_state=0, threads=None, learning_rate=None, verbose=False, training_kwds=mappingproxy({}), return_model=False, return_info=False, copy=False). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2626
https://github.com/scverse/scanpy/issues/2626:575,integrability,batch,batchnorm,575,"scanpy.external.pp.dca results still need normolize,scale,and log1p ?; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. If I run scanpy.external.pp.dca with default parameters, do I still need to perform normalization, scaling, and log1p afterward? How can I obtain the non-normalized values? ```py. scanpy.external.pp.dca(adata, mode='denoise', ae_type='nb-conddisp', normalize_per_cell=True, scale=True, log1p=True, hidden_size=(64, 32, 64), hidden_dropout=0.0, batchnorm=True, activation='relu', init='glorot_uniform', network_kwds=mappingproxy({}), epochs=300, reduce_lr=10, early_stop=15, batch_size=32, optimizer='RMSprop', random_state=0, threads=None, learning_rate=None, verbose=False, training_kwds=mappingproxy({}), return_model=False, return_info=False, copy=False). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2626
https://github.com/scverse/scanpy/issues/2626:52,modifiability,scal,scale,52,"scanpy.external.pp.dca results still need normolize,scale,and log1p ?; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. If I run scanpy.external.pp.dca with default parameters, do I still need to perform normalization, scaling, and log1p afterward? How can I obtain the non-normalized values? ```py. scanpy.external.pp.dca(adata, mode='denoise', ae_type='nb-conddisp', normalize_per_cell=True, scale=True, log1p=True, hidden_size=(64, 32, 64), hidden_dropout=0.0, batchnorm=True, activation='relu', init='glorot_uniform', network_kwds=mappingproxy({}), epochs=300, reduce_lr=10, early_stop=15, batch_size=32, optimizer='RMSprop', random_state=0, threads=None, learning_rate=None, verbose=False, training_kwds=mappingproxy({}), return_model=False, return_info=False, copy=False). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2626
https://github.com/scverse/scanpy/issues/2626:143,modifiability,paramet,parameters,143,"scanpy.external.pp.dca results still need normolize,scale,and log1p ?; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. If I run scanpy.external.pp.dca with default parameters, do I still need to perform normalization, scaling, and log1p afterward? How can I obtain the non-normalized values? ```py. scanpy.external.pp.dca(adata, mode='denoise', ae_type='nb-conddisp', normalize_per_cell=True, scale=True, log1p=True, hidden_size=(64, 32, 64), hidden_dropout=0.0, batchnorm=True, activation='relu', init='glorot_uniform', network_kwds=mappingproxy({}), epochs=300, reduce_lr=10, early_stop=15, batch_size=32, optimizer='RMSprop', random_state=0, threads=None, learning_rate=None, verbose=False, training_kwds=mappingproxy({}), return_model=False, return_info=False, copy=False). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2626
https://github.com/scverse/scanpy/issues/2626:276,modifiability,paramet,parameters,276,"scanpy.external.pp.dca results still need normolize,scale,and log1p ?; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. If I run scanpy.external.pp.dca with default parameters, do I still need to perform normalization, scaling, and log1p afterward? How can I obtain the non-normalized values? ```py. scanpy.external.pp.dca(adata, mode='denoise', ae_type='nb-conddisp', normalize_per_cell=True, scale=True, log1p=True, hidden_size=(64, 32, 64), hidden_dropout=0.0, batchnorm=True, activation='relu', init='glorot_uniform', network_kwds=mappingproxy({}), epochs=300, reduce_lr=10, early_stop=15, batch_size=32, optimizer='RMSprop', random_state=0, threads=None, learning_rate=None, verbose=False, training_kwds=mappingproxy({}), return_model=False, return_info=False, copy=False). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2626
https://github.com/scverse/scanpy/issues/2626:330,modifiability,scal,scaling,330,"scanpy.external.pp.dca results still need normolize,scale,and log1p ?; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. If I run scanpy.external.pp.dca with default parameters, do I still need to perform normalization, scaling, and log1p afterward? How can I obtain the non-normalized values? ```py. scanpy.external.pp.dca(adata, mode='denoise', ae_type='nb-conddisp', normalize_per_cell=True, scale=True, log1p=True, hidden_size=(64, 32, 64), hidden_dropout=0.0, batchnorm=True, activation='relu', init='glorot_uniform', network_kwds=mappingproxy({}), epochs=300, reduce_lr=10, early_stop=15, batch_size=32, optimizer='RMSprop', random_state=0, threads=None, learning_rate=None, verbose=False, training_kwds=mappingproxy({}), return_model=False, return_info=False, copy=False). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2626
https://github.com/scverse/scanpy/issues/2626:505,modifiability,scal,scale,505,"scanpy.external.pp.dca results still need normolize,scale,and log1p ?; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. If I run scanpy.external.pp.dca with default parameters, do I still need to perform normalization, scaling, and log1p afterward? How can I obtain the non-normalized values? ```py. scanpy.external.pp.dca(adata, mode='denoise', ae_type='nb-conddisp', normalize_per_cell=True, scale=True, log1p=True, hidden_size=(64, 32, 64), hidden_dropout=0.0, batchnorm=True, activation='relu', init='glorot_uniform', network_kwds=mappingproxy({}), epochs=300, reduce_lr=10, early_stop=15, batch_size=32, optimizer='RMSprop', random_state=0, threads=None, learning_rate=None, verbose=False, training_kwds=mappingproxy({}), return_model=False, return_info=False, copy=False). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2626
https://github.com/scverse/scanpy/issues/2626:52,performance,scale,scale,52,"scanpy.external.pp.dca results still need normolize,scale,and log1p ?; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. If I run scanpy.external.pp.dca with default parameters, do I still need to perform normalization, scaling, and log1p afterward? How can I obtain the non-normalized values? ```py. scanpy.external.pp.dca(adata, mode='denoise', ae_type='nb-conddisp', normalize_per_cell=True, scale=True, log1p=True, hidden_size=(64, 32, 64), hidden_dropout=0.0, batchnorm=True, activation='relu', init='glorot_uniform', network_kwds=mappingproxy({}), epochs=300, reduce_lr=10, early_stop=15, batch_size=32, optimizer='RMSprop', random_state=0, threads=None, learning_rate=None, verbose=False, training_kwds=mappingproxy({}), return_model=False, return_info=False, copy=False). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2626
https://github.com/scverse/scanpy/issues/2626:307,performance,perform,perform,307,"scanpy.external.pp.dca results still need normolize,scale,and log1p ?; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. If I run scanpy.external.pp.dca with default parameters, do I still need to perform normalization, scaling, and log1p afterward? How can I obtain the non-normalized values? ```py. scanpy.external.pp.dca(adata, mode='denoise', ae_type='nb-conddisp', normalize_per_cell=True, scale=True, log1p=True, hidden_size=(64, 32, 64), hidden_dropout=0.0, batchnorm=True, activation='relu', init='glorot_uniform', network_kwds=mappingproxy({}), epochs=300, reduce_lr=10, early_stop=15, batch_size=32, optimizer='RMSprop', random_state=0, threads=None, learning_rate=None, verbose=False, training_kwds=mappingproxy({}), return_model=False, return_info=False, copy=False). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2626
https://github.com/scverse/scanpy/issues/2626:505,performance,scale,scale,505,"scanpy.external.pp.dca results still need normolize,scale,and log1p ?; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. If I run scanpy.external.pp.dca with default parameters, do I still need to perform normalization, scaling, and log1p afterward? How can I obtain the non-normalized values? ```py. scanpy.external.pp.dca(adata, mode='denoise', ae_type='nb-conddisp', normalize_per_cell=True, scale=True, log1p=True, hidden_size=(64, 32, 64), hidden_dropout=0.0, batchnorm=True, activation='relu', init='glorot_uniform', network_kwds=mappingproxy({}), epochs=300, reduce_lr=10, early_stop=15, batch_size=32, optimizer='RMSprop', random_state=0, threads=None, learning_rate=None, verbose=False, training_kwds=mappingproxy({}), return_model=False, return_info=False, copy=False). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2626
https://github.com/scverse/scanpy/issues/2626:575,performance,batch,batchnorm,575,"scanpy.external.pp.dca results still need normolize,scale,and log1p ?; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. If I run scanpy.external.pp.dca with default parameters, do I still need to perform normalization, scaling, and log1p afterward? How can I obtain the non-normalized values? ```py. scanpy.external.pp.dca(adata, mode='denoise', ae_type='nb-conddisp', normalize_per_cell=True, scale=True, log1p=True, hidden_size=(64, 32, 64), hidden_dropout=0.0, batchnorm=True, activation='relu', init='glorot_uniform', network_kwds=mappingproxy({}), epochs=300, reduce_lr=10, early_stop=15, batch_size=32, optimizer='RMSprop', random_state=0, threads=None, learning_rate=None, verbose=False, training_kwds=mappingproxy({}), return_model=False, return_info=False, copy=False). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2626
https://github.com/scverse/scanpy/issues/2626:720,performance,optimiz,optimizer,720,"scanpy.external.pp.dca results still need normolize,scale,and log1p ?; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. If I run scanpy.external.pp.dca with default parameters, do I still need to perform normalization, scaling, and log1p afterward? How can I obtain the non-normalized values? ```py. scanpy.external.pp.dca(adata, mode='denoise', ae_type='nb-conddisp', normalize_per_cell=True, scale=True, log1p=True, hidden_size=(64, 32, 64), hidden_dropout=0.0, batchnorm=True, activation='relu', init='glorot_uniform', network_kwds=mappingproxy({}), epochs=300, reduce_lr=10, early_stop=15, batch_size=32, optimizer='RMSprop', random_state=0, threads=None, learning_rate=None, verbose=False, training_kwds=mappingproxy({}), return_model=False, return_info=False, copy=False). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2626
https://github.com/scverse/scanpy/issues/2626:307,usability,perform,perform,307,"scanpy.external.pp.dca results still need normolize,scale,and log1p ?; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. If I run scanpy.external.pp.dca with default parameters, do I still need to perform normalization, scaling, and log1p afterward? How can I obtain the non-normalized values? ```py. scanpy.external.pp.dca(adata, mode='denoise', ae_type='nb-conddisp', normalize_per_cell=True, scale=True, log1p=True, hidden_size=(64, 32, 64), hidden_dropout=0.0, batchnorm=True, activation='relu', init='glorot_uniform', network_kwds=mappingproxy({}), epochs=300, reduce_lr=10, early_stop=15, batch_size=32, optimizer='RMSprop', random_state=0, threads=None, learning_rate=None, verbose=False, training_kwds=mappingproxy({}), return_model=False, return_info=False, copy=False). ```",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2626
https://github.com/scverse/scanpy/issues/2627:1233,availability,Error,Error,1233,"n of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? After running `sc.external.pp.scrublet` function, the image plot embedding in jupyterlab is missing. And there is a warning,. ```. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Minimal code sample. ```python. import scanpy as sc. import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25). adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],. jitter=0.4, multi_panel=True, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight. self._figure.tight_layout(*args, **kwargs). /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI back",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:230,deployability,version,version,230,"`sc.external.pp.scrublet` disables figure plot in jupyterlab; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? After running `sc.external.pp.scrublet` function, the image plot embedding in jupyterlab is missing. And there is a warning,. ```. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Minimal code sample. ```python. import scanpy as sc. import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25). adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],. jitter=0.4, multi_panel=True, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure la",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:2288,deployability,Version,Versions,2288,"ib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight. self._figure.tight_layout(*args, **kwargs). /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.2.0. annoy NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2023.2.0. dateutil 2.8.2. debugpy 1.6.8. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastjsonschema NA. fontTools 4.42.0. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.2. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.1. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. lxml 4.9.1. markupsafe 2.1.3. matplotlib 3.7.2. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. overrides NA. pack",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:4540,deployability,updat,updated,4540,".4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2023.2.0. dateutil 2.8.2. debugpy 1.6.8. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastjsonschema NA. fontTools 4.42.0. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.2. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.1. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. lxml 4.9.1. markupsafe 2.1.3. matplotlib 3.7.2. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pyparsing 3.0.9. pythonjsonlogger NA. pytz 2023.3. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. scrublet NA. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.3.0. sniffio 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.2.0. tlz 0.12.2. toolz 0.12.0. tornado 6.3.3. traitlets 5.9.0. typing_extensions NA. uri_template NA. urllib3 2.0.4. wcwidth 0.2.6. webcolors 1.13. websocket 1.6.1. yaml 6.0. zipp NA. zmq 25.1.1. -----. IPython 8.7.0. jupyter_client 8.3.0. jupyter_core 5.3.0. jupyterlab 4.0.5. notebook 7.0.2. -----. Python 3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:46:39) [GCC 10.4.0]. Linux-4.18.0-348.7.1.el8_5.x86_64-x86_64-with-glibc2.10. -----. Session information updated at 2023-08-20 12:04. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:602,energy efficiency,current,currently,602,"`sc.external.pp.scrublet` disables figure plot in jupyterlab; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? After running `sc.external.pp.scrublet` function, the image plot embedding in jupyterlab is missing. And there is a warning,. ```. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Minimal code sample. ```python. import scanpy as sc. import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25). adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],. jitter=0.4, multi_panel=True, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure la",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:1475,energy efficiency,Estimat,Estimated,1475," /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Minimal code sample. ```python. import scanpy as sc. import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25). adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],. jitter=0.4, multi_panel=True, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight. self._figure.tight_layout(*args, **kwargs). /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.2.0. annoy NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:1564,energy efficiency,Estimat,Estimated,1564,":314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Minimal code sample. ```python. import scanpy as sc. import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25). adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],. jitter=0.4, multi_panel=True, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight. self._figure.tight_layout(*args, **kwargs). /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.2.0. annoy NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. colorama",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:2192,energy efficiency,current,currently,2192,"e, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight. self._figure.tight_layout(*args, **kwargs). /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.2.0. annoy NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2023.2.0. dateutil 2.8.2. debugpy 1.6.8. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastjsonschema NA. fontTools 4.42.0. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.2. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.1. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. lxml 4.9.1. markupsafe 2.1.3. matplotlib 3.7.2. mpl_toolkits N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:2542,energy efficiency,cloud,cloudpickle,2542,"pected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight. self._figure.tight_layout(*args, **kwargs). /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.2.0. annoy NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2023.2.0. dateutil 2.8.2. debugpy 1.6.8. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastjsonschema NA. fontTools 4.42.0. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.2. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.1. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. lxml 4.9.1. markupsafe 2.1.3. matplotlib 3.7.2. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 11.0.0. pycparser 2.21. pydev",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:230,integrability,version,version,230,"`sc.external.pp.scrublet` disables figure plot in jupyterlab; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? After running `sc.external.pp.scrublet` function, the image plot embedding in jupyterlab is missing. And there is a warning,. ```. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Minimal code sample. ```python. import scanpy as sc. import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25). adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],. jitter=0.4, multi_panel=True, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure la",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:2288,integrability,Version,Versions,2288,"ib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight. self._figure.tight_layout(*args, **kwargs). /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.2.0. annoy NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2023.2.0. dateutil 2.8.2. debugpy 1.6.8. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastjsonschema NA. fontTools 4.42.0. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.2. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.1. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. lxml 4.9.1. markupsafe 2.1.3. matplotlib 3.7.2. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. overrides NA. pack",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:3396,interoperability,platform,platformdirs,3396,sttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2023.2.0. dateutil 2.8.2. debugpy 1.6.8. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastjsonschema NA. fontTools 4.42.0. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.2. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.1. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. lxml 4.9.1. markupsafe 2.1.3. matplotlib 3.7.2. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pyparsing 3.0.9. pythonjsonlogger NA. pytz 2023.3. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. scrublet NA. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.3.0. sniffio 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.2.0. tlz 0.12.2. toolz 0.12.0. tornado 6.3.3. traitlets 5.9.0. typing_extensions NA. uri_template NA. urllib3 2.0.4. wcwidth 0.2.6. webcolors 1.13. websocket 1.6.1. yaml 6.0. zipp NA. zmq 25.1.1. -----. IPython 8.7.0. jupyter_client 8.3.0. jupyter_core 5.3.0. jupyterlab 4.0.5. notebook 7.0.2. -----. Python 3.8.15 | packaged by conda-f,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:230,modifiability,version,version,230,"`sc.external.pp.scrublet` disables figure plot in jupyterlab; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? After running `sc.external.pp.scrublet` function, the image plot embedding in jupyterlab is missing. And there is a warning,. ```. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Minimal code sample. ```python. import scanpy as sc. import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25). adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],. jitter=0.4, multi_panel=True, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure la",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:535,modifiability,pac,packages,535,"`sc.external.pp.scrublet` disables figure plot in jupyterlab; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? After running `sc.external.pp.scrublet` function, the image plot embedding in jupyterlab is missing. And there is a warning,. ```. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Minimal code sample. ```python. import scanpy as sc. import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25). adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],. jitter=0.4, multi_panel=True, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure la",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:1310,modifiability,pac,packages,1310,"ranch of scanpy. ### What happened? After running `sc.external.pp.scrublet` function, the image plot embedding in jupyterlab is missing. And there is a warning,. ```. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Minimal code sample. ```python. import scanpy as sc. import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25). adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],. jitter=0.4, multi_panel=True, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight. self._figure.tight_layout(*args, **kwargs). /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Versions. <details>. ```. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:1636,modifiability,pac,packages,1636,"I backend, so cannot show the figure. pl.show(). ```. ### Minimal code sample. ```python. import scanpy as sc. import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25). adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],. jitter=0.4, multi_panel=True, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight. self._figure.tight_layout(*args, **kwargs). /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.2.0. annoy NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. d",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:1940,modifiability,pac,packages,1940,"te = 0.06, threshold = 0.25). adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],. jitter=0.4, multi_panel=True, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight. self._figure.tight_layout(*args, **kwargs). /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.2.0. annoy NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2023.2.0. dateutil 2.8.2. debugpy 1.6.8. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastjsonschema NA. fontTools 4.42.0. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.2. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 N",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:2125,modifiability,pac,packages,2125," ['n_genes_by_counts', 'total_counts'],. jitter=0.4, multi_panel=True, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight. self._figure.tight_layout(*args, **kwargs). /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.2.0. annoy NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2023.2.0. dateutil 2.8.2. debugpy 1.6.8. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastjsonschema NA. fontTools 4.42.0. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.2. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.1. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:2288,modifiability,Version,Versions,2288,"ib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight. self._figure.tight_layout(*args, **kwargs). /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.2.0. annoy NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2023.2.0. dateutil 2.8.2. debugpy 1.6.8. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastjsonschema NA. fontTools 4.42.0. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.2. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.1. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. lxml 4.9.1. markupsafe 2.1.3. matplotlib 3.7.2. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. overrides NA. pack",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:2685,modifiability,deco,decorator,2685,"ficationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight. self._figure.tight_layout(*args, **kwargs). /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.2.0. annoy NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2023.2.0. dateutil 2.8.2. debugpy 1.6.8. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastjsonschema NA. fontTools 4.42.0. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.2. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.1. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. lxml 4.9.1. markupsafe 2.1.3. matplotlib 3.7.2. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pyparsing 3.0.9. pyth",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:3288,modifiability,pac,packaging,3288,ons. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.2.0. annoy NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2023.2.0. dateutil 2.8.2. debugpy 1.6.8. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastjsonschema NA. fontTools 4.42.0. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.2. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.1. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. lxml 4.9.1. markupsafe 2.1.3. matplotlib 3.7.2. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pyparsing 3.0.9. pythonjsonlogger NA. pytz 2023.3. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. scrublet NA. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.3.0. sniffio 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.2.0. tlz 0.12.2. toolz 0.12.0. tornado 6.3.3. traitlets 5.9.0. typing_extensions NA. uri_template NA. urllib3 2.0.4. wcwidth 0.2.6. webcolors 1.13. websocket 1.6.1. yaml 6.0. zipp NA. zmq 25.1.1. -----. IPython 8.7.0. jupyter_c,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:4383,modifiability,pac,packaged,4383,".4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2023.2.0. dateutil 2.8.2. debugpy 1.6.8. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastjsonschema NA. fontTools 4.42.0. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.2. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.1. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. lxml 4.9.1. markupsafe 2.1.3. matplotlib 3.7.2. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pyparsing 3.0.9. pythonjsonlogger NA. pytz 2023.3. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. scrublet NA. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.3.0. sniffio 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.2.0. tlz 0.12.2. toolz 0.12.0. tornado 6.3.3. traitlets 5.9.0. typing_extensions NA. uri_template NA. urllib3 2.0.4. wcwidth 0.2.6. webcolors 1.13. websocket 1.6.1. yaml 6.0. zipp NA. zmq 25.1.1. -----. IPython 8.7.0. jupyter_client 8.3.0. jupyter_core 5.3.0. jupyterlab 4.0.5. notebook 7.0.2. -----. Python 3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:46:39) [GCC 10.4.0]. Linux-4.18.0-348.7.1.el8_5.x86_64-x86_64-with-glibc2.10. -----. Session information updated at 2023-08-20 12:04. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:1233,performance,Error,Error,1233,"n of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? After running `sc.external.pp.scrublet` function, the image plot embedding in jupyterlab is missing. And there is a warning,. ```. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Minimal code sample. ```python. import scanpy as sc. import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25). adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],. jitter=0.4, multi_panel=True, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight. self._figure.tight_layout(*args, **kwargs). /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI back",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:1233,safety,Error,Error,1233,"n of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? After running `sc.external.pp.scrublet` function, the image plot embedding in jupyterlab is missing. And there is a warning,. ```. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Minimal code sample. ```python. import scanpy as sc. import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25). adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],. jitter=0.4, multi_panel=True, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight. self._figure.tight_layout(*args, **kwargs). /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI back",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:1445,safety,Detect,Detected,1445,". And there is a warning,. ```. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Minimal code sample. ```python. import scanpy as sc. import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25). adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],. jitter=0.4, multi_panel=True, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight. self._figure.tight_layout(*args, **kwargs). /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.2.0. annoy NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:1485,safety,detect,detectable,1485,"s/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Minimal code sample. ```python. import scanpy as sc. import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25). adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],. jitter=0.4, multi_panel=True, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight. self._figure.tight_layout(*args, **kwargs). /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.2.0. annoy NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:4540,safety,updat,updated,4540,".4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2023.2.0. dateutil 2.8.2. debugpy 1.6.8. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastjsonschema NA. fontTools 4.42.0. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.2. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.1. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. lxml 4.9.1. markupsafe 2.1.3. matplotlib 3.7.2. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pyparsing 3.0.9. pythonjsonlogger NA. pytz 2023.3. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. scrublet NA. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.3.0. sniffio 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.2.0. tlz 0.12.2. toolz 0.12.0. tornado 6.3.3. traitlets 5.9.0. typing_extensions NA. uri_template NA. urllib3 2.0.4. wcwidth 0.2.6. webcolors 1.13. websocket 1.6.1. yaml 6.0. zipp NA. zmq 25.1.1. -----. IPython 8.7.0. jupyter_client 8.3.0. jupyter_core 5.3.0. jupyterlab 4.0.5. notebook 7.0.2. -----. Python 3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:46:39) [GCC 10.4.0]. Linux-4.18.0-348.7.1.el8_5.x86_64-x86_64-with-glibc2.10. -----. Session information updated at 2023-08-20 12:04. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:1445,security,Detect,Detected,1445,". And there is a warning,. ```. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Minimal code sample. ```python. import scanpy as sc. import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25). adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],. jitter=0.4, multi_panel=True, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight. self._figure.tight_layout(*args, **kwargs). /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.2.0. annoy NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:1485,security,detect,detectable,1485,"s/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Minimal code sample. ```python. import scanpy as sc. import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25). adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],. jitter=0.4, multi_panel=True, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight. self._figure.tight_layout(*args, **kwargs). /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.2.0. annoy NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:1717,security,modif,modify,1717,"``python. import scanpy as sc. import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25). adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],. jitter=0.4, multi_panel=True, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight. self._figure.tight_layout(*args, **kwargs). /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.2.0. annoy NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2023.2.0. dateutil 2.8.2. debugpy 1.6.8. decorator 5.1.1. defusedxml 0.7.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:2483,security,certif,certifi,2483,"tectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight. self._figure.tight_layout(*args, **kwargs). /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.2.0. annoy NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2023.2.0. dateutil 2.8.2. debugpy 1.6.8. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastjsonschema NA. fontTools 4.42.0. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.2. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.1. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. lxml 4.9.1. markupsafe 2.1.3. matplotlib 3.7.2. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:2880,security,iso,isoduration,2880,"/data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight. self._figure.tight_layout(*args, **kwargs). /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.2.0. annoy NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2023.2.0. dateutil 2.8.2. debugpy 1.6.8. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastjsonschema NA. fontTools 4.42.0. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.2. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.1. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. lxml 4.9.1. markupsafe 2.1.3. matplotlib 3.7.2. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pyparsing 3.0.9. pythonjsonlogger NA. pytz 2023.3. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. scrublet NA. seaborn 0.12.2. send2trash NA. session_info 1.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:3951,security,soc,socks,3951,".4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2023.2.0. dateutil 2.8.2. debugpy 1.6.8. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastjsonschema NA. fontTools 4.42.0. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.2. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.1. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. lxml 4.9.1. markupsafe 2.1.3. matplotlib 3.7.2. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pyparsing 3.0.9. pythonjsonlogger NA. pytz 2023.3. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. scrublet NA. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.3.0. sniffio 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.2.0. tlz 0.12.2. toolz 0.12.0. tornado 6.3.3. traitlets 5.9.0. typing_extensions NA. uri_template NA. urllib3 2.0.4. wcwidth 0.2.6. webcolors 1.13. websocket 1.6.1. yaml 6.0. zipp NA. zmq 25.1.1. -----. IPython 8.7.0. jupyter_client 8.3.0. jupyter_core 5.3.0. jupyterlab 4.0.5. notebook 7.0.2. -----. Python 3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:46:39) [GCC 10.4.0]. Linux-4.18.0-348.7.1.el8_5.x86_64-x86_64-with-glibc2.10. -----. Session information updated at 2023-08-20 12:04. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:4520,security,Session,Session,4520,".4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2023.2.0. dateutil 2.8.2. debugpy 1.6.8. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastjsonschema NA. fontTools 4.42.0. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.2. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.1. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. lxml 4.9.1. markupsafe 2.1.3. matplotlib 3.7.2. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pyparsing 3.0.9. pythonjsonlogger NA. pytz 2023.3. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. scrublet NA. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.3.0. sniffio 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.2.0. tlz 0.12.2. toolz 0.12.0. tornado 6.3.3. traitlets 5.9.0. typing_extensions NA. uri_template NA. urllib3 2.0.4. wcwidth 0.2.6. webcolors 1.13. websocket 1.6.1. yaml 6.0. zipp NA. zmq 25.1.1. -----. IPython 8.7.0. jupyter_client 8.3.0. jupyter_core 5.3.0. jupyterlab 4.0.5. notebook 7.0.2. -----. Python 3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:46:39) [GCC 10.4.0]. Linux-4.18.0-348.7.1.el8_5.x86_64-x86_64-with-glibc2.10. -----. Session information updated at 2023-08-20 12:04. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:4540,security,updat,updated,4540,".4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2023.2.0. dateutil 2.8.2. debugpy 1.6.8. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastjsonschema NA. fontTools 4.42.0. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.2. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.1. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. lxml 4.9.1. markupsafe 2.1.3. matplotlib 3.7.2. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pyparsing 3.0.9. pythonjsonlogger NA. pytz 2023.3. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. scrublet NA. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.3.0. sniffio 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.2.0. tlz 0.12.2. toolz 0.12.0. tornado 6.3.3. traitlets 5.9.0. typing_extensions NA. uri_template NA. urllib3 2.0.4. wcwidth 0.2.6. webcolors 1.13. websocket 1.6.1. yaml 6.0. zipp NA. zmq 25.1.1. -----. IPython 8.7.0. jupyter_client 8.3.0. jupyter_core 5.3.0. jupyterlab 4.0.5. notebook 7.0.2. -----. Python 3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:46:39) [GCC 10.4.0]. Linux-4.18.0-348.7.1.el8_5.x86_64-x86_64-with-glibc2.10. -----. Session information updated at 2023-08-20 12:04. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:190,usability,confirm,confirmed,190,"`sc.external.pp.scrublet` disables figure plot in jupyterlab; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? After running `sc.external.pp.scrublet` function, the image plot embedding in jupyterlab is missing. And there is a warning,. ```. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Minimal code sample. ```python. import scanpy as sc. import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25). adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],. jitter=0.4, multi_panel=True, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure la",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:273,usability,confirm,confirmed,273,"`sc.external.pp.scrublet` disables figure plot in jupyterlab; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? After running `sc.external.pp.scrublet` function, the image plot embedding in jupyterlab is missing. And there is a warning,. ```. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Minimal code sample. ```python. import scanpy as sc. import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25). adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],. jitter=0.4, multi_panel=True, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure la",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:575,usability,User,UserWarning,575,"`sc.external.pp.scrublet` disables figure plot in jupyterlab; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? After running `sc.external.pp.scrublet` function, the image plot embedding in jupyterlab is missing. And there is a warning,. ```. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Minimal code sample. ```python. import scanpy as sc. import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25). adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],. jitter=0.4, multi_panel=True, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure la",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:698,usability,Minim,Minimal,698,"`sc.external.pp.scrublet` disables figure plot in jupyterlab; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? After running `sc.external.pp.scrublet` function, the image plot embedding in jupyterlab is missing. And there is a warning,. ```. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Minimal code sample. ```python. import scanpy as sc. import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25). adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],. jitter=0.4, multi_panel=True, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure la",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:1233,usability,Error,Error,1233,"n of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? After running `sc.external.pp.scrublet` function, the image plot embedding in jupyterlab is missing. And there is a warning,. ```. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Minimal code sample. ```python. import scanpy as sc. import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25). adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],. jitter=0.4, multi_panel=True, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight. self._figure.tight_layout(*args, **kwargs). /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI back",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:1363,usability,User,UserWarning,1363,"xternal.pp.scrublet` function, the image plot embedding in jupyterlab is missing. And there is a warning,. ```. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Minimal code sample. ```python. import scanpy as sc. import scanpy.external as sce. adata = sc.datasets.pbmc3k(). sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.external.pp.scrublet(adata, expected_doublet_rate = 0.06, threshold = 0.25). adata = adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],. jitter=0.4, multi_panel=True, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight. self._figure.tight_layout(*args, **kwargs). /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.2.0. a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:1974,usability,User,UserWarning,1974,"= adata[adata.obs.predicted_doublet == False, :]. sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True). sc.pl.violin(adata, ['n_genes_by_counts', 'total_counts'],. jitter=0.4, multi_panel=True, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight. self._figure.tight_layout(*args, **kwargs). /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.2.0. annoy NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2023.2.0. dateutil 2.8.2. debugpy 1.6.8. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastjsonschema NA. fontTools 4.42.0. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.2. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:2165,usability,User,UserWarning,2165,"itter=0.4, multi_panel=True, save=""_before_QC.pdf""). ```. ### Error output. ```pytb. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_normalization.py:170: UserWarning: Received a view of an AnnData. Making a copy. view_to_actual(adata). Detected doublet rate = 1.7%. Estimated detectable doublet fraction = 41.1%. Overall doublet rate:. 	Expected = 6.0%. 	Estimated = 4.1%. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/preprocessing/_qc.py:135: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual. adata.obs[obs_metrics.columns] = obs_metrics. WARNING: saving figure to file figures/violin_before_QC.pdf. /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/seaborn/axisgrid.py:118: UserWarning: The figure layout has changed to tight. self._figure.tight_layout(*args, **kwargs). /data/apps/anaconda3/envs/scRNAseq/lib/python3.8/site-packages/scanpy/plotting/_utils.py:314: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure. pl.show(). ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.2.0. annoy NA. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli NA. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2023.2.0. dateutil 2.8.2. debugpy 1.6.8. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastjsonschema NA. fontTools 4.42.0. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.2. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.1. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. lxml 4.9.1. markupsafe 2.1.3. matplo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2627:4083,usability,tool,toolz,4083,".4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2023.2.0. dateutil 2.8.2. debugpy 1.6.8. decorator 5.1.1. defusedxml 0.7.1. executing 1.2.0. fastjsonschema NA. fontTools 4.42.0. fqdn NA. h5py 3.9.0. idna 3.4. igraph 0.10.2. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.1. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1. lxml 4.9.1. markupsafe 2.1.3. matplotlib 3.7.2. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numexpr 2.8.4. numpy 1.24.4. overrides NA. packaging 23.1. pandas 2.0.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 11.0.0. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pyparsing 3.0.9. pythonjsonlogger NA. pytz 2023.3. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. scrublet NA. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools_scm NA. six 1.16.0. sklearn 1.3.0. sniffio 1.3.0. socks 1.7.1. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.2.0. tlz 0.12.2. toolz 0.12.0. tornado 6.3.3. traitlets 5.9.0. typing_extensions NA. uri_template NA. urllib3 2.0.4. wcwidth 0.2.6. webcolors 1.13. websocket 1.6.1. yaml 6.0. zipp NA. zmq 25.1.1. -----. IPython 8.7.0. jupyter_client 8.3.0. jupyter_core 5.3.0. jupyterlab 4.0.5. notebook 7.0.2. -----. Python 3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:46:39) [GCC 10.4.0]. Linux-4.18.0-348.7.1.el8_5.x86_64-x86_64-with-glibc2.10. -----. Session information updated at 2023-08-20 12:04. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2627
https://github.com/scverse/scanpy/issues/2628:1788,availability,Error,Error,1788,"sc.tl.rank_genes_groups finds upregulated genes (lfc > 1.5) with pts 0; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: . upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python. sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names. result = pd.DataFrame(. {group + '_' + key: results[key][group]. for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []. for i in groups:. group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]. group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}). group['group'] = i. de_results.append(group). de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True). de_results. ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628
https://github.com/scverse/scanpy/issues/2628:240,deployability,version,version,240,"sc.tl.rank_genes_groups finds upregulated genes (lfc > 1.5) with pts 0; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: . upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python. sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names. result = pd.DataFrame(. {group + '_' + key: results[key][group]. for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []. for i in groups:. group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]. group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}). group['group'] = i. de_results.append(group). de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True). de_results. ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628
https://github.com/scverse/scanpy/issues/2628:1309,deployability,log,logfoldchanges,1309,"sc.tl.rank_genes_groups finds upregulated genes (lfc > 1.5) with pts 0; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: . upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python. sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names. result = pd.DataFrame(. {group + '_' + key: results[key][group]. for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []. for i in groups:. group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]. group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}). group['group'] = i. de_results.append(group). de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True). de_results. ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628
https://github.com/scverse/scanpy/issues/2628:1821,deployability,Version,Versions,1821,"sc.tl.rank_genes_groups finds upregulated genes (lfc > 1.5) with pts 0; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: . upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python. sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names. result = pd.DataFrame(. {group + '_' + key: results[key][group]. for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []. for i in groups:. group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]. group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}). group['group'] = i. de_results.append(group). de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True). de_results. ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628
https://github.com/scverse/scanpy/issues/2628:240,integrability,version,version,240,"sc.tl.rank_genes_groups finds upregulated genes (lfc > 1.5) with pts 0; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: . upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python. sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names. result = pd.DataFrame(. {group + '_' + key: results[key][group]. for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []. for i in groups:. group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]. group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}). group['group'] = i. de_results.append(group). de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True). de_results. ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628
https://github.com/scverse/scanpy/issues/2628:400,integrability,filter,filter,400,"sc.tl.rank_genes_groups finds upregulated genes (lfc > 1.5) with pts 0; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: . upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python. sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names. result = pd.DataFrame(. {group + '_' + key: results[key][group]. for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []. for i in groups:. group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]. group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}). group['group'] = i. de_results.append(group). de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True). de_results. ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628
https://github.com/scverse/scanpy/issues/2628:1821,integrability,Version,Versions,1821,"sc.tl.rank_genes_groups finds upregulated genes (lfc > 1.5) with pts 0; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: . upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python. sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names. result = pd.DataFrame(. {group + '_' + key: results[key][group]. for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []. for i in groups:. group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]. group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}). group['group'] = i. de_results.append(group). de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True). de_results. ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628
https://github.com/scverse/scanpy/issues/2628:240,modifiability,version,version,240,"sc.tl.rank_genes_groups finds upregulated genes (lfc > 1.5) with pts 0; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: . upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python. sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names. result = pd.DataFrame(. {group + '_' + key: results[key][group]. for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []. for i in groups:. group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]. group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}). group['group'] = i. de_results.append(group). de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True). de_results. ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628
https://github.com/scverse/scanpy/issues/2628:1821,modifiability,Version,Versions,1821,"sc.tl.rank_genes_groups finds upregulated genes (lfc > 1.5) with pts 0; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: . upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python. sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names. result = pd.DataFrame(. {group + '_' + key: results[key][group]. for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []. for i in groups:. group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]. group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}). group['group'] = i. de_results.append(group). de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True). de_results. ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628
https://github.com/scverse/scanpy/issues/2628:1788,performance,Error,Error,1788,"sc.tl.rank_genes_groups finds upregulated genes (lfc > 1.5) with pts 0; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: . upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python. sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names. result = pd.DataFrame(. {group + '_' + key: results[key][group]. for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []. for i in groups:. group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]. group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}). group['group'] = i. de_results.append(group). de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True). de_results. ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628
https://github.com/scverse/scanpy/issues/2628:632,reliability,doe,does,632,"sc.tl.rank_genes_groups finds upregulated genes (lfc > 1.5) with pts 0; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: . upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python. sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names. result = pd.DataFrame(. {group + '_' + key: results[key][group]. for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []. for i in groups:. group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]. group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}). group['group'] = i. de_results.append(group). de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True). de_results. ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628
https://github.com/scverse/scanpy/issues/2628:976,safety,test,test,976,"sc.tl.rank_genes_groups finds upregulated genes (lfc > 1.5) with pts 0; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: . upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python. sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names. result = pd.DataFrame(. {group + '_' + key: results[key][group]. for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []. for i in groups:. group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]. group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}). group['group'] = i. de_results.append(group). de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True). de_results. ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628
https://github.com/scverse/scanpy/issues/2628:1309,safety,log,logfoldchanges,1309,"sc.tl.rank_genes_groups finds upregulated genes (lfc > 1.5) with pts 0; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: . upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python. sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names. result = pd.DataFrame(. {group + '_' + key: results[key][group]. for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []. for i in groups:. group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]. group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}). group['group'] = i. de_results.append(group). de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True). de_results. ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628
https://github.com/scverse/scanpy/issues/2628:1788,safety,Error,Error,1788,"sc.tl.rank_genes_groups finds upregulated genes (lfc > 1.5) with pts 0; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: . upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python. sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names. result = pd.DataFrame(. {group + '_' + key: results[key][group]. for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []. for i in groups:. group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]. group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}). group['group'] = i. de_results.append(group). de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True). de_results. ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628
https://github.com/scverse/scanpy/issues/2628:1309,security,log,logfoldchanges,1309,"sc.tl.rank_genes_groups finds upregulated genes (lfc > 1.5) with pts 0; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: . upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python. sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names. result = pd.DataFrame(. {group + '_' + key: results[key][group]. for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []. for i in groups:. group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]. group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}). group['group'] = i. de_results.append(group). de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True). de_results. ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628
https://github.com/scverse/scanpy/issues/2628:976,testability,test,test,976,"sc.tl.rank_genes_groups finds upregulated genes (lfc > 1.5) with pts 0; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: . upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python. sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names. result = pd.DataFrame(. {group + '_' + key: results[key][group]. for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []. for i in groups:. group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]. group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}). group['group'] = i. de_results.append(group). de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True). de_results. ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628
https://github.com/scverse/scanpy/issues/2628:1309,testability,log,logfoldchanges,1309,"sc.tl.rank_genes_groups finds upregulated genes (lfc > 1.5) with pts 0; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: . upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python. sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names. result = pd.DataFrame(. {group + '_' + key: results[key][group]. for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []. for i in groups:. group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]. group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}). group['group'] = i. de_results.append(group). de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True). de_results. ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628
https://github.com/scverse/scanpy/issues/2628:200,usability,confirm,confirmed,200,"sc.tl.rank_genes_groups finds upregulated genes (lfc > 1.5) with pts 0; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: . upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python. sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names. result = pd.DataFrame(. {group + '_' + key: results[key][group]. for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []. for i in groups:. group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]. group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}). group['group'] = i. de_results.append(group). de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True). de_results. ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628
https://github.com/scverse/scanpy/issues/2628:283,usability,confirm,confirmed,283,"sc.tl.rank_genes_groups finds upregulated genes (lfc > 1.5) with pts 0; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: . upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python. sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names. result = pd.DataFrame(. {group + '_' + key: results[key][group]. for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []. for i in groups:. group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]. group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}). group['group'] = i. de_results.append(group). de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True). de_results. ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628
https://github.com/scverse/scanpy/issues/2628:393,usability,custom,custom,393,"sc.tl.rank_genes_groups finds upregulated genes (lfc > 1.5) with pts 0; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: . upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python. sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names. result = pd.DataFrame(. {group + '_' + key: results[key][group]. for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []. for i in groups:. group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]. group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}). group['group'] = i. de_results.append(group). de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True). de_results. ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628
https://github.com/scverse/scanpy/issues/2628:764,usability,help,help,764,"sc.tl.rank_genes_groups finds upregulated genes (lfc > 1.5) with pts 0; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: . upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python. sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names. result = pd.DataFrame(. {group + '_' + key: results[key][group]. for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []. for i in groups:. group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]. group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}). group['group'] = i. de_results.append(group). de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True). de_results. ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628
https://github.com/scverse/scanpy/issues/2628:903,usability,Minim,Minimal,903,"sc.tl.rank_genes_groups finds upregulated genes (lfc > 1.5) with pts 0; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: . upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python. sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names. result = pd.DataFrame(. {group + '_' + key: results[key][group]. for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []. for i in groups:. group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]. group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}). group['group'] = i. de_results.append(group). de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True). de_results. ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628
https://github.com/scverse/scanpy/issues/2628:1788,usability,Error,Error,1788,"sc.tl.rank_genes_groups finds upregulated genes (lfc > 1.5) with pts 0; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I defined groups of cells with a custom filter. After I run rank_gene_groups with pts=True in order to get the precent of cells infected, the results don't make sense: . upregulated genes with lfc values and adjusted pvalues that make sense, have a pts value of 0 - which does not make sense because if this gene is upregulated in this group, it has to exist in more than 0 cells. I would appreciate any help with his, thank you in advance. ![image](https://github.com/scverse/scanpy/assets/36629785/55431851-9836-44e3-a9f9-a4680ddc9d96). ### Minimal code sample. ```python. sc.tl.rank_genes_groups(adata, method='t-test', groupby='barcodes', groups=['infected', 'unknown'], reference='uninfected', key_added='group_DE_results', pts=True). results = adata.uns[""group_DE_results""]. groups = results['names'].dtype.names. result = pd.DataFrame(. {group + '_' + key: results[key][group]. for group in groups for key in ['names', 'pvals', 'pvals_adj', 'logfoldchanges', 'pts']}). de_results = []. for i in groups:. group = result[[c for c in result.columns.tolist() if c.startswith(str(i) + '_')]]. group = group.rename(columns={f'{i}_names':'names', f'{i}_pvals':'pvals', f'{i}_pvals_adj':'pvals_adj', f'{i}_logfoldchanges':'lfc', f'{i}_pts':'pts', f'{i}_pts_rest':'pts_rest'}). group['group'] = i. de_results.append(group). de_results = pd.concat(de_results). de_results.reset_index(drop=True, inplace=True). de_results. ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2628
https://github.com/scverse/scanpy/issues/2629:504,availability,sli,slightly,504,"sc.pp.scale changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:744,availability,down,down,744,"sc.pp.scale changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:2045,availability,Error,Error,2045,". mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled with scanpy:""). print(mtx_rescaled). ```. ### Error output. ```pytb. mtx is parse=False. Rescaled with my_scale_function:. True. Rescaled with scanpy:. False. Original matrix:. [[-1.71469614e-01 -2.82757759e-01 -4.95753549e-02 ... -1.02923915e-01. -2.09179729e-01 -5.31203270e-01]. [-2.14582354e-01 -3.75530124e-01 -6.44599497e-02 ... -2.92909533e-01. -3.13310266e-01 -5.96654296e-01]. [-3.76887709e-01 -2.97174782e-01 -6.94468468e-02 ... -1.70980677e-01. -1.70931697e-01 1.37899971e+00]. ... [-2.07089618e-01 -2.52101928e-01 -4.90629673e-02 ... -4.98141423e-02. -1.61111996e-01 2.04149699e+00]. [-1.90328494e-01 -2.27726802e-01 -4.46720645e-02 ... 1.15651824e-03. -1.35240912e-01 -4.82111037e-01]. [-3.33789378e-01 -2.55257130e-01 -6.06345981e-02 ... -8.05590525e-02. -1.30351290e-01 -4.71337825e-01]]. Matrix rescaled with scanpy:. [[-1.7146961e-01 -2.8275776e-01 -4.9575359e-02 ... -1.0292391e-01. -2.0917973e-01 -5.3120327e-01]. [-2.1458235e-01 -3.7553012e-01 -6.4459950e-02 ... -2.9290953e-01. -3.1331027e-01 -5.9665430e-01]. [-3.7688771e-01 -2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:6,deployability,scale,scale,6,"sc.pp.scale changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:224,deployability,version,version,224,"sc.pp.scale changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:474,deployability,scale,scale,474,"sc.pp.scale changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:1008,deployability,scale,scale,1008," changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled with scanpy:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:1505,deployability,scale,scale,1505,"htly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled with scanpy:""). print(mtx_rescaled). ```. ### Error output. ```pytb. mtx is parse=False. Rescaled with my_scale_function:. True. Rescaled with scanpy:. False. Original matrix:. [[-1.71469614e-01 -2.82757759e-01 -4.95753549e-02 ... -1.02923915e-01. -2.09179729e-01 -5.31203270e-01]. [-2.14582354e-01 -3.75530124e-01 -6.44599497e-02 ... -2.92909533e-01. -3.13310266e-01 -5.96654296e-01]. [-3.76887709e-01 -2.97174782e-01 -6.94468468e-02 ... -1.70980677e-01. -1.70931697e-01 1.37899971e+00]. ... [-2.07089618e-01",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:1817,deployability,scale,scale,1817,"atrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled with scanpy:""). print(mtx_rescaled). ```. ### Error output. ```pytb. mtx is parse=False. Rescaled with my_scale_function:. True. Rescaled with scanpy:. False. Original matrix:. [[-1.71469614e-01 -2.82757759e-01 -4.95753549e-02 ... -1.02923915e-01. -2.09179729e-01 -5.31203270e-01]. [-2.14582354e-01 -3.75530124e-01 -6.44599497e-02 ... -2.92909533e-01. -3.13310266e-01 -5.96654296e-01]. [-3.76887709e-01 -2.97174782e-01 -6.94468468e-02 ... -1.70980677e-01. -1.70931697e-01 1.37899971e+00]. ... [-2.07089618e-01 -2.52101928e-01 -4.90629673e-02 ... -4.98141423e-02. -1.61111996e-01 2.04149699e+00]. [-1.90328494e-01 -2.27726802e-01 -4.46720645e-02 ... 1.15651824e-03. -1.35240912e-01 -4.82111037e-01]. [-3.33789378e-01 -2.55257130e-01 -6.06345981e-02 ... -8.05590525e-02. -1.30351290e-01 -4.71337825e-01]]. Matrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:3433,deployability,Version,Versions,3433, -1.70980677e-01. -1.70931697e-01 1.37899971e+00]. ... [-2.07089618e-01 -2.52101928e-01 -4.90629673e-02 ... -4.98141423e-02. -1.61111996e-01 2.04149699e+00]. [-1.90328494e-01 -2.27726802e-01 -4.46720645e-02 ... 1.15651824e-03. -1.35240912e-01 -4.82111037e-01]. [-3.33789378e-01 -2.55257130e-01 -6.06345981e-02 ... -8.05590525e-02. -1.30351290e-01 -4.71337825e-01]]. Matrix rescaled with scanpy:. [[-1.7146961e-01 -2.8275776e-01 -4.9575359e-02 ... -1.0292391e-01. -2.0917973e-01 -5.3120327e-01]. [-2.1458235e-01 -3.7553012e-01 -6.4459950e-02 ... -2.9290953e-01. -3.1331027e-01 -5.9665430e-01]. [-3.7688771e-01 -2.9717478e-01 -6.9446847e-02 ... -1.7098068e-01. -1.7093170e-01 1.3789997e+00]. ... [-2.0708962e-01 -2.5210193e-01 -4.9062971e-02 ... -4.9814139e-02. -1.6111200e-01 2.0414970e+00]. [-1.9032849e-01 -2.2772680e-01 -4.4672068e-02 ... 1.1565228e-03. -1.3524091e-01 -4.8211104e-01]. [-3.3378938e-01 -2.5525713e-01 -6.0634598e-02 ... -8.0559045e-02. -1.3035129e-01 -4.7133783e-01]]. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.5.0. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. combat NA. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.5.1. executing 1.2.0. fastjsonschema NA. fqdn NA. gseapy 1.0.5. h5py 3.9.0. idna 3.4. igraph 0.10.6. ipykernel 6.25.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.1. json5 NA. jsonpointer 2.4. jsonschema 4.18.4. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.0. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.10.1. liana 0.1.9. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.6.3. matplotlib_inline 0.1.6. mizani 0.9.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. overrides NA. packaging 23.1. pandas 1.5.3. parso ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:5665,deployability,updat,updated,5665,"cler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.5.1. executing 1.2.0. fastjsonschema NA. fqdn NA. gseapy 1.0.5. h5py 3.9.0. idna 3.4. igraph 0.10.6. ipykernel 6.25.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.1. json5 NA. jsonpointer 2.4. jsonschema 4.18.4. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.0. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.10.1. liana 0.1.9. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.6.3. matplotlib_inline 0.1.6. mizani 0.9.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. overrides NA. packaging 23.1. pandas 1.5.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. plotnine 0.12.2. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pydeseq2 0.3.5. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pyparsing 3.1.1. pythonjsonlogger NA. pytz 2023.3. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rnaxplorer NA. rpds NA. scipy 1.11.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.3.0. sniffio 1.3.0. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. texttable 1.6.7. threadpoolctl 3.2.0. torch 1.13.1+cu117. tornado 6.3.2. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. uri_template NA. urllib3 2.0.4. wcwidth 0.2.6. webcolors 1.13. websocket 1.6.1. yaml 6.0.1. zmq 25.1.0. zoneinfo NA. -----. IPython 8.14.0. jupyter_client 8.3.0. jupyter_core 5.3.1. jupyterlab 4.0.3. notebook 7.0.1. -----. Python 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]. Linux-5.15.0-1033-gke-x86_64-with-glibc2.35. -----. Session information updated at 2023-08-21 12:14. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:6,energy efficiency,scale,scale,6,"sc.pp.scale changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:474,energy efficiency,scale,scale,474,"sc.pp.scale changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:923,energy efficiency,Load,Loading,923,"sc.pp.scale changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:1008,energy efficiency,scale,scale,1008," changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled with scanpy:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:1219,energy efficiency,estimat,estimator,1219,"version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled with scanpy:""). print(mtx_rescaled). ```. ### Error output. ```pytb. mtx is parse=False. Rescaled with my_scale_function:. True. Rescaled with scanpy:. False. Original matrix:. [[-1.71469614e-01 -2.82757759e-01 -4.95753549e-0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:1505,energy efficiency,scale,scale,1505,"htly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled with scanpy:""). print(mtx_rescaled). ```. ### Error output. ```pytb. mtx is parse=False. Rescaled with my_scale_function:. True. Rescaled with scanpy:. False. Original matrix:. [[-1.71469614e-01 -2.82757759e-01 -4.95753549e-02 ... -1.02923915e-01. -2.09179729e-01 -5.31203270e-01]. [-2.14582354e-01 -3.75530124e-01 -6.44599497e-02 ... -2.92909533e-01. -3.13310266e-01 -5.96654296e-01]. [-3.76887709e-01 -2.97174782e-01 -6.94468468e-02 ... -1.70980677e-01. -1.70931697e-01 1.37899971e+00]. ... [-2.07089618e-01",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:1817,energy efficiency,scale,scale,1817,"atrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled with scanpy:""). print(mtx_rescaled). ```. ### Error output. ```pytb. mtx is parse=False. Rescaled with my_scale_function:. True. Rescaled with scanpy:. False. Original matrix:. [[-1.71469614e-01 -2.82757759e-01 -4.95753549e-02 ... -1.02923915e-01. -2.09179729e-01 -5.31203270e-01]. [-2.14582354e-01 -3.75530124e-01 -6.44599497e-02 ... -2.92909533e-01. -3.13310266e-01 -5.96654296e-01]. [-3.76887709e-01 -2.97174782e-01 -6.94468468e-02 ... -1.70980677e-01. -1.70931697e-01 1.37899971e+00]. ... [-2.07089618e-01 -2.52101928e-01 -4.90629673e-02 ... -4.98141423e-02. -1.61111996e-01 2.04149699e+00]. [-1.90328494e-01 -2.27726802e-01 -4.46720645e-02 ... 1.15651824e-03. -1.35240912e-01 -4.82111037e-01]. [-3.33789378e-01 -2.55257130e-01 -6.06345981e-02 ... -8.05590525e-02. -1.30351290e-01 -4.71337825e-01]]. Matrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:3666,energy efficiency,cloud,cloudpickle,3666,912e-01 -4.82111037e-01]. [-3.33789378e-01 -2.55257130e-01 -6.06345981e-02 ... -8.05590525e-02. -1.30351290e-01 -4.71337825e-01]]. Matrix rescaled with scanpy:. [[-1.7146961e-01 -2.8275776e-01 -4.9575359e-02 ... -1.0292391e-01. -2.0917973e-01 -5.3120327e-01]. [-2.1458235e-01 -3.7553012e-01 -6.4459950e-02 ... -2.9290953e-01. -3.1331027e-01 -5.9665430e-01]. [-3.7688771e-01 -2.9717478e-01 -6.9446847e-02 ... -1.7098068e-01. -1.7093170e-01 1.3789997e+00]. ... [-2.0708962e-01 -2.5210193e-01 -4.9062971e-02 ... -4.9814139e-02. -1.6111200e-01 2.0414970e+00]. [-1.9032849e-01 -2.2772680e-01 -4.4672068e-02 ... 1.1565228e-03. -1.3524091e-01 -4.8211104e-01]. [-3.3378938e-01 -2.5525713e-01 -6.0634598e-02 ... -8.0559045e-02. -1.3035129e-01 -4.7133783e-01]]. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.5.0. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. combat NA. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.5.1. executing 1.2.0. fastjsonschema NA. fqdn NA. gseapy 1.0.5. h5py 3.9.0. idna 3.4. igraph 0.10.6. ipykernel 6.25.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.1. json5 NA. jsonpointer 2.4. jsonschema 4.18.4. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.0. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.10.1. liana 0.1.9. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.6.3. matplotlib_inline 0.1.6. mizani 0.9.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. overrides NA. packaging 23.1. pandas 1.5.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. plotnine 0.12.2. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:224,integrability,version,version,224,"sc.pp.scale changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:3433,integrability,Version,Versions,3433, -1.70980677e-01. -1.70931697e-01 1.37899971e+00]. ... [-2.07089618e-01 -2.52101928e-01 -4.90629673e-02 ... -4.98141423e-02. -1.61111996e-01 2.04149699e+00]. [-1.90328494e-01 -2.27726802e-01 -4.46720645e-02 ... 1.15651824e-03. -1.35240912e-01 -4.82111037e-01]. [-3.33789378e-01 -2.55257130e-01 -6.06345981e-02 ... -8.05590525e-02. -1.30351290e-01 -4.71337825e-01]]. Matrix rescaled with scanpy:. [[-1.7146961e-01 -2.8275776e-01 -4.9575359e-02 ... -1.0292391e-01. -2.0917973e-01 -5.3120327e-01]. [-2.1458235e-01 -3.7553012e-01 -6.4459950e-02 ... -2.9290953e-01. -3.1331027e-01 -5.9665430e-01]. [-3.7688771e-01 -2.9717478e-01 -6.9446847e-02 ... -1.7098068e-01. -1.7093170e-01 1.3789997e+00]. ... [-2.0708962e-01 -2.5210193e-01 -4.9062971e-02 ... -4.9814139e-02. -1.6111200e-01 2.0414970e+00]. [-1.9032849e-01 -2.2772680e-01 -4.4672068e-02 ... 1.1565228e-03. -1.3524091e-01 -4.8211104e-01]. [-3.3378938e-01 -2.5525713e-01 -6.0634598e-02 ... -8.0559045e-02. -1.3035129e-01 -4.7133783e-01]]. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.5.0. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. combat NA. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.5.1. executing 1.2.0. fastjsonschema NA. fqdn NA. gseapy 1.0.5. h5py 3.9.0. idna 3.4. igraph 0.10.6. ipykernel 6.25.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.1. json5 NA. jsonpointer 2.4. jsonschema 4.18.4. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.0. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.10.1. liana 0.1.9. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.6.3. matplotlib_inline 0.1.6. mizani 0.9.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. overrides NA. packaging 23.1. pandas 1.5.3. parso ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:4509,interoperability,platform,platformdirs,4509,yio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. combat NA. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.5.1. executing 1.2.0. fastjsonschema NA. fqdn NA. gseapy 1.0.5. h5py 3.9.0. idna 3.4. igraph 0.10.6. ipykernel 6.25.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.1. json5 NA. jsonpointer 2.4. jsonschema 4.18.4. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.0. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.10.1. liana 0.1.9. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.6.3. matplotlib_inline 0.1.6. mizani 0.9.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. overrides NA. packaging 23.1. pandas 1.5.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. plotnine 0.12.2. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pydeseq2 0.3.5. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pyparsing 3.1.1. pythonjsonlogger NA. pytz 2023.3. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rnaxplorer NA. rpds NA. scipy 1.11.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.3.0. sniffio 1.3.0. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. texttable 1.6.7. threadpoolctl 3.2.0. torch 1.13.1+cu117. tornado 6.3.2. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. uri_template NA. urllib3 2.0.4. wcwidth 0.2.6. webcolors 1.13. websocket 1.6.1. yaml 6.0.1. zmq 25.1.0. zoneinfo NA. -----. IPython 8.14.0. jupyter_client 8.3.0. jupyter_core 5.3.1. jupyterlab 4.0.3. note,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:6,modifiability,scal,scale,6,"sc.pp.scale changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:224,modifiability,version,version,224,"sc.pp.scale changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:474,modifiability,scal,scale,474,"sc.pp.scale changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:1008,modifiability,scal,scale,1008," changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled with scanpy:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:1505,modifiability,scal,scale,1505,"htly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled with scanpy:""). print(mtx_rescaled). ```. ### Error output. ```pytb. mtx is parse=False. Rescaled with my_scale_function:. True. Rescaled with scanpy:. False. Original matrix:. [[-1.71469614e-01 -2.82757759e-01 -4.95753549e-02 ... -1.02923915e-01. -2.09179729e-01 -5.31203270e-01]. [-2.14582354e-01 -3.75530124e-01 -6.44599497e-02 ... -2.92909533e-01. -3.13310266e-01 -5.96654296e-01]. [-3.76887709e-01 -2.97174782e-01 -6.94468468e-02 ... -1.70980677e-01. -1.70931697e-01 1.37899971e+00]. ... [-2.07089618e-01",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:1817,modifiability,scal,scale,1817,"atrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled with scanpy:""). print(mtx_rescaled). ```. ### Error output. ```pytb. mtx is parse=False. Rescaled with my_scale_function:. True. Rescaled with scanpy:. False. Original matrix:. [[-1.71469614e-01 -2.82757759e-01 -4.95753549e-02 ... -1.02923915e-01. -2.09179729e-01 -5.31203270e-01]. [-2.14582354e-01 -3.75530124e-01 -6.44599497e-02 ... -2.92909533e-01. -3.13310266e-01 -5.96654296e-01]. [-3.76887709e-01 -2.97174782e-01 -6.94468468e-02 ... -1.70980677e-01. -1.70931697e-01 1.37899971e+00]. ... [-2.07089618e-01 -2.52101928e-01 -4.90629673e-02 ... -4.98141423e-02. -1.61111996e-01 2.04149699e+00]. [-1.90328494e-01 -2.27726802e-01 -4.46720645e-02 ... 1.15651824e-03. -1.35240912e-01 -4.82111037e-01]. [-3.33789378e-01 -2.55257130e-01 -6.06345981e-02 ... -8.05590525e-02. -1.30351290e-01 -4.71337825e-01]]. Matrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:3433,modifiability,Version,Versions,3433, -1.70980677e-01. -1.70931697e-01 1.37899971e+00]. ... [-2.07089618e-01 -2.52101928e-01 -4.90629673e-02 ... -4.98141423e-02. -1.61111996e-01 2.04149699e+00]. [-1.90328494e-01 -2.27726802e-01 -4.46720645e-02 ... 1.15651824e-03. -1.35240912e-01 -4.82111037e-01]. [-3.33789378e-01 -2.55257130e-01 -6.06345981e-02 ... -8.05590525e-02. -1.30351290e-01 -4.71337825e-01]]. Matrix rescaled with scanpy:. [[-1.7146961e-01 -2.8275776e-01 -4.9575359e-02 ... -1.0292391e-01. -2.0917973e-01 -5.3120327e-01]. [-2.1458235e-01 -3.7553012e-01 -6.4459950e-02 ... -2.9290953e-01. -3.1331027e-01 -5.9665430e-01]. [-3.7688771e-01 -2.9717478e-01 -6.9446847e-02 ... -1.7098068e-01. -1.7093170e-01 1.3789997e+00]. ... [-2.0708962e-01 -2.5210193e-01 -4.9062971e-02 ... -4.9814139e-02. -1.6111200e-01 2.0414970e+00]. [-1.9032849e-01 -2.2772680e-01 -4.4672068e-02 ... 1.1565228e-03. -1.3524091e-01 -4.8211104e-01]. [-3.3378938e-01 -2.5525713e-01 -6.0634598e-02 ... -8.0559045e-02. -1.3035129e-01 -4.7133783e-01]]. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.5.0. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. combat NA. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.5.1. executing 1.2.0. fastjsonschema NA. fqdn NA. gseapy 1.0.5. h5py 3.9.0. idna 3.4. igraph 0.10.6. ipykernel 6.25.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.1. json5 NA. jsonpointer 2.4. jsonschema 4.18.4. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.0. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.10.1. liana 0.1.9. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.6.3. matplotlib_inline 0.1.6. mizani 0.9.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. overrides NA. packaging 23.1. pandas 1.5.3. parso ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:3773,modifiability,deco,decorator,3773,0e-01 -4.71337825e-01]]. Matrix rescaled with scanpy:. [[-1.7146961e-01 -2.8275776e-01 -4.9575359e-02 ... -1.0292391e-01. -2.0917973e-01 -5.3120327e-01]. [-2.1458235e-01 -3.7553012e-01 -6.4459950e-02 ... -2.9290953e-01. -3.1331027e-01 -5.9665430e-01]. [-3.7688771e-01 -2.9717478e-01 -6.9446847e-02 ... -1.7098068e-01. -1.7093170e-01 1.3789997e+00]. ... [-2.0708962e-01 -2.5210193e-01 -4.9062971e-02 ... -4.9814139e-02. -1.6111200e-01 2.0414970e+00]. [-1.9032849e-01 -2.2772680e-01 -4.4672068e-02 ... 1.1565228e-03. -1.3524091e-01 -4.8211104e-01]. [-3.3378938e-01 -2.5525713e-01 -6.0634598e-02 ... -8.0559045e-02. -1.3035129e-01 -4.7133783e-01]]. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.5.0. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. combat NA. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.5.1. executing 1.2.0. fastjsonschema NA. fqdn NA. gseapy 1.0.5. h5py 3.9.0. idna 3.4. igraph 0.10.6. ipykernel 6.25.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.1. json5 NA. jsonpointer 2.4. jsonschema 4.18.4. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.0. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.10.1. liana 0.1.9. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.6.3. matplotlib_inline 0.1.6. mizani 0.9.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. overrides NA. packaging 23.1. pandas 1.5.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. plotnine 0.12.2. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pydeseq2 0.3.5. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:3790,modifiability,deco,decoupler,3790,e-01]]. Matrix rescaled with scanpy:. [[-1.7146961e-01 -2.8275776e-01 -4.9575359e-02 ... -1.0292391e-01. -2.0917973e-01 -5.3120327e-01]. [-2.1458235e-01 -3.7553012e-01 -6.4459950e-02 ... -2.9290953e-01. -3.1331027e-01 -5.9665430e-01]. [-3.7688771e-01 -2.9717478e-01 -6.9446847e-02 ... -1.7098068e-01. -1.7093170e-01 1.3789997e+00]. ... [-2.0708962e-01 -2.5210193e-01 -4.9062971e-02 ... -4.9814139e-02. -1.6111200e-01 2.0414970e+00]. [-1.9032849e-01 -2.2772680e-01 -4.4672068e-02 ... 1.1565228e-03. -1.3524091e-01 -4.8211104e-01]. [-3.3378938e-01 -2.5525713e-01 -6.0634598e-02 ... -8.0559045e-02. -1.3035129e-01 -4.7133783e-01]]. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.5.0. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. combat NA. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.5.1. executing 1.2.0. fastjsonschema NA. fqdn NA. gseapy 1.0.5. h5py 3.9.0. idna 3.4. igraph 0.10.6. ipykernel 6.25.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.1. json5 NA. jsonpointer 2.4. jsonschema 4.18.4. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.0. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.10.1. liana 0.1.9. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.6.3. matplotlib_inline 0.1.6. mizani 0.9.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. overrides NA. packaging 23.1. pandas 1.5.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. plotnine 0.12.2. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pydeseq2 0.3.5. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing N,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:4401,modifiability,pac,packaging,4401,-4.7133783e-01]]. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.5.0. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. combat NA. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.5.1. executing 1.2.0. fastjsonschema NA. fqdn NA. gseapy 1.0.5. h5py 3.9.0. idna 3.4. igraph 0.10.6. ipykernel 6.25.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.1. json5 NA. jsonpointer 2.4. jsonschema 4.18.4. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.0. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.10.1. liana 0.1.9. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.6.3. matplotlib_inline 0.1.6. mizani 0.9.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. overrides NA. packaging 23.1. pandas 1.5.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. plotnine 0.12.2. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pydeseq2 0.3.5. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pyparsing 3.1.1. pythonjsonlogger NA. pytz 2023.3. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rnaxplorer NA. rpds NA. scipy 1.11.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.3.0. sniffio 1.3.0. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. texttable 1.6.7. threadpoolctl 3.2.0. torch 1.13.1+cu117. tornado 6.3.2. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. uri_template NA. urllib3 2.0.4. wcwidth 0.2.6. webcolors 1.13. websocket 1.6.1. yaml 6.0.1. zmq,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:6,performance,scale,scale,6,"sc.pp.scale changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:390,performance,time,time,390,"sc.pp.scale changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:474,performance,scale,scale,474,"sc.pp.scale changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:923,performance,Load,Loading,923,"sc.pp.scale changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:1008,performance,scale,scale,1008," changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled with scanpy:",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:1505,performance,scale,scale,1505,"htly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled with scanpy:""). print(mtx_rescaled). ```. ### Error output. ```pytb. mtx is parse=False. Rescaled with my_scale_function:. True. Rescaled with scanpy:. False. Original matrix:. [[-1.71469614e-01 -2.82757759e-01 -4.95753549e-02 ... -1.02923915e-01. -2.09179729e-01 -5.31203270e-01]. [-2.14582354e-01 -3.75530124e-01 -6.44599497e-02 ... -2.92909533e-01. -3.13310266e-01 -5.96654296e-01]. [-3.76887709e-01 -2.97174782e-01 -6.94468468e-02 ... -1.70980677e-01. -1.70931697e-01 1.37899971e+00]. ... [-2.07089618e-01",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:1817,performance,scale,scale,1817,"atrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled with scanpy:""). print(mtx_rescaled). ```. ### Error output. ```pytb. mtx is parse=False. Rescaled with my_scale_function:. True. Rescaled with scanpy:. False. Original matrix:. [[-1.71469614e-01 -2.82757759e-01 -4.95753549e-02 ... -1.02923915e-01. -2.09179729e-01 -5.31203270e-01]. [-2.14582354e-01 -3.75530124e-01 -6.44599497e-02 ... -2.92909533e-01. -3.13310266e-01 -5.96654296e-01]. [-3.76887709e-01 -2.97174782e-01 -6.94468468e-02 ... -1.70980677e-01. -1.70931697e-01 1.37899971e+00]. ... [-2.07089618e-01 -2.52101928e-01 -4.90629673e-02 ... -4.98141423e-02. -1.61111996e-01 2.04149699e+00]. [-1.90328494e-01 -2.27726802e-01 -4.46720645e-02 ... 1.15651824e-03. -1.35240912e-01 -4.82111037e-01]. [-3.33789378e-01 -2.55257130e-01 -6.06345981e-02 ... -8.05590525e-02. -1.30351290e-01 -4.71337825e-01]]. Matrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:2045,performance,Error,Error,2045,". mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled with scanpy:""). print(mtx_rescaled). ```. ### Error output. ```pytb. mtx is parse=False. Rescaled with my_scale_function:. True. Rescaled with scanpy:. False. Original matrix:. [[-1.71469614e-01 -2.82757759e-01 -4.95753549e-02 ... -1.02923915e-01. -2.09179729e-01 -5.31203270e-01]. [-2.14582354e-01 -3.75530124e-01 -6.44599497e-02 ... -2.92909533e-01. -3.13310266e-01 -5.96654296e-01]. [-3.76887709e-01 -2.97174782e-01 -6.94468468e-02 ... -1.70980677e-01. -1.70931697e-01 1.37899971e+00]. ... [-2.07089618e-01 -2.52101928e-01 -4.90629673e-02 ... -4.98141423e-02. -1.61111996e-01 2.04149699e+00]. [-1.90328494e-01 -2.27726802e-01 -4.46720645e-02 ... 1.15651824e-03. -1.35240912e-01 -4.82111037e-01]. [-3.33789378e-01 -2.55257130e-01 -6.06345981e-02 ... -8.05590525e-02. -1.30351290e-01 -4.71337825e-01]]. Matrix rescaled with scanpy:. [[-1.7146961e-01 -2.8275776e-01 -4.9575359e-02 ... -1.0292391e-01. -2.0917973e-01 -5.3120327e-01]. [-2.1458235e-01 -3.7553012e-01 -6.4459950e-02 ... -2.9290953e-01. -3.1331027e-01 -5.9665430e-01]. [-3.7688771e-01 -2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:504,reliability,sli,slightly,504,"sc.pp.scale changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:447,safety,input,input,447,"sc.pp.scale changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:712,safety,input,input,712,"sc.pp.scale changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:2045,safety,Error,Error,2045,". mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled with scanpy:""). print(mtx_rescaled). ```. ### Error output. ```pytb. mtx is parse=False. Rescaled with my_scale_function:. True. Rescaled with scanpy:. False. Original matrix:. [[-1.71469614e-01 -2.82757759e-01 -4.95753549e-02 ... -1.02923915e-01. -2.09179729e-01 -5.31203270e-01]. [-2.14582354e-01 -3.75530124e-01 -6.44599497e-02 ... -2.92909533e-01. -3.13310266e-01 -5.96654296e-01]. [-3.76887709e-01 -2.97174782e-01 -6.94468468e-02 ... -1.70980677e-01. -1.70931697e-01 1.37899971e+00]. ... [-2.07089618e-01 -2.52101928e-01 -4.90629673e-02 ... -4.98141423e-02. -1.61111996e-01 2.04149699e+00]. [-1.90328494e-01 -2.27726802e-01 -4.46720645e-02 ... 1.15651824e-03. -1.35240912e-01 -4.82111037e-01]. [-3.33789378e-01 -2.55257130e-01 -6.06345981e-02 ... -8.05590525e-02. -1.30351290e-01 -4.71337825e-01]]. Matrix rescaled with scanpy:. [[-1.7146961e-01 -2.8275776e-01 -4.9575359e-02 ... -1.0292391e-01. -2.0917973e-01 -5.3120327e-01]. [-2.1458235e-01 -3.7553012e-01 -6.4459950e-02 ... -2.9290953e-01. -3.1331027e-01 -5.9665430e-01]. [-3.7688771e-01 -2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:5665,safety,updat,updated,5665,"cler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.5.1. executing 1.2.0. fastjsonschema NA. fqdn NA. gseapy 1.0.5. h5py 3.9.0. idna 3.4. igraph 0.10.6. ipykernel 6.25.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.1. json5 NA. jsonpointer 2.4. jsonschema 4.18.4. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.0. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.10.1. liana 0.1.9. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.6.3. matplotlib_inline 0.1.6. mizani 0.9.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. overrides NA. packaging 23.1. pandas 1.5.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. plotnine 0.12.2. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pydeseq2 0.3.5. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pyparsing 3.1.1. pythonjsonlogger NA. pytz 2023.3. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rnaxplorer NA. rpds NA. scipy 1.11.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.3.0. sniffio 1.3.0. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. texttable 1.6.7. threadpoolctl 3.2.0. torch 1.13.1+cu117. tornado 6.3.2. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. uri_template NA. urllib3 2.0.4. wcwidth 0.2.6. webcolors 1.13. websocket 1.6.1. yaml 6.0.1. zmq 25.1.0. zoneinfo NA. -----. IPython 8.14.0. jupyter_client 8.3.0. jupyter_core 5.3.1. jupyterlab 4.0.3. notebook 7.0.1. -----. Python 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]. Linux-5.15.0-1033-gke-x86_64-with-glibc2.35. -----. Session information updated at 2023-08-21 12:14. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:3607,security,certif,certifi,3607, -2.27726802e-01 -4.46720645e-02 ... 1.15651824e-03. -1.35240912e-01 -4.82111037e-01]. [-3.33789378e-01 -2.55257130e-01 -6.06345981e-02 ... -8.05590525e-02. -1.30351290e-01 -4.71337825e-01]]. Matrix rescaled with scanpy:. [[-1.7146961e-01 -2.8275776e-01 -4.9575359e-02 ... -1.0292391e-01. -2.0917973e-01 -5.3120327e-01]. [-2.1458235e-01 -3.7553012e-01 -6.4459950e-02 ... -2.9290953e-01. -3.1331027e-01 -5.9665430e-01]. [-3.7688771e-01 -2.9717478e-01 -6.9446847e-02 ... -1.7098068e-01. -1.7093170e-01 1.3789997e+00]. ... [-2.0708962e-01 -2.5210193e-01 -4.9062971e-02 ... -4.9814139e-02. -1.6111200e-01 2.0414970e+00]. [-1.9032849e-01 -2.2772680e-01 -4.4672068e-02 ... 1.1565228e-03. -1.3524091e-01 -4.8211104e-01]. [-3.3378938e-01 -2.5525713e-01 -6.0634598e-02 ... -8.0559045e-02. -1.3035129e-01 -4.7133783e-01]]. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.5.0. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. combat NA. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.5.1. executing 1.2.0. fastjsonschema NA. fqdn NA. gseapy 1.0.5. h5py 3.9.0. idna 3.4. igraph 0.10.6. ipykernel 6.25.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.1. json5 NA. jsonpointer 2.4. jsonschema 4.18.4. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.0. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.10.1. liana 0.1.9. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.6.3. matplotlib_inline 0.1.6. mizani 0.9.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. overrides NA. packaging 23.1. pandas 1.5.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. plotnine 0.12.2. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptypr,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:3953,security,iso,isoduration,3953,-01 -6.4459950e-02 ... -2.9290953e-01. -3.1331027e-01 -5.9665430e-01]. [-3.7688771e-01 -2.9717478e-01 -6.9446847e-02 ... -1.7098068e-01. -1.7093170e-01 1.3789997e+00]. ... [-2.0708962e-01 -2.5210193e-01 -4.9062971e-02 ... -4.9814139e-02. -1.6111200e-01 2.0414970e+00]. [-1.9032849e-01 -2.2772680e-01 -4.4672068e-02 ... 1.1565228e-03. -1.3524091e-01 -4.8211104e-01]. [-3.3378938e-01 -2.5525713e-01 -6.0634598e-02 ... -8.0559045e-02. -1.3035129e-01 -4.7133783e-01]]. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.3. -----. PIL 9.5.0. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. combat NA. comm 0.1.3. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.5.1. executing 1.2.0. fastjsonschema NA. fqdn NA. gseapy 1.0.5. h5py 3.9.0. idna 3.4. igraph 0.10.6. ipykernel 6.25.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.1. json5 NA. jsonpointer 2.4. jsonschema 4.18.4. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.0. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.10.1. liana 0.1.9. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.6.3. matplotlib_inline 0.1.6. mizani 0.9.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. overrides NA. packaging 23.1. pandas 1.5.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. plotnine 0.12.2. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pydeseq2 0.3.5. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pyparsing 3.1.1. pythonjsonlogger NA. pytz 2023.3. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validat,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:5645,security,Session,Session,5645,"cler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.5.1. executing 1.2.0. fastjsonschema NA. fqdn NA. gseapy 1.0.5. h5py 3.9.0. idna 3.4. igraph 0.10.6. ipykernel 6.25.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.1. json5 NA. jsonpointer 2.4. jsonschema 4.18.4. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.0. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.10.1. liana 0.1.9. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.6.3. matplotlib_inline 0.1.6. mizani 0.9.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. overrides NA. packaging 23.1. pandas 1.5.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. plotnine 0.12.2. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pydeseq2 0.3.5. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pyparsing 3.1.1. pythonjsonlogger NA. pytz 2023.3. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rnaxplorer NA. rpds NA. scipy 1.11.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.3.0. sniffio 1.3.0. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. texttable 1.6.7. threadpoolctl 3.2.0. torch 1.13.1+cu117. tornado 6.3.2. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. uri_template NA. urllib3 2.0.4. wcwidth 0.2.6. webcolors 1.13. websocket 1.6.1. yaml 6.0.1. zmq 25.1.0. zoneinfo NA. -----. IPython 8.14.0. jupyter_client 8.3.0. jupyter_core 5.3.1. jupyterlab 4.0.3. notebook 7.0.1. -----. Python 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]. Linux-5.15.0-1033-gke-x86_64-with-glibc2.35. -----. Session information updated at 2023-08-21 12:14. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:5665,security,updat,updated,5665,"cler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7. decorator 5.1.1. decoupler 1.4.0. defusedxml 0.7.1. dill 0.3.5.1. executing 1.2.0. fastjsonschema NA. fqdn NA. gseapy 1.0.5. h5py 3.9.0. idna 3.4. igraph 0.10.6. ipykernel 6.25.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.1. json5 NA. jsonpointer 2.4. jsonschema 4.18.4. jsonschema_specifications NA. jupyter_events 0.7.0. jupyter_server 2.7.0. jupyterlab_server 2.24.0. kiwisolver 1.4.4. leidenalg 0.10.1. liana 0.1.9. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.6.3. matplotlib_inline 0.1.6. mizani 0.9.2. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. overrides NA. packaging 23.1. pandas 1.5.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.10.0. plotnine 0.12.2. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 12.0.1. pycparser 2.21. pydeseq2 0.3.5. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pynndescent 0.5.10. pyparsing 3.1.1. pythonjsonlogger NA. pytz 2023.3. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rnaxplorer NA. rpds NA. scipy 1.11.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. sitecustomize NA. six 1.16.0. sklearn 1.3.0. sniffio 1.3.0. sphinxcontrib NA. stack_data 0.6.2. statsmodels 0.14.0. texttable 1.6.7. threadpoolctl 3.2.0. torch 1.13.1+cu117. tornado 6.3.2. tqdm 4.65.0. traitlets 5.9.0. typing_extensions NA. umap 0.5.3. uri_template NA. urllib3 2.0.4. wcwidth 0.2.6. webcolors 1.13. websocket 1.6.1. yaml 6.0.1. zmq 25.1.0. zoneinfo NA. -----. IPython 8.14.0. jupyter_client 8.3.0. jupyter_core 5.3.1. jupyterlab 4.0.3. notebook 7.0.1. -----. Python 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]. Linux-5.15.0-1033-gke-x86_64-with-glibc2.35. -----. Session information updated at 2023-08-21 12:14. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:629,testability,simpl,simple,629,"sc.pp.scale changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:184,usability,confirm,confirmed,184,"sc.pp.scale changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:267,usability,confirm,confirmed,267,"sc.pp.scale changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:447,usability,input,input,447,"sc.pp.scale changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:629,usability,simpl,simple,629,"sc.pp.scale changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:712,usability,input,input,712,"sc.pp.scale changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:846,usability,Minim,Minimal,846,"sc.pp.scale changes the adata.X values when run again.; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi! I am not sure if this is a bug... . Every time I rescale the `pbmc3k_processed` matrix using it as input in the scanpy `sc.pp.scale` function, I get a very slightly different matrix in output, enough to generate a different UMAP with each run. But if I rewrite it using numpy in a simple function called `my_scale_function` it outputs the exact same matrix as the input, generating the same UMAP down the line... Could someone explain to me what is happening? (Note: The matrix is not sparse). ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. ### Loading and preprocessing data. adata = sc.datasets.pbmc3k_processed(). ### Defining scale function. def mean_var(X, axis=0):. mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled w",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2629:2045,usability,Error,Error,2045,". mean = np.mean(X, axis=axis, dtype=np.float64). mean_sq = np.multiply(X, X).mean(axis=axis, dtype=np.float64). var = mean_sq - mean**2. # enforce R convention (unbiased estimator) for variance. var *= X.shape[axis] / (X.shape[axis] - 1). return mean, var. def my_scale_function(X, clip=False):. mean, var = mean_var(X, axis=0). X -= mean. std = np.sqrt(var). std[std == 0] = 1. X /= std. if clip:. X = np.clip(X, -10, 10). return np.matrix(X). ### Scanpy scale vs my_scale_function. mtx = adata.X. from scipy.sparse import issparse. print(""mtx is parse="" + str(issparse(np.matrix(mtx))) + ""\n""). print(""Rescaled with my_scale_function:""). mtx_rescaled = my_scale_function(mtx). print((mtx == mtx_rescaled).all()). print(""Rescaled with scanpy:""). mtx_rescaled = sc.pp.scale(mtx, zero_center=True, max_value=None, copy=True). print(str((np.matrix(mtx) == mtx_rescaled).all()) + ""\n""). print(""\nOriginal matrix:""). print(mtx). print(""\nMatrix rescaled with scanpy:""). print(mtx_rescaled). ```. ### Error output. ```pytb. mtx is parse=False. Rescaled with my_scale_function:. True. Rescaled with scanpy:. False. Original matrix:. [[-1.71469614e-01 -2.82757759e-01 -4.95753549e-02 ... -1.02923915e-01. -2.09179729e-01 -5.31203270e-01]. [-2.14582354e-01 -3.75530124e-01 -6.44599497e-02 ... -2.92909533e-01. -3.13310266e-01 -5.96654296e-01]. [-3.76887709e-01 -2.97174782e-01 -6.94468468e-02 ... -1.70980677e-01. -1.70931697e-01 1.37899971e+00]. ... [-2.07089618e-01 -2.52101928e-01 -4.90629673e-02 ... -4.98141423e-02. -1.61111996e-01 2.04149699e+00]. [-1.90328494e-01 -2.27726802e-01 -4.46720645e-02 ... 1.15651824e-03. -1.35240912e-01 -4.82111037e-01]. [-3.33789378e-01 -2.55257130e-01 -6.06345981e-02 ... -8.05590525e-02. -1.30351290e-01 -4.71337825e-01]]. Matrix rescaled with scanpy:. [[-1.7146961e-01 -2.8275776e-01 -4.9575359e-02 ... -1.0292391e-01. -2.0917973e-01 -5.3120327e-01]. [-2.1458235e-01 -3.7553012e-01 -6.4459950e-02 ... -2.9290953e-01. -3.1331027e-01 -5.9665430e-01]. [-3.7688771e-01 -2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2629
https://github.com/scverse/scanpy/issues/2630:434,availability,avail,available,434,"Improve settings documentation; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hello Scanpy team! In scanpy api documentation I see [some settings](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig), however I don't understand how we are supposed to use n_job and max_memory settings. I would like scanpy to use whatever is available. How can I do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2630
https://github.com/scverse/scanpy/issues/2630:153,deployability,api,api,153,"Improve settings documentation; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hello Scanpy team! In scanpy api documentation I see [some settings](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig), however I don't understand how we are supposed to use n_job and max_memory settings. I would like scanpy to use whatever is available. How can I do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2630
https://github.com/scverse/scanpy/issues/2630:153,integrability,api,api,153,"Improve settings documentation; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hello Scanpy team! In scanpy api documentation I see [some settings](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig), however I don't understand how we are supposed to use n_job and max_memory settings. I would like scanpy to use whatever is available. How can I do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2630
https://github.com/scverse/scanpy/issues/2630:153,interoperability,api,api,153,"Improve settings documentation; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hello Scanpy team! In scanpy api documentation I see [some settings](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig), however I don't understand how we are supposed to use n_job and max_memory settings. I would like scanpy to use whatever is available. How can I do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2630
https://github.com/scverse/scanpy/issues/2630:434,reliability,availab,available,434,"Improve settings documentation; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hello Scanpy team! In scanpy api documentation I see [some settings](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig), however I don't understand how we are supposed to use n_job and max_memory settings. I would like scanpy to use whatever is available. How can I do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2630
https://github.com/scverse/scanpy/issues/2630:434,safety,avail,available,434,"Improve settings documentation; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hello Scanpy team! In scanpy api documentation I see [some settings](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig), however I don't understand how we are supposed to use n_job and max_memory settings. I would like scanpy to use whatever is available. How can I do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2630
https://github.com/scverse/scanpy/issues/2630:137,security,team,team,137,"Improve settings documentation; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hello Scanpy team! In scanpy api documentation I see [some settings](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig), however I don't understand how we are supposed to use n_job and max_memory settings. I would like scanpy to use whatever is available. How can I do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2630
https://github.com/scverse/scanpy/issues/2630:434,security,availab,available,434,"Improve settings documentation; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hello Scanpy team! In scanpy api documentation I see [some settings](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig), however I don't understand how we are supposed to use n_job and max_memory settings. I would like scanpy to use whatever is available. How can I do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2630
https://github.com/scverse/scanpy/issues/2630:326,testability,understand,understand,326,"Improve settings documentation; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hello Scanpy team! In scanpy api documentation I see [some settings](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig), however I don't understand how we are supposed to use n_job and max_memory settings. I would like scanpy to use whatever is available. How can I do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2630
https://github.com/scverse/scanpy/issues/2630:17,usability,document,documentation,17,"Improve settings documentation; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hello Scanpy team! In scanpy api documentation I see [some settings](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig), however I don't understand how we are supposed to use n_job and max_memory settings. I would like scanpy to use whatever is available. How can I do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2630
https://github.com/scverse/scanpy/issues/2630:157,usability,document,documentation,157,"Improve settings documentation; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hello Scanpy team! In scanpy api documentation I see [some settings](https://scanpy.readthedocs.io/en/stable/generated/scanpy._settings.ScanpyConfig.html#scanpy._settings.ScanpyConfig), however I don't understand how we are supposed to use n_job and max_memory settings. I would like scanpy to use whatever is available. How can I do that?",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2630
https://github.com/scverse/scanpy/issues/2632:114,modifiability,paramet,parameters,114,"An advice for color palette in adata.uns; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. As we all know, the color palette is a list stored in uns[f'{values_key}_colors']. I wonder if the color palette can be set to dictionary by default. This makes it easy to unify colors across different adata objects.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2632
https://github.com/scverse/scanpy/issues/2634:10,availability,error,error,10,"Potential error in scanpy.tl.rank_genes_groups?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with . https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this? ### Minimal code sample. ```python. https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:460,availability,down,download,460,"Potential error in scanpy.tl.rank_genes_groups?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with . https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this? ### Minimal code sample. ```python. https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:695,availability,cluster,cluster,695,"Potential error in scanpy.tl.rank_genes_groups?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with . https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this? ### Minimal code sample. ```python. https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:876,availability,Error,Error,876,"Potential error in scanpy.tl.rank_genes_groups?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with . https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this? ### Minimal code sample. ```python. https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:217,deployability,version,version,217,"Potential error in scanpy.tl.rank_genes_groups?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with . https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this? ### Minimal code sample. ```python. https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:634,deployability,log,log-fold,634,"Potential error in scanpy.tl.rank_genes_groups?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with . https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this? ### Minimal code sample. ```python. https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:695,deployability,cluster,cluster,695,"Potential error in scanpy.tl.rank_genes_groups?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with . https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this? ### Minimal code sample. ```python. https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:909,deployability,Version,Versions,909,"Potential error in scanpy.tl.rank_genes_groups?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with . https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this? ### Minimal code sample. ```python. https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:217,integrability,version,version,217,"Potential error in scanpy.tl.rank_genes_groups?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with . https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this? ### Minimal code sample. ```python. https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:909,integrability,Version,Versions,909,"Potential error in scanpy.tl.rank_genes_groups?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with . https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this? ### Minimal code sample. ```python. https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:217,modifiability,version,version,217,"Potential error in scanpy.tl.rank_genes_groups?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with . https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this? ### Minimal code sample. ```python. https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:909,modifiability,Version,Versions,909,"Potential error in scanpy.tl.rank_genes_groups?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with . https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this? ### Minimal code sample. ```python. https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:10,performance,error,error,10,"Potential error in scanpy.tl.rank_genes_groups?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with . https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this? ### Minimal code sample. ```python. https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:387,performance,content,content,387,"Potential error in scanpy.tl.rank_genes_groups?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with . https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this? ### Minimal code sample. ```python. https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:876,performance,Error,Error,876,"Potential error in scanpy.tl.rank_genes_groups?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with . https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this? ### Minimal code sample. ```python. https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:10,safety,error,error,10,"Potential error in scanpy.tl.rank_genes_groups?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with . https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this? ### Minimal code sample. ```python. https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:634,safety,log,log-fold,634,"Potential error in scanpy.tl.rank_genes_groups?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with . https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this? ### Minimal code sample. ```python. https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:876,safety,Error,Error,876,"Potential error in scanpy.tl.rank_genes_groups?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with . https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this? ### Minimal code sample. ```python. https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:634,security,log,log-fold,634,"Potential error in scanpy.tl.rank_genes_groups?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with . https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this? ### Minimal code sample. ```python. https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:634,testability,log,log-fold,634,"Potential error in scanpy.tl.rank_genes_groups?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with . https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this? ### Minimal code sample. ```python. https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:10,usability,error,error,10,"Potential error in scanpy.tl.rank_genes_groups?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with . https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this? ### Minimal code sample. ```python. https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:177,usability,confirm,confirmed,177,"Potential error in scanpy.tl.rank_genes_groups?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with . https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this? ### Minimal code sample. ```python. https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:260,usability,confirm,confirmed,260,"Potential error in scanpy.tl.rank_genes_groups?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with . https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this? ### Minimal code sample. ```python. https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:565,usability,tool,tools,565,"Potential error in scanpy.tl.rank_genes_groups?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with . https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this? ### Minimal code sample. ```python. https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:738,usability,Minim,Minimal,738,"Potential error in scanpy.tl.rank_genes_groups?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with . https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this? ### Minimal code sample. ```python. https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:823,usability,tool,tools,823,"Potential error in scanpy.tl.rank_genes_groups?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with . https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this? ### Minimal code sample. ```python. https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2634:876,usability,Error,Error,876,"Potential error in scanpy.tl.rank_genes_groups?; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. this recent preprint https://www.biorxiv.org/content/biorxiv/early/2023/08/20/2023.07.20.549945/DC1/embed/media-1.pdf?download=true. claims that there is an issue with . https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. that reportedly leads to log-fold changes of 30 or -30 when gene expression is 0 in a cluster. What do you think about this? ### Minimal code sample. ```python. https://github.com/scverse/scanpy/blob/master/scanpy/tools/_rank_genes_groups.py#L419C1-L423C48. ```. ### Error output. _No response_. ### Versions. master",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2634
https://github.com/scverse/scanpy/issues/2635:647,availability,error,error,647,"Ingest: ValueError: all input arrays must have the same shape; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to run ingest in order to transfer labels from a reference dataset to a query dataset. . I have subsetted both datasets to the same features and re-run basic processing on both datasets, including pca, umap, and generating neighbor graphs. . When I run ingest I receive the following error message:. `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python. var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:1575,availability,Error,Error,1575,"erating neighbor graphs. . When I run ingest I receive the following error message:. `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python. var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeling_method * len(obs). 125 . --> 126 ing = Ingest(adata_ref, neighbors_key). 127 ing.fit(adata). 128 . ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata, neighbors_key). 383 . 384 if neighbors_key in adata.uns:. --> 385 self._init_neighbors(adata, neighbors_key). 386 else:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3588,availability,down,downgrade,3588,"def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.9.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 3.0.8. pytz 2022.1. ruamel NA. scipy 1.7.0. seaborn 0.11.2. setuptools ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3772,availability,sli,slightly,3772," None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.9.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 3.0.8. pytz 2022.1. ruamel NA. scipy 1.7.0. seaborn 0.11.2. setuptools 62.1.0. simplejson 3.17.6. six 1.16.0. sklearn 1.0.1. statsmodels 0.13.2. storemagic NA. tables 3.7.0. threadpoolctl 3.1.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:231,deployability,version,version,231,"Ingest: ValueError: all input arrays must have the same shape; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to run ingest in order to transfer labels from a reference dataset to a query dataset. . I have subsetted both datasets to the same features and re-run basic processing on both datasets, including pca, umap, and generating neighbor graphs. . When I run ingest I receive the following error message:. `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python. var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:1680,deployability,modul,module,1680,"ut arrays must have the same shape`. ### Minimal code sample. ```python. var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeling_method * len(obs). 125 . --> 126 ing = Ingest(adata_ref, neighbors_key). 127 ing.fit(adata). 128 . ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata, neighbors_key). 383 . 384 if neighbors_key in adata.uns:. --> 385 self._init_neighbors(adata, neighbors_key). 386 else:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:2832,deployability,stack,stack,2832,"-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeling_method * len(obs). 125 . --> 126 ing = Ingest(adata_ref, neighbors_key). 127 ing.fit(adata). 128 . ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata, neighbors_key). 383 . 384 if neighbors_key in adata.uns:. --> 385 self._init_neighbors(adata, neighbors_key). 386 else:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:2937,deployability,stack,stack,2937,"ghbors_key, inplace, **kwargs). 124 labeling_method = labeling_method * len(obs). 125 . --> 126 ing = Ingest(adata_ref, neighbors_key). 127 ing.fit(adata). 128 . ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata, neighbors_key). 383 . 384 if neighbors_key in adata.uns:. --> 385 self._init_neighbors(adata, neighbors_key). 386 else:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3026,deployability,stack,stack,3026,"-> 126 ing = Ingest(adata_ref, neighbors_key). 127 ing.fit(adata). 128 . ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata, neighbors_key). 383 . 384 if neighbors_key in adata.uns:. --> 385 self._init_neighbors(adata, neighbors_key). 386 else:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3301,deployability,Version,Versions,3301,"e:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3567,deployability,instal,installs,3567,"stances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.9.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 3.0.8. pytz 2022.1. ruamel NA. scipy 1.7.0. seabo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3704,deployability,instal,install,3704,", distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.9.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 3.0.8. pytz 2022.1. ruamel NA. scipy 1.7.0. seaborn 0.11.2. setuptools 62.1.0. simplejson 3.17.6. six 1.16.0. sklearn 1.0.1. statsmodels 0.13.2. storemagic NA. tables 3.7.0. threadpoolct",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:5060,deployability,log,logical,5060,"'all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.9.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 3.0.8. pytz 2022.1. ruamel NA. scipy 1.7.0. seaborn 0.11.2. setuptools 62.1.0. simplejson 3.17.6. six 1.16.0. sklearn 1.0.1. statsmodels 0.13.2. storemagic NA. tables 3.7.0. threadpoolctl 3.1.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 19.0.1. -----. IPython 7.15.0. jupyter_client 6.1.3. jupyter_core 4.6.3. jupyterlab 2.1.4. notebook 6.1.5. -----. Python 3.7.13 (default, Aug 6 2022, 00:43:34) [GCC 9.2.0]. Linux-4.18.0-348.12.2.el8_5.x86_64-x86_64-with-centos-8.7-Green_Obsidian. 192 logical CPU cores, x86_64. -----. Session information updated at 2023-08-22 16:49. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:5114,deployability,updat,updated,5114,"'all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.9.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 3.0.8. pytz 2022.1. ruamel NA. scipy 1.7.0. seaborn 0.11.2. setuptools 62.1.0. simplejson 3.17.6. six 1.16.0. sklearn 1.0.1. statsmodels 0.13.2. storemagic NA. tables 3.7.0. threadpoolctl 3.1.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 19.0.1. -----. IPython 7.15.0. jupyter_client 6.1.3. jupyter_core 4.6.3. jupyterlab 2.1.4. notebook 6.1.5. -----. Python 3.7.13 (default, Aug 6 2022, 00:43:34) [GCC 9.2.0]. Linux-4.18.0-348.12.2.el8_5.x86_64-x86_64-with-centos-8.7-Green_Obsidian. 192 logical CPU cores, x86_64. -----. Session information updated at 2023-08-22 16:49. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3004,energy efficiency,core,core,3004,"hod * len(obs). 125 . --> 126 ing = Ingest(adata_ref, neighbors_key). 127 ing.fit(adata). 128 . ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata, neighbors_key). 383 . 384 if neighbors_key in adata.uns:. --> 385 self._init_neighbors(adata, neighbors_key). 386 else:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:5068,energy efficiency,CPU,CPU,5068,"'all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.9.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 3.0.8. pytz 2022.1. ruamel NA. scipy 1.7.0. seaborn 0.11.2. setuptools 62.1.0. simplejson 3.17.6. six 1.16.0. sklearn 1.0.1. statsmodels 0.13.2. storemagic NA. tables 3.7.0. threadpoolctl 3.1.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 19.0.1. -----. IPython 7.15.0. jupyter_client 6.1.3. jupyter_core 4.6.3. jupyterlab 2.1.4. notebook 6.1.5. -----. Python 3.7.13 (default, Aug 6 2022, 00:43:34) [GCC 9.2.0]. Linux-4.18.0-348.12.2.el8_5.x86_64-x86_64-with-centos-8.7-Green_Obsidian. 192 logical CPU cores, x86_64. -----. Session information updated at 2023-08-22 16:49. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:5072,energy efficiency,core,cores,5072,"'all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.9.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 3.0.8. pytz 2022.1. ruamel NA. scipy 1.7.0. seaborn 0.11.2. setuptools 62.1.0. simplejson 3.17.6. six 1.16.0. sklearn 1.0.1. statsmodels 0.13.2. storemagic NA. tables 3.7.0. threadpoolctl 3.1.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 19.0.1. -----. IPython 7.15.0. jupyter_client 6.1.3. jupyter_core 4.6.3. jupyterlab 2.1.4. notebook 6.1.5. -----. Python 3.7.13 (default, Aug 6 2022, 00:43:34) [GCC 9.2.0]. Linux-4.18.0-348.12.2.el8_5.x86_64-x86_64-with-centos-8.7-Green_Obsidian. 192 logical CPU cores, x86_64. -----. Session information updated at 2023-08-22 16:49. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:231,integrability,version,version,231,"Ingest: ValueError: all input arrays must have the same shape; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to run ingest in order to transfer labels from a reference dataset to a query dataset. . I have subsetted both datasets to the same features and re-run basic processing on both datasets, including pca, umap, and generating neighbor graphs. . When I run ingest I receive the following error message:. `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python. var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:459,integrability,sub,subsetted,459,"Ingest: ValueError: all input arrays must have the same shape; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to run ingest in order to transfer labels from a reference dataset to a query dataset. . I have subsetted both datasets to the same features and re-run basic processing on both datasets, including pca, umap, and generating neighbor graphs. . When I run ingest I receive the following error message:. `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python. var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:653,integrability,messag,message,653,"Ingest: ValueError: all input arrays must have the same shape; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to run ingest in order to transfer labels from a reference dataset to a query dataset. . I have subsetted both datasets to the same features and re-run basic processing on both datasets, including pca, umap, and generating neighbor graphs. . When I run ingest I receive the following error message:. `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python. var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3301,integrability,Version,Versions,3301,"e:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3465,integrability,discover,discoverable,3465,"dom_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3649,integrability,messag,message,3649,"kages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.9.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 3.0.8. pytz 2022.1. ruamel NA. scipy 1.7.0. seaborn 0.11.2. setuptools 62.1.0. simplejson 3.17.6. six 1.16.0. sklearn 1.0.1. statsm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:653,interoperability,messag,message,653,"Ingest: ValueError: all input arrays must have the same shape; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to run ingest in order to transfer labels from a reference dataset to a query dataset. . I have subsetted both datasets to the same features and re-run basic processing on both datasets, including pca, umap, and generating neighbor graphs. . When I run ingest I receive the following error message:. `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python. var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3465,interoperability,discover,discoverable,3465,"dom_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3649,interoperability,messag,message,3649,"kages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.9.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 3.0.8. pytz 2022.1. ruamel NA. scipy 1.7.0. seaborn 0.11.2. setuptools 62.1.0. simplejson 3.17.6. six 1.16.0. sklearn 1.0.1. statsm",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:231,modifiability,version,version,231,"Ingest: ValueError: all input arrays must have the same shape; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to run ingest in order to transfer labels from a reference dataset to a query dataset. . I have subsetted both datasets to the same features and re-run basic processing on both datasets, including pca, umap, and generating neighbor graphs. . When I run ingest I receive the following error message:. `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python. var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:1680,modifiability,modul,module,1680,"ut arrays must have the same shape`. ### Minimal code sample. ```python. var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeling_method * len(obs). 125 . --> 126 ing = Ingest(adata_ref, neighbors_key). 127 ing.fit(adata). 128 . ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata, neighbors_key). 383 . 384 if neighbors_key in adata.uns:. --> 385 self._init_neighbors(adata, neighbors_key). 386 else:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:1836,modifiability,pac,packages,1836,"[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeling_method * len(obs). 125 . --> 126 ing = Ingest(adata_ref, neighbors_key). 127 ing.fit(adata). 128 . ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata, neighbors_key). 383 . 384 if neighbors_key in adata.uns:. --> 385 self._init_neighbors(adata, neighbors_key). 386 else:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(di",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:2130,modifiability,pac,packages,2130,"umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeling_method * len(obs). 125 . --> 126 ing = Ingest(adata_ref, neighbors_key). 127 ing.fit(adata). 128 . ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata, neighbors_key). 383 . 384 if neighbors_key in adata.uns:. --> 385 self._init_neighbors(adata, neighbors_key). 386 else:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 rais",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:2360,modifiability,pac,packages,2360,"'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeling_method * len(obs). 125 . --> 126 ing = Ingest(adata_ref, neighbors_key). 127 ing.fit(adata). 128 . ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata, neighbors_key). 383 . 384 if neighbors_key in adata.uns:. --> 385 self._init_neighbors(adata, neighbors_key). 386 else:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:2650,modifiability,pac,packages,2650,"nput-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeling_method * len(obs). 125 . --> 126 ing = Ingest(adata_ref, neighbors_key). 127 ing.fit(adata). 128 . ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata, neighbors_key). 383 . 384 if neighbors_key in adata.uns:. --> 385 self._init_neighbors(adata, neighbors_key). 386 else:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this messa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:2989,modifiability,pac,packages,2989," labeling_method * len(obs). 125 . --> 126 ing = Ingest(adata_ref, neighbors_key). 127 ing.fit(adata). 128 . ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata, neighbors_key). 383 . 384 if neighbors_key in adata.uns:. --> 385 self._init_neighbors(adata, neighbors_key). 386 else:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. c",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3301,modifiability,Version,Versions,3301,"e:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. n",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3392,modifiability,pac,package,3392,"_init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpec",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3517,modifiability,pac,package,3517,", 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.9.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:4058,modifiability,deco,decorator,4058,"= {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.9.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 3.0.8. pytz 2022.1. ruamel NA. scipy 1.7.0. seaborn 0.11.2. setuptools 62.1.0. simplejson 3.17.6. six 1.16.0. sklearn 1.0.1. statsmodels 0.13.2. storemagic NA. tables 3.7.0. threadpoolctl 3.1.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 19.0.1. -----. IPython 7.15.0. jupyter_client 6.1.3. jupyter_core 4.6.3. jupyterlab 2.1.4. notebook 6.1.5. -----. Python 3.7.13 (default, Aug 6 2022, 00:43:34) [GCC 9.2.0]. Linux-4.18.0-348.12.2.el8_5.x86_64-x86_64-with-centos-8.7-Green_Obsidian. 192 log",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:4347,modifiability,pac,packaging,4347,"'all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.9.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 3.0.8. pytz 2022.1. ruamel NA. scipy 1.7.0. seaborn 0.11.2. setuptools 62.1.0. simplejson 3.17.6. six 1.16.0. sklearn 1.0.1. statsmodels 0.13.2. storemagic NA. tables 3.7.0. threadpoolctl 3.1.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 19.0.1. -----. IPython 7.15.0. jupyter_client 6.1.3. jupyter_core 4.6.3. jupyterlab 2.1.4. notebook 6.1.5. -----. Python 3.7.13 (default, Aug 6 2022, 00:43:34) [GCC 9.2.0]. Linux-4.18.0-348.12.2.el8_5.x86_64-x86_64-with-centos-8.7-Green_Obsidian. 192 logical CPU cores, x86_64. -----. Session information updated at 2023-08-22 16:49. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:647,performance,error,error,647,"Ingest: ValueError: all input arrays must have the same shape; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to run ingest in order to transfer labels from a reference dataset to a query dataset. . I have subsetted both datasets to the same features and re-run basic processing on both datasets, including pca, umap, and generating neighbor graphs. . When I run ingest I receive the following error message:. `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python. var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:1575,performance,Error,Error,1575,"erating neighbor graphs. . When I run ingest I receive the following error message:. `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python. var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeling_method * len(obs). 125 . --> 126 ing = Ingest(adata_ref, neighbors_key). 127 ing.fit(adata). 128 . ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata, neighbors_key). 383 . 384 if neighbors_key in adata.uns:. --> 385 self._init_neighbors(adata, neighbors_key). 386 else:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:5068,performance,CPU,CPU,5068,"'all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.9.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 3.0.8. pytz 2022.1. ruamel NA. scipy 1.7.0. seaborn 0.11.2. setuptools 62.1.0. simplejson 3.17.6. six 1.16.0. sklearn 1.0.1. statsmodels 0.13.2. storemagic NA. tables 3.7.0. threadpoolctl 3.1.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 19.0.1. -----. IPython 7.15.0. jupyter_client 6.1.3. jupyter_core 4.6.3. jupyterlab 2.1.4. notebook 6.1.5. -----. Python 3.7.13 (default, Aug 6 2022, 00:43:34) [GCC 9.2.0]. Linux-4.18.0-348.12.2.el8_5.x86_64-x86_64-with-centos-8.7-Green_Obsidian. 192 logical CPU cores, x86_64. -----. Session information updated at 2023-08-22 16:49. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3772,reliability,sli,slightly,3772," None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.9.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 3.0.8. pytz 2022.1. ruamel NA. scipy 1.7.0. seaborn 0.11.2. setuptools 62.1.0. simplejson 3.17.6. six 1.16.0. sklearn 1.0.1. statsmodels 0.13.2. storemagic NA. tables 3.7.0. threadpoolctl 3.1.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwid",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:24,safety,input,input,24,"Ingest: ValueError: all input arrays must have the same shape; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to run ingest in order to transfer labels from a reference dataset to a query dataset. . I have subsetted both datasets to the same features and re-run basic processing on both datasets, including pca, umap, and generating neighbor graphs. . When I run ingest I receive the following error message:. `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python. var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:647,safety,error,error,647,"Ingest: ValueError: all input arrays must have the same shape; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to run ingest in order to transfer labels from a reference dataset to a query dataset. . I have subsetted both datasets to the same features and re-run basic processing on both datasets, including pca, umap, and generating neighbor graphs. . When I run ingest I receive the following error message:. `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python. var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:680,safety,input,input,680,"Ingest: ValueError: all input arrays must have the same shape; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to run ingest in order to transfer labels from a reference dataset to a query dataset. . I have subsetted both datasets to the same features and re-run basic processing on both datasets, including pca, umap, and generating neighbor graphs. . When I run ingest I receive the following error message:. `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python. var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:1575,safety,Error,Error,1575,"erating neighbor graphs. . When I run ingest I receive the following error message:. `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python. var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeling_method * len(obs). 125 . --> 126 ing = Ingest(adata_ref, neighbors_key). 127 ing.fit(adata). 128 . ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata, neighbors_key). 383 . 384 if neighbors_key in adata.uns:. --> 385 self._init_neighbors(adata, neighbors_key). 386 else:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:1653,safety,input,input-,1653,"sage:. `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python. var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeling_method * len(obs). 125 . --> 126 ing = Ingest(adata_ref, neighbors_key). 127 ing.fit(adata). 128 . ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata, neighbors_key). 383 . 384 if neighbors_key in adata.uns:. --> 385 self._init_neighbors(adata, neighbors_key). 386 else:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:1680,safety,modul,module,1680,"ut arrays must have the same shape`. ### Minimal code sample. ```python. var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeling_method * len(obs). 125 . --> 126 ing = Ingest(adata_ref, neighbors_key). 127 ing.fit(adata). 128 . ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata, neighbors_key). 383 . 384 if neighbors_key in adata.uns:. --> 385 self._init_neighbors(adata, neighbors_key). 386 else:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3152,safety,input,input,3152,"gest.py in __init__(self, adata, neighbors_key). 383 . 384 if neighbors_key in adata.uns:. --> 385 self._init_neighbors(adata, neighbors_key). 386 else:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3253,safety,input,input,3253,"lf._init_neighbors(adata, neighbors_key). 386 else:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. na",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3548,safety,avoid,avoid,3548,"escent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.9.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 3.0.8. pytz 2022.1. ruamel NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3792,safety,review,review,3792,"t_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.9.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 3.0.8. pytz 2022.1. ruamel NA. scipy 1.7.0. seaborn 0.11.2. setuptools 62.1.0. simplejson 3.17.6. six 1.16.0. sklearn 1.0.1. statsmodels 0.13.2. storemagic NA. tables 3.7.0. threadpoolctl 3.1.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 6.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:5060,safety,log,logical,5060,"'all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.9.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 3.0.8. pytz 2022.1. ruamel NA. scipy 1.7.0. seaborn 0.11.2. setuptools 62.1.0. simplejson 3.17.6. six 1.16.0. sklearn 1.0.1. statsmodels 0.13.2. storemagic NA. tables 3.7.0. threadpoolctl 3.1.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 19.0.1. -----. IPython 7.15.0. jupyter_client 6.1.3. jupyter_core 4.6.3. jupyterlab 2.1.4. notebook 6.1.5. -----. Python 3.7.13 (default, Aug 6 2022, 00:43:34) [GCC 9.2.0]. Linux-4.18.0-348.12.2.el8_5.x86_64-x86_64-with-centos-8.7-Green_Obsidian. 192 logical CPU cores, x86_64. -----. Session information updated at 2023-08-22 16:49. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:5114,safety,updat,updated,5114,"'all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.9.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 3.0.8. pytz 2022.1. ruamel NA. scipy 1.7.0. seaborn 0.11.2. setuptools 62.1.0. simplejson 3.17.6. six 1.16.0. sklearn 1.0.1. statsmodels 0.13.2. storemagic NA. tables 3.7.0. threadpoolctl 3.1.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 19.0.1. -----. IPython 7.15.0. jupyter_client 6.1.3. jupyter_core 4.6.3. jupyterlab 2.1.4. notebook 6.1.5. -----. Python 3.7.13 (default, Aug 6 2022, 00:43:34) [GCC 9.2.0]. Linux-4.18.0-348.12.2.el8_5.x86_64-x86_64-with-centos-8.7-Green_Obsidian. 192 logical CPU cores, x86_64. -----. Session information updated at 2023-08-22 16:49. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:5060,security,log,logical,5060,"'all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.9.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 3.0.8. pytz 2022.1. ruamel NA. scipy 1.7.0. seaborn 0.11.2. setuptools 62.1.0. simplejson 3.17.6. six 1.16.0. sklearn 1.0.1. statsmodels 0.13.2. storemagic NA. tables 3.7.0. threadpoolctl 3.1.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 19.0.1. -----. IPython 7.15.0. jupyter_client 6.1.3. jupyter_core 4.6.3. jupyterlab 2.1.4. notebook 6.1.5. -----. Python 3.7.13 (default, Aug 6 2022, 00:43:34) [GCC 9.2.0]. Linux-4.18.0-348.12.2.el8_5.x86_64-x86_64-with-centos-8.7-Green_Obsidian. 192 logical CPU cores, x86_64. -----. Session information updated at 2023-08-22 16:49. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:5094,security,Session,Session,5094,"'all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.9.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 3.0.8. pytz 2022.1. ruamel NA. scipy 1.7.0. seaborn 0.11.2. setuptools 62.1.0. simplejson 3.17.6. six 1.16.0. sklearn 1.0.1. statsmodels 0.13.2. storemagic NA. tables 3.7.0. threadpoolctl 3.1.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 19.0.1. -----. IPython 7.15.0. jupyter_client 6.1.3. jupyter_core 4.6.3. jupyterlab 2.1.4. notebook 6.1.5. -----. Python 3.7.13 (default, Aug 6 2022, 00:43:34) [GCC 9.2.0]. Linux-4.18.0-348.12.2.el8_5.x86_64-x86_64-with-centos-8.7-Green_Obsidian. 192 logical CPU cores, x86_64. -----. Session information updated at 2023-08-22 16:49. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:5114,security,updat,updated,5114,"'all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.9.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 3.0.8. pytz 2022.1. ruamel NA. scipy 1.7.0. seaborn 0.11.2. setuptools 62.1.0. simplejson 3.17.6. six 1.16.0. sklearn 1.0.1. statsmodels 0.13.2. storemagic NA. tables 3.7.0. threadpoolctl 3.1.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 19.0.1. -----. IPython 7.15.0. jupyter_client 6.1.3. jupyter_core 4.6.3. jupyterlab 2.1.4. notebook 6.1.5. -----. Python 3.7.13 (default, Aug 6 2022, 00:43:34) [GCC 9.2.0]. Linux-4.18.0-348.12.2.el8_5.x86_64-x86_64-with-centos-8.7-Green_Obsidian. 192 logical CPU cores, x86_64. -----. Session information updated at 2023-08-22 16:49. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:1609,testability,Trace,Traceback,1609,"n ingest I receive the following error message:. `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python. var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeling_method * len(obs). 125 . --> 126 ing = Ingest(adata_ref, neighbors_key). 127 ing.fit(adata). 128 . ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata, neighbors_key). 383 . 384 if neighbors_key in adata.uns:. --> 385 self._init_neighbors(adata, neighbors_key). 386 else:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3792,testability,review,review,3792,"t_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.9.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 3.0.8. pytz 2022.1. ruamel NA. scipy 1.7.0. seaborn 0.11.2. setuptools 62.1.0. simplejson 3.17.6. six 1.16.0. sklearn 1.0.1. statsmodels 0.13.2. storemagic NA. tables 3.7.0. threadpoolctl 3.1.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 6.0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:4601,testability,simpl,simplejson,4601,"'all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.9.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 3.0.8. pytz 2022.1. ruamel NA. scipy 1.7.0. seaborn 0.11.2. setuptools 62.1.0. simplejson 3.17.6. six 1.16.0. sklearn 1.0.1. statsmodels 0.13.2. storemagic NA. tables 3.7.0. threadpoolctl 3.1.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 19.0.1. -----. IPython 7.15.0. jupyter_client 6.1.3. jupyter_core 4.6.3. jupyterlab 2.1.4. notebook 6.1.5. -----. Python 3.7.13 (default, Aug 6 2022, 00:43:34) [GCC 9.2.0]. Linux-4.18.0-348.12.2.el8_5.x86_64-x86_64-with-centos-8.7-Green_Obsidian. 192 logical CPU cores, x86_64. -----. Session information updated at 2023-08-22 16:49. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:5060,testability,log,logical,5060,"'all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.9.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 3.0.8. pytz 2022.1. ruamel NA. scipy 1.7.0. seaborn 0.11.2. setuptools 62.1.0. simplejson 3.17.6. six 1.16.0. sklearn 1.0.1. statsmodels 0.13.2. storemagic NA. tables 3.7.0. threadpoolctl 3.1.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 19.0.1. -----. IPython 7.15.0. jupyter_client 6.1.3. jupyter_core 4.6.3. jupyterlab 2.1.4. notebook 6.1.5. -----. Python 3.7.13 (default, Aug 6 2022, 00:43:34) [GCC 9.2.0]. Linux-4.18.0-348.12.2.el8_5.x86_64-x86_64-with-centos-8.7-Green_Obsidian. 192 logical CPU cores, x86_64. -----. Session information updated at 2023-08-22 16:49. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:24,usability,input,input,24,"Ingest: ValueError: all input arrays must have the same shape; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to run ingest in order to transfer labels from a reference dataset to a query dataset. . I have subsetted both datasets to the same features and re-run basic processing on both datasets, including pca, umap, and generating neighbor graphs. . When I run ingest I receive the following error message:. `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python. var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:191,usability,confirm,confirmed,191,"Ingest: ValueError: all input arrays must have the same shape; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to run ingest in order to transfer labels from a reference dataset to a query dataset. . I have subsetted both datasets to the same features and re-run basic processing on both datasets, including pca, umap, and generating neighbor graphs. . When I run ingest I receive the following error message:. `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python. var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:274,usability,confirm,confirmed,274,"Ingest: ValueError: all input arrays must have the same shape; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to run ingest in order to transfer labels from a reference dataset to a query dataset. . I have subsetted both datasets to the same features and re-run basic processing on both datasets, including pca, umap, and generating neighbor graphs. . When I run ingest I receive the following error message:. `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python. var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:647,usability,error,error,647,"Ingest: ValueError: all input arrays must have the same shape; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to run ingest in order to transfer labels from a reference dataset to a query dataset. . I have subsetted both datasets to the same features and re-run basic processing on both datasets, including pca, umap, and generating neighbor graphs. . When I run ingest I receive the following error message:. `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python. var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:680,usability,input,input,680,"Ingest: ValueError: all input arrays must have the same shape; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to run ingest in order to transfer labels from a reference dataset to a query dataset. . I have subsetted both datasets to the same features and re-run basic processing on both datasets, including pca, umap, and generating neighbor graphs. . When I run ingest I receive the following error message:. `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python. var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:724,usability,Minim,Minimal,724,"Ingest: ValueError: all input arrays must have the same shape; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to run ingest in order to transfer labels from a reference dataset to a query dataset. . I have subsetted both datasets to the same features and re-run basic processing on both datasets, including pca, umap, and generating neighbor graphs. . When I run ingest I receive the following error message:. `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python. var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:1575,usability,Error,Error,1575,"erating neighbor graphs. . When I run ingest I receive the following error message:. `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python. var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeling_method * len(obs). 125 . --> 126 ing = Ingest(adata_ref, neighbors_key). 127 ing.fit(adata). 128 . ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata, neighbors_key). 383 . 384 if neighbors_key in adata.uns:. --> 385 self._init_neighbors(adata, neighbors_key). 386 else:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:1653,usability,input,input-,1653,"sage:. `ValueError: all input arrays must have the same shape`. ### Minimal code sample. ```python. var_names = adata_ref.var_names.intersection(adata.var_names). adata_ref = adata_ref[:, var_names]. adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeling_method * len(obs). 125 . --> 126 ing = Ingest(adata_ref, neighbors_key). 127 ing.fit(adata). 128 . ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata, neighbors_key). 383 . 384 if neighbors_key in adata.uns:. --> 385 self._init_neighbors(adata, neighbors_key). 386 else:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packag",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:1852,usability,tool,tools,1852," adata = adata[:, var_names]. sc.tl.pca(adata_ref, svd_solver='arpack'). sc.pp.neighbors(adata_ref, n_neighbors=10, n_pcs=40). sc.tl.paga(adata_ref, groups = 'cell_type'). sc.pl.paga(adata_ref, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata_ref, init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeling_method * len(obs). 125 . --> 126 ing = Ingest(adata_ref, neighbors_key). 127 ing.fit(adata). 128 . ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata, neighbors_key). 383 . 384 if neighbors_key in adata.uns:. --> 385 self._init_neighbors(adata, neighbors_key). 386 else:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil()",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:2146,usability,tool,tools,2146," init_pos='paga'). adata.obs['seurat_clusters'] = adata.obs['seurat_clusters'].astype('category'). sc.tl.pca(adata, svd_solver='arpack'). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40). sc.tl.paga(adata, groups = 'seurat_clusters'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeling_method * len(obs). 125 . --> 126 ing = Ingest(adata_ref, neighbors_key). 127 ing.fit(adata). 128 . ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata, neighbors_key). 383 . 384 if neighbors_key in adata.uns:. --> 385 self._init_neighbors(adata, neighbors_key). 386 else:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('a",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:2376,usability,tool,tools,2376,"s'). sc.pl.paga(adata, plot=False) # remove `plot=False` if you want to see the coarse-grained graph. sc.tl.umap(adata, init_pos='paga'). sc.tl.ingest(adata, adata_ref, obs='cell_type'). ```. ### Error output. ```pytb. ValueError Traceback (most recent call last). <ipython-input-18-6b34a6250614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeling_method * len(obs). 125 . --> 126 ing = Ingest(adata_ref, neighbors_key). 127 ing.fit(adata). 128 . ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata, neighbors_key). 383 . 384 if neighbors_key in adata.uns:. --> 385 self._init_neighbors(adata, neighbors_key). 386 else:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`!",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:2666,usability,tool,tools,2666,"50614> in <module>. 1 # we map our tabula sapiens cell type labels onto our data. ----> 2 sc.tl.ingest(adata, adata_ref, obs='cell_type'). ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in ingest(adata, adata_ref, obs, embedding_method, labeling_method, neighbors_key, inplace, **kwargs). 124 labeling_method = labeling_method * len(obs). 125 . --> 126 ing = Ingest(adata_ref, neighbors_key). 127 ing.fit(adata). 128 . ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in __init__(self, adata, neighbors_key). 383 . 384 if neighbors_key in adata.uns:. --> 385 self._init_neighbors(adata, neighbors_key). 386 else:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the lat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3152,usability,input,input,3152,"gest.py in __init__(self, adata, neighbors_key). 383 . 384 if neighbors_key in adata.uns:. --> 385 self._init_neighbors(adata, neighbors_key). 386 else:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3253,usability,input,input,3253,"lf._init_neighbors(adata, neighbors_key). 386 else:. 387 raise ValueError(. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_neighbors(self, adata, neighbors_key). 349 else:. 350 self._neigh_random_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. na",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:3465,usability,discov,discoverable,3465,"dom_state = neighbors['params'].get('random_state', 0). --> 351 self._init_pynndescent(neighbors['distances']). 352 . 353 def _init_pca(self, adata):. ~/.local/lib/python3.7/site-packages/scanpy/tools/_ingest.py in _init_pynndescent(self, distances). 284 . 285 first_col = np.arange(distances.shape[0])[:, None]. --> 286 init_indices = np.hstack((first_col, np.stack(distances.tolil().rows))). 287 . 288 self._nnd_idx = NNDescent(. <__array_function__ internals> in stack(*args, **kwargs). ~/.local/lib/python3.7/site-packages/numpy/core/shape_base.py in stack(arrays, axis, out). 425 shapes = {arr.shape for arr in arrays}. 426 if len(shapes) != 1:. --> 427 raise ValueError('all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2635:4601,usability,simpl,simplejson,4601,"'all input arrays must have the same shape'). 428 . 429 result_ndim = arrays[0].ndim + 1. ValueError: all input arrays must have the same shape. ```. ### Versions. ```. WARNING: If you miss a compact list, please try `print_header`! The `sinfo` package has changed name and is now called `session_info` to become more discoverable and self-explanatory. The `sinfo` PyPI package will be kept around to avoid breaking old installs and you can downgrade to 0.3.2 if you want to use it without seeing this message. For the latest features and bug fixes, please install `session_info` instead. The usage and defaults also changed slightly, so please review the latest README at https://gitlab.com/joelostblom/session_info. -----. anndata 0.8.0. scanpy 1.8.1. sinfo 0.3.4. -----. PIL 7.1.2. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.0. colorama 0.4.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. decorator 5.1.1. google NA. h5py 3.7.0. ipykernel 5.3.0. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.0. joblib 1.1.0. kiwisolver 1.2.0. llvmlite 0.38.1. matplotlib 3.3.0. mpl_toolkits NA. natsort 8.1.0. nbinom_ufunc NA. netifaces 0.11.0. numba 0.55.2. numexpr 2.8.3. numpy 1.20.0. packaging 21.3. pandas 1.1.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. prompt_toolkit 3.0.5. psutil 5.9.0. ptyprocess 0.6.0. pygments 2.6.1. pyparsing 3.0.8. pytz 2022.1. ruamel NA. scipy 1.7.0. seaborn 0.11.2. setuptools 62.1.0. simplejson 3.17.6. six 1.16.0. sklearn 1.0.1. statsmodels 0.13.2. storemagic NA. tables 3.7.0. threadpoolctl 3.1.0. tornado 6.0.4. traitlets 4.3.3. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 19.0.1. -----. IPython 7.15.0. jupyter_client 6.1.3. jupyter_core 4.6.3. jupyterlab 2.1.4. notebook 6.1.5. -----. Python 3.7.13 (default, Aug 6 2022, 00:43:34) [GCC 9.2.0]. Linux-4.18.0-348.12.2.el8_5.x86_64-x86_64-with-centos-8.7-Green_Obsidian. 192 logical CPU cores, x86_64. -----. Session information updated at 2023-08-22 16:49. ```.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2635
https://github.com/scverse/scanpy/issues/2636:616,deployability,releas,release,616,"Go back to tutorial submodule; ### What kind of feature would you like to request? Other? ### Please describe your wishes. The tutorial submodule was removed as part of a fix-up pass over the docs by @flying-sheep. The issue at the time was warnings which weren't immediately obvious how to fix. Since there are a number of reasons to prefer the submodule approach over a separate scanpy-tutorials website, I would like to bring it back. The plan is: bring back the submodule. In this PR I'll see if the warnings can be easily fixed. If they can't, they'll be silenced and an issue tracking fixing them for the next release will be opened.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2636
https://github.com/scverse/scanpy/issues/2636:20,integrability,sub,submodule,20,"Go back to tutorial submodule; ### What kind of feature would you like to request? Other? ### Please describe your wishes. The tutorial submodule was removed as part of a fix-up pass over the docs by @flying-sheep. The issue at the time was warnings which weren't immediately obvious how to fix. Since there are a number of reasons to prefer the submodule approach over a separate scanpy-tutorials website, I would like to bring it back. The plan is: bring back the submodule. In this PR I'll see if the warnings can be easily fixed. If they can't, they'll be silenced and an issue tracking fixing them for the next release will be opened.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2636
https://github.com/scverse/scanpy/issues/2636:136,integrability,sub,submodule,136,"Go back to tutorial submodule; ### What kind of feature would you like to request? Other? ### Please describe your wishes. The tutorial submodule was removed as part of a fix-up pass over the docs by @flying-sheep. The issue at the time was warnings which weren't immediately obvious how to fix. Since there are a number of reasons to prefer the submodule approach over a separate scanpy-tutorials website, I would like to bring it back. The plan is: bring back the submodule. In this PR I'll see if the warnings can be easily fixed. If they can't, they'll be silenced and an issue tracking fixing them for the next release will be opened.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2636
https://github.com/scverse/scanpy/issues/2636:346,integrability,sub,submodule,346,"Go back to tutorial submodule; ### What kind of feature would you like to request? Other? ### Please describe your wishes. The tutorial submodule was removed as part of a fix-up pass over the docs by @flying-sheep. The issue at the time was warnings which weren't immediately obvious how to fix. Since there are a number of reasons to prefer the submodule approach over a separate scanpy-tutorials website, I would like to bring it back. The plan is: bring back the submodule. In this PR I'll see if the warnings can be easily fixed. If they can't, they'll be silenced and an issue tracking fixing them for the next release will be opened.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2636
https://github.com/scverse/scanpy/issues/2636:466,integrability,sub,submodule,466,"Go back to tutorial submodule; ### What kind of feature would you like to request? Other? ### Please describe your wishes. The tutorial submodule was removed as part of a fix-up pass over the docs by @flying-sheep. The issue at the time was warnings which weren't immediately obvious how to fix. Since there are a number of reasons to prefer the submodule approach over a separate scanpy-tutorials website, I would like to bring it back. The plan is: bring back the submodule. In this PR I'll see if the warnings can be easily fixed. If they can't, they'll be silenced and an issue tracking fixing them for the next release will be opened.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2636
https://github.com/scverse/scanpy/issues/2636:232,performance,time,time,232,"Go back to tutorial submodule; ### What kind of feature would you like to request? Other? ### Please describe your wishes. The tutorial submodule was removed as part of a fix-up pass over the docs by @flying-sheep. The issue at the time was warnings which weren't immediately obvious how to fix. Since there are a number of reasons to prefer the submodule approach over a separate scanpy-tutorials website, I would like to bring it back. The plan is: bring back the submodule. In this PR I'll see if the warnings can be easily fixed. If they can't, they'll be silenced and an issue tracking fixing them for the next release will be opened.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2636
https://github.com/scverse/scanpy/issues/2636:442,testability,plan,plan,442,"Go back to tutorial submodule; ### What kind of feature would you like to request? Other? ### Please describe your wishes. The tutorial submodule was removed as part of a fix-up pass over the docs by @flying-sheep. The issue at the time was warnings which weren't immediately obvious how to fix. Since there are a number of reasons to prefer the submodule approach over a separate scanpy-tutorials website, I would like to bring it back. The plan is: bring back the submodule. In this PR I'll see if the warnings can be easily fixed. If they can't, they'll be silenced and an issue tracking fixing them for the next release will be opened.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2636
https://github.com/scverse/scanpy/issues/2636:335,usability,prefer,prefer,335,"Go back to tutorial submodule; ### What kind of feature would you like to request? Other? ### Please describe your wishes. The tutorial submodule was removed as part of a fix-up pass over the docs by @flying-sheep. The issue at the time was warnings which weren't immediately obvious how to fix. Since there are a number of reasons to prefer the submodule approach over a separate scanpy-tutorials website, I would like to bring it back. The plan is: bring back the submodule. In this PR I'll see if the warnings can be easily fixed. If they can't, they'll be silenced and an issue tracking fixing them for the next release will be opened.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2636
https://github.com/scverse/scanpy/pull/2637:240,safety,review,review,240,Improve n_jobs docs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes #2630.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2637
https://github.com/scverse/scanpy/pull/2637:240,testability,review,review,240,Improve n_jobs docs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes #2630.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2637
https://github.com/scverse/scanpy/pull/2637:91,usability,guid,guidelines,91,Improve n_jobs docs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes #2630.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2637
https://github.com/scverse/scanpy/pull/2637:122,usability,guid,guide,122,Improve n_jobs docs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes #2630.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2637
https://github.com/scverse/scanpy/pull/2637:218,usability,workflow,workflow,218,Improve n_jobs docs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Fixes #2630.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2637
https://github.com/scverse/scanpy/pull/2639:14,deployability,releas,release,14,"Prepare 1.9.4 release; I went through the PRs and we actually did a good job (at least for the backported ones): Nothing missing! Regarding the new 1.9.5.md: Even if 1.9.5 will probably not happen, we should just keep the file and fill it as expected, and if we release 1.10 first, we just migrate the by-then-merged changes over and delete the 1.9.5.md. Better to stick to a clean process than improvising and making things confusing.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2639
https://github.com/scverse/scanpy/pull/2639:262,deployability,releas,release,262,"Prepare 1.9.4 release; I went through the PRs and we actually did a good job (at least for the backported ones): Nothing missing! Regarding the new 1.9.5.md: Even if 1.9.5 will probably not happen, we should just keep the file and fill it as expected, and if we release 1.10 first, we just migrate the by-then-merged changes over and delete the 1.9.5.md. Better to stick to a clean process than improvising and making things confusing.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2639
https://github.com/scverse/scanpy/pull/2641:33,deployability,releas,release,33,Backport PR #2639: Prepare 1.9.4 release; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2641
https://github.com/scverse/scanpy/pull/2641:261,safety,review,review,261,Backport PR #2639: Prepare 1.9.4 release; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2641
https://github.com/scverse/scanpy/pull/2641:261,testability,review,review,261,Backport PR #2639: Prepare 1.9.4 release; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2641
https://github.com/scverse/scanpy/pull/2641:112,usability,guid,guidelines,112,Backport PR #2639: Prepare 1.9.4 release; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2641
https://github.com/scverse/scanpy/pull/2641:143,usability,guid,guide,143,Backport PR #2639: Prepare 1.9.4 release; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2641
https://github.com/scverse/scanpy/pull/2641:239,usability,workflow,workflow,239,Backport PR #2639: Prepare 1.9.4 release; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2641
https://github.com/scverse/scanpy/issues/2644:6,deployability,releas,release,6,Add a release workflow; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Basically using the GitHub UI to create a tag & release should kick of both a PyPI release and also ideally activate that tag on rtd (#2425). We should finish #2569 before that,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2644
https://github.com/scverse/scanpy/issues/2644:164,deployability,releas,release,164,Add a release workflow; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Basically using the GitHub UI to create a tag & release should kick of both a PyPI release and also ideally activate that tag on rtd (#2425). We should finish #2569 before that,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2644
https://github.com/scverse/scanpy/issues/2644:199,deployability,releas,release,199,Add a release workflow; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Basically using the GitHub UI to create a tag & release should kick of both a PyPI release and also ideally activate that tag on rtd (#2425). We should finish #2569 before that,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2644
https://github.com/scverse/scanpy/issues/2644:14,usability,workflow,workflow,14,Add a release workflow; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Basically using the GitHub UI to create a tag & release should kick of both a PyPI release and also ideally activate that tag on rtd (#2425). We should finish #2569 before that,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2644
https://github.com/scverse/scanpy/issues/2644:143,usability,UI,UI,143,Add a release workflow; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Basically using the GitHub UI to create a tag & release should kick of both a PyPI release and also ideally activate that tag on rtd (#2425). We should finish #2569 before that,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2644
https://github.com/scverse/scanpy/issues/2645:653,availability,Error,Error,653,"Issue with writing to h5ad/ hdf5 and plotting functions after concatenating datasets; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:936,availability,error,error,936,"Issue with writing to h5ad/ hdf5 and plotting functions after concatenating datasets; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:1139,availability,error,errors,1139,"ave checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:1151,availability,error,error,1151,"that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:1359,availability,replic,replicated,1359,"happened? I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns #",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:1699,availability,error,error,1699,"_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform strin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:1796,availability,Error,Error,1796,"adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:2365,availability,Slo,Slow,2365,"ed without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. ```. ### Versions. <details>. ```. anndata 0.7.8. scanpy 1.9.3. -----. PIL 10.0.0. asttokens NA. backcall 0.2.0. clustergrammer2 0.18.0. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7.post1. decor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:3006,availability,error,error,3006,"ype error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. ```. ### Versions. <details>. ```. anndata 0.7.8. scanpy 1.9.3. -----. PIL 10.0.0. asttokens NA. backcall 0.2.0. clustergrammer2 0.18.0. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7.post1. decorator 5.1.1. executing 1.2.0. google NA. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. jedi 0.19.0. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.9.0. ... Python 3.9.12 (main, Jun 1 2022, 11:38:51) [GCC 7.5.0]. Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:254,deployability,version,version,254,"Issue with writing to h5ad/ hdf5 and plotting functions after concatenating datasets; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:2141,deployability,log,log,2141,"rs. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:2187,deployability,scale,scale,2187,"anipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. ```. ### Versions. <details>. ```. anndata 0.7.8",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:2926,deployability,continu,continue,2926,"ype error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. ```. ### Versions. <details>. ```. anndata 0.7.8. scanpy 1.9.3. -----. PIL 10.0.0. asttokens NA. backcall 0.2.0. clustergrammer2 0.18.0. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7.post1. decorator 5.1.1. executing 1.2.0. google NA. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. jedi 0.19.0. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.9.0. ... Python 3.9.12 (main, Jun 1 2022, 11:38:51) [GCC 7.5.0]. Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:3151,deployability,Version,Versions,3151,"ype error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. ```. ### Versions. <details>. ```. anndata 0.7.8. scanpy 1.9.3. -----. PIL 10.0.0. asttokens NA. backcall 0.2.0. clustergrammer2 0.18.0. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7.post1. decorator 5.1.1. executing 1.2.0. google NA. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. jedi 0.19.0. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.9.0. ... Python 3.9.12 (main, Jun 1 2022, 11:38:51) [GCC 7.5.0]. Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:2187,energy efficiency,scale,scale,2187,"anipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. ```. ### Versions. <details>. ```. anndata 0.7.8",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:254,integrability,version,version,254,"Issue with writing to h5ad/ hdf5 and plotting functions after concatenating datasets; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:1157,integrability,messag,message,1157,"is issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:1246,integrability,sub,subsetting,1246,"st version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:2687,integrability,Transform,Transform,2687,"e type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. ```. ### Versions. <details>. ```. anndata 0.7.8. scanpy 1.9.3. -----. PIL 10.0.0. asttokens NA. backcall 0.2.0. clustergrammer2 0.18.0. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7.post1. decorator 5.1.1. executing 1.2.0. google NA. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. jedi 0.19.0. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.9.0. ... Python 3.9.12 (main, Jun 1 2022, 11:38:51) [GCC 7.5.0]. Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31. ```. </detail",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:3012,integrability,messag,message,3012,"ype error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. ```. ### Versions. <details>. ```. anndata 0.7.8. scanpy 1.9.3. -----. PIL 10.0.0. asttokens NA. backcall 0.2.0. clustergrammer2 0.18.0. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7.post1. decorator 5.1.1. executing 1.2.0. google NA. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. jedi 0.19.0. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.9.0. ... Python 3.9.12 (main, Jun 1 2022, 11:38:51) [GCC 7.5.0]. Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:3151,integrability,Version,Versions,3151,"ype error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. ```. ### Versions. <details>. ```. anndata 0.7.8. scanpy 1.9.3. -----. PIL 10.0.0. asttokens NA. backcall 0.2.0. clustergrammer2 0.18.0. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7.post1. decorator 5.1.1. executing 1.2.0. google NA. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. jedi 0.19.0. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.9.0. ... Python 3.9.12 (main, Jun 1 2022, 11:38:51) [GCC 7.5.0]. Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:1157,interoperability,messag,message,1157,"is issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:2687,interoperability,Transform,Transform,2687,"e type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. ```. ### Versions. <details>. ```. anndata 0.7.8. scanpy 1.9.3. -----. PIL 10.0.0. asttokens NA. backcall 0.2.0. clustergrammer2 0.18.0. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7.post1. decorator 5.1.1. executing 1.2.0. google NA. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. jedi 0.19.0. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.9.0. ... Python 3.9.12 (main, Jun 1 2022, 11:38:51) [GCC 7.5.0]. Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31. ```. </detail",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:3012,interoperability,messag,message,3012,"ype error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. ```. ### Versions. <details>. ```. anndata 0.7.8. scanpy 1.9.3. -----. PIL 10.0.0. asttokens NA. backcall 0.2.0. clustergrammer2 0.18.0. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7.post1. decorator 5.1.1. executing 1.2.0. google NA. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. jedi 0.19.0. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.9.0. ... Python 3.9.12 (main, Jun 1 2022, 11:38:51) [GCC 7.5.0]. Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:3642,interoperability,standard,standard-,3642,"ype error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. ```. ### Versions. <details>. ```. anndata 0.7.8. scanpy 1.9.3. -----. PIL 10.0.0. asttokens NA. backcall 0.2.0. clustergrammer2 0.18.0. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7.post1. decorator 5.1.1. executing 1.2.0. google NA. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. jedi 0.19.0. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.9.0. ... Python 3.9.12 (main, Jun 1 2022, 11:38:51) [GCC 7.5.0]. Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:254,modifiability,version,version,254,"Issue with writing to h5ad/ hdf5 and plotting functions after concatenating datasets; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:2067,modifiability,pac,packages,2067," and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeErr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:2180,modifiability,layer,layer,2180,"ng to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. ```. ### Versions. <details>. ```. anndat",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:2187,modifiability,scal,scale,2187,"anipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. ```. ### Versions. <details>. ```. anndata 0.7.8",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:2578,modifiability,pac,packages,2578," curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. ```. ### Versions. <details>. ```. anndata 0.7.8. scanpy 1.9.3. -----. PIL 10.0.0. asttokens NA. backcall 0.2.0. clustergrammer2 0.18.0. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7.post1. decorator 5.1.1. executing 1.2.0. google NA. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. jedi 0.19.0. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.9.0. ... Python 3.9.12 (main, J",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:2797,modifiability,pac,packages,2797,"ype error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. ```. ### Versions. <details>. ```. anndata 0.7.8. scanpy 1.9.3. -----. PIL 10.0.0. asttokens NA. backcall 0.2.0. clustergrammer2 0.18.0. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7.post1. decorator 5.1.1. executing 1.2.0. google NA. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. jedi 0.19.0. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.9.0. ... Python 3.9.12 (main, Jun 1 2022, 11:38:51) [GCC 7.5.0]. Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:3151,modifiability,Version,Versions,3151,"ype error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. ```. ### Versions. <details>. ```. anndata 0.7.8. scanpy 1.9.3. -----. PIL 10.0.0. asttokens NA. backcall 0.2.0. clustergrammer2 0.18.0. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7.post1. decorator 5.1.1. executing 1.2.0. google NA. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. jedi 0.19.0. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.9.0. ... Python 3.9.12 (main, Jun 1 2022, 11:38:51) [GCC 7.5.0]. Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:3362,modifiability,deco,decorator,3362,"ype error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. ```. ### Versions. <details>. ```. anndata 0.7.8. scanpy 1.9.3. -----. PIL 10.0.0. asttokens NA. backcall 0.2.0. clustergrammer2 0.18.0. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7.post1. decorator 5.1.1. executing 1.2.0. google NA. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. jedi 0.19.0. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.9.0. ... Python 3.9.12 (main, Jun 1 2022, 11:38:51) [GCC 7.5.0]. Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:653,performance,Error,Error,653,"Issue with writing to h5ad/ hdf5 and plotting functions after concatenating datasets; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:936,performance,error,error,936,"Issue with writing to h5ad/ hdf5 and plotting functions after concatenating datasets; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:1139,performance,error,errors,1139,"ave checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:1151,performance,error,error,1151,"that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:1699,performance,error,error,1699,"_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform strin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:1796,performance,Error,Error,1796,"adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:2187,performance,scale,scale,2187,"anipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. ```. ### Versions. <details>. ```. anndata 0.7.8",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:3006,performance,error,error,3006,"ype error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. ```. ### Versions. <details>. ```. anndata 0.7.8. scanpy 1.9.3. -----. PIL 10.0.0. asttokens NA. backcall 0.2.0. clustergrammer2 0.18.0. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7.post1. decorator 5.1.1. executing 1.2.0. google NA. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. jedi 0.19.0. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.9.0. ... Python 3.9.12 (main, Jun 1 2022, 11:38:51) [GCC 7.5.0]. Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:3048,performance,disk,disk,3048,"ype error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. ```. ### Versions. <details>. ```. anndata 0.7.8. scanpy 1.9.3. -----. PIL 10.0.0. asttokens NA. backcall 0.2.0. clustergrammer2 0.18.0. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7.post1. decorator 5.1.1. executing 1.2.0. google NA. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. jedi 0.19.0. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.9.0. ... Python 3.9.12 (main, Jun 1 2022, 11:38:51) [GCC 7.5.0]. Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:2365,reliability,Slo,Slow,2365,"ed without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. ```. ### Versions. <details>. ```. anndata 0.7.8. scanpy 1.9.3. -----. PIL 10.0.0. asttokens NA. backcall 0.2.0. clustergrammer2 0.18.0. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7.post1. decor",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:653,safety,Error,Error,653,"Issue with writing to h5ad/ hdf5 and plotting functions after concatenating datasets; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:682,safety,sanit,sanitize,682,"Issue with writing to h5ad/ hdf5 and plotting functions after concatenating datasets; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:936,safety,error,error,936,"Issue with writing to h5ad/ hdf5 and plotting functions after concatenating datasets; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:1139,safety,error,errors,1139,"ave checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:1151,safety,error,error,1151,"that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:1699,safety,error,error,1699,"_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform strin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:1796,safety,Error,Error,1796,"adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:2141,safety,log,log,2141,"rs. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:3006,safety,error,error,3006,"ype error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. ```. ### Versions. <details>. ```. anndata 0.7.8. scanpy 1.9.3. -----. PIL 10.0.0. asttokens NA. backcall 0.2.0. clustergrammer2 0.18.0. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7.post1. decorator 5.1.1. executing 1.2.0. google NA. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. jedi 0.19.0. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.9.0. ... Python 3.9.12 (main, Jun 1 2022, 11:38:51) [GCC 7.5.0]. Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:682,security,sanit,sanitize,682,"Issue with writing to h5ad/ hdf5 and plotting functions after concatenating datasets; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:2141,security,log,log,2141,"rs. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:2230,security,rotat,rotation,2230,"ugh I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. ```. ### Versions. <details>. ```. anndata 0.7.8. scanpy 1.9.3. -----. PIL 10.0.0. asttokens",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:1906,testability,Trace,Traceback,1906,"d it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >=",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:2141,testability,log,log,2141,"rs. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. `",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:214,usability,confirm,confirmed,214,"Issue with writing to h5ad/ hdf5 and plotting functions after concatenating datasets; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:297,usability,confirm,confirmed,297,"Issue with writing to h5ad/ hdf5 and plotting functions after concatenating datasets; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:653,usability,Error,Error,653,"Issue with writing to h5ad/ hdf5 and plotting functions after concatenating datasets; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:936,usability,error,error,936,"Issue with writing to h5ad/ hdf5 and plotting functions after concatenating datasets; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:1139,usability,error,errors,1139,"ave checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, l",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:1151,usability,error,error,1151,"that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I am trying to concatenate multiple datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:1403,usability,Minim,Minimal,1403,"le datasets. I have Anndata's of 4 runs that I'm trying to analyze together. I tried the plotting functions (e.g. sc.pl. violin) and saving to h5ad files on individual Anndata's and it works. When I merge them via ad.concat I keep getting a Type Error due to Anndata calling sanitize and strings_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 74",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:1699,usability,error,error,1699,"_to_categoricals when I try to save or use plotting functions. I thought it might be because I'm adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform strin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:1796,usability,Error,Error,1796,"adding new obs before merging but then I tried to just merge without any manipulation of individual Anndata's and it still gave the same error. Then I tried to manually merge the Anndata's by saving X as dataframe and obs as separate dataframes, merging them as dataframes and then creating a new Anndata object. I still keep getting these errors. The error message says that I'm trying to manipulate a view of the Anndata object although I'm not subsetting it and when I do adata.is_view it says False. . I'm not sure how to provide a code sample that can be replicated without data in this case. . ### Minimal code sample. ```python. samples= [ <list of 4 hdf5 files>]. all_adata = []. i = 0. for s in samples:. curr_adata = sc.read_h5ad(f""/mnt/d/Labmembers/Deniz/aging_data/{s}""). curr_adata.var_names_make_unique(). all_adata.append(curr_adata). adata= ad.concat(all_adata). #I get the same type error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-pa",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/issues/2645:3006,usability,error,error,3006,"ype error when I try to do. adata.write('trial.hdf5') . #or. sc.pl.violin(adata, 'volume'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). Cell In[8], line 1. ----> 1 sc.pl.violin(adata, 'volume'). File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/plotting/_anndata.py:749, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 645 """"""\. 646 Violin plot. 647 . (...). 745 pl.stacked_violin. 746 """""". 747 import seaborn as sns # Slow import, only import if called. --> 749 sanitize_anndata(adata). 750 use_raw = _check_use_raw(adata, use_raw). 751 if isinstance(keys, str):. File /home/denizparmaksiz/anaconda3/envs/scanpy/lib/python3.9/site-packages/scanpy/_utils/__init__.py:406, in sanitize_anndata(adata). 404 def sanitize_anndata(adata):. 405 """"""Transform string annotations to categoricals."""""". --> 406 adata._sanitize(). File ~/.local/lib/python3.9/site-packages/anndata/_core/anndata.py:1228, in AnnData.strings_to_categoricals(self, df). 1226 if len(c.categories) >= len(c):. 1227 continue. ... 1232 ""AnnData, not on this view. You might encounter this"". 1233 ""error message while copying or writing to disk."". 1234 ). TypeError: reorder_categories() got an unexpected keyword argument 'inplace'. ```. ### Versions. <details>. ```. anndata 0.7.8. scanpy 1.9.3. -----. PIL 10.0.0. asttokens NA. backcall 0.2.0. clustergrammer2 0.18.0. comm 0.1.4. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.7.post1. decorator 5.1.1. executing 1.2.0. google NA. h5py 3.9.0. igraph 0.10.6. importlib_resources NA. ipykernel 6.25.1. ipywidgets 8.1.0. jedi 0.19.0. joblib 1.3.2. kiwisolver 1.4.4. leidenalg 0.9.0. ... Python 3.9.12 (main, Jun 1 2022, 11:38:51) [GCC 7.5.0]. Linux-5.10.16.3-microsoft-standard-WSL2-x86_64-with-glibc2.31. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2645
https://github.com/scverse/scanpy/pull/2646:319,safety,review,review,319,Improve code samples in `neighbors` docs; added some quotes to make the code copy-able in the docs. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2646
https://github.com/scverse/scanpy/pull/2646:319,testability,review,review,319,Improve code samples in `neighbors` docs; added some quotes to make the code copy-able in the docs. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2646
https://github.com/scverse/scanpy/pull/2646:170,usability,guid,guidelines,170,Improve code samples in `neighbors` docs; added some quotes to make the code copy-able in the docs. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2646
https://github.com/scverse/scanpy/pull/2646:201,usability,guid,guide,201,Improve code samples in `neighbors` docs; added some quotes to make the code copy-able in the docs. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2646
https://github.com/scverse/scanpy/pull/2646:297,usability,workflow,workflow,297,Improve code samples in `neighbors` docs; added some quotes to make the code copy-able in the docs. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2646
https://github.com/scverse/scanpy/pull/2647:148,deployability,integr,integrate,148,"correct scanorama_integrate docs; I just found a small mistake in the documentation of `scanorama_integrate`:. **kwargs are passed to assemble, not integrate. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2647
https://github.com/scverse/scanpy/pull/2647:148,integrability,integr,integrate,148,"correct scanorama_integrate docs; I just found a small mistake in the documentation of `scanorama_integrate`:. **kwargs are passed to assemble, not integrate. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2647
https://github.com/scverse/scanpy/pull/2647:148,interoperability,integr,integrate,148,"correct scanorama_integrate docs; I just found a small mistake in the documentation of `scanorama_integrate`:. **kwargs are passed to assemble, not integrate. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2647
https://github.com/scverse/scanpy/pull/2647:148,modifiability,integr,integrate,148,"correct scanorama_integrate docs; I just found a small mistake in the documentation of `scanorama_integrate`:. **kwargs are passed to assemble, not integrate. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2647
https://github.com/scverse/scanpy/pull/2647:148,reliability,integr,integrate,148,"correct scanorama_integrate docs; I just found a small mistake in the documentation of `scanorama_integrate`:. **kwargs are passed to assemble, not integrate. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2647
https://github.com/scverse/scanpy/pull/2647:378,safety,review,review,378,"correct scanorama_integrate docs; I just found a small mistake in the documentation of `scanorama_integrate`:. **kwargs are passed to assemble, not integrate. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2647
https://github.com/scverse/scanpy/pull/2647:148,security,integr,integrate,148,"correct scanorama_integrate docs; I just found a small mistake in the documentation of `scanorama_integrate`:. **kwargs are passed to assemble, not integrate. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2647
https://github.com/scverse/scanpy/pull/2647:148,testability,integr,integrate,148,"correct scanorama_integrate docs; I just found a small mistake in the documentation of `scanorama_integrate`:. **kwargs are passed to assemble, not integrate. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2647
https://github.com/scverse/scanpy/pull/2647:378,testability,review,review,378,"correct scanorama_integrate docs; I just found a small mistake in the documentation of `scanorama_integrate`:. **kwargs are passed to assemble, not integrate. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2647
https://github.com/scverse/scanpy/pull/2647:70,usability,document,documentation,70,"correct scanorama_integrate docs; I just found a small mistake in the documentation of `scanorama_integrate`:. **kwargs are passed to assemble, not integrate. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2647
https://github.com/scverse/scanpy/pull/2647:229,usability,guid,guidelines,229,"correct scanorama_integrate docs; I just found a small mistake in the documentation of `scanorama_integrate`:. **kwargs are passed to assemble, not integrate. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2647
https://github.com/scverse/scanpy/pull/2647:260,usability,guid,guide,260,"correct scanorama_integrate docs; I just found a small mistake in the documentation of `scanorama_integrate`:. **kwargs are passed to assemble, not integrate. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2647
https://github.com/scverse/scanpy/pull/2647:356,usability,workflow,workflow,356,"correct scanorama_integrate docs; I just found a small mistake in the documentation of `scanorama_integrate`:. **kwargs are passed to assemble, not integrate. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2647
https://github.com/scverse/scanpy/pull/2648:72,safety,Hot,Hotfix,72,"Fix and deprecate RAPIDS implementations in favor of rapids_singlecell; Hotfix for rapids nn:. * fixes bug with `random_state` for `RapidsKNNTransformer.__init__`. * now return distance matrix with `self.nn.kneighbors_graph(X_contiguous, mode=""distance"")`",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2648
https://github.com/scverse/scanpy/issues/2649:145,deployability,continu,continuation,145,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:229,deployability,api,api,229,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:577,deployability,modul,module,577,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:918,deployability,modul,module,918,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:955,deployability,modul,module,955,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:550,energy efficiency,current,currently,550,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:229,integrability,api,api,229,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:229,interoperability,api,api,229,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:577,modifiability,modul,module,577,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:918,modifiability,modul,module,918,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:955,modifiability,modul,module,955,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:311,performance,time,time,311,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:321,safety,test,test,321,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:400,safety,test,test,400,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:577,safety,modul,module,577,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:629,safety,test,test,629,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:918,safety,modul,module,918,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:955,safety,modul,module,955,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:1082,safety,test,test,1082,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:1428,safety,test,test,1428,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:1450,safety,test,test,1450,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:178,testability,simpl,simplify,178,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:321,testability,test,test,321,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:400,testability,test,test,400,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:629,testability,test,test,629,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:1082,testability,test,test,1082,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:1428,testability,test,test,1428,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:1450,testability,test,test,1450,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:8,usability,ergonom,ergonomics,8,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/issues/2649:178,usability,simpl,simplify,178,"Improve ergonomics of image comparison fixture; ### What kind of feature would you like to request? Other? ### Please describe your wishes. As a continuation of #1772, we should simplify how this is done. - [ ] Decide on fixture api. - [ ] Decide how generated outputs are handled (`.gitignore`-d, deleted each time that test is run, both?). My proposal for the first TODO is as follows. In order to test the image files. - ./_images/some_plot/expected.png. - ./_images/some_plot_x_context/expected.png.  against their `actual.png` counterparts, we currently do. ```py. # per module setup. ROOT = HERE / '_images'. # individual test. def test_some_plot(image_comparer):. save_and_compare_images = partial(image_comparer, ROOT, tol=15). ... save_and_compare_images('some_plot'). ... # and maybe. save_and_compare_images('some_plot_x_context'). ```. I propose we arrive here (with `--strict-markers` on):. ```py. # per module setup. @pytest.fixture(scope='module'). def compare_images_root():. """"""Set image root for save_and_compare_images."""""". return HERE / '_images'. # individual test. @pytest.mark.compare_images_tol(15). def test_some_plot(save_and_compare_images):. ... save_and_compare_images(). ... # and maybe. save_and_compare_images('x_context'). ```. for that we can make `save_and_compare_images`. 1. use the [`request`](https://docs.pytest.org/en/7.1.x/reference/reference.html#request) fixture to retrieve tol and test name. 2. use the test name for the png directory name used.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2649
https://github.com/scverse/scanpy/pull/2650:15,availability,cluster,cluster,15,Enforce stable cluster order in notebook test; This should fix the tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2650
https://github.com/scverse/scanpy/pull/2650:15,deployability,cluster,cluster,15,Enforce stable cluster order in notebook test; This should fix the tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2650
https://github.com/scverse/scanpy/pull/2650:41,safety,test,test,41,Enforce stable cluster order in notebook test; This should fix the tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2650
https://github.com/scverse/scanpy/pull/2650:67,safety,test,tests,67,Enforce stable cluster order in notebook test; This should fix the tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2650
https://github.com/scverse/scanpy/pull/2650:41,testability,test,test,41,Enforce stable cluster order in notebook test; This should fix the tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2650
https://github.com/scverse/scanpy/pull/2650:67,testability,test,tests,67,Enforce stable cluster order in notebook test; This should fix the tests,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2650
https://github.com/scverse/scanpy/issues/2653:924,availability,Error,Error,924,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:221,deployability,version,version,221,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:383,deployability,modul,module,383,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:465,deployability,modul,modularity,465,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:513,deployability,modul,modularity,513,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:564,deployability,modul,modularity,564,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:957,deployability,Version,Versions,957,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:2522,deployability,updat,updated,2522,"ularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0.12.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. stack_data 0.5.0. statsmodels 0.14.0. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. traitlets 5.3.0. typing_extensions NA. wcwidth 0.2.5. xxhash NA. yaml 6.0. zipp NA. zmq 23.2.1. zope NA. -----. IPython 8.4.0. jupyter_client 7.3.5. jupyter_core 4.11.1. jupyterlab 3.4.6. notebook 6.4.12. -----. Python 3.10.6 (main, Aug 9 2022, 08:40:02) [GCC 11.2.0]. Linux-6.2.0-1010-aws-x86_64-with-glibc2.35. -----. Session information updated at 2023-09-05 09:34. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:476,energy efficiency,optim,optimization,476,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:1080,energy efficiency,cloud,cloudpickle,1080,"ions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0.12.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. stack_data 0.5.0. statsmodels 0.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:221,integrability,version,version,221,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:465,integrability,modular,modularity,465,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:513,integrability,modular,modularity,513,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:564,integrability,modular,modularity,564,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:957,integrability,Version,Versions,957,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:395,interoperability,specif,specifying,395,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:221,modifiability,version,version,221,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:383,modifiability,modul,module,383,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:465,modifiability,modul,modularity,465,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:513,modifiability,modul,modularity,513,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:564,modifiability,modul,modularity,564,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:957,modifiability,Version,Versions,957,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:1195,modifiability,deco,decorator,1195,"exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0.12.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. stack_data 0.5.0. statsmodels 0.14.0. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. traitlets 5.3.0. t",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:1591,modifiability,pac,packaging,1591,"ularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0.12.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. stack_data 0.5.0. statsmodels 0.14.0. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. traitlets 5.3.0. typing_extensions NA. wcwidth 0.2.5. xxhash NA. yaml 6.0. zipp NA. zmq 23.2.1. zope NA. -----. IPython 8.4.0. jupyter_client 7.3.5. jupyter_core 4.11.1. jupyterlab 3.4.6. notebook 6.4.12. -----. Python 3.10.6 (main, Aug 9 2022, 08:40:02) [GCC 11.2.0]. Linux-6.2.0-1010-aws-x86_64-with-glibc2.35. -----. Session information updated at 2023-09-05 09:34. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:476,performance,optimiz,optimization,476,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:924,performance,Error,Error,924,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:383,safety,modul,module,383,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:465,safety,modul,modularity,465,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:513,safety,modul,modularity,513,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:564,safety,modul,modularity,564,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:600,safety,compl,completed,600,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:924,safety,Error,Error,924,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:2522,safety,updat,updated,2522,"ularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0.12.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. stack_data 0.5.0. statsmodels 0.14.0. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. traitlets 5.3.0. typing_extensions NA. wcwidth 0.2.5. xxhash NA. yaml 6.0. zipp NA. zmq 23.2.1. zope NA. -----. IPython 8.4.0. jupyter_client 7.3.5. jupyter_core 4.11.1. jupyterlab 3.4.6. notebook 6.4.12. -----. Python 3.10.6 (main, Aug 9 2022, 08:40:02) [GCC 11.2.0]. Linux-6.2.0-1010-aws-x86_64-with-glibc2.35. -----. Session information updated at 2023-09-05 09:34. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:600,security,compl,completed,600,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:2502,security,Session,Session,2502,"ularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0.12.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. stack_data 0.5.0. statsmodels 0.14.0. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. traitlets 5.3.0. typing_extensions NA. wcwidth 0.2.5. xxhash NA. yaml 6.0. zipp NA. zmq 23.2.1. zope NA. -----. IPython 8.4.0. jupyter_client 7.3.5. jupyter_core 4.11.1. jupyterlab 3.4.6. notebook 6.4.12. -----. Python 3.10.6 (main, Aug 9 2022, 08:40:02) [GCC 11.2.0]. Linux-6.2.0-1010-aws-x86_64-with-glibc2.35. -----. Session information updated at 2023-09-05 09:34. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:2522,security,updat,updated,2522,"ularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0.12.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. stack_data 0.5.0. statsmodels 0.14.0. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. traitlets 5.3.0. typing_extensions NA. wcwidth 0.2.5. xxhash NA. yaml 6.0. zipp NA. zmq 23.2.1. zope NA. -----. IPython 8.4.0. jupyter_client 7.3.5. jupyter_core 4.11.1. jupyterlab 3.4.6. notebook 6.4.12. -----. Python 3.10.6 (main, Aug 9 2022, 08:40:02) [GCC 11.2.0]. Linux-6.2.0-1010-aws-x86_64-with-glibc2.35. -----. Session information updated at 2023-09-05 09:34. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:465,testability,modula,modularity,465,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:513,testability,modula,modularity,513,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:564,testability,modula,modularity,564,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:181,usability,confirm,confirmed,181,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:264,usability,confirm,confirmed,264,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:716,usability,Minim,Minimal,716,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:924,usability,Error,Error,924,"PhenoGraph outputs Louvain method when using Leiden; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When running phenograph from the external module, and specifying `method='leiden'`, the output says that: . Running Louvain modularity optimization . After 1 runs, maximum modularity is Q = 0.794615. After 16 runs, maximum modularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/issues/2653:2155,usability,tool,toolz,2155,"ularity is Q = 0.796318. Louvain completed 36 runs in 2.867233991622925 seconds. `Louvain` in the above example should be changed to `Leiden`. . ### Minimal code sample. ```python. from scanpy import external. df = pd.DataFrame(np.zeros(1000,10)). phenograph = external.tl.phenograph . cluster_ph = phenograph(df.values, k=60, method='leiden')[0]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.4. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. dask 2023.6.0. dateutil 2.8.2. debugpy 1.6.3. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.0.0. functions NA. google NA. h5py 3.9.0. igraph 0.10.4. ipykernel 6.15.2. ipython_genutils 0.2.0. ipywidgets 8.0.2. jedi 0.18.1. jinja2 3.1.2. joblib 1.3.2. jupyter_server 1.18.1. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.1rc1. markupsafe 2.1.1. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.4.0. numba 0.57.1. numpy 1.24.4. packaging 21.3. pandas 1.4.4. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. phenograph 1.5.7. pickleshare 0.7.5. pkg_resources NA. plotly 5.14.1. prompt_toolkit 3.0.31. psutil 5.9.2. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 9.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.8.0. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.13.0. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.11.2. seaborn 0.12.2. session_info 1.0.0. six 1.16.0. sklearn 1.3.0. stack_data 0.5.0. statsmodels 0.14.0. tblib 1.7.0. texttable 1.6.7. threadpoolctl 3.1.0. tlz 0.12.0. toolz 0.12.0. tornado 6.2. traitlets 5.3.0. typing_extensions NA. wcwidth 0.2.5. xxhash NA. yaml 6.0. zipp NA. zmq 23.2.1. zope NA. -----. IPython 8.4.0. jupyter_client 7.3.5. jupyter_core 4.11.1. jupyterlab 3.4.6. notebook 6.4.12. -----. Python 3.10.6 (main, Aug 9 2022, 08:40:02) [GCC 11.2.0]. Linux-6.2.0-1010-aws-x86_64-with-glibc2.35. -----. Session information updated at 2023-09-05 09:34. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2653
https://github.com/scverse/scanpy/pull/2655:130,availability,down,downstream,130,Harmony 64bit; This PR makes `harmony_integrate` run with 64 bit floats. This makes it reproducible for `neighbors` and therefore downstream clustering.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655
https://github.com/scverse/scanpy/pull/2655:141,availability,cluster,clustering,141,Harmony 64bit; This PR makes `harmony_integrate` run with 64 bit floats. This makes it reproducible for `neighbors` and therefore downstream clustering.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655
https://github.com/scverse/scanpy/pull/2655:141,deployability,cluster,clustering,141,Harmony 64bit; This PR makes `harmony_integrate` run with 64 bit floats. This makes it reproducible for `neighbors` and therefore downstream clustering.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2655
https://github.com/scverse/scanpy/issues/2656:200,availability,slo,slow,200,"Datashader as plotting backend; ### What kind of feature would you like to request? Other? ### Please describe your wishes. When dealing with millions of cells, plotting embeddings becomes annoyingly slow. Datashader aggregates data points before plotting, which is much faster than just making a scatterplot in matplotlib. . For instance, making a multi-panel UMAP plot with 2M cells that takes 1min15s with `sc.pl.umap` takes 7s with [datashader+matplotlib](https://datashader.org/getting_started/Interactivity.html#native-support-for-matplotlib). I know datashader has come up before in different contexts (e.g. https://github.com/scverse/scanpy/issues/1263), but here I mainly suggest it for speed. . <img src=""https://github.com/scverse/scanpy/assets/7051479/da60149d-0f95-40a2-a9d5-147ee461aff5"" width=350 >. ---. FWIW, I made a prototype implementation of `sc.pl.embedding` with datashader. It's not feature-complete but covers some common use-cases: . https://gist.github.com/grst/424e3e24bf244820000c33a823a47ec1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2656
https://github.com/scverse/scanpy/issues/2656:200,reliability,slo,slow,200,"Datashader as plotting backend; ### What kind of feature would you like to request? Other? ### Please describe your wishes. When dealing with millions of cells, plotting embeddings becomes annoyingly slow. Datashader aggregates data points before plotting, which is much faster than just making a scatterplot in matplotlib. . For instance, making a multi-panel UMAP plot with 2M cells that takes 1min15s with `sc.pl.umap` takes 7s with [datashader+matplotlib](https://datashader.org/getting_started/Interactivity.html#native-support-for-matplotlib). I know datashader has come up before in different contexts (e.g. https://github.com/scverse/scanpy/issues/1263), but here I mainly suggest it for speed. . <img src=""https://github.com/scverse/scanpy/assets/7051479/da60149d-0f95-40a2-a9d5-147ee461aff5"" width=350 >. ---. FWIW, I made a prototype implementation of `sc.pl.embedding` with datashader. It's not feature-complete but covers some common use-cases: . https://gist.github.com/grst/424e3e24bf244820000c33a823a47ec1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2656
https://github.com/scverse/scanpy/issues/2656:915,safety,compl,complete,915,"Datashader as plotting backend; ### What kind of feature would you like to request? Other? ### Please describe your wishes. When dealing with millions of cells, plotting embeddings becomes annoyingly slow. Datashader aggregates data points before plotting, which is much faster than just making a scatterplot in matplotlib. . For instance, making a multi-panel UMAP plot with 2M cells that takes 1min15s with `sc.pl.umap` takes 7s with [datashader+matplotlib](https://datashader.org/getting_started/Interactivity.html#native-support-for-matplotlib). I know datashader has come up before in different contexts (e.g. https://github.com/scverse/scanpy/issues/1263), but here I mainly suggest it for speed. . <img src=""https://github.com/scverse/scanpy/assets/7051479/da60149d-0f95-40a2-a9d5-147ee461aff5"" width=350 >. ---. FWIW, I made a prototype implementation of `sc.pl.embedding` with datashader. It's not feature-complete but covers some common use-cases: . https://gist.github.com/grst/424e3e24bf244820000c33a823a47ec1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2656
https://github.com/scverse/scanpy/issues/2656:915,security,compl,complete,915,"Datashader as plotting backend; ### What kind of feature would you like to request? Other? ### Please describe your wishes. When dealing with millions of cells, plotting embeddings becomes annoyingly slow. Datashader aggregates data points before plotting, which is much faster than just making a scatterplot in matplotlib. . For instance, making a multi-panel UMAP plot with 2M cells that takes 1min15s with `sc.pl.umap` takes 7s with [datashader+matplotlib](https://datashader.org/getting_started/Interactivity.html#native-support-for-matplotlib). I know datashader has come up before in different contexts (e.g. https://github.com/scverse/scanpy/issues/1263), but here I mainly suggest it for speed. . <img src=""https://github.com/scverse/scanpy/assets/7051479/da60149d-0f95-40a2-a9d5-147ee461aff5"" width=350 >. ---. FWIW, I made a prototype implementation of `sc.pl.embedding` with datashader. It's not feature-complete but covers some common use-cases: . https://gist.github.com/grst/424e3e24bf244820000c33a823a47ec1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2656
https://github.com/scverse/scanpy/issues/2656:600,testability,context,contexts,600,"Datashader as plotting backend; ### What kind of feature would you like to request? Other? ### Please describe your wishes. When dealing with millions of cells, plotting embeddings becomes annoyingly slow. Datashader aggregates data points before plotting, which is much faster than just making a scatterplot in matplotlib. . For instance, making a multi-panel UMAP plot with 2M cells that takes 1min15s with `sc.pl.umap` takes 7s with [datashader+matplotlib](https://datashader.org/getting_started/Interactivity.html#native-support-for-matplotlib). I know datashader has come up before in different contexts (e.g. https://github.com/scverse/scanpy/issues/1263), but here I mainly suggest it for speed. . <img src=""https://github.com/scverse/scanpy/assets/7051479/da60149d-0f95-40a2-a9d5-147ee461aff5"" width=350 >. ---. FWIW, I made a prototype implementation of `sc.pl.embedding` with datashader. It's not feature-complete but covers some common use-cases: . https://gist.github.com/grst/424e3e24bf244820000c33a823a47ec1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2656
https://github.com/scverse/scanpy/issues/2656:499,usability,Interact,Interactivity,499,"Datashader as plotting backend; ### What kind of feature would you like to request? Other? ### Please describe your wishes. When dealing with millions of cells, plotting embeddings becomes annoyingly slow. Datashader aggregates data points before plotting, which is much faster than just making a scatterplot in matplotlib. . For instance, making a multi-panel UMAP plot with 2M cells that takes 1min15s with `sc.pl.umap` takes 7s with [datashader+matplotlib](https://datashader.org/getting_started/Interactivity.html#native-support-for-matplotlib). I know datashader has come up before in different contexts (e.g. https://github.com/scverse/scanpy/issues/1263), but here I mainly suggest it for speed. . <img src=""https://github.com/scverse/scanpy/assets/7051479/da60149d-0f95-40a2-a9d5-147ee461aff5"" width=350 >. ---. FWIW, I made a prototype implementation of `sc.pl.embedding` with datashader. It's not feature-complete but covers some common use-cases: . https://gist.github.com/grst/424e3e24bf244820000c33a823a47ec1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2656
https://github.com/scverse/scanpy/issues/2656:525,usability,support,support-for-matplotlib,525,"Datashader as plotting backend; ### What kind of feature would you like to request? Other? ### Please describe your wishes. When dealing with millions of cells, plotting embeddings becomes annoyingly slow. Datashader aggregates data points before plotting, which is much faster than just making a scatterplot in matplotlib. . For instance, making a multi-panel UMAP plot with 2M cells that takes 1min15s with `sc.pl.umap` takes 7s with [datashader+matplotlib](https://datashader.org/getting_started/Interactivity.html#native-support-for-matplotlib). I know datashader has come up before in different contexts (e.g. https://github.com/scverse/scanpy/issues/1263), but here I mainly suggest it for speed. . <img src=""https://github.com/scverse/scanpy/assets/7051479/da60149d-0f95-40a2-a9d5-147ee461aff5"" width=350 >. ---. FWIW, I made a prototype implementation of `sc.pl.embedding` with datashader. It's not feature-complete but covers some common use-cases: . https://gist.github.com/grst/424e3e24bf244820000c33a823a47ec1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2656
https://github.com/scverse/scanpy/issues/2656:835,usability,prototyp,prototype,835,"Datashader as plotting backend; ### What kind of feature would you like to request? Other? ### Please describe your wishes. When dealing with millions of cells, plotting embeddings becomes annoyingly slow. Datashader aggregates data points before plotting, which is much faster than just making a scatterplot in matplotlib. . For instance, making a multi-panel UMAP plot with 2M cells that takes 1min15s with `sc.pl.umap` takes 7s with [datashader+matplotlib](https://datashader.org/getting_started/Interactivity.html#native-support-for-matplotlib). I know datashader has come up before in different contexts (e.g. https://github.com/scverse/scanpy/issues/1263), but here I mainly suggest it for speed. . <img src=""https://github.com/scverse/scanpy/assets/7051479/da60149d-0f95-40a2-a9d5-147ee461aff5"" width=350 >. ---. FWIW, I made a prototype implementation of `sc.pl.embedding` with datashader. It's not feature-complete but covers some common use-cases: . https://gist.github.com/grst/424e3e24bf244820000c33a823a47ec1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2656
https://github.com/scverse/scanpy/pull/2657:579,energy efficiency,current,current,579,Add note to the groups arg in rank_genes_groups(); <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. It was unclear if the `groups` argument in `rank_genes_groups()` is equivalent to subsetting when `reference='rest'`(i.e. only the selected groups are tested against each other) or if only those groups are tested but all groups are still used as the reference. This PR adds a note explaining the current behaviour (option 2).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2657
https://github.com/scverse/scanpy/pull/2657:365,integrability,sub,subsetting,365,Add note to the groups arg in rank_genes_groups(); <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. It was unclear if the `groups` argument in `rank_genes_groups()` is equivalent to subsetting when `reference='rest'`(i.e. only the selected groups are tested against each other) or if only those groups are tested but all groups are still used as the reference. This PR adds a note explaining the current behaviour (option 2).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2657
https://github.com/scverse/scanpy/pull/2657:270,safety,review,review,270,Add note to the groups arg in rank_genes_groups(); <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. It was unclear if the `groups` argument in `rank_genes_groups()` is equivalent to subsetting when `reference='rest'`(i.e. only the selected groups are tested against each other) or if only those groups are tested but all groups are still used as the reference. This PR adds a note explaining the current behaviour (option 2).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2657
https://github.com/scverse/scanpy/pull/2657:434,safety,test,tested,434,Add note to the groups arg in rank_genes_groups(); <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. It was unclear if the `groups` argument in `rank_genes_groups()` is equivalent to subsetting when `reference='rest'`(i.e. only the selected groups are tested against each other) or if only those groups are tested but all groups are still used as the reference. This PR adds a note explaining the current behaviour (option 2).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2657
https://github.com/scverse/scanpy/pull/2657:489,safety,test,tested,489,Add note to the groups arg in rank_genes_groups(); <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. It was unclear if the `groups` argument in `rank_genes_groups()` is equivalent to subsetting when `reference='rest'`(i.e. only the selected groups are tested against each other) or if only those groups are tested but all groups are still used as the reference. This PR adds a note explaining the current behaviour (option 2).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2657
https://github.com/scverse/scanpy/pull/2657:270,testability,review,review,270,Add note to the groups arg in rank_genes_groups(); <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. It was unclear if the `groups` argument in `rank_genes_groups()` is equivalent to subsetting when `reference='rest'`(i.e. only the selected groups are tested against each other) or if only those groups are tested but all groups are still used as the reference. This PR adds a note explaining the current behaviour (option 2).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2657
https://github.com/scverse/scanpy/pull/2657:434,testability,test,tested,434,Add note to the groups arg in rank_genes_groups(); <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. It was unclear if the `groups` argument in `rank_genes_groups()` is equivalent to subsetting when `reference='rest'`(i.e. only the selected groups are tested against each other) or if only those groups are tested but all groups are still used as the reference. This PR adds a note explaining the current behaviour (option 2).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2657
https://github.com/scverse/scanpy/pull/2657:489,testability,test,tested,489,Add note to the groups arg in rank_genes_groups(); <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. It was unclear if the `groups` argument in `rank_genes_groups()` is equivalent to subsetting when `reference='rest'`(i.e. only the selected groups are tested against each other) or if only those groups are tested but all groups are still used as the reference. This PR adds a note explaining the current behaviour (option 2).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2657
https://github.com/scverse/scanpy/pull/2657:121,usability,guid,guidelines,121,Add note to the groups arg in rank_genes_groups(); <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. It was unclear if the `groups` argument in `rank_genes_groups()` is equivalent to subsetting when `reference='rest'`(i.e. only the selected groups are tested against each other) or if only those groups are tested but all groups are still used as the reference. This PR adds a note explaining the current behaviour (option 2).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2657
https://github.com/scverse/scanpy/pull/2657:152,usability,guid,guide,152,Add note to the groups arg in rank_genes_groups(); <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. It was unclear if the `groups` argument in `rank_genes_groups()` is equivalent to subsetting when `reference='rest'`(i.e. only the selected groups are tested against each other) or if only those groups are tested but all groups are still used as the reference. This PR adds a note explaining the current behaviour (option 2).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2657
https://github.com/scverse/scanpy/pull/2657:248,usability,workflow,workflow,248,Add note to the groups arg in rank_genes_groups(); <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. It was unclear if the `groups` argument in `rank_genes_groups()` is equivalent to subsetting when `reference='rest'`(i.e. only the selected groups are tested against each other) or if only those groups are tested but all groups are still used as the reference. This PR adds a note explaining the current behaviour (option 2).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2657
https://github.com/scverse/scanpy/pull/2657:587,usability,behavi,behaviour,587,Add note to the groups arg in rank_genes_groups(); <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. It was unclear if the `groups` argument in `rank_genes_groups()` is equivalent to subsetting when `reference='rest'`(i.e. only the selected groups are tested against each other) or if only those groups are tested but all groups are still used as the reference. This PR adds a note explaining the current behaviour (option 2).,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2657
https://github.com/scverse/scanpy/pull/2658:132,deployability,releas,release,132,Remove use of AnnData constructor dtype kwarg; As it's scheduled to be removed in anndata 0.10.0. This will require a quick bug fix release. It may also require bumping the anndata dependency to >0.8.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2658
https://github.com/scverse/scanpy/pull/2658:181,deployability,depend,dependency,181,Remove use of AnnData constructor dtype kwarg; As it's scheduled to be removed in anndata 0.10.0. This will require a quick bug fix release. It may also require bumping the anndata dependency to >0.8.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2658
https://github.com/scverse/scanpy/pull/2658:55,energy efficiency,schedul,scheduled,55,Remove use of AnnData constructor dtype kwarg; As it's scheduled to be removed in anndata 0.10.0. This will require a quick bug fix release. It may also require bumping the anndata dependency to >0.8.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2658
https://github.com/scverse/scanpy/pull/2658:181,integrability,depend,dependency,181,Remove use of AnnData constructor dtype kwarg; As it's scheduled to be removed in anndata 0.10.0. This will require a quick bug fix release. It may also require bumping the anndata dependency to >0.8.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2658
https://github.com/scverse/scanpy/pull/2658:181,modifiability,depend,dependency,181,Remove use of AnnData constructor dtype kwarg; As it's scheduled to be removed in anndata 0.10.0. This will require a quick bug fix release. It may also require bumping the anndata dependency to >0.8.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2658
https://github.com/scverse/scanpy/pull/2658:55,performance,schedul,scheduled,55,Remove use of AnnData constructor dtype kwarg; As it's scheduled to be removed in anndata 0.10.0. This will require a quick bug fix release. It may also require bumping the anndata dependency to >0.8.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2658
https://github.com/scverse/scanpy/pull/2658:181,safety,depend,dependency,181,Remove use of AnnData constructor dtype kwarg; As it's scheduled to be removed in anndata 0.10.0. This will require a quick bug fix release. It may also require bumping the anndata dependency to >0.8.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2658
https://github.com/scverse/scanpy/pull/2658:181,testability,depend,dependency,181,Remove use of AnnData constructor dtype kwarg; As it's scheduled to be removed in anndata 0.10.0. This will require a quick bug fix release. It may also require bumping the anndata dependency to >0.8.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2658
https://github.com/scverse/scanpy/pull/2659:106,deployability,releas,release,106,Remove use of AnnData constructor dtype kwarg (#2658); * Remove use of AnnData constructor dtype kwarg. * release note. * Fix release note. (cherry picked from commit 0b49eebbcf6007e2fa742763e382d99e6a151a78). <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2659
https://github.com/scverse/scanpy/pull/2659:126,deployability,releas,release,126,Remove use of AnnData constructor dtype kwarg (#2658); * Remove use of AnnData constructor dtype kwarg. * release note. * Fix release note. (cherry picked from commit 0b49eebbcf6007e2fa742763e382d99e6a151a78). <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2659
https://github.com/scverse/scanpy/pull/2659:429,safety,review,review,429,Remove use of AnnData constructor dtype kwarg (#2658); * Remove use of AnnData constructor dtype kwarg. * release note. * Fix release note. (cherry picked from commit 0b49eebbcf6007e2fa742763e382d99e6a151a78). <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2659
https://github.com/scverse/scanpy/pull/2659:429,testability,review,review,429,Remove use of AnnData constructor dtype kwarg (#2658); * Remove use of AnnData constructor dtype kwarg. * release note. * Fix release note. (cherry picked from commit 0b49eebbcf6007e2fa742763e382d99e6a151a78). <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2659
https://github.com/scverse/scanpy/pull/2659:280,usability,guid,guidelines,280,Remove use of AnnData constructor dtype kwarg (#2658); * Remove use of AnnData constructor dtype kwarg. * release note. * Fix release note. (cherry picked from commit 0b49eebbcf6007e2fa742763e382d99e6a151a78). <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2659
https://github.com/scverse/scanpy/pull/2659:311,usability,guid,guide,311,Remove use of AnnData constructor dtype kwarg (#2658); * Remove use of AnnData constructor dtype kwarg. * release note. * Fix release note. (cherry picked from commit 0b49eebbcf6007e2fa742763e382d99e6a151a78). <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2659
https://github.com/scverse/scanpy/pull/2659:407,usability,workflow,workflow,407,Remove use of AnnData constructor dtype kwarg (#2658); * Remove use of AnnData constructor dtype kwarg. * release note. * Fix release note. (cherry picked from commit 0b49eebbcf6007e2fa742763e382d99e6a151a78). <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2659
https://github.com/scverse/scanpy/pull/2660:232,safety,review,review,232,Start 1.9.6; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2660
https://github.com/scverse/scanpy/pull/2660:232,testability,review,review,232,Start 1.9.6; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2660
https://github.com/scverse/scanpy/pull/2660:83,usability,guid,guidelines,83,Start 1.9.6; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2660
https://github.com/scverse/scanpy/pull/2660:114,usability,guid,guide,114,Start 1.9.6; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2660
https://github.com/scverse/scanpy/pull/2660:210,usability,workflow,workflow,210,Start 1.9.6; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2660
https://github.com/scverse/scanpy/issues/2662:0,deployability,Integr,Integration,0,"Integration across SmartSeq2 and 10X Datasets; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis? Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662
https://github.com/scverse/scanpy/issues/2662:230,deployability,integr,integrate,230,"Integration across SmartSeq2 and 10X Datasets; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis? Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662
https://github.com/scverse/scanpy/issues/2662:426,deployability,integr,integrate,426,"Integration across SmartSeq2 and 10X Datasets; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis? Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662
https://github.com/scverse/scanpy/issues/2662:0,integrability,Integr,Integration,0,"Integration across SmartSeq2 and 10X Datasets; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis? Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662
https://github.com/scverse/scanpy/issues/2662:230,integrability,integr,integrate,230,"Integration across SmartSeq2 and 10X Datasets; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis? Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662
https://github.com/scverse/scanpy/issues/2662:426,integrability,integr,integrate,426,"Integration across SmartSeq2 and 10X Datasets; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis? Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662
https://github.com/scverse/scanpy/issues/2662:0,interoperability,Integr,Integration,0,"Integration across SmartSeq2 and 10X Datasets; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis? Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662
https://github.com/scverse/scanpy/issues/2662:230,interoperability,integr,integrate,230,"Integration across SmartSeq2 and 10X Datasets; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis? Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662
https://github.com/scverse/scanpy/issues/2662:297,interoperability,platform,platforms,297,"Integration across SmartSeq2 and 10X Datasets; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis? Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662
https://github.com/scverse/scanpy/issues/2662:426,interoperability,integr,integrate,426,"Integration across SmartSeq2 and 10X Datasets; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis? Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662
https://github.com/scverse/scanpy/issues/2662:0,modifiability,Integr,Integration,0,"Integration across SmartSeq2 and 10X Datasets; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis? Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662
https://github.com/scverse/scanpy/issues/2662:119,modifiability,paramet,parameters,119,"Integration across SmartSeq2 and 10X Datasets; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis? Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662
https://github.com/scverse/scanpy/issues/2662:230,modifiability,integr,integrate,230,"Integration across SmartSeq2 and 10X Datasets; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis? Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662
https://github.com/scverse/scanpy/issues/2662:426,modifiability,integr,integrate,426,"Integration across SmartSeq2 and 10X Datasets; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis? Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662
https://github.com/scverse/scanpy/issues/2662:0,reliability,Integr,Integration,0,"Integration across SmartSeq2 and 10X Datasets; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis? Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662
https://github.com/scverse/scanpy/issues/2662:230,reliability,integr,integrate,230,"Integration across SmartSeq2 and 10X Datasets; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis? Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662
https://github.com/scverse/scanpy/issues/2662:426,reliability,integr,integrate,426,"Integration across SmartSeq2 and 10X Datasets; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis? Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662
https://github.com/scverse/scanpy/issues/2662:0,security,Integr,Integration,0,"Integration across SmartSeq2 and 10X Datasets; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis? Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662
https://github.com/scverse/scanpy/issues/2662:230,security,integr,integrate,230,"Integration across SmartSeq2 and 10X Datasets; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis? Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662
https://github.com/scverse/scanpy/issues/2662:426,security,integr,integrate,426,"Integration across SmartSeq2 and 10X Datasets; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis? Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662
https://github.com/scverse/scanpy/issues/2662:0,testability,Integr,Integration,0,"Integration across SmartSeq2 and 10X Datasets; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis? Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662
https://github.com/scverse/scanpy/issues/2662:230,testability,integr,integrate,230,"Integration across SmartSeq2 and 10X Datasets; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis? Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662
https://github.com/scverse/scanpy/issues/2662:426,testability,integr,integrate,426,"Integration across SmartSeq2 and 10X Datasets; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. I am trying to integrate some datasets that were generated with SmartSeq2 and 10X platforms. For the SmartSeq2 datasets, I only got the TPM data, while for the 10x data,I got raw counts matrix. How to merge and integrate SmartSeq2 and 10X Datasets? Can the TPM and raw counts be merged for analysis? Thank you in advance for your assistance.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2662
https://github.com/scverse/scanpy/issues/2663:656,energy efficiency,draw,draw,656,"When you enter a dictonary var.name in sc.pl.dotplot, it converts the size of the text to the right of the plot.; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. ![ 2023-09-12 194600](https://github.com/scverse/scanpy/assets/79529451/965f2e8c-1c23-4ee6-a778-9f28363e2504). Hello. As the title suggests, sc.pl .dotplot var dictionary.I'm very curious about how to change the size of the text on the right side of the picture when using the name. Below is the code I'm using. Even if I look for the source code, I can't find the part where I draw by receiving the dictionary as input, and I can't find the part that is saved. Thank you. dp18 = sc.pl.dotplot(total_adata[total_adata.obs['author_cell_type'] == 'CD14+_Monocyte'], cd14_p_monocyte, groupby='age_group',. dendrogram=False,title = ""CD14+_Monocyte"",swap_axes=True,gene_symbols=""feature_name"",cmap=""RdBu_r"",. standard_scale = ""var"",figsize=(7,15),return_fig=True). #dp18.legend(show_size_legend = False,width = 1.5). axes_dict18 = dp18.get_axes(). for tick18 in axes_dict18['mainplot_ax'].get_yticklabels():. tick18.set_rotation(0). for lab in axes_dict18['mainplot_ax'].get_yticklabels():. lab.set_fontstyle('italic'). #lab.set_fontsize(14). for lab in axes_dict18['mainplot_ax'].get_yticklabels():. lab.set_fontweight('bold'). #lab.set_fontsize(14). for lab in axes_dict18['mainplot_ax'].get_xticklabels():. lab.set_fontweight('bold'). #lab.set_fontsize(14). axes_dict18['mainplot_ax'].set_title(""CD14+_Monocyte MT gene"", fontsize=16, fontweight='bold', zorder=10). plt.tight_layout(). plt.savefig('savefig_CD14_monocyte_mt_dotplot.png',dpi=600). @falexwolf . @ivirshup . @flying-sheep . @fidelram . @gokceneraslan . @Koncopd . @giovp . @awnimo . @adamgayoso .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2663
https://github.com/scverse/scanpy/issues/2663:186,modifiability,paramet,parameters,186,"When you enter a dictonary var.name in sc.pl.dotplot, it converts the size of the text to the right of the plot.; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. ![ 2023-09-12 194600](https://github.com/scverse/scanpy/assets/79529451/965f2e8c-1c23-4ee6-a778-9f28363e2504). Hello. As the title suggests, sc.pl .dotplot var dictionary.I'm very curious about how to change the size of the text on the right side of the picture when using the name. Below is the code I'm using. Even if I look for the source code, I can't find the part where I draw by receiving the dictionary as input, and I can't find the part that is saved. Thank you. dp18 = sc.pl.dotplot(total_adata[total_adata.obs['author_cell_type'] == 'CD14+_Monocyte'], cd14_p_monocyte, groupby='age_group',. dendrogram=False,title = ""CD14+_Monocyte"",swap_axes=True,gene_symbols=""feature_name"",cmap=""RdBu_r"",. standard_scale = ""var"",figsize=(7,15),return_fig=True). #dp18.legend(show_size_legend = False,width = 1.5). axes_dict18 = dp18.get_axes(). for tick18 in axes_dict18['mainplot_ax'].get_yticklabels():. tick18.set_rotation(0). for lab in axes_dict18['mainplot_ax'].get_yticklabels():. lab.set_fontstyle('italic'). #lab.set_fontsize(14). for lab in axes_dict18['mainplot_ax'].get_yticklabels():. lab.set_fontweight('bold'). #lab.set_fontsize(14). for lab in axes_dict18['mainplot_ax'].get_xticklabels():. lab.set_fontweight('bold'). #lab.set_fontsize(14). axes_dict18['mainplot_ax'].set_title(""CD14+_Monocyte MT gene"", fontsize=16, fontweight='bold', zorder=10). plt.tight_layout(). plt.savefig('savefig_CD14_monocyte_mt_dotplot.png',dpi=600). @falexwolf . @ivirshup . @flying-sheep . @fidelram . @gokceneraslan . @Koncopd . @giovp . @awnimo . @adamgayoso .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2663
https://github.com/scverse/scanpy/issues/2663:692,safety,input,input,692,"When you enter a dictonary var.name in sc.pl.dotplot, it converts the size of the text to the right of the plot.; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. ![ 2023-09-12 194600](https://github.com/scverse/scanpy/assets/79529451/965f2e8c-1c23-4ee6-a778-9f28363e2504). Hello. As the title suggests, sc.pl .dotplot var dictionary.I'm very curious about how to change the size of the text on the right side of the picture when using the name. Below is the code I'm using. Even if I look for the source code, I can't find the part where I draw by receiving the dictionary as input, and I can't find the part that is saved. Thank you. dp18 = sc.pl.dotplot(total_adata[total_adata.obs['author_cell_type'] == 'CD14+_Monocyte'], cd14_p_monocyte, groupby='age_group',. dendrogram=False,title = ""CD14+_Monocyte"",swap_axes=True,gene_symbols=""feature_name"",cmap=""RdBu_r"",. standard_scale = ""var"",figsize=(7,15),return_fig=True). #dp18.legend(show_size_legend = False,width = 1.5). axes_dict18 = dp18.get_axes(). for tick18 in axes_dict18['mainplot_ax'].get_yticklabels():. tick18.set_rotation(0). for lab in axes_dict18['mainplot_ax'].get_yticklabels():. lab.set_fontstyle('italic'). #lab.set_fontsize(14). for lab in axes_dict18['mainplot_ax'].get_yticklabels():. lab.set_fontweight('bold'). #lab.set_fontsize(14). for lab in axes_dict18['mainplot_ax'].get_xticklabels():. lab.set_fontweight('bold'). #lab.set_fontsize(14). axes_dict18['mainplot_ax'].set_title(""CD14+_Monocyte MT gene"", fontsize=16, fontweight='bold', zorder=10). plt.tight_layout(). plt.savefig('savefig_CD14_monocyte_mt_dotplot.png',dpi=600). @falexwolf . @ivirshup . @flying-sheep . @fidelram . @gokceneraslan . @Koncopd . @giovp . @awnimo . @adamgayoso .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2663
https://github.com/scverse/scanpy/issues/2663:692,usability,input,input,692,"When you enter a dictonary var.name in sc.pl.dotplot, it converts the size of the text to the right of the plot.; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. ![ 2023-09-12 194600](https://github.com/scverse/scanpy/assets/79529451/965f2e8c-1c23-4ee6-a778-9f28363e2504). Hello. As the title suggests, sc.pl .dotplot var dictionary.I'm very curious about how to change the size of the text on the right side of the picture when using the name. Below is the code I'm using. Even if I look for the source code, I can't find the part where I draw by receiving the dictionary as input, and I can't find the part that is saved. Thank you. dp18 = sc.pl.dotplot(total_adata[total_adata.obs['author_cell_type'] == 'CD14+_Monocyte'], cd14_p_monocyte, groupby='age_group',. dendrogram=False,title = ""CD14+_Monocyte"",swap_axes=True,gene_symbols=""feature_name"",cmap=""RdBu_r"",. standard_scale = ""var"",figsize=(7,15),return_fig=True). #dp18.legend(show_size_legend = False,width = 1.5). axes_dict18 = dp18.get_axes(). for tick18 in axes_dict18['mainplot_ax'].get_yticklabels():. tick18.set_rotation(0). for lab in axes_dict18['mainplot_ax'].get_yticklabels():. lab.set_fontstyle('italic'). #lab.set_fontsize(14). for lab in axes_dict18['mainplot_ax'].get_yticklabels():. lab.set_fontweight('bold'). #lab.set_fontsize(14). for lab in axes_dict18['mainplot_ax'].get_xticklabels():. lab.set_fontweight('bold'). #lab.set_fontsize(14). axes_dict18['mainplot_ax'].set_title(""CD14+_Monocyte MT gene"", fontsize=16, fontweight='bold', zorder=10). plt.tight_layout(). plt.savefig('savefig_CD14_monocyte_mt_dotplot.png',dpi=600). @falexwolf . @ivirshup . @flying-sheep . @fidelram . @gokceneraslan . @Koncopd . @giovp . @awnimo . @adamgayoso .",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2663
https://github.com/scverse/scanpy/pull/2664:0,deployability,Updat,Update,0,Update Neighbors docstring; updates the function link to `pp.neighbors` for rapids-singlecell,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2664
https://github.com/scverse/scanpy/pull/2664:28,deployability,updat,updates,28,Update Neighbors docstring; updates the function link to `pp.neighbors` for rapids-singlecell,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2664
https://github.com/scverse/scanpy/pull/2664:0,safety,Updat,Update,0,Update Neighbors docstring; updates the function link to `pp.neighbors` for rapids-singlecell,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2664
https://github.com/scverse/scanpy/pull/2664:28,safety,updat,updates,28,Update Neighbors docstring; updates the function link to `pp.neighbors` for rapids-singlecell,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2664
https://github.com/scverse/scanpy/pull/2664:0,security,Updat,Update,0,Update Neighbors docstring; updates the function link to `pp.neighbors` for rapids-singlecell,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2664
https://github.com/scverse/scanpy/pull/2664:28,security,updat,updates,28,Update Neighbors docstring; updates the function link to `pp.neighbors` for rapids-singlecell,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2664
https://github.com/scverse/scanpy/issues/2665:824,availability,Error,Error,824,"Zoomed out PAGA output; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . I cannot produce normal looking paga plot. Whether I am using my own data or datasets provided through scanpy, the output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes? Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python. adata2 = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata2, groups='louvain'). sc.pl.paga(adata2). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.5. -----. PIL 8.0.1. backcall 0.2.0. bottleneck 1.3.7. cellrank 1.5.1. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. decorator 5.1.1. docrep 0.3.2. google NA. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 3.0.3. joblib 1.2.0. kiwisolver 1.3.0. leidenalg 0.9.1. llvmlite 0.34.0. lz4 3.1.10. markupsafe 2.1.3. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.51.2. numexpr 2.8.5. numpy 1.23.5. packaging 23.1. pandas 1.5.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 4.2.0. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pygpcca 1.0.4. pyparsing 2.4.7. python_utils NA. pytz 2020.1. ruamel NA. scipy 1.10.1. scvelo 0.2.5. seaborn 0.11.0. session_info 1.0.0. six 1.15.0. sklearn 1.2.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.1.0. tlz 0.12.1. toolz 0.11.1. tornado 6.1. tqdm 4.50.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2665:192,deployability,version,version,192,"Zoomed out PAGA output; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . I cannot produce normal looking paga plot. Whether I am using my own data or datasets provided through scanpy, the output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes? Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python. adata2 = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata2, groups='louvain'). sc.pl.paga(adata2). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.5. -----. PIL 8.0.1. backcall 0.2.0. bottleneck 1.3.7. cellrank 1.5.1. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. decorator 5.1.1. docrep 0.3.2. google NA. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 3.0.3. joblib 1.2.0. kiwisolver 1.3.0. leidenalg 0.9.1. llvmlite 0.34.0. lz4 3.1.10. markupsafe 2.1.3. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.51.2. numexpr 2.8.5. numpy 1.23.5. packaging 23.1. pandas 1.5.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 4.2.0. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pygpcca 1.0.4. pyparsing 2.4.7. python_utils NA. pytz 2020.1. ruamel NA. scipy 1.10.1. scvelo 0.2.5. seaborn 0.11.0. session_info 1.0.0. six 1.15.0. sklearn 1.2.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.1.0. tlz 0.12.1. toolz 0.11.1. tornado 6.1. tqdm 4.50.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2665:857,deployability,Version,Versions,857,"Zoomed out PAGA output; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . I cannot produce normal looking paga plot. Whether I am using my own data or datasets provided through scanpy, the output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes? Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python. adata2 = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata2, groups='louvain'). sc.pl.paga(adata2). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.5. -----. PIL 8.0.1. backcall 0.2.0. bottleneck 1.3.7. cellrank 1.5.1. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. decorator 5.1.1. docrep 0.3.2. google NA. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 3.0.3. joblib 1.2.0. kiwisolver 1.3.0. leidenalg 0.9.1. llvmlite 0.34.0. lz4 3.1.10. markupsafe 2.1.3. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.51.2. numexpr 2.8.5. numpy 1.23.5. packaging 23.1. pandas 1.5.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 4.2.0. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pygpcca 1.0.4. pyparsing 2.4.7. python_utils NA. pytz 2020.1. ruamel NA. scipy 1.10.1. scvelo 0.2.5. seaborn 0.11.0. session_info 1.0.0. six 1.15.0. sklearn 1.2.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.1.0. tlz 0.12.1. toolz 0.11.1. tornado 6.1. tqdm 4.50.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2665:2332,deployability,updat,updated,2332,"e output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes? Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python. adata2 = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata2, groups='louvain'). sc.pl.paga(adata2). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.5. -----. PIL 8.0.1. backcall 0.2.0. bottleneck 1.3.7. cellrank 1.5.1. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. decorator 5.1.1. docrep 0.3.2. google NA. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 3.0.3. joblib 1.2.0. kiwisolver 1.3.0. leidenalg 0.9.1. llvmlite 0.34.0. lz4 3.1.10. markupsafe 2.1.3. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.51.2. numexpr 2.8.5. numpy 1.23.5. packaging 23.1. pandas 1.5.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 4.2.0. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pygpcca 1.0.4. pyparsing 2.4.7. python_utils NA. pytz 2020.1. ruamel NA. scipy 1.10.1. scvelo 0.2.5. seaborn 0.11.0. session_info 1.0.0. six 1.15.0. sklearn 1.2.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.1.0. tlz 0.12.1. toolz 0.11.1. tornado 6.1. tqdm 4.50.2. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. wrapt 1.15.0. yaml 5.3.1. zipp NA. zmq 19.0.2. zope NA. -----. IPython 7.25.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.0. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.4.0-137-generic-x86_64-with-glibc2.10. -----. Session information updated at 2023-09-15 09:42. Running scvelo 0.2.5 (python 3.8.5) on 2023-09-15 09:42. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2665:1000,energy efficiency,cloud,cloudpickle,1000," out PAGA output; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . I cannot produce normal looking paga plot. Whether I am using my own data or datasets provided through scanpy, the output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes? Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python. adata2 = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata2, groups='louvain'). sc.pl.paga(adata2). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.5. -----. PIL 8.0.1. backcall 0.2.0. bottleneck 1.3.7. cellrank 1.5.1. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. decorator 5.1.1. docrep 0.3.2. google NA. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 3.0.3. joblib 1.2.0. kiwisolver 1.3.0. leidenalg 0.9.1. llvmlite 0.34.0. lz4 3.1.10. markupsafe 2.1.3. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.51.2. numexpr 2.8.5. numpy 1.23.5. packaging 23.1. pandas 1.5.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 4.2.0. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pygpcca 1.0.4. pyparsing 2.4.7. python_utils NA. pytz 2020.1. ruamel NA. scipy 1.10.1. scvelo 0.2.5. seaborn 0.11.0. session_info 1.0.0. six 1.15.0. sklearn 1.2.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.1.0. tlz 0.12.1. toolz 0.11.1. tornado 6.1. tqdm 4.50.2. trait",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2665:192,integrability,version,version,192,"Zoomed out PAGA output; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . I cannot produce normal looking paga plot. Whether I am using my own data or datasets provided through scanpy, the output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes? Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python. adata2 = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata2, groups='louvain'). sc.pl.paga(adata2). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.5. -----. PIL 8.0.1. backcall 0.2.0. bottleneck 1.3.7. cellrank 1.5.1. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. decorator 5.1.1. docrep 0.3.2. google NA. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 3.0.3. joblib 1.2.0. kiwisolver 1.3.0. leidenalg 0.9.1. llvmlite 0.34.0. lz4 3.1.10. markupsafe 2.1.3. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.51.2. numexpr 2.8.5. numpy 1.23.5. packaging 23.1. pandas 1.5.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 4.2.0. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pygpcca 1.0.4. pyparsing 2.4.7. python_utils NA. pytz 2020.1. ruamel NA. scipy 1.10.1. scvelo 0.2.5. seaborn 0.11.0. session_info 1.0.0. six 1.15.0. sklearn 1.2.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.1.0. tlz 0.12.1. toolz 0.11.1. tornado 6.1. tqdm 4.50.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2665:857,integrability,Version,Versions,857,"Zoomed out PAGA output; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . I cannot produce normal looking paga plot. Whether I am using my own data or datasets provided through scanpy, the output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes? Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python. adata2 = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata2, groups='louvain'). sc.pl.paga(adata2). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.5. -----. PIL 8.0.1. backcall 0.2.0. bottleneck 1.3.7. cellrank 1.5.1. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. decorator 5.1.1. docrep 0.3.2. google NA. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 3.0.3. joblib 1.2.0. kiwisolver 1.3.0. leidenalg 0.9.1. llvmlite 0.34.0. lz4 3.1.10. markupsafe 2.1.3. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.51.2. numexpr 2.8.5. numpy 1.23.5. packaging 23.1. pandas 1.5.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 4.2.0. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pygpcca 1.0.4. pyparsing 2.4.7. python_utils NA. pytz 2020.1. ruamel NA. scipy 1.10.1. scvelo 0.2.5. seaborn 0.11.0. session_info 1.0.0. six 1.15.0. sklearn 1.2.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.1.0. tlz 0.12.1. toolz 0.11.1. tornado 6.1. tqdm 4.50.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2665:2055,integrability,wrap,wrapt,2055,"e output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes? Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python. adata2 = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata2, groups='louvain'). sc.pl.paga(adata2). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.5. -----. PIL 8.0.1. backcall 0.2.0. bottleneck 1.3.7. cellrank 1.5.1. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. decorator 5.1.1. docrep 0.3.2. google NA. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 3.0.3. joblib 1.2.0. kiwisolver 1.3.0. leidenalg 0.9.1. llvmlite 0.34.0. lz4 3.1.10. markupsafe 2.1.3. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.51.2. numexpr 2.8.5. numpy 1.23.5. packaging 23.1. pandas 1.5.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 4.2.0. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pygpcca 1.0.4. pyparsing 2.4.7. python_utils NA. pytz 2020.1. ruamel NA. scipy 1.10.1. scvelo 0.2.5. seaborn 0.11.0. session_info 1.0.0. six 1.15.0. sklearn 1.2.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.1.0. tlz 0.12.1. toolz 0.11.1. tornado 6.1. tqdm 4.50.2. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. wrapt 1.15.0. yaml 5.3.1. zipp NA. zmq 19.0.2. zope NA. -----. IPython 7.25.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.0. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.4.0-137-generic-x86_64-with-glibc2.10. -----. Session information updated at 2023-09-15 09:42. Running scvelo 0.2.5 (python 3.8.5) on 2023-09-15 09:42. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2665:192,modifiability,version,version,192,"Zoomed out PAGA output; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . I cannot produce normal looking paga plot. Whether I am using my own data or datasets provided through scanpy, the output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes? Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python. adata2 = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata2, groups='louvain'). sc.pl.paga(adata2). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.5. -----. PIL 8.0.1. backcall 0.2.0. bottleneck 1.3.7. cellrank 1.5.1. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. decorator 5.1.1. docrep 0.3.2. google NA. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 3.0.3. joblib 1.2.0. kiwisolver 1.3.0. leidenalg 0.9.1. llvmlite 0.34.0. lz4 3.1.10. markupsafe 2.1.3. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.51.2. numexpr 2.8.5. numpy 1.23.5. packaging 23.1. pandas 1.5.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 4.2.0. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pygpcca 1.0.4. pyparsing 2.4.7. python_utils NA. pytz 2020.1. ruamel NA. scipy 1.10.1. scvelo 0.2.5. seaborn 0.11.0. session_info 1.0.0. six 1.15.0. sklearn 1.2.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.1.0. tlz 0.12.1. toolz 0.11.1. tornado 6.1. tqdm 4.50.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2665:857,modifiability,Version,Versions,857,"Zoomed out PAGA output; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . I cannot produce normal looking paga plot. Whether I am using my own data or datasets provided through scanpy, the output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes? Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python. adata2 = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata2, groups='louvain'). sc.pl.paga(adata2). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.5. -----. PIL 8.0.1. backcall 0.2.0. bottleneck 1.3.7. cellrank 1.5.1. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. decorator 5.1.1. docrep 0.3.2. google NA. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 3.0.3. joblib 1.2.0. kiwisolver 1.3.0. leidenalg 0.9.1. llvmlite 0.34.0. lz4 3.1.10. markupsafe 2.1.3. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.51.2. numexpr 2.8.5. numpy 1.23.5. packaging 23.1. pandas 1.5.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 4.2.0. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pygpcca 1.0.4. pyparsing 2.4.7. python_utils NA. pytz 2020.1. ruamel NA. scipy 1.10.1. scvelo 0.2.5. seaborn 0.11.0. session_info 1.0.0. six 1.15.0. sklearn 1.2.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.1.0. tlz 0.12.1. toolz 0.11.1. tornado 6.1. tqdm 4.50.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2665:1116,modifiability,deco,decorator,1116,"dy been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . I cannot produce normal looking paga plot. Whether I am using my own data or datasets provided through scanpy, the output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes? Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python. adata2 = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata2, groups='louvain'). sc.pl.paga(adata2). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.5. -----. PIL 8.0.1. backcall 0.2.0. bottleneck 1.3.7. cellrank 1.5.1. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. decorator 5.1.1. docrep 0.3.2. google NA. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 3.0.3. joblib 1.2.0. kiwisolver 1.3.0. leidenalg 0.9.1. llvmlite 0.34.0. lz4 3.1.10. markupsafe 2.1.3. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.51.2. numexpr 2.8.5. numpy 1.23.5. packaging 23.1. pandas 1.5.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 4.2.0. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pygpcca 1.0.4. pyparsing 2.4.7. python_utils NA. pytz 2020.1. ruamel NA. scipy 1.10.1. scvelo 0.2.5. seaborn 0.11.0. session_info 1.0.0. six 1.15.0. sklearn 1.2.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.1.0. tlz 0.12.1. toolz 0.11.1. tornado 6.1. tqdm 4.50.2. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. wrapt 1.15.0. yaml 5.3.1. zipp NA. zmq 19.0.2. zope NA. -----. IPy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2665:1484,modifiability,pac,packaging,1484,"e output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes? Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python. adata2 = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata2, groups='louvain'). sc.pl.paga(adata2). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.5. -----. PIL 8.0.1. backcall 0.2.0. bottleneck 1.3.7. cellrank 1.5.1. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. decorator 5.1.1. docrep 0.3.2. google NA. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 3.0.3. joblib 1.2.0. kiwisolver 1.3.0. leidenalg 0.9.1. llvmlite 0.34.0. lz4 3.1.10. markupsafe 2.1.3. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.51.2. numexpr 2.8.5. numpy 1.23.5. packaging 23.1. pandas 1.5.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 4.2.0. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pygpcca 1.0.4. pyparsing 2.4.7. python_utils NA. pytz 2020.1. ruamel NA. scipy 1.10.1. scvelo 0.2.5. seaborn 0.11.0. session_info 1.0.0. six 1.15.0. sklearn 1.2.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.1.0. tlz 0.12.1. toolz 0.11.1. tornado 6.1. tqdm 4.50.2. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. wrapt 1.15.0. yaml 5.3.1. zipp NA. zmq 19.0.2. zope NA. -----. IPython 7.25.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.0. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.4.0-137-generic-x86_64-with-glibc2.10. -----. Session information updated at 2023-09-15 09:42. Running scvelo 0.2.5 (python 3.8.5) on 2023-09-15 09:42. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2665:824,performance,Error,Error,824,"Zoomed out PAGA output; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . I cannot produce normal looking paga plot. Whether I am using my own data or datasets provided through scanpy, the output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes? Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python. adata2 = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata2, groups='louvain'). sc.pl.paga(adata2). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.5. -----. PIL 8.0.1. backcall 0.2.0. bottleneck 1.3.7. cellrank 1.5.1. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. decorator 5.1.1. docrep 0.3.2. google NA. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 3.0.3. joblib 1.2.0. kiwisolver 1.3.0. leidenalg 0.9.1. llvmlite 0.34.0. lz4 3.1.10. markupsafe 2.1.3. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.51.2. numexpr 2.8.5. numpy 1.23.5. packaging 23.1. pandas 1.5.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 4.2.0. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pygpcca 1.0.4. pyparsing 2.4.7. python_utils NA. pytz 2020.1. ruamel NA. scipy 1.10.1. scvelo 0.2.5. seaborn 0.11.0. session_info 1.0.0. six 1.15.0. sklearn 1.2.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.1.0. tlz 0.12.1. toolz 0.11.1. tornado 6.1. tqdm 4.50.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2665:953,performance,bottleneck,bottleneck,953,"Zoomed out PAGA output; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . I cannot produce normal looking paga plot. Whether I am using my own data or datasets provided through scanpy, the output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes? Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python. adata2 = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata2, groups='louvain'). sc.pl.paga(adata2). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.5. -----. PIL 8.0.1. backcall 0.2.0. bottleneck 1.3.7. cellrank 1.5.1. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. decorator 5.1.1. docrep 0.3.2. google NA. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 3.0.3. joblib 1.2.0. kiwisolver 1.3.0. leidenalg 0.9.1. llvmlite 0.34.0. lz4 3.1.10. markupsafe 2.1.3. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.51.2. numexpr 2.8.5. numpy 1.23.5. packaging 23.1. pandas 1.5.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 4.2.0. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pygpcca 1.0.4. pyparsing 2.4.7. python_utils NA. pytz 2020.1. ruamel NA. scipy 1.10.1. scvelo 0.2.5. seaborn 0.11.0. session_info 1.0.0. six 1.15.0. sklearn 1.2.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.1.0. tlz 0.12.1. toolz 0.11.1. tornado 6.1. tqdm 4.50.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2665:824,safety,Error,Error,824,"Zoomed out PAGA output; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . I cannot produce normal looking paga plot. Whether I am using my own data or datasets provided through scanpy, the output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes? Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python. adata2 = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata2, groups='louvain'). sc.pl.paga(adata2). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.5. -----. PIL 8.0.1. backcall 0.2.0. bottleneck 1.3.7. cellrank 1.5.1. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. decorator 5.1.1. docrep 0.3.2. google NA. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 3.0.3. joblib 1.2.0. kiwisolver 1.3.0. leidenalg 0.9.1. llvmlite 0.34.0. lz4 3.1.10. markupsafe 2.1.3. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.51.2. numexpr 2.8.5. numpy 1.23.5. packaging 23.1. pandas 1.5.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 4.2.0. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pygpcca 1.0.4. pyparsing 2.4.7. python_utils NA. pytz 2020.1. ruamel NA. scipy 1.10.1. scvelo 0.2.5. seaborn 0.11.0. session_info 1.0.0. six 1.15.0. sklearn 1.2.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.1.0. tlz 0.12.1. toolz 0.11.1. tornado 6.1. tqdm 4.50.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2665:2332,safety,updat,updated,2332,"e output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes? Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python. adata2 = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata2, groups='louvain'). sc.pl.paga(adata2). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.5. -----. PIL 8.0.1. backcall 0.2.0. bottleneck 1.3.7. cellrank 1.5.1. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. decorator 5.1.1. docrep 0.3.2. google NA. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 3.0.3. joblib 1.2.0. kiwisolver 1.3.0. leidenalg 0.9.1. llvmlite 0.34.0. lz4 3.1.10. markupsafe 2.1.3. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.51.2. numexpr 2.8.5. numpy 1.23.5. packaging 23.1. pandas 1.5.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 4.2.0. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pygpcca 1.0.4. pyparsing 2.4.7. python_utils NA. pytz 2020.1. ruamel NA. scipy 1.10.1. scvelo 0.2.5. seaborn 0.11.0. session_info 1.0.0. six 1.15.0. sklearn 1.2.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.1.0. tlz 0.12.1. toolz 0.11.1. tornado 6.1. tqdm 4.50.2. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. wrapt 1.15.0. yaml 5.3.1. zipp NA. zmq 19.0.2. zope NA. -----. IPython 7.25.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.0. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.4.0-137-generic-x86_64-with-glibc2.10. -----. Session information updated at 2023-09-15 09:42. Running scvelo 0.2.5 (python 3.8.5) on 2023-09-15 09:42. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2665:2312,security,Session,Session,2312,"e output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes? Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python. adata2 = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata2, groups='louvain'). sc.pl.paga(adata2). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.5. -----. PIL 8.0.1. backcall 0.2.0. bottleneck 1.3.7. cellrank 1.5.1. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. decorator 5.1.1. docrep 0.3.2. google NA. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 3.0.3. joblib 1.2.0. kiwisolver 1.3.0. leidenalg 0.9.1. llvmlite 0.34.0. lz4 3.1.10. markupsafe 2.1.3. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.51.2. numexpr 2.8.5. numpy 1.23.5. packaging 23.1. pandas 1.5.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 4.2.0. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pygpcca 1.0.4. pyparsing 2.4.7. python_utils NA. pytz 2020.1. ruamel NA. scipy 1.10.1. scvelo 0.2.5. seaborn 0.11.0. session_info 1.0.0. six 1.15.0. sklearn 1.2.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.1.0. tlz 0.12.1. toolz 0.11.1. tornado 6.1. tqdm 4.50.2. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. wrapt 1.15.0. yaml 5.3.1. zipp NA. zmq 19.0.2. zope NA. -----. IPython 7.25.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.0. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.4.0-137-generic-x86_64-with-glibc2.10. -----. Session information updated at 2023-09-15 09:42. Running scvelo 0.2.5 (python 3.8.5) on 2023-09-15 09:42. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2665:2332,security,updat,updated,2332,"e output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes? Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python. adata2 = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata2, groups='louvain'). sc.pl.paga(adata2). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.5. -----. PIL 8.0.1. backcall 0.2.0. bottleneck 1.3.7. cellrank 1.5.1. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. decorator 5.1.1. docrep 0.3.2. google NA. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 3.0.3. joblib 1.2.0. kiwisolver 1.3.0. leidenalg 0.9.1. llvmlite 0.34.0. lz4 3.1.10. markupsafe 2.1.3. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.51.2. numexpr 2.8.5. numpy 1.23.5. packaging 23.1. pandas 1.5.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 4.2.0. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pygpcca 1.0.4. pyparsing 2.4.7. python_utils NA. pytz 2020.1. ruamel NA. scipy 1.10.1. scvelo 0.2.5. seaborn 0.11.0. session_info 1.0.0. six 1.15.0. sklearn 1.2.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.1.0. tlz 0.12.1. toolz 0.11.1. tornado 6.1. tqdm 4.50.2. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. wrapt 1.15.0. yaml 5.3.1. zipp NA. zmq 19.0.2. zope NA. -----. IPython 7.25.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.0. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.4.0-137-generic-x86_64-with-glibc2.10. -----. Session information updated at 2023-09-15 09:42. Running scvelo 0.2.5 (python 3.8.5) on 2023-09-15 09:42. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2665:152,usability,confirm,confirmed,152,"Zoomed out PAGA output; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . I cannot produce normal looking paga plot. Whether I am using my own data or datasets provided through scanpy, the output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes? Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python. adata2 = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata2, groups='louvain'). sc.pl.paga(adata2). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.5. -----. PIL 8.0.1. backcall 0.2.0. bottleneck 1.3.7. cellrank 1.5.1. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. decorator 5.1.1. docrep 0.3.2. google NA. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 3.0.3. joblib 1.2.0. kiwisolver 1.3.0. leidenalg 0.9.1. llvmlite 0.34.0. lz4 3.1.10. markupsafe 2.1.3. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.51.2. numexpr 2.8.5. numpy 1.23.5. packaging 23.1. pandas 1.5.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 4.2.0. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pygpcca 1.0.4. pyparsing 2.4.7. python_utils NA. pytz 2020.1. ruamel NA. scipy 1.10.1. scvelo 0.2.5. seaborn 0.11.0. session_info 1.0.0. six 1.15.0. sklearn 1.2.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.1.0. tlz 0.12.1. toolz 0.11.1. tornado 6.1. tqdm 4.50.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2665:235,usability,confirm,confirmed,235,"Zoomed out PAGA output; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . I cannot produce normal looking paga plot. Whether I am using my own data or datasets provided through scanpy, the output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes? Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python. adata2 = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata2, groups='louvain'). sc.pl.paga(adata2). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.5. -----. PIL 8.0.1. backcall 0.2.0. bottleneck 1.3.7. cellrank 1.5.1. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. decorator 5.1.1. docrep 0.3.2. google NA. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 3.0.3. joblib 1.2.0. kiwisolver 1.3.0. leidenalg 0.9.1. llvmlite 0.34.0. lz4 3.1.10. markupsafe 2.1.3. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.51.2. numexpr 2.8.5. numpy 1.23.5. packaging 23.1. pandas 1.5.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 4.2.0. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pygpcca 1.0.4. pyparsing 2.4.7. python_utils NA. pytz 2020.1. ruamel NA. scipy 1.10.1. scvelo 0.2.5. seaborn 0.11.0. session_info 1.0.0. six 1.15.0. sklearn 1.2.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.1.0. tlz 0.12.1. toolz 0.11.1. tornado 6.1. tqdm 4.50.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2665:684,usability,Minim,Minimal,684,"Zoomed out PAGA output; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . I cannot produce normal looking paga plot. Whether I am using my own data or datasets provided through scanpy, the output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes? Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python. adata2 = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata2, groups='louvain'). sc.pl.paga(adata2). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.5. -----. PIL 8.0.1. backcall 0.2.0. bottleneck 1.3.7. cellrank 1.5.1. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. decorator 5.1.1. docrep 0.3.2. google NA. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 3.0.3. joblib 1.2.0. kiwisolver 1.3.0. leidenalg 0.9.1. llvmlite 0.34.0. lz4 3.1.10. markupsafe 2.1.3. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.51.2. numexpr 2.8.5. numpy 1.23.5. packaging 23.1. pandas 1.5.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 4.2.0. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pygpcca 1.0.4. pyparsing 2.4.7. python_utils NA. pytz 2020.1. ruamel NA. scipy 1.10.1. scvelo 0.2.5. seaborn 0.11.0. session_info 1.0.0. six 1.15.0. sklearn 1.2.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.1.0. tlz 0.12.1. toolz 0.11.1. tornado 6.1. tqdm 4.50.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2665:824,usability,Error,Error,824,"Zoomed out PAGA output; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, . I cannot produce normal looking paga plot. Whether I am using my own data or datasets provided through scanpy, the output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes? Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python. adata2 = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata2, groups='louvain'). sc.pl.paga(adata2). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.5. -----. PIL 8.0.1. backcall 0.2.0. bottleneck 1.3.7. cellrank 1.5.1. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. decorator 5.1.1. docrep 0.3.2. google NA. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 3.0.3. joblib 1.2.0. kiwisolver 1.3.0. leidenalg 0.9.1. llvmlite 0.34.0. lz4 3.1.10. markupsafe 2.1.3. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.51.2. numexpr 2.8.5. numpy 1.23.5. packaging 23.1. pandas 1.5.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 4.2.0. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pygpcca 1.0.4. pyparsing 2.4.7. python_utils NA. pytz 2020.1. ruamel NA. scipy 1.10.1. scvelo 0.2.5. seaborn 0.11.0. session_info 1.0.0. six 1.15.0. sklearn 1.2.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.1.0. tlz 0.12.1. toolz 0.11.1. tornado 6.1. tqdm 4.50.2.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2665:1579,usability,progress,progressbar,1579,"e output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes? Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python. adata2 = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata2, groups='louvain'). sc.pl.paga(adata2). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.5. -----. PIL 8.0.1. backcall 0.2.0. bottleneck 1.3.7. cellrank 1.5.1. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. decorator 5.1.1. docrep 0.3.2. google NA. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 3.0.3. joblib 1.2.0. kiwisolver 1.3.0. leidenalg 0.9.1. llvmlite 0.34.0. lz4 3.1.10. markupsafe 2.1.3. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.51.2. numexpr 2.8.5. numpy 1.23.5. packaging 23.1. pandas 1.5.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 4.2.0. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pygpcca 1.0.4. pyparsing 2.4.7. python_utils NA. pytz 2020.1. ruamel NA. scipy 1.10.1. scvelo 0.2.5. seaborn 0.11.0. session_info 1.0.0. six 1.15.0. sklearn 1.2.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.1.0. tlz 0.12.1. toolz 0.11.1. tornado 6.1. tqdm 4.50.2. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. wrapt 1.15.0. yaml 5.3.1. zipp NA. zmq 19.0.2. zope NA. -----. IPython 7.25.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.0. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.4.0-137-generic-x86_64-with-glibc2.10. -----. Session information updated at 2023-09-15 09:42. Running scvelo 0.2.5 (python 3.8.5) on 2023-09-15 09:42. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2665:1961,usability,tool,toolz,1961,"e output for PAGA looks weird. . Please see below. Is this something to do with figure margins/axes? Thanks in advance. ![Screenshot 2023-09-13 at 20 48 43](https://github.com/scverse/scanpy/assets/40166451/c7313231-a2dc-49cb-a3df-21e97d86d278). ### Minimal code sample. ```python. adata2 = sc.datasets.pbmc3k_processed(). sc.tl.paga(adata2, groups='louvain'). sc.pl.paga(adata2). ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.5. -----. PIL 8.0.1. backcall 0.2.0. bottleneck 1.3.7. cellrank 1.5.1. cffi 1.15.1. cloudpickle 2.2.1. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.1. dask 2023.5.0. dateutil 2.8.2. decorator 5.1.1. docrep 0.3.2. google NA. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 5.3.4. ipython_genutils 0.2.0. ipywidgets 7.5.1. jedi 0.17.2. jinja2 3.0.3. joblib 1.2.0. kiwisolver 1.3.0. leidenalg 0.9.1. llvmlite 0.34.0. lz4 3.1.10. markupsafe 2.1.3. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.51.2. numexpr 2.8.5. numpy 1.23.5. packaging 23.1. pandas 1.5.3. parso 0.7.0. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. progressbar 4.2.0. prompt_toolkit 3.0.8. psutil 5.7.2. ptyprocess 0.6.0. pygam 0.8.0. pygments 2.7.2. pygpcca 1.0.4. pyparsing 2.4.7. python_utils NA. pytz 2020.1. ruamel NA. scipy 1.10.1. scvelo 0.2.5. seaborn 0.11.0. session_info 1.0.0. six 1.15.0. sklearn 1.2.2. sphinxcontrib NA. statsmodels 0.12.0. storemagic NA. tblib 1.7.0. texttable 1.6.7. threadpoolctl 2.1.0. tlz 0.12.1. toolz 0.11.1. tornado 6.1. tqdm 4.50.2. traitlets 5.0.5. typing_extensions NA. wcwidth 0.2.5. wrapt 1.15.0. yaml 5.3.1. zipp NA. zmq 19.0.2. zope NA. -----. IPython 7.25.0. jupyter_client 6.1.12. jupyter_core 4.7.1. notebook 6.4.0. -----. Python 3.8.5 (default, Sep 4 2020, 07:30:14) [GCC 7.3.0]. Linux-5.4.0-137-generic-x86_64-with-glibc2.10. -----. Session information updated at 2023-09-15 09:42. Running scvelo 0.2.5 (python 3.8.5) on 2023-09-15 09:42. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2665
https://github.com/scverse/scanpy/issues/2666:770,availability,Error,Error,770,"Can't implicitly convert non-string objects to strings. Bug about tl.filter_rank_genes_groups and tl.rank_genes_groups; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When I use `sc.tl.filter_rank_genes_groups` or `sc.tl.filter_rank_genes_groups`, I can not write the result file until I delete the output files stored as `adata.uns['rank_genes_groups_filtered']` and `adata.uns['rank_genes_groups']`. ### Minimal code sample. ```python. sc.tl.filter_rank_genes_groups. sc.tl.filter_rank_genes_groups. Both default use. ```. ### Error output. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'names' of <class 'h5py._hl.group.Group'> to /. ```. ### Versions. anndata: 0.9.2. scanpy version: 1.9.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2666
https://github.com/scverse/scanpy/issues/2666:866,availability,error,error,866,"Can't implicitly convert non-string objects to strings. Bug about tl.filter_rank_genes_groups and tl.rank_genes_groups; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When I use `sc.tl.filter_rank_genes_groups` or `sc.tl.filter_rank_genes_groups`, I can not write the result file until I delete the output files stored as `adata.uns['rank_genes_groups_filtered']` and `adata.uns['rank_genes_groups']`. ### Minimal code sample. ```python. sc.tl.filter_rank_genes_groups. sc.tl.filter_rank_genes_groups. Both default use. ```. ### Error output. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'names' of <class 'h5py._hl.group.Group'> to /. ```. ### Versions. anndata: 0.9.2. scanpy version: 1.9.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2666
https://github.com/scverse/scanpy/issues/2666:288,deployability,version,version,288,"Can't implicitly convert non-string objects to strings. Bug about tl.filter_rank_genes_groups and tl.rank_genes_groups; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When I use `sc.tl.filter_rank_genes_groups` or `sc.tl.filter_rank_genes_groups`, I can not write the result file until I delete the output files stored as `adata.uns['rank_genes_groups_filtered']` and `adata.uns['rank_genes_groups']`. ### Minimal code sample. ```python. sc.tl.filter_rank_genes_groups. sc.tl.filter_rank_genes_groups. Both default use. ```. ### Error output. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'names' of <class 'h5py._hl.group.Group'> to /. ```. ### Versions. anndata: 0.9.2. scanpy version: 1.9.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2666
https://github.com/scverse/scanpy/issues/2666:954,deployability,Version,Versions,954,"Can't implicitly convert non-string objects to strings. Bug about tl.filter_rank_genes_groups and tl.rank_genes_groups; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When I use `sc.tl.filter_rank_genes_groups` or `sc.tl.filter_rank_genes_groups`, I can not write the result file until I delete the output files stored as `adata.uns['rank_genes_groups_filtered']` and `adata.uns['rank_genes_groups']`. ### Minimal code sample. ```python. sc.tl.filter_rank_genes_groups. sc.tl.filter_rank_genes_groups. Both default use. ```. ### Error output. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'names' of <class 'h5py._hl.group.Group'> to /. ```. ### Versions. anndata: 0.9.2. scanpy version: 1.9.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2666
https://github.com/scverse/scanpy/issues/2666:987,deployability,version,version,987,"Can't implicitly convert non-string objects to strings. Bug about tl.filter_rank_genes_groups and tl.rank_genes_groups; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When I use `sc.tl.filter_rank_genes_groups` or `sc.tl.filter_rank_genes_groups`, I can not write the result file until I delete the output files stored as `adata.uns['rank_genes_groups_filtered']` and `adata.uns['rank_genes_groups']`. ### Minimal code sample. ```python. sc.tl.filter_rank_genes_groups. sc.tl.filter_rank_genes_groups. Both default use. ```. ### Error output. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'names' of <class 'h5py._hl.group.Group'> to /. ```. ### Versions. anndata: 0.9.2. scanpy version: 1.9.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2666
https://github.com/scverse/scanpy/issues/2666:288,integrability,version,version,288,"Can't implicitly convert non-string objects to strings. Bug about tl.filter_rank_genes_groups and tl.rank_genes_groups; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When I use `sc.tl.filter_rank_genes_groups` or `sc.tl.filter_rank_genes_groups`, I can not write the result file until I delete the output files stored as `adata.uns['rank_genes_groups_filtered']` and `adata.uns['rank_genes_groups']`. ### Minimal code sample. ```python. sc.tl.filter_rank_genes_groups. sc.tl.filter_rank_genes_groups. Both default use. ```. ### Error output. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'names' of <class 'h5py._hl.group.Group'> to /. ```. ### Versions. anndata: 0.9.2. scanpy version: 1.9.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2666
https://github.com/scverse/scanpy/issues/2666:954,integrability,Version,Versions,954,"Can't implicitly convert non-string objects to strings. Bug about tl.filter_rank_genes_groups and tl.rank_genes_groups; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When I use `sc.tl.filter_rank_genes_groups` or `sc.tl.filter_rank_genes_groups`, I can not write the result file until I delete the output files stored as `adata.uns['rank_genes_groups_filtered']` and `adata.uns['rank_genes_groups']`. ### Minimal code sample. ```python. sc.tl.filter_rank_genes_groups. sc.tl.filter_rank_genes_groups. Both default use. ```. ### Error output. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'names' of <class 'h5py._hl.group.Group'> to /. ```. ### Versions. anndata: 0.9.2. scanpy version: 1.9.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2666
https://github.com/scverse/scanpy/issues/2666:987,integrability,version,version,987,"Can't implicitly convert non-string objects to strings. Bug about tl.filter_rank_genes_groups and tl.rank_genes_groups; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When I use `sc.tl.filter_rank_genes_groups` or `sc.tl.filter_rank_genes_groups`, I can not write the result file until I delete the output files stored as `adata.uns['rank_genes_groups_filtered']` and `adata.uns['rank_genes_groups']`. ### Minimal code sample. ```python. sc.tl.filter_rank_genes_groups. sc.tl.filter_rank_genes_groups. Both default use. ```. ### Error output. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'names' of <class 'h5py._hl.group.Group'> to /. ```. ### Versions. anndata: 0.9.2. scanpy version: 1.9.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2666
https://github.com/scverse/scanpy/issues/2666:288,modifiability,version,version,288,"Can't implicitly convert non-string objects to strings. Bug about tl.filter_rank_genes_groups and tl.rank_genes_groups; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When I use `sc.tl.filter_rank_genes_groups` or `sc.tl.filter_rank_genes_groups`, I can not write the result file until I delete the output files stored as `adata.uns['rank_genes_groups_filtered']` and `adata.uns['rank_genes_groups']`. ### Minimal code sample. ```python. sc.tl.filter_rank_genes_groups. sc.tl.filter_rank_genes_groups. Both default use. ```. ### Error output. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'names' of <class 'h5py._hl.group.Group'> to /. ```. ### Versions. anndata: 0.9.2. scanpy version: 1.9.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2666
https://github.com/scverse/scanpy/issues/2666:954,modifiability,Version,Versions,954,"Can't implicitly convert non-string objects to strings. Bug about tl.filter_rank_genes_groups and tl.rank_genes_groups; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When I use `sc.tl.filter_rank_genes_groups` or `sc.tl.filter_rank_genes_groups`, I can not write the result file until I delete the output files stored as `adata.uns['rank_genes_groups_filtered']` and `adata.uns['rank_genes_groups']`. ### Minimal code sample. ```python. sc.tl.filter_rank_genes_groups. sc.tl.filter_rank_genes_groups. Both default use. ```. ### Error output. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'names' of <class 'h5py._hl.group.Group'> to /. ```. ### Versions. anndata: 0.9.2. scanpy version: 1.9.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2666
https://github.com/scverse/scanpy/issues/2666:987,modifiability,version,version,987,"Can't implicitly convert non-string objects to strings. Bug about tl.filter_rank_genes_groups and tl.rank_genes_groups; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When I use `sc.tl.filter_rank_genes_groups` or `sc.tl.filter_rank_genes_groups`, I can not write the result file until I delete the output files stored as `adata.uns['rank_genes_groups_filtered']` and `adata.uns['rank_genes_groups']`. ### Minimal code sample. ```python. sc.tl.filter_rank_genes_groups. sc.tl.filter_rank_genes_groups. Both default use. ```. ### Error output. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'names' of <class 'h5py._hl.group.Group'> to /. ```. ### Versions. anndata: 0.9.2. scanpy version: 1.9.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2666
https://github.com/scverse/scanpy/issues/2666:770,performance,Error,Error,770,"Can't implicitly convert non-string objects to strings. Bug about tl.filter_rank_genes_groups and tl.rank_genes_groups; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When I use `sc.tl.filter_rank_genes_groups` or `sc.tl.filter_rank_genes_groups`, I can not write the result file until I delete the output files stored as `adata.uns['rank_genes_groups_filtered']` and `adata.uns['rank_genes_groups']`. ### Minimal code sample. ```python. sc.tl.filter_rank_genes_groups. sc.tl.filter_rank_genes_groups. Both default use. ```. ### Error output. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'names' of <class 'h5py._hl.group.Group'> to /. ```. ### Versions. anndata: 0.9.2. scanpy version: 1.9.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2666
https://github.com/scverse/scanpy/issues/2666:866,performance,error,error,866,"Can't implicitly convert non-string objects to strings. Bug about tl.filter_rank_genes_groups and tl.rank_genes_groups; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When I use `sc.tl.filter_rank_genes_groups` or `sc.tl.filter_rank_genes_groups`, I can not write the result file until I delete the output files stored as `adata.uns['rank_genes_groups_filtered']` and `adata.uns['rank_genes_groups']`. ### Minimal code sample. ```python. sc.tl.filter_rank_genes_groups. sc.tl.filter_rank_genes_groups. Both default use. ```. ### Error output. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'names' of <class 'h5py._hl.group.Group'> to /. ```. ### Versions. anndata: 0.9.2. scanpy version: 1.9.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2666
https://github.com/scverse/scanpy/issues/2666:770,safety,Error,Error,770,"Can't implicitly convert non-string objects to strings. Bug about tl.filter_rank_genes_groups and tl.rank_genes_groups; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When I use `sc.tl.filter_rank_genes_groups` or `sc.tl.filter_rank_genes_groups`, I can not write the result file until I delete the output files stored as `adata.uns['rank_genes_groups_filtered']` and `adata.uns['rank_genes_groups']`. ### Minimal code sample. ```python. sc.tl.filter_rank_genes_groups. sc.tl.filter_rank_genes_groups. Both default use. ```. ### Error output. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'names' of <class 'h5py._hl.group.Group'> to /. ```. ### Versions. anndata: 0.9.2. scanpy version: 1.9.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2666
https://github.com/scverse/scanpy/issues/2666:866,safety,error,error,866,"Can't implicitly convert non-string objects to strings. Bug about tl.filter_rank_genes_groups and tl.rank_genes_groups; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When I use `sc.tl.filter_rank_genes_groups` or `sc.tl.filter_rank_genes_groups`, I can not write the result file until I delete the output files stored as `adata.uns['rank_genes_groups_filtered']` and `adata.uns['rank_genes_groups']`. ### Minimal code sample. ```python. sc.tl.filter_rank_genes_groups. sc.tl.filter_rank_genes_groups. Both default use. ```. ### Error output. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'names' of <class 'h5py._hl.group.Group'> to /. ```. ### Versions. anndata: 0.9.2. scanpy version: 1.9.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2666
https://github.com/scverse/scanpy/issues/2666:248,usability,confirm,confirmed,248,"Can't implicitly convert non-string objects to strings. Bug about tl.filter_rank_genes_groups and tl.rank_genes_groups; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When I use `sc.tl.filter_rank_genes_groups` or `sc.tl.filter_rank_genes_groups`, I can not write the result file until I delete the output files stored as `adata.uns['rank_genes_groups_filtered']` and `adata.uns['rank_genes_groups']`. ### Minimal code sample. ```python. sc.tl.filter_rank_genes_groups. sc.tl.filter_rank_genes_groups. Both default use. ```. ### Error output. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'names' of <class 'h5py._hl.group.Group'> to /. ```. ### Versions. anndata: 0.9.2. scanpy version: 1.9.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2666
https://github.com/scverse/scanpy/issues/2666:331,usability,confirm,confirmed,331,"Can't implicitly convert non-string objects to strings. Bug about tl.filter_rank_genes_groups and tl.rank_genes_groups; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When I use `sc.tl.filter_rank_genes_groups` or `sc.tl.filter_rank_genes_groups`, I can not write the result file until I delete the output files stored as `adata.uns['rank_genes_groups_filtered']` and `adata.uns['rank_genes_groups']`. ### Minimal code sample. ```python. sc.tl.filter_rank_genes_groups. sc.tl.filter_rank_genes_groups. Both default use. ```. ### Error output. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'names' of <class 'h5py._hl.group.Group'> to /. ```. ### Versions. anndata: 0.9.2. scanpy version: 1.9.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2666
https://github.com/scverse/scanpy/issues/2666:647,usability,Minim,Minimal,647,"Can't implicitly convert non-string objects to strings. Bug about tl.filter_rank_genes_groups and tl.rank_genes_groups; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When I use `sc.tl.filter_rank_genes_groups` or `sc.tl.filter_rank_genes_groups`, I can not write the result file until I delete the output files stored as `adata.uns['rank_genes_groups_filtered']` and `adata.uns['rank_genes_groups']`. ### Minimal code sample. ```python. sc.tl.filter_rank_genes_groups. sc.tl.filter_rank_genes_groups. Both default use. ```. ### Error output. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'names' of <class 'h5py._hl.group.Group'> to /. ```. ### Versions. anndata: 0.9.2. scanpy version: 1.9.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2666
https://github.com/scverse/scanpy/issues/2666:770,usability,Error,Error,770,"Can't implicitly convert non-string objects to strings. Bug about tl.filter_rank_genes_groups and tl.rank_genes_groups; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When I use `sc.tl.filter_rank_genes_groups` or `sc.tl.filter_rank_genes_groups`, I can not write the result file until I delete the output files stored as `adata.uns['rank_genes_groups_filtered']` and `adata.uns['rank_genes_groups']`. ### Minimal code sample. ```python. sc.tl.filter_rank_genes_groups. sc.tl.filter_rank_genes_groups. Both default use. ```. ### Error output. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'names' of <class 'h5py._hl.group.Group'> to /. ```. ### Versions. anndata: 0.9.2. scanpy version: 1.9.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2666
https://github.com/scverse/scanpy/issues/2666:866,usability,error,error,866,"Can't implicitly convert non-string objects to strings. Bug about tl.filter_rank_genes_groups and tl.rank_genes_groups; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When I use `sc.tl.filter_rank_genes_groups` or `sc.tl.filter_rank_genes_groups`, I can not write the result file until I delete the output files stored as `adata.uns['rank_genes_groups_filtered']` and `adata.uns['rank_genes_groups']`. ### Minimal code sample. ```python. sc.tl.filter_rank_genes_groups. sc.tl.filter_rank_genes_groups. Both default use. ```. ### Error output. ```pytb. TypeError: Can't implicitly convert non-string objects to strings. Above error raised while writing key 'names' of <class 'h5py._hl.group.Group'> to /. ```. ### Versions. anndata: 0.9.2. scanpy version: 1.9.5",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2666
https://github.com/scverse/scanpy/issues/2667:468,availability,error,error,468,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:0,deployability,Patch,Patching,0,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:301,deployability,fail,fails,301,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:474,deployability,log,log,474,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:509,deployability,depend,dependency,509,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:680,deployability,depend,dependency,680,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:805,deployability,instal,install,805,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:338,energy efficiency,current,currently,338,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:509,integrability,depend,dependency,509,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:680,integrability,depend,dependency,680,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:325,modifiability,pac,packages,325,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:509,modifiability,depend,dependency,509,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:573,modifiability,pac,packages,573,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:680,modifiability,depend,dependency,680,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:468,performance,error,error,468,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:301,reliability,fail,fails,301,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:0,safety,Patch,Patching,0,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:468,safety,error,error,468,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:474,safety,log,log,474,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:509,safety,depend,dependency,509,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:680,safety,depend,dependency,680,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:0,security,Patch,Patching,0,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:474,security,log,log,474,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:474,testability,log,log,474,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:509,testability,depend,dependency,509,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:680,testability,depend,dependency,680,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:348,usability,support,supported,348,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:468,usability,error,error,468,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2667:734,usability,help,helpful,734,"Patching scanpy for xeus; ### What kind of feature would you like to request? Other? ### Please describe your wishes. Hi! I [tried](https://github.com/VPetukhov/ngschool2023-bayesian) running scanpy using [JupyterLite](https://jupyterlite.readthedocs.io/en/stable/) for teaching purposes. However, it fails, as only `noarch` packages are currently supported in [xeus](https://jupyterlite.readthedocs.io/en/stable/howto/xeus-python/preinstalled_packages.html). From my error log it seems the only non-`noarch` dependency is [h5py](https://beta.mamba.pm/channels/conda-forge/packages/h5py), which is not really needed for teaching. . Would it be possible to make `h5py` an optional dependency on conda-forge somehow? It would be really helpful for many students to be able to try scanpy without the need to install anything locally.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2667
https://github.com/scverse/scanpy/issues/2668:1849,availability,Error,Error,1849,'). print(prot.X). ```. Output. ```. before. [[ 0.00612707 -0.05152755 -0.29209763 ... -0.30049595 -0.04813165. -0.05565361]. [ 0.24357025 0.359029 0.4300756 ... 0.10488246 0.03976884. 0.03547253]. [ 0.13372123 -0.18821767 -0.20151998 ... -0.36478856 -0.15580176. -0.05032819]. ... [ 0.22013764 0.1011355 -0.6299254 ... -0.06087471 0.06812771. -0.01558504]. [-0.29464224 0.2627981 -0.11072742 ... -0.48136345 -0.23690814. 0.0116325 ]. [-0.05685111 -0.3491494 0.08344086 ... -0.11356537 0.05052189. 0.02879048]]. after. [[ 0.00424696 -0.03571618 -0.20246665 ... -0.20828792 -0.03336232. -0.03857614]. [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566. 0.02458768]. [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355. -0.03488484]. ... [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253. -0.01080273]. [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221. 0.00806304]. [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191. 0.01995604]]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. entrypoints 0.4. executing 1.2.0. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.20.2. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.1. llvmlite 0.39.1. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prompt_toolkit 3.0.36. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.14.0. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10.0. ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668
https://github.com/scverse/scanpy/issues/2668:208,deployability,version,version,208,"highly_variable_genes changing my data; ### Please make sure these conditions are met. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I noticed that hvg computation is changing my data. I guess here X is only a reference, not a copy of my data. https://github.com/scverse/scanpy/blob/414092f68b4b40aa99153556377c32839b392636/scanpy/preprocessing/_highly_variable_genes.py#L195. Didn't manage to create a reproducible small example, not sure when anndata objects are copied vs referenced. . ### Minimal code sample. ```python. import scanpy as sc. prot = sc.read_h5ad('my_data'). print('before'). print(prot.X). sc.pp.highly_variable_genes(prot). print('after'). print(prot.X). ```. Output. ```. before. [[ 0.00612707 -0.05152755 -0.29209763 ... -0.30049595 -0.04813165. -0.05565361]. [ 0.24357025 0.359029 0.4300756 ... 0.10488246 0.03976884. 0.03547253]. [ 0.13372123 -0.18821767 -0.20151998 ... -0.36478856 -0.15580176. -0.05032819]. ... [ 0.22013764 0.1011355 -0.6299254 ... -0.06087471 0.06812771. -0.01558504]. [-0.29464224 0.2627981 -0.11072742 ... -0.48136345 -0.23690814. 0.0116325 ]. [-0.05685111 -0.3491494 0.08344086 ... -0.11356537 0.05052189. 0.02879048]]. after. [[ 0.00424696 -0.03571618 -0.20246665 ... -0.20828792 -0.03336232. -0.03857614]. [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566. 0.02458768]. [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355. -0.03488484]. ... [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253. -0.01080273]. [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221. 0.00806304]. [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191. 0.01995604]]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668
https://github.com/scverse/scanpy/issues/2668:579,deployability,manag,manage,579,"highly_variable_genes changing my data; ### Please make sure these conditions are met. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I noticed that hvg computation is changing my data. I guess here X is only a reference, not a copy of my data. https://github.com/scverse/scanpy/blob/414092f68b4b40aa99153556377c32839b392636/scanpy/preprocessing/_highly_variable_genes.py#L195. Didn't manage to create a reproducible small example, not sure when anndata objects are copied vs referenced. . ### Minimal code sample. ```python. import scanpy as sc. prot = sc.read_h5ad('my_data'). print('before'). print(prot.X). sc.pp.highly_variable_genes(prot). print('after'). print(prot.X). ```. Output. ```. before. [[ 0.00612707 -0.05152755 -0.29209763 ... -0.30049595 -0.04813165. -0.05565361]. [ 0.24357025 0.359029 0.4300756 ... 0.10488246 0.03976884. 0.03547253]. [ 0.13372123 -0.18821767 -0.20151998 ... -0.36478856 -0.15580176. -0.05032819]. ... [ 0.22013764 0.1011355 -0.6299254 ... -0.06087471 0.06812771. -0.01558504]. [-0.29464224 0.2627981 -0.11072742 ... -0.48136345 -0.23690814. 0.0116325 ]. [-0.05685111 -0.3491494 0.08344086 ... -0.11356537 0.05052189. 0.02879048]]. after. [[ 0.00424696 -0.03571618 -0.20246665 ... -0.20828792 -0.03336232. -0.03857614]. [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566. 0.02458768]. [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355. -0.03488484]. ... [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253. -0.01080273]. [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221. 0.00806304]. [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191. 0.01995604]]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668
https://github.com/scverse/scanpy/issues/2668:1882,deployability,Version,Versions,1882,`. before. [[ 0.00612707 -0.05152755 -0.29209763 ... -0.30049595 -0.04813165. -0.05565361]. [ 0.24357025 0.359029 0.4300756 ... 0.10488246 0.03976884. 0.03547253]. [ 0.13372123 -0.18821767 -0.20151998 ... -0.36478856 -0.15580176. -0.05032819]. ... [ 0.22013764 0.1011355 -0.6299254 ... -0.06087471 0.06812771. -0.01558504]. [-0.29464224 0.2627981 -0.11072742 ... -0.48136345 -0.23690814. 0.0116325 ]. [-0.05685111 -0.3491494 0.08344086 ... -0.11356537 0.05052189. 0.02879048]]. after. [[ 0.00424696 -0.03571618 -0.20246665 ... -0.20828792 -0.03336232. -0.03857614]. [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566. 0.02458768]. [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355. -0.03488484]. ... [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253. -0.01080273]. [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221. 0.00806304]. [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191. 0.01995604]]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. entrypoints 0.4. executing 1.2.0. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.20.2. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.1. llvmlite 0.39.1. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prompt_toolkit 3.0.36. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.14.0. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10.0. session_info 1.0.0. setuptools 66.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668
https://github.com/scverse/scanpy/issues/2668:3343,deployability,updat,updated,3343,"03571618 -0.20246665 ... -0.20828792 -0.03336232. -0.03857614]. [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566. 0.02458768]. [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355. -0.03488484]. ... [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253. -0.01080273]. [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221. 0.00806304]. [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191. 0.01995604]]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. entrypoints 0.4. executing 1.2.0. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.20.2. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.1. llvmlite 0.39.1. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prompt_toolkit 3.0.36. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.14.0. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10.0. session_info 1.0.0. setuptools 66.1.1. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. stack_data 0.6.2. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.2. traitlets 5.8.1. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zipp NA. zmq 25.0.0. zoneinfo NA. -----. IPython 8.8.0. jupyter_client 7.4.9. jupyter_core 5.1.5. -----. Python 3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 15:55:03) [GCC 10.4.0]. Linux-4.18.0-425.3.1.el8.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2023-09-18 17:04. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668
https://github.com/scverse/scanpy/issues/2668:579,energy efficiency,manag,manage,579,"highly_variable_genes changing my data; ### Please make sure these conditions are met. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I noticed that hvg computation is changing my data. I guess here X is only a reference, not a copy of my data. https://github.com/scverse/scanpy/blob/414092f68b4b40aa99153556377c32839b392636/scanpy/preprocessing/_highly_variable_genes.py#L195. Didn't manage to create a reproducible small example, not sure when anndata objects are copied vs referenced. . ### Minimal code sample. ```python. import scanpy as sc. prot = sc.read_h5ad('my_data'). print('before'). print(prot.X). sc.pp.highly_variable_genes(prot). print('after'). print(prot.X). ```. Output. ```. before. [[ 0.00612707 -0.05152755 -0.29209763 ... -0.30049595 -0.04813165. -0.05565361]. [ 0.24357025 0.359029 0.4300756 ... 0.10488246 0.03976884. 0.03547253]. [ 0.13372123 -0.18821767 -0.20151998 ... -0.36478856 -0.15580176. -0.05032819]. ... [ 0.22013764 0.1011355 -0.6299254 ... -0.06087471 0.06812771. -0.01558504]. [-0.29464224 0.2627981 -0.11072742 ... -0.48136345 -0.23690814. 0.0116325 ]. [-0.05685111 -0.3491494 0.08344086 ... -0.11356537 0.05052189. 0.02879048]]. after. [[ 0.00424696 -0.03571618 -0.20246665 ... -0.20828792 -0.03336232. -0.03857614]. [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566. 0.02458768]. [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355. -0.03488484]. ... [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253. -0.01080273]. [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221. 0.00806304]. [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191. 0.01995604]]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668
https://github.com/scverse/scanpy/issues/2668:208,integrability,version,version,208,"highly_variable_genes changing my data; ### Please make sure these conditions are met. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I noticed that hvg computation is changing my data. I guess here X is only a reference, not a copy of my data. https://github.com/scverse/scanpy/blob/414092f68b4b40aa99153556377c32839b392636/scanpy/preprocessing/_highly_variable_genes.py#L195. Didn't manage to create a reproducible small example, not sure when anndata objects are copied vs referenced. . ### Minimal code sample. ```python. import scanpy as sc. prot = sc.read_h5ad('my_data'). print('before'). print(prot.X). sc.pp.highly_variable_genes(prot). print('after'). print(prot.X). ```. Output. ```. before. [[ 0.00612707 -0.05152755 -0.29209763 ... -0.30049595 -0.04813165. -0.05565361]. [ 0.24357025 0.359029 0.4300756 ... 0.10488246 0.03976884. 0.03547253]. [ 0.13372123 -0.18821767 -0.20151998 ... -0.36478856 -0.15580176. -0.05032819]. ... [ 0.22013764 0.1011355 -0.6299254 ... -0.06087471 0.06812771. -0.01558504]. [-0.29464224 0.2627981 -0.11072742 ... -0.48136345 -0.23690814. 0.0116325 ]. [-0.05685111 -0.3491494 0.08344086 ... -0.11356537 0.05052189. 0.02879048]]. after. [[ 0.00424696 -0.03571618 -0.20246665 ... -0.20828792 -0.03336232. -0.03857614]. [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566. 0.02458768]. [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355. -0.03488484]. ... [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253. -0.01080273]. [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221. 0.00806304]. [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191. 0.01995604]]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668
https://github.com/scverse/scanpy/issues/2668:1882,integrability,Version,Versions,1882,`. before. [[ 0.00612707 -0.05152755 -0.29209763 ... -0.30049595 -0.04813165. -0.05565361]. [ 0.24357025 0.359029 0.4300756 ... 0.10488246 0.03976884. 0.03547253]. [ 0.13372123 -0.18821767 -0.20151998 ... -0.36478856 -0.15580176. -0.05032819]. ... [ 0.22013764 0.1011355 -0.6299254 ... -0.06087471 0.06812771. -0.01558504]. [-0.29464224 0.2627981 -0.11072742 ... -0.48136345 -0.23690814. 0.0116325 ]. [-0.05685111 -0.3491494 0.08344086 ... -0.11356537 0.05052189. 0.02879048]]. after. [[ 0.00424696 -0.03571618 -0.20246665 ... -0.20828792 -0.03336232. -0.03857614]. [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566. 0.02458768]. [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355. -0.03488484]. ... [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253. -0.01080273]. [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221. 0.00806304]. [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191. 0.01995604]]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. entrypoints 0.4. executing 1.2.0. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.20.2. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.1. llvmlite 0.39.1. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prompt_toolkit 3.0.36. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.14.0. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10.0. session_info 1.0.0. setuptools 66.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668
https://github.com/scverse/scanpy/issues/2668:2588,interoperability,platform,platformdirs,2588,"03571618 -0.20246665 ... -0.20828792 -0.03336232. -0.03857614]. [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566. 0.02458768]. [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355. -0.03488484]. ... [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253. -0.01080273]. [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221. 0.00806304]. [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191. 0.01995604]]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. entrypoints 0.4. executing 1.2.0. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.20.2. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.1. llvmlite 0.39.1. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prompt_toolkit 3.0.36. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.14.0. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10.0. session_info 1.0.0. setuptools 66.1.1. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. stack_data 0.6.2. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.2. traitlets 5.8.1. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zipp NA. zmq 25.0.0. zoneinfo NA. -----. IPython 8.8.0. jupyter_client 7.4.9. jupyter_core 5.1.5. -----. Python 3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 15:55:03) [GCC 10.4.0]. Linux-4.18.0-425.3.1.el8.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2023-09-18 17:04. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668
https://github.com/scverse/scanpy/issues/2668:208,modifiability,version,version,208,"highly_variable_genes changing my data; ### Please make sure these conditions are met. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I noticed that hvg computation is changing my data. I guess here X is only a reference, not a copy of my data. https://github.com/scverse/scanpy/blob/414092f68b4b40aa99153556377c32839b392636/scanpy/preprocessing/_highly_variable_genes.py#L195. Didn't manage to create a reproducible small example, not sure when anndata objects are copied vs referenced. . ### Minimal code sample. ```python. import scanpy as sc. prot = sc.read_h5ad('my_data'). print('before'). print(prot.X). sc.pp.highly_variable_genes(prot). print('after'). print(prot.X). ```. Output. ```. before. [[ 0.00612707 -0.05152755 -0.29209763 ... -0.30049595 -0.04813165. -0.05565361]. [ 0.24357025 0.359029 0.4300756 ... 0.10488246 0.03976884. 0.03547253]. [ 0.13372123 -0.18821767 -0.20151998 ... -0.36478856 -0.15580176. -0.05032819]. ... [ 0.22013764 0.1011355 -0.6299254 ... -0.06087471 0.06812771. -0.01558504]. [-0.29464224 0.2627981 -0.11072742 ... -0.48136345 -0.23690814. 0.0116325 ]. [-0.05685111 -0.3491494 0.08344086 ... -0.11356537 0.05052189. 0.02879048]]. after. [[ 0.00424696 -0.03571618 -0.20246665 ... -0.20828792 -0.03336232. -0.03857614]. [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566. 0.02458768]. [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355. -0.03488484]. ... [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253. -0.01080273]. [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221. 0.00806304]. [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191. 0.01995604]]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668
https://github.com/scverse/scanpy/issues/2668:1882,modifiability,Version,Versions,1882,`. before. [[ 0.00612707 -0.05152755 -0.29209763 ... -0.30049595 -0.04813165. -0.05565361]. [ 0.24357025 0.359029 0.4300756 ... 0.10488246 0.03976884. 0.03547253]. [ 0.13372123 -0.18821767 -0.20151998 ... -0.36478856 -0.15580176. -0.05032819]. ... [ 0.22013764 0.1011355 -0.6299254 ... -0.06087471 0.06812771. -0.01558504]. [-0.29464224 0.2627981 -0.11072742 ... -0.48136345 -0.23690814. 0.0116325 ]. [-0.05685111 -0.3491494 0.08344086 ... -0.11356537 0.05052189. 0.02879048]]. after. [[ 0.00424696 -0.03571618 -0.20246665 ... -0.20828792 -0.03336232. -0.03857614]. [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566. 0.02458768]. [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355. -0.03488484]. ... [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253. -0.01080273]. [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221. 0.00806304]. [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191. 0.01995604]]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. entrypoints 0.4. executing 1.2.0. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.20.2. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.1. llvmlite 0.39.1. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prompt_toolkit 3.0.36. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.14.0. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10.0. session_info 1.0.0. setuptools 66.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668
https://github.com/scverse/scanpy/issues/2668:2129,modifiability,deco,decorator,2129,[ 0.22013764 0.1011355 -0.6299254 ... -0.06087471 0.06812771. -0.01558504]. [-0.29464224 0.2627981 -0.11072742 ... -0.48136345 -0.23690814. 0.0116325 ]. [-0.05685111 -0.3491494 0.08344086 ... -0.11356537 0.05052189. 0.02879048]]. after. [[ 0.00424696 -0.03571618 -0.20246665 ... -0.20828792 -0.03336232. -0.03857614]. [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566. 0.02458768]. [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355. -0.03488484]. ... [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253. -0.01080273]. [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221. 0.00806304]. [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191. 0.01995604]]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. entrypoints 0.4. executing 1.2.0. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.20.2. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.1. llvmlite 0.39.1. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prompt_toolkit 3.0.36. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.14.0. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10.0. session_info 1.0.0. setuptools 66.1.1. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. stack_data 0.6.2. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.2. traitlets 5.8.1. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zipp NA. zmq 25.0.0. zoneinfo NA. -----. IPython 8.8.0. jupyter_,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668
https://github.com/scverse/scanpy/issues/2668:2493,modifiability,pac,packaging,2493,"03571618 -0.20246665 ... -0.20828792 -0.03336232. -0.03857614]. [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566. 0.02458768]. [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355. -0.03488484]. ... [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253. -0.01080273]. [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221. 0.00806304]. [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191. 0.01995604]]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. entrypoints 0.4. executing 1.2.0. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.20.2. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.1. llvmlite 0.39.1. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prompt_toolkit 3.0.36. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.14.0. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10.0. session_info 1.0.0. setuptools 66.1.1. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. stack_data 0.6.2. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.2. traitlets 5.8.1. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zipp NA. zmq 25.0.0. zoneinfo NA. -----. IPython 8.8.0. jupyter_client 7.4.9. jupyter_core 5.1.5. -----. Python 3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 15:55:03) [GCC 10.4.0]. Linux-4.18.0-425.3.1.el8.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2023-09-18 17:04. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668
https://github.com/scverse/scanpy/issues/2668:3191,modifiability,pac,packaged,3191,"03571618 -0.20246665 ... -0.20828792 -0.03336232. -0.03857614]. [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566. 0.02458768]. [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355. -0.03488484]. ... [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253. -0.01080273]. [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221. 0.00806304]. [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191. 0.01995604]]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. entrypoints 0.4. executing 1.2.0. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.20.2. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.1. llvmlite 0.39.1. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prompt_toolkit 3.0.36. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.14.0. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10.0. session_info 1.0.0. setuptools 66.1.1. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. stack_data 0.6.2. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.2. traitlets 5.8.1. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zipp NA. zmq 25.0.0. zoneinfo NA. -----. IPython 8.8.0. jupyter_client 7.4.9. jupyter_core 5.1.5. -----. Python 3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 15:55:03) [GCC 10.4.0]. Linux-4.18.0-425.3.1.el8.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2023-09-18 17:04. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668
https://github.com/scverse/scanpy/issues/2668:1849,performance,Error,Error,1849,'). print(prot.X). ```. Output. ```. before. [[ 0.00612707 -0.05152755 -0.29209763 ... -0.30049595 -0.04813165. -0.05565361]. [ 0.24357025 0.359029 0.4300756 ... 0.10488246 0.03976884. 0.03547253]. [ 0.13372123 -0.18821767 -0.20151998 ... -0.36478856 -0.15580176. -0.05032819]. ... [ 0.22013764 0.1011355 -0.6299254 ... -0.06087471 0.06812771. -0.01558504]. [-0.29464224 0.2627981 -0.11072742 ... -0.48136345 -0.23690814. 0.0116325 ]. [-0.05685111 -0.3491494 0.08344086 ... -0.11356537 0.05052189. 0.02879048]]. after. [[ 0.00424696 -0.03571618 -0.20246665 ... -0.20828792 -0.03336232. -0.03857614]. [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566. 0.02458768]. [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355. -0.03488484]. ... [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253. -0.01080273]. [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221. 0.00806304]. [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191. 0.01995604]]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. entrypoints 0.4. executing 1.2.0. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.20.2. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.1. llvmlite 0.39.1. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prompt_toolkit 3.0.36. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.14.0. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10.0. ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668
https://github.com/scverse/scanpy/issues/2668:579,safety,manag,manage,579,"highly_variable_genes changing my data; ### Please make sure these conditions are met. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I noticed that hvg computation is changing my data. I guess here X is only a reference, not a copy of my data. https://github.com/scverse/scanpy/blob/414092f68b4b40aa99153556377c32839b392636/scanpy/preprocessing/_highly_variable_genes.py#L195. Didn't manage to create a reproducible small example, not sure when anndata objects are copied vs referenced. . ### Minimal code sample. ```python. import scanpy as sc. prot = sc.read_h5ad('my_data'). print('before'). print(prot.X). sc.pp.highly_variable_genes(prot). print('after'). print(prot.X). ```. Output. ```. before. [[ 0.00612707 -0.05152755 -0.29209763 ... -0.30049595 -0.04813165. -0.05565361]. [ 0.24357025 0.359029 0.4300756 ... 0.10488246 0.03976884. 0.03547253]. [ 0.13372123 -0.18821767 -0.20151998 ... -0.36478856 -0.15580176. -0.05032819]. ... [ 0.22013764 0.1011355 -0.6299254 ... -0.06087471 0.06812771. -0.01558504]. [-0.29464224 0.2627981 -0.11072742 ... -0.48136345 -0.23690814. 0.0116325 ]. [-0.05685111 -0.3491494 0.08344086 ... -0.11356537 0.05052189. 0.02879048]]. after. [[ 0.00424696 -0.03571618 -0.20246665 ... -0.20828792 -0.03336232. -0.03857614]. [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566. 0.02458768]. [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355. -0.03488484]. ... [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253. -0.01080273]. [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221. 0.00806304]. [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191. 0.01995604]]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668
https://github.com/scverse/scanpy/issues/2668:1849,safety,Error,Error,1849,'). print(prot.X). ```. Output. ```. before. [[ 0.00612707 -0.05152755 -0.29209763 ... -0.30049595 -0.04813165. -0.05565361]. [ 0.24357025 0.359029 0.4300756 ... 0.10488246 0.03976884. 0.03547253]. [ 0.13372123 -0.18821767 -0.20151998 ... -0.36478856 -0.15580176. -0.05032819]. ... [ 0.22013764 0.1011355 -0.6299254 ... -0.06087471 0.06812771. -0.01558504]. [-0.29464224 0.2627981 -0.11072742 ... -0.48136345 -0.23690814. 0.0116325 ]. [-0.05685111 -0.3491494 0.08344086 ... -0.11356537 0.05052189. 0.02879048]]. after. [[ 0.00424696 -0.03571618 -0.20246665 ... -0.20828792 -0.03336232. -0.03857614]. [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566. 0.02458768]. [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355. -0.03488484]. ... [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253. -0.01080273]. [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221. 0.00806304]. [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191. 0.01995604]]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. entrypoints 0.4. executing 1.2.0. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.20.2. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.1. llvmlite 0.39.1. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prompt_toolkit 3.0.36. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.14.0. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10.0. ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668
https://github.com/scverse/scanpy/issues/2668:3343,safety,updat,updated,3343,"03571618 -0.20246665 ... -0.20828792 -0.03336232. -0.03857614]. [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566. 0.02458768]. [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355. -0.03488484]. ... [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253. -0.01080273]. [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221. 0.00806304]. [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191. 0.01995604]]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. entrypoints 0.4. executing 1.2.0. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.20.2. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.1. llvmlite 0.39.1. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prompt_toolkit 3.0.36. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.14.0. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10.0. session_info 1.0.0. setuptools 66.1.1. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. stack_data 0.6.2. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.2. traitlets 5.8.1. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zipp NA. zmq 25.0.0. zoneinfo NA. -----. IPython 8.8.0. jupyter_client 7.4.9. jupyter_core 5.1.5. -----. Python 3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 15:55:03) [GCC 10.4.0]. Linux-4.18.0-425.3.1.el8.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2023-09-18 17:04. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668
https://github.com/scverse/scanpy/issues/2668:3323,security,Session,Session,3323,"03571618 -0.20246665 ... -0.20828792 -0.03336232. -0.03857614]. [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566. 0.02458768]. [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355. -0.03488484]. ... [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253. -0.01080273]. [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221. 0.00806304]. [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191. 0.01995604]]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. entrypoints 0.4. executing 1.2.0. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.20.2. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.1. llvmlite 0.39.1. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prompt_toolkit 3.0.36. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.14.0. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10.0. session_info 1.0.0. setuptools 66.1.1. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. stack_data 0.6.2. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.2. traitlets 5.8.1. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zipp NA. zmq 25.0.0. zoneinfo NA. -----. IPython 8.8.0. jupyter_client 7.4.9. jupyter_core 5.1.5. -----. Python 3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 15:55:03) [GCC 10.4.0]. Linux-4.18.0-425.3.1.el8.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2023-09-18 17:04. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668
https://github.com/scverse/scanpy/issues/2668:3343,security,updat,updated,3343,"03571618 -0.20246665 ... -0.20828792 -0.03336232. -0.03857614]. [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566. 0.02458768]. [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355. -0.03488484]. ... [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253. -0.01080273]. [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221. 0.00806304]. [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191. 0.01995604]]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. entrypoints 0.4. executing 1.2.0. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.20.2. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.1. llvmlite 0.39.1. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prompt_toolkit 3.0.36. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.14.0. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10.0. session_info 1.0.0. setuptools 66.1.1. six 1.16.0. skewnorm_ufunc NA. sklearn 1.2.1. stack_data 0.6.2. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.2. traitlets 5.8.1. typing_extensions NA. wcwidth 0.2.6. yaml 6.0. zipp NA. zmq 25.0.0. zoneinfo NA. -----. IPython 8.8.0. jupyter_client 7.4.9. jupyter_core 5.1.5. -----. Python 3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 15:55:03) [GCC 10.4.0]. Linux-4.18.0-425.3.1.el8.x86_64-x86_64-with-glibc2.28. -----. Session information updated at 2023-09-18 17:04. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668
https://github.com/scverse/scanpy/issues/2668:168,usability,confirm,confirmed,168,"highly_variable_genes changing my data; ### Please make sure these conditions are met. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I noticed that hvg computation is changing my data. I guess here X is only a reference, not a copy of my data. https://github.com/scverse/scanpy/blob/414092f68b4b40aa99153556377c32839b392636/scanpy/preprocessing/_highly_variable_genes.py#L195. Didn't manage to create a reproducible small example, not sure when anndata objects are copied vs referenced. . ### Minimal code sample. ```python. import scanpy as sc. prot = sc.read_h5ad('my_data'). print('before'). print(prot.X). sc.pp.highly_variable_genes(prot). print('after'). print(prot.X). ```. Output. ```. before. [[ 0.00612707 -0.05152755 -0.29209763 ... -0.30049595 -0.04813165. -0.05565361]. [ 0.24357025 0.359029 0.4300756 ... 0.10488246 0.03976884. 0.03547253]. [ 0.13372123 -0.18821767 -0.20151998 ... -0.36478856 -0.15580176. -0.05032819]. ... [ 0.22013764 0.1011355 -0.6299254 ... -0.06087471 0.06812771. -0.01558504]. [-0.29464224 0.2627981 -0.11072742 ... -0.48136345 -0.23690814. 0.0116325 ]. [-0.05685111 -0.3491494 0.08344086 ... -0.11356537 0.05052189. 0.02879048]]. after. [[ 0.00424696 -0.03571618 -0.20246665 ... -0.20828792 -0.03336232. -0.03857614]. [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566. 0.02458768]. [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355. -0.03488484]. ... [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253. -0.01080273]. [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221. 0.00806304]. [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191. 0.01995604]]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668
https://github.com/scverse/scanpy/issues/2668:251,usability,confirm,confirmed,251,"highly_variable_genes changing my data; ### Please make sure these conditions are met. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I noticed that hvg computation is changing my data. I guess here X is only a reference, not a copy of my data. https://github.com/scverse/scanpy/blob/414092f68b4b40aa99153556377c32839b392636/scanpy/preprocessing/_highly_variable_genes.py#L195. Didn't manage to create a reproducible small example, not sure when anndata objects are copied vs referenced. . ### Minimal code sample. ```python. import scanpy as sc. prot = sc.read_h5ad('my_data'). print('before'). print(prot.X). sc.pp.highly_variable_genes(prot). print('after'). print(prot.X). ```. Output. ```. before. [[ 0.00612707 -0.05152755 -0.29209763 ... -0.30049595 -0.04813165. -0.05565361]. [ 0.24357025 0.359029 0.4300756 ... 0.10488246 0.03976884. 0.03547253]. [ 0.13372123 -0.18821767 -0.20151998 ... -0.36478856 -0.15580176. -0.05032819]. ... [ 0.22013764 0.1011355 -0.6299254 ... -0.06087471 0.06812771. -0.01558504]. [-0.29464224 0.2627981 -0.11072742 ... -0.48136345 -0.23690814. 0.0116325 ]. [-0.05685111 -0.3491494 0.08344086 ... -0.11356537 0.05052189. 0.02879048]]. after. [[ 0.00424696 -0.03571618 -0.20246665 ... -0.20828792 -0.03336232. -0.03857614]. [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566. 0.02458768]. [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355. -0.03488484]. ... [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253. -0.01080273]. [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221. 0.00806304]. [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191. 0.01995604]]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668
https://github.com/scverse/scanpy/issues/2668:688,usability,Minim,Minimal,688,"highly_variable_genes changing my data; ### Please make sure these conditions are met. - [ ] I have checked that this issue has not already been reported. - [ ] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I noticed that hvg computation is changing my data. I guess here X is only a reference, not a copy of my data. https://github.com/scverse/scanpy/blob/414092f68b4b40aa99153556377c32839b392636/scanpy/preprocessing/_highly_variable_genes.py#L195. Didn't manage to create a reproducible small example, not sure when anndata objects are copied vs referenced. . ### Minimal code sample. ```python. import scanpy as sc. prot = sc.read_h5ad('my_data'). print('before'). print(prot.X). sc.pp.highly_variable_genes(prot). print('after'). print(prot.X). ```. Output. ```. before. [[ 0.00612707 -0.05152755 -0.29209763 ... -0.30049595 -0.04813165. -0.05565361]. [ 0.24357025 0.359029 0.4300756 ... 0.10488246 0.03976884. 0.03547253]. [ 0.13372123 -0.18821767 -0.20151998 ... -0.36478856 -0.15580176. -0.05032819]. ... [ 0.22013764 0.1011355 -0.6299254 ... -0.06087471 0.06812771. -0.01558504]. [-0.29464224 0.2627981 -0.11072742 ... -0.48136345 -0.23690814. 0.0116325 ]. [-0.05685111 -0.3491494 0.08344086 ... -0.11356537 0.05052189. 0.02879048]]. after. [[ 0.00424696 -0.03571618 -0.20246665 ... -0.20828792 -0.03336232. -0.03857614]. [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566. 0.02458768]. [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355. -0.03488484]. ... [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253. -0.01080273]. [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221. 0.00806304]. [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191. 0.01995604]]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufu",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668
https://github.com/scverse/scanpy/issues/2668:1849,usability,Error,Error,1849,'). print(prot.X). ```. Output. ```. before. [[ 0.00612707 -0.05152755 -0.29209763 ... -0.30049595 -0.04813165. -0.05565361]. [ 0.24357025 0.359029 0.4300756 ... 0.10488246 0.03976884. 0.03547253]. [ 0.13372123 -0.18821767 -0.20151998 ... -0.36478856 -0.15580176. -0.05032819]. ... [ 0.22013764 0.1011355 -0.6299254 ... -0.06087471 0.06812771. -0.01558504]. [-0.29464224 0.2627981 -0.11072742 ... -0.48136345 -0.23690814. 0.0116325 ]. [-0.05685111 -0.3491494 0.08344086 ... -0.11356537 0.05052189. 0.02879048]]. after. [[ 0.00424696 -0.03571618 -0.20246665 ... -0.20828792 -0.03336232. -0.03857614]. [ 0.16883004 0.24885994 0.2981057 ... 0.07269898 0.02756566. 0.02458768]. [ 0.09268849 -0.13046254 -0.13968301 ... -0.25285217 -0.10799355. -0.03488484]. ... [ 0.15258779 0.07010179 -0.436631 ... -0.04219513 0.04722253. -0.01080273]. [-0.20423044 0.18215777 -0.0767504 ... -0.33365571 -0.16421221. 0.00806304]. [-0.03940619 -0.24201192 0.05783679 ... -0.07871751 0.0350191. 0.01995604]]. ```. ### Error output. _No response_. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.1. -----. PIL 9.4.0. asttokens NA. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. cffi 1.15.1. colorama 0.4.6. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.6.6. decorator 5.1.1. entrypoints 0.4. executing 1.2.0. google NA. h5py 3.8.0. hypergeom_ufunc NA. igraph 0.10.3. invgauss_ufunc NA. ipykernel 6.20.2. jedi 0.18.2. joblib 1.2.0. kiwisolver 1.4.4. leidenalg 0.10.1. llvmlite 0.39.1. matplotlib 3.6.3. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. nct_ufunc NA. ncx2_ufunc NA. numba 0.56.4. numpy 1.23.5. packaging 23.0. pandas 1.5.3. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.6.2. prompt_toolkit 3.0.36. psutil 5.9.4. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.14.0. pyparsing 3.0.9. pytz 2022.7.1. scipy 1.10.0. ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2668
https://github.com/scverse/scanpy/issues/2669:66,availability,error,error,66,"highly variable genes + batch_key --> reciprocal condition number error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_hig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:492,availability,error,error-in-highly-variable-gene-selection,492,"highly variable genes + batch_key --> reciprocal condition number error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_hig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:799,availability,error,error,799,"highly variable genes + batch_key --> reciprocal condition number error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_hig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:948,availability,Error,Error,948,"highly variable genes + batch_key --> reciprocal condition number error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_hig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:241,deployability,version,version,241,"highly variable genes + batch_key --> reciprocal condition number error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_hig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:2442,deployability,Version,Versions,2442,"`inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 83 x = np.log10(mean[not_const]). 84 model = loess(x, y, span=span, degree=2). ---> 85 model.fit(). 86 estimat_var[not_const] = model.outputs.fitted_values. 87 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:899, in _loess.loess.fit(). ValueError: b'reciprocal condition number 6.4708e-16'. ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 6.19.2. ipython_genutils 0.2.0. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.57.0. numpy 1.24.3. packaging 23.0. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.5.2. prompt_toolkit 3.0.36. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.10.1. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. sklearn 1.2.2. stack_data 0.2.0. textta",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:3819,deployability,updat,updated,3819," layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 83 x = np.log10(mean[not_const]). 84 model = loess(x, y, span=span, degree=2). ---> 85 model.fit(). 86 estimat_var[not_const] = model.outputs.fitted_values. 87 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:899, in _loess.loess.fit(). ValueError: b'reciprocal condition number 6.4708e-16'. ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 6.19.2. ipython_genutils 0.2.0. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.57.0. numpy 1.24.3. packaging 23.0. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.5.2. prompt_toolkit 3.0.36. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.10.1. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. sklearn 1.2.2. stack_data 0.2.0. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.2. traitlets 5.7.1. typing_extensions NA. wcwidth 0.2.5. yaml 6.0.1. zipp NA. zmq 25.0.2. -----. IPython 8.12.0. jupyter_client 8.1.0. jupyter_core 5.3.0. jupyterlab 3.5.3. notebook 6.5.4. -----. Python 3.8.16 (default, Mar 2 2023, 03:21:46) [GCC 11.2.0]. Linux-4.15.0-212-generic-x86_64-with-glibc2.17. -----. Session information updated at 2023-09-19 02:18. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:2175,energy efficiency,model,model,2175,"nes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 83 x = np.log10(mean[not_const]). 84 model = loess(x, y, span=span, degree=2). ---> 85 model.fit(). 86 estimat_var[not_const] = model.outputs.fitted_values. 87 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:899, in _loess.loess.fit(). ValueError: b'reciprocal condition number 6.4708e-16'. ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 6.19.2. ipython_genutils 0.2.0. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.57.0. numpy 1.24.3. packaging 23.0. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.5.2. prompt_toolkit 3.0.36. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:2225,energy efficiency,model,model,2225," n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 83 x = np.log10(mean[not_const]). 84 model = loess(x, y, span=span, degree=2). ---> 85 model.fit(). 86 estimat_var[not_const] = model.outputs.fitted_values. 87 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:899, in _loess.loess.fit(). ValueError: b'reciprocal condition number 6.4708e-16'. ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 6.19.2. ipython_genutils 0.2.0. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.57.0. numpy 1.24.3. packaging 23.0. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.5.2. prompt_toolkit 3.0.36. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analys",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:2266,energy efficiency,model,model,2266,"n, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 83 x = np.log10(mean[not_const]). 84 model = loess(x, y, span=span, degree=2). ---> 85 model.fit(). 86 estimat_var[not_const] = model.outputs.fitted_values. 87 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:899, in _loess.loess.fit(). ValueError: b'reciprocal condition number 6.4708e-16'. ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 6.19.2. ipython_genutils 0.2.0. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.57.0. numpy 1.24.3. packaging 23.0. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.5.2. prompt_toolkit 3.0.36. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:241,integrability,version,version,241,"highly variable genes + batch_key --> reciprocal condition number error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_hig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:1304,integrability,sub,subset,1304,"ts on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 83 x = np.log10(mean[not_const]). 84 model = loess(x, y, span=span, degree=2). ---> 85 model.fit(). 86 estimat_var[not_const] = model.outputs.fitted_values. 87 reg_std =",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:1730,integrability,sub,subset,1730,"the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 83 x = np.log10(mean[not_const]). 84 model = loess(x, y, span=span, degree=2). ---> 85 model.fit(). 86 estimat_var[not_const] = model.outputs.fitted_values. 87 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:899, in _loess.loess.fit(). ValueError: b'reciprocal condition number 6.4708e-16'. ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. h5py 3.8.0. igraph 0.10.4. importlib_re",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:1737,integrability,sub,subset,1737,"ction runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 83 x = np.log10(mean[not_const]). 84 model = loess(x, y, span=span, degree=2). ---> 85 model.fit(). 86 estimat_var[not_const] = model.outputs.fitted_values. 87 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:899, in _loess.loess.fit(). ValueError: b'reciprocal condition number 6.4708e-16'. ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. h5py 3.8.0. igraph 0.10.4. importlib_resources",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:2120,integrability,sub,subset,2120,"/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 83 x = np.log10(mean[not_const]). 84 model = loess(x, y, span=span, degree=2). ---> 85 model.fit(). 86 estimat_var[not_const] = model.outputs.fitted_values. 87 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:899, in _loess.loess.fit(). ValueError: b'reciprocal condition number 6.4708e-16'. ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 6.19.2. ipython_genutils 0.2.0. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.57.0. numpy 1.24.3. packaging 23.0. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.5.2. prompt_toolkit 3.0.36. psutil 5.9.0. ptyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:2442,integrability,Version,Versions,2442,"`inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 83 x = np.log10(mean[not_const]). 84 model = loess(x, y, span=span, degree=2). ---> 85 model.fit(). 86 estimat_var[not_const] = model.outputs.fitted_values. 87 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:899, in _loess.loess.fit(). ValueError: b'reciprocal condition number 6.4708e-16'. ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 6.19.2. ipython_genutils 0.2.0. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.57.0. numpy 1.24.3. packaging 23.0. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.5.2. prompt_toolkit 3.0.36. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.10.1. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. sklearn 1.2.2. stack_data 0.2.0. textta",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:3062,interoperability,platform,platformdirs,3062," layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 83 x = np.log10(mean[not_const]). 84 model = loess(x, y, span=span, degree=2). ---> 85 model.fit(). 86 estimat_var[not_const] = model.outputs.fitted_values. 87 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:899, in _loess.loess.fit(). ValueError: b'reciprocal condition number 6.4708e-16'. ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 6.19.2. ipython_genutils 0.2.0. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.57.0. numpy 1.24.3. packaging 23.0. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.5.2. prompt_toolkit 3.0.36. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.10.1. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. sklearn 1.2.2. stack_data 0.2.0. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.2. traitlets 5.7.1. typing_extensions NA. wcwidth 0.2.5. yaml 6.0.1. zipp NA. zmq 25.0.2. -----. IPython 8.12.0. jupyter_client 8.1.0. jupyter_core 5.3.0. jupyterlab 3.5.3. notebook 6.5.4. -----. Python 3.8.16 (default, Mar 2 2023, 03:21:46) [GCC 11.2.0]. Linux-4.15.0-212-generic-x86_64-with-glibc2.17. -----. Session information updated at 2023-09-19 02:18. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:7,modifiability,variab,variable,7,"highly variable genes + batch_key --> reciprocal condition number error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_hig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:241,modifiability,version,version,241,"highly variable genes + batch_key --> reciprocal condition number error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_hig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:508,modifiability,variab,variable-gene-selection,508,"highly variable genes + batch_key --> reciprocal condition number error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_hig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:1129,modifiability,pac,packages,1129,"checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inpla",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:1222,modifiability,layer,layer,1222,"s on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 83 x = np.log10(mean[not_const]). 84 model = loess(x, y, span=span, degree=2). ---> 85 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:1608,modifiability,layer,layer,1608,"resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 83 x = np.log10(mean[not_const]). 84 model = loess(x, y, span=span, degree=2). ---> 85 model.fit(). 86 estimat_var[not_const] = model.outputs.fitted_values. 87 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:899, in _loess.loess.fit(). ValueError: b'reciprocal condition number 6.4708e-16'. ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. comm 0.1.2. cycler 0.10.0. cython_runtime NA. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:1614,modifiability,layer,layer,1614,"tion was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 83 x = np.log10(mean[not_const]). 84 model = loess(x, y, span=span, degree=2). ---> 85 model.fit(). 86 estimat_var[not_const] = model.outputs.fitted_values. 87 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:899, in _loess.loess.fit(). ValueError: b'reciprocal condition number 6.4708e-16'. ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateut",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:1865,modifiability,layer,layer,1865,"s(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 83 x = np.log10(mean[not_const]). 84 model = loess(x, y, span=span, degree=2). ---> 85 model.fit(). 86 estimat_var[not_const] = model.outputs.fitted_values. 87 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:899, in _loess.loess.fit(). ValueError: b'reciprocal condition number 6.4708e-16'. ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 6.19.2. ipython_genutils 0.2.0. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:1871,modifiability,layer,layer,1871,"a, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 83 x = np.log10(mean[not_const]). 84 model = loess(x, y, span=span, degree=2). ---> 85 model.fit(). 86 estimat_var[not_const] = model.outputs.fitted_values. 87 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:899, in _loess.loess.fit(). ValueError: b'reciprocal condition number 6.4708e-16'. ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 6.19.2. ipython_genutils 0.2.0. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. ll",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:1966,modifiability,pac,packages,1966," ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 83 x = np.log10(mean[not_const]). 84 model = loess(x, y, span=span, degree=2). ---> 85 model.fit(). 86 estimat_var[not_const] = model.outputs.fitted_values. 87 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:899, in _loess.loess.fit(). ValueError: b'reciprocal condition number 6.4708e-16'. ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 6.19.2. ipython_genutils 0.2.0. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.57.0. numpy 1.24.3. pac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:2069,modifiability,layer,layer,2069,"""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 83 x = np.log10(mean[not_const]). 84 model = loess(x, y, span=span, degree=2). ---> 85 model.fit(). 86 estimat_var[not_const] = model.outputs.fitted_values. 87 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:899, in _loess.loess.fit(). ValueError: b'reciprocal condition number 6.4708e-16'. ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 6.19.2. ipython_genutils 0.2.0. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.57.0. numpy 1.24.3. packaging 23.0. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:2442,modifiability,Version,Versions,2442,"`inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 83 x = np.log10(mean[not_const]). 84 model = loess(x, y, span=span, degree=2). ---> 85 model.fit(). 86 estimat_var[not_const] = model.outputs.fitted_values. 87 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:899, in _loess.loess.fit(). ValueError: b'reciprocal condition number 6.4708e-16'. ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 6.19.2. ipython_genutils 0.2.0. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.57.0. numpy 1.24.3. packaging 23.0. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.5.2. prompt_toolkit 3.0.36. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.10.1. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. sklearn 1.2.2. stack_data 0.2.0. textta",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:2642,modifiability,deco,decorator,2642,"es,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 83 x = np.log10(mean[not_const]). 84 model = loess(x, y, span=span, degree=2). ---> 85 model.fit(). 86 estimat_var[not_const] = model.outputs.fitted_values. 87 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:899, in _loess.loess.fit(). ValueError: b'reciprocal condition number 6.4708e-16'. ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 6.19.2. ipython_genutils 0.2.0. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.57.0. numpy 1.24.3. packaging 23.0. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.5.2. prompt_toolkit 3.0.36. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.10.1. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. sklearn 1.2.2. stack_data 0.2.0. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.2. traitlets 5.7.1. typing_extensions NA. wcwidth 0.2.5. yaml 6.0.1. zipp NA. zmq 25.0.2. -----. IPython 8.12.0. jupyter_client 8.1.0. jupyter_core 5.3.0. jupy",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:2967,modifiability,pac,packaging,2967," layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 83 x = np.log10(mean[not_const]). 84 model = loess(x, y, span=span, degree=2). ---> 85 model.fit(). 86 estimat_var[not_const] = model.outputs.fitted_values. 87 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:899, in _loess.loess.fit(). ValueError: b'reciprocal condition number 6.4708e-16'. ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 6.19.2. ipython_genutils 0.2.0. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.57.0. numpy 1.24.3. packaging 23.0. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.5.2. prompt_toolkit 3.0.36. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.10.1. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. sklearn 1.2.2. stack_data 0.2.0. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.2. traitlets 5.7.1. typing_extensions NA. wcwidth 0.2.5. yaml 6.0.1. zipp NA. zmq 25.0.2. -----. IPython 8.12.0. jupyter_client 8.1.0. jupyter_core 5.3.0. jupyterlab 3.5.3. notebook 6.5.4. -----. Python 3.8.16 (default, Mar 2 2023, 03:21:46) [GCC 11.2.0]. Linux-4.15.0-212-generic-x86_64-with-glibc2.17. -----. Session information updated at 2023-09-19 02:18. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:66,performance,error,error,66,"highly variable genes + batch_key --> reciprocal condition number error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_hig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:492,performance,error,error-in-highly-variable-gene-selection,492,"highly variable genes + batch_key --> reciprocal condition number error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_hig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:799,performance,error,error,799,"highly variable genes + batch_key --> reciprocal condition number error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_hig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:948,performance,Error,Error,948,"highly variable genes + batch_key --> reciprocal condition number error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_hig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:66,safety,error,error,66,"highly variable genes + batch_key --> reciprocal condition number error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_hig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:492,safety,error,error-in-highly-variable-gene-selection,492,"highly variable genes + batch_key --> reciprocal condition number error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_hig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:799,safety,error,error,799,"highly variable genes + batch_key --> reciprocal condition number error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_hig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:948,safety,Error,Error,948,"highly variable genes + batch_key --> reciprocal condition number error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_hig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:3819,safety,updat,updated,3819," layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 83 x = np.log10(mean[not_const]). 84 model = loess(x, y, span=span, degree=2). ---> 85 model.fit(). 86 estimat_var[not_const] = model.outputs.fitted_values. 87 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:899, in _loess.loess.fit(). ValueError: b'reciprocal condition number 6.4708e-16'. ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 6.19.2. ipython_genutils 0.2.0. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.57.0. numpy 1.24.3. packaging 23.0. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.5.2. prompt_toolkit 3.0.36. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.10.1. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. sklearn 1.2.2. stack_data 0.2.0. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.2. traitlets 5.7.1. typing_extensions NA. wcwidth 0.2.5. yaml 6.0.1. zipp NA. zmq 25.0.2. -----. IPython 8.12.0. jupyter_client 8.1.0. jupyter_core 5.3.0. jupyterlab 3.5.3. notebook 6.5.4. -----. Python 3.8.16 (default, Mar 2 2023, 03:21:46) [GCC 11.2.0]. Linux-4.15.0-212-generic-x86_64-with-glibc2.17. -----. Session information updated at 2023-09-19 02:18. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:562,security,access,access,562,"highly variable genes + batch_key --> reciprocal condition number error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_hig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:2175,security,model,model,2175,"nes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 83 x = np.log10(mean[not_const]). 84 model = loess(x, y, span=span, degree=2). ---> 85 model.fit(). 86 estimat_var[not_const] = model.outputs.fitted_values. 87 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:899, in _loess.loess.fit(). ValueError: b'reciprocal condition number 6.4708e-16'. ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 6.19.2. ipython_genutils 0.2.0. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.57.0. numpy 1.24.3. packaging 23.0. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.5.2. prompt_toolkit 3.0.36. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevc",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:2225,security,model,model,2225," n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 83 x = np.log10(mean[not_const]). 84 model = loess(x, y, span=span, degree=2). ---> 85 model.fit(). 86 estimat_var[not_const] = model.outputs.fitted_values. 87 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:899, in _loess.loess.fit(). ValueError: b'reciprocal condition number 6.4708e-16'. ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 6.19.2. ipython_genutils 0.2.0. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.57.0. numpy 1.24.3. packaging 23.0. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.5.2. prompt_toolkit 3.0.36. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analys",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:2266,security,model,model,2266,"n, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 83 x = np.log10(mean[not_const]). 84 model = loess(x, y, span=span, degree=2). ---> 85 model.fit(). 86 estimat_var[not_const] = model.outputs.fitted_values. 87 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:899, in _loess.loess.fit(). ValueError: b'reciprocal condition number 6.4708e-16'. ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 6.19.2. ipython_genutils 0.2.0. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.57.0. numpy 1.24.3. packaging 23.0. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.5.2. prompt_toolkit 3.0.36. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:3799,security,Session,Session,3799," layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 83 x = np.log10(mean[not_const]). 84 model = loess(x, y, span=span, degree=2). ---> 85 model.fit(). 86 estimat_var[not_const] = model.outputs.fitted_values. 87 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:899, in _loess.loess.fit(). ValueError: b'reciprocal condition number 6.4708e-16'. ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 6.19.2. ipython_genutils 0.2.0. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.57.0. numpy 1.24.3. packaging 23.0. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.5.2. prompt_toolkit 3.0.36. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.10.1. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. sklearn 1.2.2. stack_data 0.2.0. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.2. traitlets 5.7.1. typing_extensions NA. wcwidth 0.2.5. yaml 6.0.1. zipp NA. zmq 25.0.2. -----. IPython 8.12.0. jupyter_client 8.1.0. jupyter_core 5.3.0. jupyterlab 3.5.3. notebook 6.5.4. -----. Python 3.8.16 (default, Mar 2 2023, 03:21:46) [GCC 11.2.0]. Linux-4.15.0-212-generic-x86_64-with-glibc2.17. -----. Session information updated at 2023-09-19 02:18. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:3819,security,updat,updated,3819," layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:85, in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, check_values, span, subset, inplace). 83 x = np.log10(mean[not_const]). 84 model = loess(x, y, span=span, degree=2). ---> 85 model.fit(). 86 estimat_var[not_const] = model.outputs.fitted_values. 87 reg_std = np.sqrt(10**estimat_var). File _loess.pyx:899, in _loess.loess.fit(). ValueError: b'reciprocal condition number 6.4708e-16'. ```. ### Versions. <details>. ```. -----. anndata 0.9.1. scanpy 1.9.3. -----. PIL 9.5.0. asttokens NA. backcall 0.2.0. cffi 1.15.1. comm 0.1.2. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. executing 0.8.3. h5py 3.8.0. igraph 0.10.4. importlib_resources NA. ipykernel 6.19.2. ipython_genutils 0.2.0. jedi 0.18.1. joblib 1.2.0. jupyter_server 1.23.4. kiwisolver 1.4.4. leidenalg 0.9.1. llvmlite 0.40.0. matplotlib 3.7.1. mpl_toolkits NA. natsort 8.3.1. numba 0.57.0. numpy 1.24.3. packaging 23.0. pandas 2.0.1. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 2.5.2. prompt_toolkit 3.0.36. psutil 5.9.0. ptyprocess 0.7.0. pure_eval 0.2.2. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2022.7. scipy 1.10.1. session_info 1.0.0. setuptools 66.0.0. six 1.16.0. sklearn 1.2.2. stack_data 0.2.0. texttable 1.6.7. threadpoolctl 3.1.0. tornado 6.2. traitlets 5.7.1. typing_extensions NA. wcwidth 0.2.5. yaml 6.0.1. zipp NA. zmq 25.0.2. -----. IPython 8.12.0. jupyter_client 8.1.0. jupyter_core 5.3.0. jupyterlab 3.5.3. notebook 6.5.4. -----. Python 3.8.16 (default, Mar 2 2023, 03:21:46) [GCC 11.2.0]. Linux-4.15.0-212-generic-x86_64-with-glibc2.17. -----. Session information updated at 2023-09-19 02:18. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:66,usability,error,error,66,"highly variable genes + batch_key --> reciprocal condition number error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_hig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:201,usability,confirm,confirmed,201,"highly variable genes + batch_key --> reciprocal condition number error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_hig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:284,usability,confirm,confirmed,284,"highly variable genes + batch_key --> reciprocal condition number error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_hig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:492,usability,error,error-in-highly-variable-gene-selection,492,"highly variable genes + batch_key --> reciprocal condition number error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_hig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:799,usability,error,error,799,"highly variable genes + batch_key --> reciprocal condition number error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_hig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:810,usability,Minim,Minimal,810,"highly variable genes + batch_key --> reciprocal condition number error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_hig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2669:948,usability,Error,Error,948,"highly variable genes + batch_key --> reciprocal condition number error; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? **Note**: This bug seems to have been mentioned on 2/13/2022 in this discourse.scverse.org thread: https://discourse.scverse.org/t/error-in-highly-variable-gene-selection/276. However, I can't seem to access scverse.org so I can't see what the cause/resolution was. **Issue**: I am running highly_variable_genes with flavor='seurat_v3'. When I do not include a batch_key, the function runs fine. When I add a batch_key, I get a numerical error. ### Minimal code sample. ```python. sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). ```. ### Error output. ```pytb. ----> 1 sc.pp.highly_variable_genes(adata, flavor='seurat_v3', n_top_genes=1000, batch_key=""Covariate""). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py:428, in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key, check_values). 422 raise ValueError(. 423 '`pp.highly_variable_genes` expects an `AnnData` argument, '. 424 'pass `inplace=False` if you want to return a `pd.DataFrame`.'. 425 ). 427 if flavor == 'seurat_v3':. --> 428 return _highly_variable_genes_seurat_v3(. 429 adata,. 430 layer=layer,. 431 n_top_genes=n_top_genes,. 432 batch_key=batch_key,. 433 check_values=check_values,. 434 span=span,. 435 subset=subset,. 436 inplace=inplace,. 437 ). 439 if batch_key is None:. 440 df = _highly_variable_genes_single_batch(. 441 adata,. 442 layer=layer,. (...). 449 flavor=flavor,. 450 ). File ~/miniconda3/envs/singlecell/lib/python3.8/site-packages/scanpy/preprocessing/_hig",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2669
https://github.com/scverse/scanpy/issues/2670:746,availability,Error,Error,746,"Blank plot when using sc.pl.scatter; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I use `sc.pl.scatter` it returns a blank plot. The axis values are alright but the plot itself is empty. There are about 23M cells. Please advise. ![image](https://github.com/scverse/scanpy/assets/32474661/2d858133-6e60-478a-a98c-b0acd8c64700). Thanks and good day. ### Minimal code sample. ```python. sc.pl.scatter(adata, ""total_counts"", ""n_genes_by_counts"", color=""pct_counts_mt"", save='_test.png'). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2670
https://github.com/scverse/scanpy/issues/2670:205,deployability,version,version,205,"Blank plot when using sc.pl.scatter; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I use `sc.pl.scatter` it returns a blank plot. The axis values are alright but the plot itself is empty. There are about 23M cells. Please advise. ![image](https://github.com/scverse/scanpy/assets/32474661/2d858133-6e60-478a-a98c-b0acd8c64700). Thanks and good day. ### Minimal code sample. ```python. sc.pl.scatter(adata, ""total_counts"", ""n_genes_by_counts"", color=""pct_counts_mt"", save='_test.png'). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2670
https://github.com/scverse/scanpy/issues/2670:779,deployability,Version,Versions,779,"Blank plot when using sc.pl.scatter; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I use `sc.pl.scatter` it returns a blank plot. The axis values are alright but the plot itself is empty. There are about 23M cells. Please advise. ![image](https://github.com/scverse/scanpy/assets/32474661/2d858133-6e60-478a-a98c-b0acd8c64700). Thanks and good day. ### Minimal code sample. ```python. sc.pl.scatter(adata, ""total_counts"", ""n_genes_by_counts"", color=""pct_counts_mt"", save='_test.png'). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2670
https://github.com/scverse/scanpy/issues/2670:205,integrability,version,version,205,"Blank plot when using sc.pl.scatter; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I use `sc.pl.scatter` it returns a blank plot. The axis values are alright but the plot itself is empty. There are about 23M cells. Please advise. ![image](https://github.com/scverse/scanpy/assets/32474661/2d858133-6e60-478a-a98c-b0acd8c64700). Thanks and good day. ### Minimal code sample. ```python. sc.pl.scatter(adata, ""total_counts"", ""n_genes_by_counts"", color=""pct_counts_mt"", save='_test.png'). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2670
https://github.com/scverse/scanpy/issues/2670:779,integrability,Version,Versions,779,"Blank plot when using sc.pl.scatter; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I use `sc.pl.scatter` it returns a blank plot. The axis values are alright but the plot itself is empty. There are about 23M cells. Please advise. ![image](https://github.com/scverse/scanpy/assets/32474661/2d858133-6e60-478a-a98c-b0acd8c64700). Thanks and good day. ### Minimal code sample. ```python. sc.pl.scatter(adata, ""total_counts"", ""n_genes_by_counts"", color=""pct_counts_mt"", save='_test.png'). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2670
https://github.com/scverse/scanpy/issues/2670:205,modifiability,version,version,205,"Blank plot when using sc.pl.scatter; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I use `sc.pl.scatter` it returns a blank plot. The axis values are alright but the plot itself is empty. There are about 23M cells. Please advise. ![image](https://github.com/scverse/scanpy/assets/32474661/2d858133-6e60-478a-a98c-b0acd8c64700). Thanks and good day. ### Minimal code sample. ```python. sc.pl.scatter(adata, ""total_counts"", ""n_genes_by_counts"", color=""pct_counts_mt"", save='_test.png'). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2670
https://github.com/scverse/scanpy/issues/2670:779,modifiability,Version,Versions,779,"Blank plot when using sc.pl.scatter; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I use `sc.pl.scatter` it returns a blank plot. The axis values are alright but the plot itself is empty. There are about 23M cells. Please advise. ![image](https://github.com/scverse/scanpy/assets/32474661/2d858133-6e60-478a-a98c-b0acd8c64700). Thanks and good day. ### Minimal code sample. ```python. sc.pl.scatter(adata, ""total_counts"", ""n_genes_by_counts"", color=""pct_counts_mt"", save='_test.png'). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2670
https://github.com/scverse/scanpy/issues/2670:746,performance,Error,Error,746,"Blank plot when using sc.pl.scatter; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I use `sc.pl.scatter` it returns a blank plot. The axis values are alright but the plot itself is empty. There are about 23M cells. Please advise. ![image](https://github.com/scverse/scanpy/assets/32474661/2d858133-6e60-478a-a98c-b0acd8c64700). Thanks and good day. ### Minimal code sample. ```python. sc.pl.scatter(adata, ""total_counts"", ""n_genes_by_counts"", color=""pct_counts_mt"", save='_test.png'). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2670
https://github.com/scverse/scanpy/issues/2670:746,safety,Error,Error,746,"Blank plot when using sc.pl.scatter; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I use `sc.pl.scatter` it returns a blank plot. The axis values are alright but the plot itself is empty. There are about 23M cells. Please advise. ![image](https://github.com/scverse/scanpy/assets/32474661/2d858133-6e60-478a-a98c-b0acd8c64700). Thanks and good day. ### Minimal code sample. ```python. sc.pl.scatter(adata, ""total_counts"", ""n_genes_by_counts"", color=""pct_counts_mt"", save='_test.png'). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2670
https://github.com/scverse/scanpy/issues/2670:165,usability,confirm,confirmed,165,"Blank plot when using sc.pl.scatter; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I use `sc.pl.scatter` it returns a blank plot. The axis values are alright but the plot itself is empty. There are about 23M cells. Please advise. ![image](https://github.com/scverse/scanpy/assets/32474661/2d858133-6e60-478a-a98c-b0acd8c64700). Thanks and good day. ### Minimal code sample. ```python. sc.pl.scatter(adata, ""total_counts"", ""n_genes_by_counts"", color=""pct_counts_mt"", save='_test.png'). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2670
https://github.com/scverse/scanpy/issues/2670:248,usability,confirm,confirmed,248,"Blank plot when using sc.pl.scatter; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I use `sc.pl.scatter` it returns a blank plot. The axis values are alright but the plot itself is empty. There are about 23M cells. Please advise. ![image](https://github.com/scverse/scanpy/assets/32474661/2d858133-6e60-478a-a98c-b0acd8c64700). Thanks and good day. ### Minimal code sample. ```python. sc.pl.scatter(adata, ""total_counts"", ""n_genes_by_counts"", color=""pct_counts_mt"", save='_test.png'). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2670
https://github.com/scverse/scanpy/issues/2670:605,usability,Minim,Minimal,605,"Blank plot when using sc.pl.scatter; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I use `sc.pl.scatter` it returns a blank plot. The axis values are alright but the plot itself is empty. There are about 23M cells. Please advise. ![image](https://github.com/scverse/scanpy/assets/32474661/2d858133-6e60-478a-a98c-b0acd8c64700). Thanks and good day. ### Minimal code sample. ```python. sc.pl.scatter(adata, ""total_counts"", ""n_genes_by_counts"", color=""pct_counts_mt"", save='_test.png'). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2670
https://github.com/scverse/scanpy/issues/2670:746,usability,Error,Error,746,"Blank plot when using sc.pl.scatter; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I use `sc.pl.scatter` it returns a blank plot. The axis values are alright but the plot itself is empty. There are about 23M cells. Please advise. ![image](https://github.com/scverse/scanpy/assets/32474661/2d858133-6e60-478a-a98c-b0acd8c64700). Thanks and good day. ### Minimal code sample. ```python. sc.pl.scatter(adata, ""total_counts"", ""n_genes_by_counts"", color=""pct_counts_mt"", save='_test.png'). ```. ### Error output. _No response_. ### Versions. <details>. ```. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2670
https://github.com/scverse/scanpy/pull/2671:533,deployability,updat,updated,533,"n_components parameter for sc.tl.tsne; Dear scanpy-team,. thank you very much for this great package! Similar to issues [https://github.com/scverse/scanpy/issues/1435](url) and [https://github.com/scverse/scanpy/issues/460](url) I am interested in having an n_components parameter in the sc.tl.tsne function. . Apparently, the commit was made but no pull request was opened back in 2019. I added the necessary parameter to the arguments and passed them via the params_sklearn dict to the respective function. . Documentation is also updated. If you feel there is a need for a separate test, let me know, happy to include one. Best,. Tarik.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2671
https://github.com/scverse/scanpy/pull/2671:13,modifiability,paramet,parameter,13,"n_components parameter for sc.tl.tsne; Dear scanpy-team,. thank you very much for this great package! Similar to issues [https://github.com/scverse/scanpy/issues/1435](url) and [https://github.com/scverse/scanpy/issues/460](url) I am interested in having an n_components parameter in the sc.tl.tsne function. . Apparently, the commit was made but no pull request was opened back in 2019. I added the necessary parameter to the arguments and passed them via the params_sklearn dict to the respective function. . Documentation is also updated. If you feel there is a need for a separate test, let me know, happy to include one. Best,. Tarik.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2671
https://github.com/scverse/scanpy/pull/2671:93,modifiability,pac,package,93,"n_components parameter for sc.tl.tsne; Dear scanpy-team,. thank you very much for this great package! Similar to issues [https://github.com/scverse/scanpy/issues/1435](url) and [https://github.com/scverse/scanpy/issues/460](url) I am interested in having an n_components parameter in the sc.tl.tsne function. . Apparently, the commit was made but no pull request was opened back in 2019. I added the necessary parameter to the arguments and passed them via the params_sklearn dict to the respective function. . Documentation is also updated. If you feel there is a need for a separate test, let me know, happy to include one. Best,. Tarik.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2671
https://github.com/scverse/scanpy/pull/2671:271,modifiability,paramet,parameter,271,"n_components parameter for sc.tl.tsne; Dear scanpy-team,. thank you very much for this great package! Similar to issues [https://github.com/scverse/scanpy/issues/1435](url) and [https://github.com/scverse/scanpy/issues/460](url) I am interested in having an n_components parameter in the sc.tl.tsne function. . Apparently, the commit was made but no pull request was opened back in 2019. I added the necessary parameter to the arguments and passed them via the params_sklearn dict to the respective function. . Documentation is also updated. If you feel there is a need for a separate test, let me know, happy to include one. Best,. Tarik.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2671
https://github.com/scverse/scanpy/pull/2671:410,modifiability,paramet,parameter,410,"n_components parameter for sc.tl.tsne; Dear scanpy-team,. thank you very much for this great package! Similar to issues [https://github.com/scverse/scanpy/issues/1435](url) and [https://github.com/scverse/scanpy/issues/460](url) I am interested in having an n_components parameter in the sc.tl.tsne function. . Apparently, the commit was made but no pull request was opened back in 2019. I added the necessary parameter to the arguments and passed them via the params_sklearn dict to the respective function. . Documentation is also updated. If you feel there is a need for a separate test, let me know, happy to include one. Best,. Tarik.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2671
https://github.com/scverse/scanpy/pull/2671:533,safety,updat,updated,533,"n_components parameter for sc.tl.tsne; Dear scanpy-team,. thank you very much for this great package! Similar to issues [https://github.com/scverse/scanpy/issues/1435](url) and [https://github.com/scverse/scanpy/issues/460](url) I am interested in having an n_components parameter in the sc.tl.tsne function. . Apparently, the commit was made but no pull request was opened back in 2019. I added the necessary parameter to the arguments and passed them via the params_sklearn dict to the respective function. . Documentation is also updated. If you feel there is a need for a separate test, let me know, happy to include one. Best,. Tarik.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2671
https://github.com/scverse/scanpy/pull/2671:585,safety,test,test,585,"n_components parameter for sc.tl.tsne; Dear scanpy-team,. thank you very much for this great package! Similar to issues [https://github.com/scverse/scanpy/issues/1435](url) and [https://github.com/scverse/scanpy/issues/460](url) I am interested in having an n_components parameter in the sc.tl.tsne function. . Apparently, the commit was made but no pull request was opened back in 2019. I added the necessary parameter to the arguments and passed them via the params_sklearn dict to the respective function. . Documentation is also updated. If you feel there is a need for a separate test, let me know, happy to include one. Best,. Tarik.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2671
https://github.com/scverse/scanpy/pull/2671:51,security,team,team,51,"n_components parameter for sc.tl.tsne; Dear scanpy-team,. thank you very much for this great package! Similar to issues [https://github.com/scverse/scanpy/issues/1435](url) and [https://github.com/scverse/scanpy/issues/460](url) I am interested in having an n_components parameter in the sc.tl.tsne function. . Apparently, the commit was made but no pull request was opened back in 2019. I added the necessary parameter to the arguments and passed them via the params_sklearn dict to the respective function. . Documentation is also updated. If you feel there is a need for a separate test, let me know, happy to include one. Best,. Tarik.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2671
https://github.com/scverse/scanpy/pull/2671:533,security,updat,updated,533,"n_components parameter for sc.tl.tsne; Dear scanpy-team,. thank you very much for this great package! Similar to issues [https://github.com/scverse/scanpy/issues/1435](url) and [https://github.com/scverse/scanpy/issues/460](url) I am interested in having an n_components parameter in the sc.tl.tsne function. . Apparently, the commit was made but no pull request was opened back in 2019. I added the necessary parameter to the arguments and passed them via the params_sklearn dict to the respective function. . Documentation is also updated. If you feel there is a need for a separate test, let me know, happy to include one. Best,. Tarik.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2671
https://github.com/scverse/scanpy/pull/2671:585,testability,test,test,585,"n_components parameter for sc.tl.tsne; Dear scanpy-team,. thank you very much for this great package! Similar to issues [https://github.com/scverse/scanpy/issues/1435](url) and [https://github.com/scverse/scanpy/issues/460](url) I am interested in having an n_components parameter in the sc.tl.tsne function. . Apparently, the commit was made but no pull request was opened back in 2019. I added the necessary parameter to the arguments and passed them via the params_sklearn dict to the respective function. . Documentation is also updated. If you feel there is a need for a separate test, let me know, happy to include one. Best,. Tarik.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2671
https://github.com/scverse/scanpy/pull/2671:511,usability,Document,Documentation,511,"n_components parameter for sc.tl.tsne; Dear scanpy-team,. thank you very much for this great package! Similar to issues [https://github.com/scverse/scanpy/issues/1435](url) and [https://github.com/scverse/scanpy/issues/460](url) I am interested in having an n_components parameter in the sc.tl.tsne function. . Apparently, the commit was made but no pull request was opened back in 2019. I added the necessary parameter to the arguments and passed them via the params_sklearn dict to the respective function. . Documentation is also updated. If you feel there is a need for a separate test, let me know, happy to include one. Best,. Tarik.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2671
https://github.com/scverse/scanpy/pull/2672:216,deployability,releas,releases,216,"Compatibility with Palantir>=v1.3.0; This PR resolves [Issue #2608](https://github.com/scverse/scanpy/issues/2608) in Scanpy by ensuring compatibility with both [Palantir v1.3.0](https://github.com/dpeerlab/Palantir/releases/tag/v1.3.0) ([function signature](https://github.com/dpeerlab/Palantir/blob/870a9ba88b978a070fd0c29df4d1a3b94b0c9ad9/src/palantir/core.py#L34-L51)) and its [earlier versions](https://github.com/dpeerlab/Palantir/blob/4d4f9fcdbfebcf47b4ca1b7ac8a0fb1b8e5fc089/src/palantir/core.py#L31-L41). This is achieved by substituting the initial keyword argument (`data_df`) with a positional argument. The change aligns with Palantir v1.3.0's new optionality to accept AnnData objects as the first argument, making the keyword `data_df` potentially misleading. Adopting a positional argument ensures compatibility with both new and prior versions of Palantir.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2672
https://github.com/scverse/scanpy/pull/2672:390,deployability,version,versions,390,"Compatibility with Palantir>=v1.3.0; This PR resolves [Issue #2608](https://github.com/scverse/scanpy/issues/2608) in Scanpy by ensuring compatibility with both [Palantir v1.3.0](https://github.com/dpeerlab/Palantir/releases/tag/v1.3.0) ([function signature](https://github.com/dpeerlab/Palantir/blob/870a9ba88b978a070fd0c29df4d1a3b94b0c9ad9/src/palantir/core.py#L34-L51)) and its [earlier versions](https://github.com/dpeerlab/Palantir/blob/4d4f9fcdbfebcf47b4ca1b7ac8a0fb1b8e5fc089/src/palantir/core.py#L31-L41). This is achieved by substituting the initial keyword argument (`data_df`) with a positional argument. The change aligns with Palantir v1.3.0's new optionality to accept AnnData objects as the first argument, making the keyword `data_df` potentially misleading. Adopting a positional argument ensures compatibility with both new and prior versions of Palantir.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2672
https://github.com/scverse/scanpy/pull/2672:852,deployability,version,versions,852,"Compatibility with Palantir>=v1.3.0; This PR resolves [Issue #2608](https://github.com/scverse/scanpy/issues/2608) in Scanpy by ensuring compatibility with both [Palantir v1.3.0](https://github.com/dpeerlab/Palantir/releases/tag/v1.3.0) ([function signature](https://github.com/dpeerlab/Palantir/blob/870a9ba88b978a070fd0c29df4d1a3b94b0c9ad9/src/palantir/core.py#L34-L51)) and its [earlier versions](https://github.com/dpeerlab/Palantir/blob/4d4f9fcdbfebcf47b4ca1b7ac8a0fb1b8e5fc089/src/palantir/core.py#L31-L41). This is achieved by substituting the initial keyword argument (`data_df`) with a positional argument. The change aligns with Palantir v1.3.0's new optionality to accept AnnData objects as the first argument, making the keyword `data_df` potentially misleading. Adopting a positional argument ensures compatibility with both new and prior versions of Palantir.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2672
https://github.com/scverse/scanpy/pull/2672:355,energy efficiency,core,core,355,"Compatibility with Palantir>=v1.3.0; This PR resolves [Issue #2608](https://github.com/scverse/scanpy/issues/2608) in Scanpy by ensuring compatibility with both [Palantir v1.3.0](https://github.com/dpeerlab/Palantir/releases/tag/v1.3.0) ([function signature](https://github.com/dpeerlab/Palantir/blob/870a9ba88b978a070fd0c29df4d1a3b94b0c9ad9/src/palantir/core.py#L34-L51)) and its [earlier versions](https://github.com/dpeerlab/Palantir/blob/4d4f9fcdbfebcf47b4ca1b7ac8a0fb1b8e5fc089/src/palantir/core.py#L31-L41). This is achieved by substituting the initial keyword argument (`data_df`) with a positional argument. The change aligns with Palantir v1.3.0's new optionality to accept AnnData objects as the first argument, making the keyword `data_df` potentially misleading. Adopting a positional argument ensures compatibility with both new and prior versions of Palantir.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2672
https://github.com/scverse/scanpy/pull/2672:496,energy efficiency,core,core,496,"Compatibility with Palantir>=v1.3.0; This PR resolves [Issue #2608](https://github.com/scverse/scanpy/issues/2608) in Scanpy by ensuring compatibility with both [Palantir v1.3.0](https://github.com/dpeerlab/Palantir/releases/tag/v1.3.0) ([function signature](https://github.com/dpeerlab/Palantir/blob/870a9ba88b978a070fd0c29df4d1a3b94b0c9ad9/src/palantir/core.py#L34-L51)) and its [earlier versions](https://github.com/dpeerlab/Palantir/blob/4d4f9fcdbfebcf47b4ca1b7ac8a0fb1b8e5fc089/src/palantir/core.py#L31-L41). This is achieved by substituting the initial keyword argument (`data_df`) with a positional argument. The change aligns with Palantir v1.3.0's new optionality to accept AnnData objects as the first argument, making the keyword `data_df` potentially misleading. Adopting a positional argument ensures compatibility with both new and prior versions of Palantir.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2672
https://github.com/scverse/scanpy/pull/2672:390,integrability,version,versions,390,"Compatibility with Palantir>=v1.3.0; This PR resolves [Issue #2608](https://github.com/scverse/scanpy/issues/2608) in Scanpy by ensuring compatibility with both [Palantir v1.3.0](https://github.com/dpeerlab/Palantir/releases/tag/v1.3.0) ([function signature](https://github.com/dpeerlab/Palantir/blob/870a9ba88b978a070fd0c29df4d1a3b94b0c9ad9/src/palantir/core.py#L34-L51)) and its [earlier versions](https://github.com/dpeerlab/Palantir/blob/4d4f9fcdbfebcf47b4ca1b7ac8a0fb1b8e5fc089/src/palantir/core.py#L31-L41). This is achieved by substituting the initial keyword argument (`data_df`) with a positional argument. The change aligns with Palantir v1.3.0's new optionality to accept AnnData objects as the first argument, making the keyword `data_df` potentially misleading. Adopting a positional argument ensures compatibility with both new and prior versions of Palantir.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2672
https://github.com/scverse/scanpy/pull/2672:534,integrability,sub,substituting,534,"Compatibility with Palantir>=v1.3.0; This PR resolves [Issue #2608](https://github.com/scverse/scanpy/issues/2608) in Scanpy by ensuring compatibility with both [Palantir v1.3.0](https://github.com/dpeerlab/Palantir/releases/tag/v1.3.0) ([function signature](https://github.com/dpeerlab/Palantir/blob/870a9ba88b978a070fd0c29df4d1a3b94b0c9ad9/src/palantir/core.py#L34-L51)) and its [earlier versions](https://github.com/dpeerlab/Palantir/blob/4d4f9fcdbfebcf47b4ca1b7ac8a0fb1b8e5fc089/src/palantir/core.py#L31-L41). This is achieved by substituting the initial keyword argument (`data_df`) with a positional argument. The change aligns with Palantir v1.3.0's new optionality to accept AnnData objects as the first argument, making the keyword `data_df` potentially misleading. Adopting a positional argument ensures compatibility with both new and prior versions of Palantir.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2672
https://github.com/scverse/scanpy/pull/2672:852,integrability,version,versions,852,"Compatibility with Palantir>=v1.3.0; This PR resolves [Issue #2608](https://github.com/scverse/scanpy/issues/2608) in Scanpy by ensuring compatibility with both [Palantir v1.3.0](https://github.com/dpeerlab/Palantir/releases/tag/v1.3.0) ([function signature](https://github.com/dpeerlab/Palantir/blob/870a9ba88b978a070fd0c29df4d1a3b94b0c9ad9/src/palantir/core.py#L34-L51)) and its [earlier versions](https://github.com/dpeerlab/Palantir/blob/4d4f9fcdbfebcf47b4ca1b7ac8a0fb1b8e5fc089/src/palantir/core.py#L31-L41). This is achieved by substituting the initial keyword argument (`data_df`) with a positional argument. The change aligns with Palantir v1.3.0's new optionality to accept AnnData objects as the first argument, making the keyword `data_df` potentially misleading. Adopting a positional argument ensures compatibility with both new and prior versions of Palantir.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2672
https://github.com/scverse/scanpy/pull/2672:0,interoperability,Compatib,Compatibility,0,"Compatibility with Palantir>=v1.3.0; This PR resolves [Issue #2608](https://github.com/scverse/scanpy/issues/2608) in Scanpy by ensuring compatibility with both [Palantir v1.3.0](https://github.com/dpeerlab/Palantir/releases/tag/v1.3.0) ([function signature](https://github.com/dpeerlab/Palantir/blob/870a9ba88b978a070fd0c29df4d1a3b94b0c9ad9/src/palantir/core.py#L34-L51)) and its [earlier versions](https://github.com/dpeerlab/Palantir/blob/4d4f9fcdbfebcf47b4ca1b7ac8a0fb1b8e5fc089/src/palantir/core.py#L31-L41). This is achieved by substituting the initial keyword argument (`data_df`) with a positional argument. The change aligns with Palantir v1.3.0's new optionality to accept AnnData objects as the first argument, making the keyword `data_df` potentially misleading. Adopting a positional argument ensures compatibility with both new and prior versions of Palantir.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2672
https://github.com/scverse/scanpy/pull/2672:137,interoperability,compatib,compatibility,137,"Compatibility with Palantir>=v1.3.0; This PR resolves [Issue #2608](https://github.com/scverse/scanpy/issues/2608) in Scanpy by ensuring compatibility with both [Palantir v1.3.0](https://github.com/dpeerlab/Palantir/releases/tag/v1.3.0) ([function signature](https://github.com/dpeerlab/Palantir/blob/870a9ba88b978a070fd0c29df4d1a3b94b0c9ad9/src/palantir/core.py#L34-L51)) and its [earlier versions](https://github.com/dpeerlab/Palantir/blob/4d4f9fcdbfebcf47b4ca1b7ac8a0fb1b8e5fc089/src/palantir/core.py#L31-L41). This is achieved by substituting the initial keyword argument (`data_df`) with a positional argument. The change aligns with Palantir v1.3.0's new optionality to accept AnnData objects as the first argument, making the keyword `data_df` potentially misleading. Adopting a positional argument ensures compatibility with both new and prior versions of Palantir.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2672
https://github.com/scverse/scanpy/pull/2672:814,interoperability,compatib,compatibility,814,"Compatibility with Palantir>=v1.3.0; This PR resolves [Issue #2608](https://github.com/scverse/scanpy/issues/2608) in Scanpy by ensuring compatibility with both [Palantir v1.3.0](https://github.com/dpeerlab/Palantir/releases/tag/v1.3.0) ([function signature](https://github.com/dpeerlab/Palantir/blob/870a9ba88b978a070fd0c29df4d1a3b94b0c9ad9/src/palantir/core.py#L34-L51)) and its [earlier versions](https://github.com/dpeerlab/Palantir/blob/4d4f9fcdbfebcf47b4ca1b7ac8a0fb1b8e5fc089/src/palantir/core.py#L31-L41). This is achieved by substituting the initial keyword argument (`data_df`) with a positional argument. The change aligns with Palantir v1.3.0's new optionality to accept AnnData objects as the first argument, making the keyword `data_df` potentially misleading. Adopting a positional argument ensures compatibility with both new and prior versions of Palantir.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2672
https://github.com/scverse/scanpy/pull/2672:390,modifiability,version,versions,390,"Compatibility with Palantir>=v1.3.0; This PR resolves [Issue #2608](https://github.com/scverse/scanpy/issues/2608) in Scanpy by ensuring compatibility with both [Palantir v1.3.0](https://github.com/dpeerlab/Palantir/releases/tag/v1.3.0) ([function signature](https://github.com/dpeerlab/Palantir/blob/870a9ba88b978a070fd0c29df4d1a3b94b0c9ad9/src/palantir/core.py#L34-L51)) and its [earlier versions](https://github.com/dpeerlab/Palantir/blob/4d4f9fcdbfebcf47b4ca1b7ac8a0fb1b8e5fc089/src/palantir/core.py#L31-L41). This is achieved by substituting the initial keyword argument (`data_df`) with a positional argument. The change aligns with Palantir v1.3.0's new optionality to accept AnnData objects as the first argument, making the keyword `data_df` potentially misleading. Adopting a positional argument ensures compatibility with both new and prior versions of Palantir.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2672
https://github.com/scverse/scanpy/pull/2672:852,modifiability,version,versions,852,"Compatibility with Palantir>=v1.3.0; This PR resolves [Issue #2608](https://github.com/scverse/scanpy/issues/2608) in Scanpy by ensuring compatibility with both [Palantir v1.3.0](https://github.com/dpeerlab/Palantir/releases/tag/v1.3.0) ([function signature](https://github.com/dpeerlab/Palantir/blob/870a9ba88b978a070fd0c29df4d1a3b94b0c9ad9/src/palantir/core.py#L34-L51)) and its [earlier versions](https://github.com/dpeerlab/Palantir/blob/4d4f9fcdbfebcf47b4ca1b7ac8a0fb1b8e5fc089/src/palantir/core.py#L31-L41). This is achieved by substituting the initial keyword argument (`data_df`) with a positional argument. The change aligns with Palantir v1.3.0's new optionality to accept AnnData objects as the first argument, making the keyword `data_df` potentially misleading. Adopting a positional argument ensures compatibility with both new and prior versions of Palantir.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2672
https://github.com/scverse/scanpy/pull/2672:248,security,sign,signature,248,"Compatibility with Palantir>=v1.3.0; This PR resolves [Issue #2608](https://github.com/scverse/scanpy/issues/2608) in Scanpy by ensuring compatibility with both [Palantir v1.3.0](https://github.com/dpeerlab/Palantir/releases/tag/v1.3.0) ([function signature](https://github.com/dpeerlab/Palantir/blob/870a9ba88b978a070fd0c29df4d1a3b94b0c9ad9/src/palantir/core.py#L34-L51)) and its [earlier versions](https://github.com/dpeerlab/Palantir/blob/4d4f9fcdbfebcf47b4ca1b7ac8a0fb1b8e5fc089/src/palantir/core.py#L31-L41). This is achieved by substituting the initial keyword argument (`data_df`) with a positional argument. The change aligns with Palantir v1.3.0's new optionality to accept AnnData objects as the first argument, making the keyword `data_df` potentially misleading. Adopting a positional argument ensures compatibility with both new and prior versions of Palantir.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2672
https://github.com/scverse/scanpy/issues/2673:3,availability,error,error,3,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:32,availability,cluster,clustermap,32,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:408,availability,cluster,clusters,408,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:438,availability,cluster,clustermap,438,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:538,availability,cluster,clustermap,538,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:762,availability,error,error,762,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:991,availability,cluster,clustermap,991,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:1045,availability,Error,Error,1045,"# Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 727 copy=copy,. 728 typ=manager,. 729 ). 731",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:1227,availability,cluster,clustermap,1227," - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 727 copy=copy,. 728 typ=manager,. 729 ). 731 # For data is list-like, or Iterable (will consume into list). 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:1364,availability,cluster,clustermap,1364," their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 727 copy=copy,. 728 typ=manager,. 729 ). 731 # For data is list-like, or Iterable (will consume into list). 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:349, in ndarray_to_mgr(values, index, columns, dtype, copy, typ). 344 # _prep_ndarraylike ensures that values.ndim == 2 at this point",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:1786,availability,error,error,1786,"o the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 727 copy=copy,. 728 typ=manager,. 729 ). 731 # For data is list-like, or Iterable (will consume into list). 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:349, in ndarray_to_mgr(values, index, columns, dtype, copy, typ). 344 # _prep_ndarraylike ensures that values.ndim == 2 at this point. 345 index, columns = _get_axes(. 346 values.shape[0], values.shape[1], index=index, columns=columns. 347 ). --> 349 _check_values_indices_shape_match(values, index, columns). 351 if typ == ""array"":. 353 if issubclass(values.dtype.type, str):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:420, in _check_values_indices_shape_match(values, index, columns). 418 passed = v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:32,deployability,cluster,clustermap,32,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:214,deployability,version,version,214,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:408,deployability,cluster,clusters,408,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:438,deployability,cluster,clustermap,438,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:538,deployability,cluster,clustermap,538,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:795,deployability,version,version,795,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:991,deployability,cluster,clustermap,991,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:1227,deployability,cluster,clustermap,1227," - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 727 copy=copy,. 728 typ=manager,. 729 ). 731 # For data is list-like, or Iterable (will consume into list). 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:1364,deployability,cluster,clustermap,1364," their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 727 copy=copy,. 728 typ=manager,. 729 ). 731 # For data is list-like, or Iterable (will consume into list). 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:349, in ndarray_to_mgr(values, index, columns, dtype, copy, typ). 344 # _prep_ndarraylike ensures that values.ndim == 2 at this point",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:1890,deployability,manag,manager,1890,"np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 727 copy=copy,. 728 typ=manager,. 729 ). 731 # For data is list-like, or Iterable (will consume into list). 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:349, in ndarray_to_mgr(values, index, columns, dtype, copy, typ). 344 # _prep_ndarraylike ensures that values.ndim == 2 at this point. 345 index, columns = _get_axes(. 346 values.shape[0], values.shape[1], index=index, columns=columns. 347 ). --> 349 _check_values_indices_shape_match(values, index, columns). 351 if typ == ""array"":. 353 if issubclass(values.dtype.type, str):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:420, in _check_values_indices_shape_match(values, index, columns). 418 passed = values.shape. 419 implied = (len(index), len(columns)). --> 420 raise ValueError(f""Shape of passed values ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:2028,deployability,manag,manager,2028,"""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 727 copy=copy,. 728 typ=manager,. 729 ). 731 # For data is list-like, or Iterable (will consume into list). 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:349, in ndarray_to_mgr(values, index, columns, dtype, copy, typ). 344 # _prep_ndarraylike ensures that values.ndim == 2 at this point. 345 index, columns = _get_axes(. 346 values.shape[0], values.shape[1], index=index, columns=columns. 347 ). --> 349 _check_values_indices_shape_match(values, index, columns). 351 if typ == ""array"":. 353 if issubclass(values.dtype.type, str):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:420, in _check_values_indices_shape_match(values, index, columns). 418 passed = values.shape. 419 implied = (len(index), len(columns)). --> 420 raise ValueError(f""Shape of passed values is {passed}, indices imply {implied}""). ValueError: Shape of passed values is (29214, 22333), indices imply (29214, 921). ```. ### Version",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:3025,deployability,Version,Versions,3025,"anager,. 729 ). 731 # For data is list-like, or Iterable (will consume into list). 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:349, in ndarray_to_mgr(values, index, columns, dtype, copy, typ). 344 # _prep_ndarraylike ensures that values.ndim == 2 at this point. 345 index, columns = _get_axes(. 346 values.shape[0], values.shape[1], index=index, columns=columns. 347 ). --> 349 _check_values_indices_shape_match(values, index, columns). 351 if typ == ""array"":. 353 if issubclass(values.dtype.type, str):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:420, in _check_values_indices_shape_match(values, index, columns). 418 passed = values.shape. 419 implied = (len(index), len(columns)). --> 420 raise ValueError(f""Shape of passed values is {passed}, indices imply {implied}""). ValueError: Shape of passed values is (29214, 22333), indices imply (29214, 921). ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.5. -----. PIL 10.0.0. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2021.04.0. dateutil 2.8.2. debugpy 1.7.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. fqdn NA. fsspec 2023.9.0. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. importlib_resources NA. ipykernel 6.25.2. ipython_genutils 0.2.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_server 1.24.0. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. louvain 0.8.1. markupsafe 2.1.3. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:5273,deployability,updat,updated,5273,". cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2021.04.0. dateutil 2.8.2. debugpy 1.7.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. fqdn NA. fsspec 2023.9.0. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. importlib_resources NA. ipykernel 6.25.2. ipython_genutils 0.2.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_server 1.24.0. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. louvain 0.8.1. markupsafe 2.1.3. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numexpr 2.8.6. numpy 1.24.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.17.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pyparsing 2.4.7. pytz 2023.3.post1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 68.2.2. setuptools_scm NA. six 1.16.0. sklearn 1.3.0. sniffio 1.3.0. socks 1.7.1. stack_data 0.6.2. statsmodels 0.14.0. tblib 1.7.0. terminado 0.17.1. texttable 1.6.7. threadpoolctl 3.2.0. tlz 0.12.2. toolz 0.12.0. tornado 6.1. traitlets 5.9.0. typing_extensions NA. uri_template NA. urllib3 1.26.16. wcwidth 0.2.6. webcolors 1.13. websocket 1.6.3. yaml 6.0.1. zipp NA. zmq 25.1.1. -----. IPython 8.12.0. jupyter_client 7.3.4. jupyter_core 4.12.0. jupyterlab 3.6.5. notebook 6.3.0. -----. Python 3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]. Linux-3.10.0-862.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2023-09-27 17:56. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:1673,energy efficiency,core,core,1673," `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 727 copy=copy,. 728 typ=manager,. 729 ). 731 # For data is list-like, or Iterable (will consume into list). 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:349, in ndarray_to_mgr(values, index, columns, dtype, copy, typ). 344 # _prep_ndarraylike ensures that values.ndim == 2 at this point. 345 index, columns = _get_axes(. 346 values.shape[0], values.shape[1], index=index, columns=columns. 347 ). --> 349 _check_values_indices_shape_match(values, index, columns). 351 if typ == ""array"":. 353 if issubclass(values.dtype.type, str):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/panda",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:1890,energy efficiency,manag,manager,1890,"np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 727 copy=copy,. 728 typ=manager,. 729 ). 731 # For data is list-like, or Iterable (will consume into list). 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:349, in ndarray_to_mgr(values, index, columns, dtype, copy, typ). 344 # _prep_ndarraylike ensures that values.ndim == 2 at this point. 345 index, columns = _get_axes(. 346 values.shape[0], values.shape[1], index=index, columns=columns. 347 ). --> 349 _check_values_indices_shape_match(values, index, columns). 351 if typ == ""array"":. 353 if issubclass(values.dtype.type, str):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:420, in _check_values_indices_shape_match(values, index, columns). 418 passed = values.shape. 419 implied = (len(index), len(columns)). --> 420 raise ValueError(f""Shape of passed values ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:2028,energy efficiency,manag,manager,2028,"""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 727 copy=copy,. 728 typ=manager,. 729 ). 731 # For data is list-like, or Iterable (will consume into list). 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:349, in ndarray_to_mgr(values, index, columns, dtype, copy, typ). 344 # _prep_ndarraylike ensures that values.ndim == 2 at this point. 345 index, columns = _get_axes(. 346 values.shape[0], values.shape[1], index=index, columns=columns. 347 ). --> 349 _check_values_indices_shape_match(values, index, columns). 351 if typ == ""array"":. 353 if issubclass(values.dtype.type, str):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:420, in _check_values_indices_shape_match(values, index, columns). 418 passed = values.shape. 419 implied = (len(index), len(columns)). --> 420 raise ValueError(f""Shape of passed values is {passed}, indices imply {implied}""). ValueError: Shape of passed values is (29214, 22333), indices imply (29214, 921). ```. ### Version",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:2205,energy efficiency,core,core,2205,"ne 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 727 copy=copy,. 728 typ=manager,. 729 ). 731 # For data is list-like, or Iterable (will consume into list). 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:349, in ndarray_to_mgr(values, index, columns, dtype, copy, typ). 344 # _prep_ndarraylike ensures that values.ndim == 2 at this point. 345 index, columns = _get_axes(. 346 values.shape[0], values.shape[1], index=index, columns=columns. 347 ). --> 349 _check_values_indices_shape_match(values, index, columns). 351 if typ == ""array"":. 353 if issubclass(values.dtype.type, str):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:420, in _check_values_indices_shape_match(values, index, columns). 418 passed = values.shape. 419 implied = (len(index), len(columns)). --> 420 raise ValueError(f""Shape of passed values is {passed}, indices imply {implied}""). ValueError: Shape of passed values is (29214, 22333), indices imply (29214, 921). ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.5. -----. PIL 10.0.0. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:2677,energy efficiency,core,core,2677,"rame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 727 copy=copy,. 728 typ=manager,. 729 ). 731 # For data is list-like, or Iterable (will consume into list). 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:349, in ndarray_to_mgr(values, index, columns, dtype, copy, typ). 344 # _prep_ndarraylike ensures that values.ndim == 2 at this point. 345 index, columns = _get_axes(. 346 values.shape[0], values.shape[1], index=index, columns=columns. 347 ). --> 349 _check_values_indices_shape_match(values, index, columns). 351 if typ == ""array"":. 353 if issubclass(values.dtype.type, str):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:420, in _check_values_indices_shape_match(values, index, columns). 418 passed = values.shape. 419 implied = (len(index), len(columns)). --> 420 raise ValueError(f""Shape of passed values is {passed}, indices imply {implied}""). ValueError: Shape of passed values is (29214, 22333), indices imply (29214, 921). ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.5. -----. PIL 10.0.0. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2021.04.0. dateutil 2.8.2. debugpy 1.7.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. fqdn NA. fsspec 2023.9.0. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. importlib_resources NA. ipykernel 6.25.2. ipython_genutils 0.2.0. isoduration NA.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:3273,energy efficiency,cloud,cloudpickle,3273,"ns, dtype, copy, typ). 344 # _prep_ndarraylike ensures that values.ndim == 2 at this point. 345 index, columns = _get_axes(. 346 values.shape[0], values.shape[1], index=index, columns=columns. 347 ). --> 349 _check_values_indices_shape_match(values, index, columns). 351 if typ == ""array"":. 353 if issubclass(values.dtype.type, str):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:420, in _check_values_indices_shape_match(values, index, columns). 418 passed = values.shape. 419 implied = (len(index), len(columns)). --> 420 raise ValueError(f""Shape of passed values is {passed}, indices imply {implied}""). ValueError: Shape of passed values is (29214, 22333), indices imply (29214, 921). ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.5. -----. PIL 10.0.0. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2021.04.0. dateutil 2.8.2. debugpy 1.7.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. fqdn NA. fsspec 2023.9.0. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. importlib_resources NA. ipykernel 6.25.2. ipython_genutils 0.2.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_server 1.24.0. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. louvain 0.8.1. markupsafe 2.1.3. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numexpr 2.8.6. numpy 1.24.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.17.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:214,integrability,version,version,214,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:612,integrability,sub,subadata,612,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:694,integrability,sub,subadata,694,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:795,integrability,version,version,795,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:953,integrability,sub,subadata,953,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:1002,integrability,sub,subadata,1002,"or when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 72",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:1238,integrability,sub,subadata,1238,"tional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 727 copy=copy,. 728 typ=manager,. 729 ). 731 # For data is list-like, or Iterable (will consume into list). 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:349, i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:3025,integrability,Version,Versions,3025,"anager,. 729 ). 731 # For data is list-like, or Iterable (will consume into list). 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:349, in ndarray_to_mgr(values, index, columns, dtype, copy, typ). 344 # _prep_ndarraylike ensures that values.ndim == 2 at this point. 345 index, columns = _get_axes(. 346 values.shape[0], values.shape[1], index=index, columns=columns. 347 ). --> 349 _check_values_indices_shape_match(values, index, columns). 351 if typ == ""array"":. 353 if issubclass(values.dtype.type, str):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:420, in _check_values_indices_shape_match(values, index, columns). 418 passed = values.shape. 419 implied = (len(index), len(columns)). --> 420 raise ValueError(f""Shape of passed values is {passed}, indices imply {implied}""). ValueError: Shape of passed values is (29214, 22333), indices imply (29214, 921). ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.5. -----. PIL 10.0.0. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2021.04.0. dateutil 2.8.2. debugpy 1.7.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. fqdn NA. fsspec 2023.9.0. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. importlib_resources NA. ipykernel 6.25.2. ipython_genutils 0.2.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_server 1.24.0. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. louvain 0.8.1. markupsafe 2.1.3. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:569,interoperability,specif,specify,569,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:214,modifiability,version,version,214,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:581,modifiability,paramet,parameters,581,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:795,modifiability,version,version,795,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:811,modifiability,pac,packages,811,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:1319,modifiability,pac,packages,1319," happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 727 copy=copy,. 728 typ=manager,. 729 ). 731 # For data is list-like, or Iterable (will consume into list). 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:349, in ndarray_to_mgr(values, index, columns, dtype, copy, typ). 344 # _prep_ndarrayli",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:1657,modifiability,pac,packages,1657,"gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 727 copy=copy,. 728 typ=manager,. 729 ). 731 # For data is list-like, or Iterable (will consume into list). 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:349, in ndarray_to_mgr(values, index, columns, dtype, copy, typ). 344 # _prep_ndarraylike ensures that values.ndim == 2 at this point. 345 index, columns = _get_axes(. 346 values.shape[0], values.shape[1], index=index, columns=columns. 347 ). --> 349 _check_values_indices_shape_match(values, index, columns). 351 if typ == ""array"":. 353 if issubclass(values.dtype.type, str):. File ~/anaconda3/envs/scell/lib/python3.8/site-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:2189,modifiability,pac,packages,2189,"ll In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 727 copy=copy,. 728 typ=manager,. 729 ). 731 # For data is list-like, or Iterable (will consume into list). 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:349, in ndarray_to_mgr(values, index, columns, dtype, copy, typ). 344 # _prep_ndarraylike ensures that values.ndim == 2 at this point. 345 index, columns = _get_axes(. 346 values.shape[0], values.shape[1], index=index, columns=columns. 347 ). --> 349 _check_values_indices_shape_match(values, index, columns). 351 if typ == ""array"":. 353 if issubclass(values.dtype.type, str):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:420, in _check_values_indices_shape_match(values, index, columns). 418 passed = values.shape. 419 implied = (len(index), len(columns)). --> 420 raise ValueError(f""Shape of passed values is {passed}, indices imply {implied}""). ValueError: Shape of passed values is (29214, 22333), indices imply (29214, 921). ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.5. -----. PIL 10.0.0. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:2661,modifiability,pac,packages,2661,"/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 727 copy=copy,. 728 typ=manager,. 729 ). 731 # For data is list-like, or Iterable (will consume into list). 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:349, in ndarray_to_mgr(values, index, columns, dtype, copy, typ). 344 # _prep_ndarraylike ensures that values.ndim == 2 at this point. 345 index, columns = _get_axes(. 346 values.shape[0], values.shape[1], index=index, columns=columns. 347 ). --> 349 _check_values_indices_shape_match(values, index, columns). 351 if typ == ""array"":. 353 if issubclass(values.dtype.type, str):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:420, in _check_values_indices_shape_match(values, index, columns). 418 passed = values.shape. 419 implied = (len(index), len(columns)). --> 420 raise ValueError(f""Shape of passed values is {passed}, indices imply {implied}""). ValueError: Shape of passed values is (29214, 22333), indices imply (29214, 921). ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.5. -----. PIL 10.0.0. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2021.04.0. dateutil 2.8.2. debugpy 1.7.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. fqdn NA. fsspec 2023.9.0. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. importlib_resources NA. ipykernel 6.25.2. ipython_genutils 0.2.0. i",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:3025,modifiability,Version,Versions,3025,"anager,. 729 ). 731 # For data is list-like, or Iterable (will consume into list). 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:349, in ndarray_to_mgr(values, index, columns, dtype, copy, typ). 344 # _prep_ndarraylike ensures that values.ndim == 2 at this point. 345 index, columns = _get_axes(. 346 values.shape[0], values.shape[1], index=index, columns=columns. 347 ). --> 349 _check_values_indices_shape_match(values, index, columns). 351 if typ == ""array"":. 353 if issubclass(values.dtype.type, str):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:420, in _check_values_indices_shape_match(values, index, columns). 418 passed = values.shape. 419 implied = (len(index), len(columns)). --> 420 raise ValueError(f""Shape of passed values is {passed}, indices imply {implied}""). ValueError: Shape of passed values is (29214, 22333), indices imply (29214, 921). ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.5. -----. PIL 10.0.0. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2021.04.0. dateutil 2.8.2. debugpy 1.7.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. fqdn NA. fsspec 2023.9.0. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. importlib_resources NA. ipykernel 6.25.2. ipython_genutils 0.2.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_server 1.24.0. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. louvain 0.8.1. markupsafe 2.1.3. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:3417,modifiability,deco,decorator,3417,"], values.shape[1], index=index, columns=columns. 347 ). --> 349 _check_values_indices_shape_match(values, index, columns). 351 if typ == ""array"":. 353 if issubclass(values.dtype.type, str):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:420, in _check_values_indices_shape_match(values, index, columns). 418 passed = values.shape. 419 implied = (len(index), len(columns)). --> 420 raise ValueError(f""Shape of passed values is {passed}, indices imply {implied}""). ValueError: Shape of passed values is (29214, 22333), indices imply (29214, 921). ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.5. -----. PIL 10.0.0. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2021.04.0. dateutil 2.8.2. debugpy 1.7.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. fqdn NA. fsspec 2023.9.0. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. importlib_resources NA. ipykernel 6.25.2. ipython_genutils 0.2.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_server 1.24.0. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. louvain 0.8.1. markupsafe 2.1.3. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numexpr 2.8.6. numpy 1.24.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.17.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:4066,modifiability,pac,packaging,4066,. scanpy 1.9.5. -----. PIL 10.0.0. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2021.04.0. dateutil 2.8.2. debugpy 1.7.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. fqdn NA. fsspec 2023.9.0. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. importlib_resources NA. ipykernel 6.25.2. ipython_genutils 0.2.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_server 1.24.0. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. louvain 0.8.1. markupsafe 2.1.3. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numexpr 2.8.6. numpy 1.24.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.17.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pyparsing 2.4.7. pytz 2023.3.post1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 68.2.2. setuptools_scm NA. six 1.16.0. sklearn 1.3.0. sniffio 1.3.0. socks 1.7.1. stack_data 0.6.2. statsmodels 0.14.0. tblib 1.7.0. terminado 0.17.1. texttable 1.6.7. threadpoolctl 3.2.0. tlz 0.12.2. toolz 0.12.0. tornado 6.1. traitlets 5.9.0. typing_extensions NA. uri_template NA. urllib3 1.26.16. wcwidth 0.2.6. webcolors 1.13. websocket 1.6.3. yaml 6.0.1. zipp NA. zmq 25.1.1. -----. IPython 8.12.0. jupyter_client 7.3.4.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:3,performance,error,error,3,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:762,performance,error,error,762,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:1045,performance,Error,Error,1045,"# Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 727 copy=copy,. 728 typ=manager,. 729 ). 731",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:1786,performance,error,error,1786,"o the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 727 copy=copy,. 728 typ=manager,. 729 ). 731 # For data is list-like, or Iterable (will consume into list). 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:349, in ndarray_to_mgr(values, index, columns, dtype, copy, typ). 344 # _prep_ndarraylike ensures that values.ndim == 2 at this point. 345 index, columns = _get_axes(. 346 values.shape[0], values.shape[1], index=index, columns=columns. 347 ). --> 349 _check_values_indices_shape_match(values, index, columns). 351 if typ == ""array"":. 353 if issubclass(values.dtype.type, str):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:420, in _check_values_indices_shape_match(values, index, columns). 418 passed = v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:552,reliability,doe,does,552,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:3,safety,error,error,3,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:762,safety,error,error,762,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:1045,safety,Error,Error,1045,"# Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 727 copy=copy,. 728 typ=manager,. 729 ). 731",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:1786,safety,error,error,1786,"o the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 727 copy=copy,. 728 typ=manager,. 729 ). 731 # For data is list-like, or Iterable (will consume into list). 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:349, in ndarray_to_mgr(values, index, columns, dtype, copy, typ). 344 # _prep_ndarraylike ensures that values.ndim == 2 at this point. 345 index, columns = _get_axes(. 346 values.shape[0], values.shape[1], index=index, columns=columns. 347 ). --> 349 _check_values_indices_shape_match(values, index, columns). 351 if typ == ""array"":. 353 if issubclass(values.dtype.type, str):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:420, in _check_values_indices_shape_match(values, index, columns). 418 passed = v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:1890,safety,manag,manager,1890,"np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 727 copy=copy,. 728 typ=manager,. 729 ). 731 # For data is list-like, or Iterable (will consume into list). 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:349, in ndarray_to_mgr(values, index, columns, dtype, copy, typ). 344 # _prep_ndarraylike ensures that values.ndim == 2 at this point. 345 index, columns = _get_axes(. 346 values.shape[0], values.shape[1], index=index, columns=columns. 347 ). --> 349 _check_values_indices_shape_match(values, index, columns). 351 if typ == ""array"":. 353 if issubclass(values.dtype.type, str):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:420, in _check_values_indices_shape_match(values, index, columns). 418 passed = values.shape. 419 implied = (len(index), len(columns)). --> 420 raise ValueError(f""Shape of passed values ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:2028,safety,manag,manager,2028,"""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 727 copy=copy,. 728 typ=manager,. 729 ). 731 # For data is list-like, or Iterable (will consume into list). 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:349, in ndarray_to_mgr(values, index, columns, dtype, copy, typ). 344 # _prep_ndarraylike ensures that values.ndim == 2 at this point. 345 index, columns = _get_axes(. 346 values.shape[0], values.shape[1], index=index, columns=columns. 347 ). --> 349 _check_values_indices_shape_match(values, index, columns). 351 if typ == ""array"":. 353 if issubclass(values.dtype.type, str):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:420, in _check_values_indices_shape_match(values, index, columns). 418 passed = values.shape. 419 implied = (len(index), len(columns)). --> 420 raise ValueError(f""Shape of passed values is {passed}, indices imply {implied}""). ValueError: Shape of passed values is (29214, 22333), indices imply (29214, 921). ```. ### Version",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:5273,safety,updat,updated,5273,". cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2021.04.0. dateutil 2.8.2. debugpy 1.7.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. fqdn NA. fsspec 2023.9.0. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. importlib_resources NA. ipykernel 6.25.2. ipython_genutils 0.2.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_server 1.24.0. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. louvain 0.8.1. markupsafe 2.1.3. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numexpr 2.8.6. numpy 1.24.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.17.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pyparsing 2.4.7. pytz 2023.3.post1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 68.2.2. setuptools_scm NA. six 1.16.0. sklearn 1.3.0. sniffio 1.3.0. socks 1.7.1. stack_data 0.6.2. statsmodels 0.14.0. tblib 1.7.0. terminado 0.17.1. texttable 1.6.7. threadpoolctl 3.2.0. tlz 0.12.2. toolz 0.12.0. tornado 6.1. traitlets 5.9.0. typing_extensions NA. uri_template NA. urllib3 1.26.16. wcwidth 0.2.6. webcolors 1.13. websocket 1.6.3. yaml 6.0.1. zipp NA. zmq 25.1.1. -----. IPython 8.12.0. jupyter_client 7.3.4. jupyter_core 4.12.0. jupyterlab 3.6.5. notebook 6.3.0. -----. Python 3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]. Linux-3.10.0-862.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2023-09-27 17:56. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:3214,security,certif,certifi,3214,"s/construction.py:349, in ndarray_to_mgr(values, index, columns, dtype, copy, typ). 344 # _prep_ndarraylike ensures that values.ndim == 2 at this point. 345 index, columns = _get_axes(. 346 values.shape[0], values.shape[1], index=index, columns=columns. 347 ). --> 349 _check_values_indices_shape_match(values, index, columns). 351 if typ == ""array"":. 353 if issubclass(values.dtype.type, str):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:420, in _check_values_indices_shape_match(values, index, columns). 418 passed = values.shape. 419 implied = (len(index), len(columns)). --> 420 raise ValueError(f""Shape of passed values is {passed}, indices imply {implied}""). ValueError: Shape of passed values is (29214, 22333), indices imply (29214, 921). ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.5. -----. PIL 10.0.0. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2021.04.0. dateutil 2.8.2. debugpy 1.7.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. fqdn NA. fsspec 2023.9.0. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. importlib_resources NA. ipykernel 6.25.2. ipython_genutils 0.2.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_server 1.24.0. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. louvain 0.8.1. markupsafe 2.1.3. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numexpr 2.8.6. numpy 1.24.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.17.0. prometheus_client NA. prompt_",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:3664,security,iso,isoduration,3664,"pandas/core/internals/construction.py:420, in _check_values_indices_shape_match(values, index, columns). 418 passed = values.shape. 419 implied = (len(index), len(columns)). --> 420 raise ValueError(f""Shape of passed values is {passed}, indices imply {implied}""). ValueError: Shape of passed values is (29214, 22333), indices imply (29214, 921). ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.9.5. -----. PIL 10.0.0. anyio NA. arrow 1.2.3. asttokens NA. attr 23.1.0. attrs 23.1.0. babel 2.12.1. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.15.1. charset_normalizer 3.2.0. cloudpickle 2.2.1. colorama 0.4.6. comm 0.1.4. cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2021.04.0. dateutil 2.8.2. debugpy 1.7.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. fqdn NA. fsspec 2023.9.0. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. importlib_resources NA. ipykernel 6.25.2. ipython_genutils 0.2.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_server 1.24.0. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. louvain 0.8.1. markupsafe 2.1.3. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numexpr 2.8.6. numpy 1.24.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.17.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pyparsing 2.4.7. pytz 2023.3.post1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 68.2.2. setuptools_scm NA",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:4714,security,soc,socks,4714,". cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2021.04.0. dateutil 2.8.2. debugpy 1.7.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. fqdn NA. fsspec 2023.9.0. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. importlib_resources NA. ipykernel 6.25.2. ipython_genutils 0.2.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_server 1.24.0. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. louvain 0.8.1. markupsafe 2.1.3. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numexpr 2.8.6. numpy 1.24.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.17.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pyparsing 2.4.7. pytz 2023.3.post1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 68.2.2. setuptools_scm NA. six 1.16.0. sklearn 1.3.0. sniffio 1.3.0. socks 1.7.1. stack_data 0.6.2. statsmodels 0.14.0. tblib 1.7.0. terminado 0.17.1. texttable 1.6.7. threadpoolctl 3.2.0. tlz 0.12.2. toolz 0.12.0. tornado 6.1. traitlets 5.9.0. typing_extensions NA. uri_template NA. urllib3 1.26.16. wcwidth 0.2.6. webcolors 1.13. websocket 1.6.3. yaml 6.0.1. zipp NA. zmq 25.1.1. -----. IPython 8.12.0. jupyter_client 7.3.4. jupyter_core 4.12.0. jupyterlab 3.6.5. notebook 6.3.0. -----. Python 3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]. Linux-3.10.0-862.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2023-09-27 17:56. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:5253,security,Session,Session,5253,". cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2021.04.0. dateutil 2.8.2. debugpy 1.7.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. fqdn NA. fsspec 2023.9.0. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. importlib_resources NA. ipykernel 6.25.2. ipython_genutils 0.2.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_server 1.24.0. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. louvain 0.8.1. markupsafe 2.1.3. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numexpr 2.8.6. numpy 1.24.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.17.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pyparsing 2.4.7. pytz 2023.3.post1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 68.2.2. setuptools_scm NA. six 1.16.0. sklearn 1.3.0. sniffio 1.3.0. socks 1.7.1. stack_data 0.6.2. statsmodels 0.14.0. tblib 1.7.0. terminado 0.17.1. texttable 1.6.7. threadpoolctl 3.2.0. tlz 0.12.2. toolz 0.12.0. tornado 6.1. traitlets 5.9.0. typing_extensions NA. uri_template NA. urllib3 1.26.16. wcwidth 0.2.6. webcolors 1.13. websocket 1.6.3. yaml 6.0.1. zipp NA. zmq 25.1.1. -----. IPython 8.12.0. jupyter_client 7.3.4. jupyter_core 4.12.0. jupyterlab 3.6.5. notebook 6.3.0. -----. Python 3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]. Linux-3.10.0-862.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2023-09-27 17:56. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:5273,security,updat,updated,5273,". cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2021.04.0. dateutil 2.8.2. debugpy 1.7.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. fqdn NA. fsspec 2023.9.0. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. importlib_resources NA. ipykernel 6.25.2. ipython_genutils 0.2.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_server 1.24.0. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. louvain 0.8.1. markupsafe 2.1.3. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numexpr 2.8.6. numpy 1.24.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.17.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pyparsing 2.4.7. pytz 2023.3.post1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 68.2.2. setuptools_scm NA. six 1.16.0. sklearn 1.3.0. sniffio 1.3.0. socks 1.7.1. stack_data 0.6.2. statsmodels 0.14.0. tblib 1.7.0. terminado 0.17.1. texttable 1.6.7. threadpoolctl 3.2.0. tlz 0.12.2. toolz 0.12.0. tornado 6.1. traitlets 5.9.0. typing_extensions NA. uri_template NA. urllib3 1.26.16. wcwidth 0.2.6. webcolors 1.13. websocket 1.6.3. yaml 6.0.1. zipp NA. zmq 25.1.1. -----. IPython 8.12.0. jupyter_client 7.3.4. jupyter_core 4.12.0. jupyterlab 3.6.5. notebook 6.3.0. -----. Python 3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]. Linux-3.10.0-862.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2023-09-27 17:56. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:1156,testability,Trace,Traceback,1156,"- [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 727 copy=copy,. 728 typ=manager,. 729 ). 731 # For data is list-like, or Iterable (will consume into list). 732 elif is_list_like(data):. File ~/anaconda3/en",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:3,usability,error,error,3,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:174,usability,confirm,confirmed,174,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:257,usability,confirm,confirmed,257,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:762,usability,error,error,762,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:825,usability,Minim,Minimal,825,"An error when running scanpy.pl.clustermap(); ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtyp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:1045,usability,Error,Error,1045,"# Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? I have an interesting gene list and their expression pattern in different clusters. So I ran `scanpy.pl.clustermap()` to obtain the pattern and find genes with similar expression patterns. The `scanpy.pl.clustermap()` does not seem to specify the parameters of var.names, so I `subadata = adata[: , genelist]` with interesting gene list. The `adata.shape` or `subadata.shape` both return the correct value. I don't know why the error occurs, perhaps due to the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 727 copy=copy,. 728 typ=manager,. 729 ). 731",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:1786,usability,error,error,1786,"o the version of some packages? ### Minimal code sample. ```python. import scanpy as sc. import numpy as np. import pandas as pd. adata = sc.read_h5ad(""ori.h5ad""). subadata = adata[: , genelist]. sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). Cell In[100], line 1. ----> 1 sc.pl.clustermap(subadata,obs_keys=""leiden_r0.6""). File ~/anaconda3/envs/scell/lib/python3.8/site-packages/scanpy/plotting/_anndata.py:933, in clustermap(adata, obs_keys, use_raw, show, save, **kwds). 931 if issparse(X):. 932 X = X.toarray(). --> 933 df = pd.DataFrame(X, index=adata.obs_names, columns=adata.var_names). 934 if obs_keys is not None:. 935 row_colors = adata.obs[obs_keys]. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/frame.py:722, in DataFrame.__init__(self, data, index, columns, dtype, copy). 712 mgr = dict_to_mgr(. 713 # error: Item ""ndarray"" of ""Union[ndarray, Series, Index]"" has no. 714 # attribute ""name"". (...). 719 typ=manager,. 720 ). 721 else:. --> 722 mgr = ndarray_to_mgr(. 723 data,. 724 index,. 725 columns,. 726 dtype=dtype,. 727 copy=copy,. 728 typ=manager,. 729 ). 731 # For data is list-like, or Iterable (will consume into list). 732 elif is_list_like(data):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:349, in ndarray_to_mgr(values, index, columns, dtype, copy, typ). 344 # _prep_ndarraylike ensures that values.ndim == 2 at this point. 345 index, columns = _get_axes(. 346 values.shape[0], values.shape[1], index=index, columns=columns. 347 ). --> 349 _check_values_indices_shape_match(values, index, columns). 351 if typ == ""array"":. 353 if issubclass(values.dtype.type, str):. File ~/anaconda3/envs/scell/lib/python3.8/site-packages/pandas/core/internals/construction.py:420, in _check_values_indices_shape_match(values, index, columns). 418 passed = v",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2673:4846,usability,tool,toolz,4846,". cycler 0.10.0. cython_runtime NA. cytoolz 0.12.2. dask 2021.04.0. dateutil 2.8.2. debugpy 1.7.0. decorator 5.1.1. defusedxml 0.7.1. entrypoints 0.4. executing 1.2.0. fastcluster 1.2.6. fastjsonschema NA. fqdn NA. fsspec 2023.9.0. google NA. h5py 3.9.0. idna 3.4. igraph 0.10.8. importlib_resources NA. ipykernel 6.25.2. ipython_genutils 0.2.0. isoduration NA. jedi 0.19.0. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.0. jsonschema 4.19.0. jsonschema_specifications NA. jupyter_server 1.24.0. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. louvain 0.8.1. markupsafe 2.1.3. matplotlib 3.7.2. matplotlib_inline 0.1.6. mpl_toolkits NA. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numexpr 2.8.6. numpy 1.24.4. packaging 23.1. pandas 1.5.3. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.17.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pyarrow 10.0.1. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pyparsing 2.4.7. pytz 2023.3.post1. referencing NA. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpds NA. scipy 1.10.1. seaborn 0.12.2. send2trash NA. session_info 1.0.0. setuptools 68.2.2. setuptools_scm NA. six 1.16.0. sklearn 1.3.0. sniffio 1.3.0. socks 1.7.1. stack_data 0.6.2. statsmodels 0.14.0. tblib 1.7.0. terminado 0.17.1. texttable 1.6.7. threadpoolctl 3.2.0. tlz 0.12.2. toolz 0.12.0. tornado 6.1. traitlets 5.9.0. typing_extensions NA. uri_template NA. urllib3 1.26.16. wcwidth 0.2.6. webcolors 1.13. websocket 1.6.3. yaml 6.0.1. zipp NA. zmq 25.1.1. -----. IPython 8.12.0. jupyter_client 7.3.4. jupyter_core 4.12.0. jupyterlab 3.6.5. notebook 6.3.0. -----. Python 3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]. Linux-3.10.0-862.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2023-09-27 17:56. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2673
https://github.com/scverse/scanpy/issues/2674:282,availability,cluster,cluster,282,"Scanpy Shouldn't Append Writekey by Defualt; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. After using Cellrank, a program that requires scanpy, on a computing cluster, I realized I was having issues with the saving of my figures due to the behavior caused by line 311 of scanpy/plotting/_utils.py - writekey _appends_ the filepath the user provides instead of _using_ it. . Since a lot of bioinformatics is done on cluster computing, where many users may not have permissions to create new directories, this feature should be optional. It should be up to the user to fully determine they filepath they wise to use IMO - would it be possible to implement new default functionality? I can create a pull request if that makes it easier. Many thanks for your consideration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2674
https://github.com/scverse/scanpy/issues/2674:538,availability,cluster,cluster,538,"Scanpy Shouldn't Append Writekey by Defualt; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. After using Cellrank, a program that requires scanpy, on a computing cluster, I realized I was having issues with the saving of my figures due to the behavior caused by line 311 of scanpy/plotting/_utils.py - writekey _appends_ the filepath the user provides instead of _using_ it. . Since a lot of bioinformatics is done on cluster computing, where many users may not have permissions to create new directories, this feature should be optional. It should be up to the user to fully determine they filepath they wise to use IMO - would it be possible to implement new default functionality? I can create a pull request if that makes it easier. Many thanks for your consideration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2674
https://github.com/scverse/scanpy/issues/2674:282,deployability,cluster,cluster,282,"Scanpy Shouldn't Append Writekey by Defualt; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. After using Cellrank, a program that requires scanpy, on a computing cluster, I realized I was having issues with the saving of my figures due to the behavior caused by line 311 of scanpy/plotting/_utils.py - writekey _appends_ the filepath the user provides instead of _using_ it. . Since a lot of bioinformatics is done on cluster computing, where many users may not have permissions to create new directories, this feature should be optional. It should be up to the user to fully determine they filepath they wise to use IMO - would it be possible to implement new default functionality? I can create a pull request if that makes it easier. Many thanks for your consideration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2674
https://github.com/scverse/scanpy/issues/2674:538,deployability,cluster,cluster,538,"Scanpy Shouldn't Append Writekey by Defualt; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. After using Cellrank, a program that requires scanpy, on a computing cluster, I realized I was having issues with the saving of my figures due to the behavior caused by line 311 of scanpy/plotting/_utils.py - writekey _appends_ the filepath the user provides instead of _using_ it. . Since a lot of bioinformatics is done on cluster computing, where many users may not have permissions to create new directories, this feature should be optional. It should be up to the user to fully determine they filepath they wise to use IMO - would it be possible to implement new default functionality? I can create a pull request if that makes it easier. Many thanks for your consideration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2674
https://github.com/scverse/scanpy/issues/2674:117,modifiability,paramet,parameters,117,"Scanpy Shouldn't Append Writekey by Defualt; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. After using Cellrank, a program that requires scanpy, on a computing cluster, I realized I was having issues with the saving of my figures due to the behavior caused by line 311 of scanpy/plotting/_utils.py - writekey _appends_ the filepath the user provides instead of _using_ it. . Since a lot of bioinformatics is done on cluster computing, where many users may not have permissions to create new directories, this feature should be optional. It should be up to the user to fully determine they filepath they wise to use IMO - would it be possible to implement new default functionality? I can create a pull request if that makes it easier. Many thanks for your consideration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2674
https://github.com/scverse/scanpy/issues/2674:587,safety,permiss,permissions,587,"Scanpy Shouldn't Append Writekey by Defualt; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. After using Cellrank, a program that requires scanpy, on a computing cluster, I realized I was having issues with the saving of my figures due to the behavior caused by line 311 of scanpy/plotting/_utils.py - writekey _appends_ the filepath the user provides instead of _using_ it. . Since a lot of bioinformatics is done on cluster computing, where many users may not have permissions to create new directories, this feature should be optional. It should be up to the user to fully determine they filepath they wise to use IMO - would it be possible to implement new default functionality? I can create a pull request if that makes it easier. Many thanks for your consideration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2674
https://github.com/scverse/scanpy/issues/2674:363,usability,behavi,behavior,363,"Scanpy Shouldn't Append Writekey by Defualt; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. After using Cellrank, a program that requires scanpy, on a computing cluster, I realized I was having issues with the saving of my figures due to the behavior caused by line 311 of scanpy/plotting/_utils.py - writekey _appends_ the filepath the user provides instead of _using_ it. . Since a lot of bioinformatics is done on cluster computing, where many users may not have permissions to create new directories, this feature should be optional. It should be up to the user to fully determine they filepath they wise to use IMO - would it be possible to implement new default functionality? I can create a pull request if that makes it easier. Many thanks for your consideration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2674
https://github.com/scverse/scanpy/issues/2674:458,usability,user,user,458,"Scanpy Shouldn't Append Writekey by Defualt; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. After using Cellrank, a program that requires scanpy, on a computing cluster, I realized I was having issues with the saving of my figures due to the behavior caused by line 311 of scanpy/plotting/_utils.py - writekey _appends_ the filepath the user provides instead of _using_ it. . Since a lot of bioinformatics is done on cluster computing, where many users may not have permissions to create new directories, this feature should be optional. It should be up to the user to fully determine they filepath they wise to use IMO - would it be possible to implement new default functionality? I can create a pull request if that makes it easier. Many thanks for your consideration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2674
https://github.com/scverse/scanpy/issues/2674:568,usability,user,users,568,"Scanpy Shouldn't Append Writekey by Defualt; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. After using Cellrank, a program that requires scanpy, on a computing cluster, I realized I was having issues with the saving of my figures due to the behavior caused by line 311 of scanpy/plotting/_utils.py - writekey _appends_ the filepath the user provides instead of _using_ it. . Since a lot of bioinformatics is done on cluster computing, where many users may not have permissions to create new directories, this feature should be optional. It should be up to the user to fully determine they filepath they wise to use IMO - would it be possible to implement new default functionality? I can create a pull request if that makes it easier. Many thanks for your consideration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2674
https://github.com/scverse/scanpy/issues/2674:682,usability,user,user,682,"Scanpy Shouldn't Append Writekey by Defualt; ### What kind of feature would you like to request? Additional function parameters / changed functionality / changed defaults? ### Please describe your wishes. Hello,. After using Cellrank, a program that requires scanpy, on a computing cluster, I realized I was having issues with the saving of my figures due to the behavior caused by line 311 of scanpy/plotting/_utils.py - writekey _appends_ the filepath the user provides instead of _using_ it. . Since a lot of bioinformatics is done on cluster computing, where many users may not have permissions to create new directories, this feature should be optional. It should be up to the user to fully determine they filepath they wise to use IMO - would it be possible to implement new default functionality? I can create a pull request if that makes it easier. Many thanks for your consideration.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2674
https://github.com/scverse/scanpy/issues/2675:463,availability,error,error,463,"Scanpy in Jupyter notebook: 'Kernel appears to have died'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:899,availability,Error,Error,899,"Scanpy in Jupyter notebook: 'Kernel appears to have died'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:227,deployability,version,version,227,"Scanpy in Jupyter notebook: 'Kernel appears to have died'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:808,deployability,log,logging,808,"Scanpy in Jupyter notebook: 'Kernel appears to have died'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:1126,deployability,modul,module,1126,"at this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.4. numpy 1.21.6. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:1247,deployability,Version,Versions,1247," (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.4. numpy 1.21.6. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pyarr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:3053,deployability,updat,updated,3053,"rnel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.4. numpy 1.21.6. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pyarrow 13.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2022.1. ruamel NA. scipy 1.9.1. session_info 1.0.0. setuptools 63.4.1. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. storemagic NA. sympy 1.10.1. tblib 1.7.0. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. torch 2.0.1. tornado 6.1. tqdm 4.64.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. zstandard 0.19.0. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.13 (main, Aug 25 2022, 18:29:29) [Clang 12.0.0 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2023-09-30 11:34. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:1454,energy efficiency,cloud,cloudpickle,1454,"an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.4. numpy 1.21.6. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pyarrow 13.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2022.1. ruamel NA.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:227,integrability,version,version,227,"Scanpy in Jupyter notebook: 'Kernel appears to have died'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:1247,integrability,Version,Versions,1247," (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.4. numpy 1.21.6. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pyarr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:227,modifiability,version,version,227,"Scanpy in Jupyter notebook: 'Kernel appears to have died'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:1126,modifiability,modul,module,1126,"at this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.4. numpy 1.21.6. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:1247,modifiability,Version,Versions,1247," (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.4. numpy 1.21.6. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pyarr",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:1585,modifiability,deco,decorator,1585,"commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.4. numpy 1.21.6. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pyarrow 13.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2022.1. ruamel NA. scipy 1.9.1. session_info 1.0.0. setuptools 63.4.1. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. storemagic NA. sympy ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:2082,modifiability,pac,packaging,2082,"0gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.4. numpy 1.21.6. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pyarrow 13.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2022.1. ruamel NA. scipy 1.9.1. session_info 1.0.0. setuptools 63.4.1. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. storemagic NA. sympy 1.10.1. tblib 1.7.0. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. torch 2.0.1. tornado 6.1. tqdm 4.64.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. zstandard 0.19.0. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.13 (main, Aug 25 2022, 18:29:29) [Clang 12.0.0 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2023-09-30 11:34. ```. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:463,performance,error,error,463,"Scanpy in Jupyter notebook: 'Kernel appears to have died'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:899,performance,Error,Error,899,"Scanpy in Jupyter notebook: 'Kernel appears to have died'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:1423,performance,bottleneck,bottleneck,1423,"ecently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.4. numpy 1.21.6. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pyarrow 13.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsin",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:463,safety,error,error,463,"Scanpy in Jupyter notebook: 'Kernel appears to have died'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:808,safety,log,logging,808,"Scanpy in Jupyter notebook: 'Kernel appears to have died'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:899,safety,Error,Error,899,"Scanpy in Jupyter notebook: 'Kernel appears to have died'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:1126,safety,modul,module,1126,"at this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.4. numpy 1.21.6. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexp",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:3053,safety,updat,updated,3053,"rnel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.4. numpy 1.21.6. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pyarrow 13.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2022.1. ruamel NA. scipy 1.9.1. session_info 1.0.0. setuptools 63.4.1. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. storemagic NA. sympy 1.10.1. tblib 1.7.0. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. torch 2.0.1. tornado 6.1. tqdm 4.64.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. zstandard 0.19.0. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.13 (main, Aug 25 2022, 18:29:29) [Clang 12.0.0 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2023-09-30 11:34. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:808,security,log,logging,808,"Scanpy in Jupyter notebook: 'Kernel appears to have died'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:3033,security,Session,Session,3033,"rnel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.4. numpy 1.21.6. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pyarrow 13.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2022.1. ruamel NA. scipy 1.9.1. session_info 1.0.0. setuptools 63.4.1. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. storemagic NA. sympy 1.10.1. tblib 1.7.0. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. torch 2.0.1. tornado 6.1. tqdm 4.64.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. zstandard 0.19.0. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.13 (main, Aug 25 2022, 18:29:29) [Clang 12.0.0 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2023-09-30 11:34. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:3053,security,updat,updated,3053,"rnel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.4. numpy 1.21.6. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pyarrow 13.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2022.1. ruamel NA. scipy 1.9.1. session_info 1.0.0. setuptools 63.4.1. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. storemagic NA. sympy 1.10.1. tblib 1.7.0. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. torch 2.0.1. tornado 6.1. tqdm 4.64.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. zstandard 0.19.0. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.13 (main, Aug 25 2022, 18:29:29) [Clang 12.0.0 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2023-09-30 11:34. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:808,testability,log,logging,808,"Scanpy in Jupyter notebook: 'Kernel appears to have died'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:1009,testability,Trace,Traceback,1009,"ter notebook: 'Kernel appears to have died'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufunc NA. ncf_ufun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:187,usability,confirm,confirmed,187,"Scanpy in Jupyter notebook: 'Kernel appears to have died'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:270,usability,confirm,confirmed,270,"Scanpy in Jupyter notebook: 'Kernel appears to have died'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:371,usability,user,user,371,"Scanpy in Jupyter notebook: 'Kernel appears to have died'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:463,usability,error,error,463,"Scanpy in Jupyter notebook: 'Kernel appears to have died'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:590,usability,command,commands,590,"Scanpy in Jupyter notebook: 'Kernel appears to have died'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:683,usability,Minim,Minimal,683,"Scanpy in Jupyter notebook: 'Kernel appears to have died'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:899,usability,Error,Error,899,"Scanpy in Jupyter notebook: 'Kernel appears to have died'; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hello, I'm a new ScanPy user and have been working through the great tutorials. Recently, I've been encountering an error after I import ScanPy that causes the kernel I'm using to die and restart. After this happens, I can no longer call sc.- commands and have to import the library again. And then the kernel quickly dies again. . ### Minimal code sample. ```python. import numpy as np. import pandas as pd. import scanpy as sc. sc.settings.verbosity = 3 . sc.logging.print_header(). sc.settings.set_figure_params(dpi=80, facecolor='white'). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. NameError Traceback (most recent call last). /var/folders/jt/m9v9k7dd4f31m5pl8v_g8m3m0000gn/T/ipykernel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufun",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/issues/2675:2661,usability,tool,toolz,2661,"rnel_3816/1026803476.py in <module>. ----> 1 sc.settings.set_figure_params(dpi=80, facecolor='white'). NameError: name 'sc' is not defined. ```. ### Versions. <details>. ```. -----. anndata 0.9.2. scanpy 1.9.4. -----. PIL 9.2.0. PyObjCTools NA. appnope 0.1.2. astunparse 1.6.3. backcall 0.2.0. beta_ufunc NA. binom_ufunc NA. bottleneck 1.3.5. cffi 1.15.1. cloudpickle 2.0.0. colorama 0.4.5. cycler 0.10.0. cython_runtime NA. cytoolz 0.11.0. dask 2022.7.0. dateutil 2.8.2. debugpy 1.5.1. decorator 5.1.1. defusedxml 0.7.1. dill 0.3.7. entrypoints 0.4. fsspec 2022.7.1. gmpy2 2.1.2. google NA. h5py 3.7.0. hypergeom_ufunc NA. igraph 0.10.1. ipykernel 6.15.2. ipython_genutils 0.2.0. jedi 0.18.1. jinja2 2.11.3. joblib 1.1.0. jupyter_server 1.18.1. kiwisolver 1.4.2. leidenalg 0.9.1. llvmlite 0.38.0. lz4 3.1.3. markupsafe 2.0.1. matplotlib 3.5.2. mpl_toolkits NA. mpmath 1.2.1. natsort 7.1.1. nbinom_ufunc NA. ncf_ufunc NA. numba 0.55.1. numexpr 2.8.4. numpy 1.21.6. opt_einsum v3.3.0. packaging 21.3. pandas 1.4.4. parso 0.8.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. plotly 5.9.0. prompt_toolkit 3.0.20. psutil 5.9.0. ptyprocess 0.7.0. pyarrow 13.0.0. pydev_ipython NA. pydevconsole NA. pydevd 2.6.0. pydevd_concurrency_analyser NA. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.15.1. pyparsing 3.0.9. pytz 2022.1. ruamel NA. scipy 1.9.1. session_info 1.0.0. setuptools 63.4.1. six 1.16.0. sklearn 1.0.2. snappy NA. sphinxcontrib NA. storemagic NA. sympy 1.10.1. tblib 1.7.0. texttable 1.6.4. threadpoolctl 2.2.0. tlz 0.11.0. toolz 0.11.2. torch 2.0.1. tornado 6.1. tqdm 4.64.1. traitlets 5.1.1. typing_extensions NA. wcwidth 0.2.5. yaml 6.0. zipp NA. zmq 23.2.0. zope NA. zstandard 0.19.0. -----. IPython 7.31.1. jupyter_client 7.3.4. jupyter_core 4.11.1. jupyterlab 3.4.4. notebook 6.4.12. -----. Python 3.9.13 (main, Aug 25 2022, 18:29:29) [Clang 12.0.0 ]. macOS-10.16-x86_64-i386-64bit. -----. Session information updated at 2023-09-30 11:34. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2675
https://github.com/scverse/scanpy/pull/2676:264,safety,review,review,264,Backport PR #2571: Fix scatter palette name; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2676
https://github.com/scverse/scanpy/pull/2676:264,testability,review,review,264,Backport PR #2571: Fix scatter palette name; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2676
https://github.com/scverse/scanpy/pull/2676:115,usability,guid,guidelines,115,Backport PR #2571: Fix scatter palette name; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2676
https://github.com/scverse/scanpy/pull/2676:146,usability,guid,guide,146,Backport PR #2571: Fix scatter palette name; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2676
https://github.com/scverse/scanpy/pull/2676:242,usability,workflow,workflow,242,Backport PR #2571: Fix scatter palette name; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2676
https://github.com/scverse/scanpy/pull/2677:277,safety,review,review,277,Backport PR #2661: [pre-commit.ci] pre-commit autoupdate; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2677
https://github.com/scverse/scanpy/pull/2677:277,testability,review,review,277,Backport PR #2661: [pre-commit.ci] pre-commit autoupdate; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2677
https://github.com/scverse/scanpy/pull/2677:128,usability,guid,guidelines,128,Backport PR #2661: [pre-commit.ci] pre-commit autoupdate; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2677
https://github.com/scverse/scanpy/pull/2677:159,usability,guid,guide,159,Backport PR #2661: [pre-commit.ci] pre-commit autoupdate; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2677
https://github.com/scverse/scanpy/pull/2677:255,usability,workflow,workflow,255,Backport PR #2661: [pre-commit.ci] pre-commit autoupdate; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2677
https://github.com/scverse/scanpy/pull/2678:48,safety,prevent,prevented,48,Fix pandas function deprecation warnings; TODO (prevented by banning import):. - [x] Deprecated `is_categorical_dtype`. - [x] Deprecated `pandas.value_counts`. . probably more,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2678
https://github.com/scverse/scanpy/pull/2678:48,security,preven,prevented,48,Fix pandas function deprecation warnings; TODO (prevented by banning import):. - [x] Deprecated `is_categorical_dtype`. - [x] Deprecated `pandas.value_counts`. . probably more,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2678
https://github.com/scverse/scanpy/issues/2680:46,availability,error,error,46,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:383,availability,error,error,383,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:544,availability,Error,Error,544,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1640,availability,error,errorbar,1640,"AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 2940 linewidth=linewidth,. 2941 inner=inner,. 2942 density_norm=density_norm,. 2943 common_norm=common_norm,. 2944 kde_kws=kde_kws,. 2945 inner_kws=inner_kws,. 2946 plot_kws=plot_kws,. 2947 ). 2949 elif kind == ""boxen"":. 2951 plot_kws = kwargs.copy(). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:1153, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:6894,availability,servic,service,6894,16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsdangerous 2.1.2. jaraco.classes 3.3.0. jedi 0.18.1. jeepney 0.8.0. jellyfish 1.0.1. Jinja2 3.1.2. jmespath 1.0.1. joblib 1.3.2. json5 0.9.14. jsonpatch 1.33. jsonpointer 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1.0.0. jupyter_client 8.3.1. jupyter-console 6.6.3. jupyter_core 5.3.2. jupyter-events 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. MarkupSafe 2.1.3. matplotlib 3.8.0. matplotlib-inline 0.1.6. mccabe 0.7.0. mdit-py-plugins 0.4.0. mdurl 0.1.0. mistune 3.0.1. mkl-service 2.4.0. more-itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. packaging 23.2. pandas 2.1.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:9256,availability,servic,service-identity,9256,5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.2. tblib 2.0.0. tenacity 8.2.3. terminado 0.17.1. text-unidecode 1.3. textdistance 4.5.0. texttable 1.7.0. threadpoolctl 3.2.0. three-merge 0.1.1. throttler 1.2.2. tifffile 2023.4.12. tinycss2 1.2.1. tldextract 3.6.0. tokenizers 0.14.0. toml 0.10.2. tomli 2.0.1. tomlkit 0.12.1. toolz 0.12.0. toposort 1.10. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. transformers 4.34.0. truststore 0.8.0. Twisted 22.10.0. types-python-d,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:10463,availability,watchdog,watchdog,10463,3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.2. tblib 2.0.0. tenacity 8.2.3. terminado 0.17.1. text-unidecode 1.3. textdistance 4.5.0. texttable 1.7.0. threadpoolctl 3.2.0. three-merge 0.1.1. throttler 1.2.2. tifffile 2023.4.12. tinycss2 1.2.1. tldextract 3.6.0. tokenizers 0.14.0. toml 0.10.2. tomli 2.0.1. tomlkit 0.12.1. toolz 0.12.0. toposort 1.10. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. transformers 4.34.0. truststore 0.8.0. Twisted 22.10.0. types-python-dateutil 2.8.19.14. typing_extensions 4.8.0. typing-utils 0.1.0. tzdata 2023.3. uc-micro-py 1.0.1. ujson 5.8.0. umap-learn 0.5.4. uri-template 1.3.0. urllib3 1.26.15. virtualenv 20.24.5. w3lib 2.1.2. watchdog 3.0.0. wcwidth 0.2.8. webcolors 1.13. webencodings 0.5.1. websocket-client 1.6.4. Werkzeug 3.0.0. whatthepatch 1.0.5. wheel 0.38.4. widgetsnbextension 4.0.9. wrapt 1.15.0. wurlitzer 3.0.3. xarray 2023.9.0. xxhash 3.4.1. xyzservices 2023.10.0. yapf 0.24.0. yarl 1.9.2. yte 1.5.1. zict 3.0.0. zipp 3.17.0. zope.interface 6.1. zstandard 0.21.0. ```. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:223,deployability,version,version,223,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:941,deployability,log,log,941,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:987,deployability,scale,scale,987,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1172,deployability,scale,scales,1172," I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 2940 linewi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1321,deployability,scale,scale,1321,"### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 2940 linewidth=linewidth,. 2941 inner=inner,. 2942 density_norm=density_norm,. 2943 common_norm=common_norm,. 2944 kde_kws=kde_kws,. 2945 inner_kws=inner_kws,. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1327,deployability,scale,scale,1327,"at happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 2940 linewidth=linewidth,. 2941 inner=inner,. 2942 density_norm=density_norm,. 2943 common_norm=common_norm,. 2944 kde_kws=kde_kws,. 2945 inner_kws=inner_kws,. 2946 p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:3308,deployability,Version,Versions,3308,"inner_kws,. 2946 plot_kws=plot_kws,. 2947 ). 2949 elif kind == ""boxen"":. 2951 plot_kws = kwargs.copy(). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:1153, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1151 legend_artist = _get_patch_legend_artist(fill). 1152 common_kws = {**plot_kws, ""linewidth"": linewidth, ""edgecolor"": linecolor}. -> 1153 self._configure_legend(ax, legend_artist, common_kws). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:420, in _CategoricalPlotter._configure_legend(self, ax, func, common_kws, semantic_kws). 418 if show_legend:. 419 self.add_legend_data(ax, func, common_kws, semantic_kws=semantic_kws). --> 420 handles, _ = ax.get_legend_handles_labels(). 421 if handles:. 422 ax.legend(title=self.legend_title). AttributeError: 'NoneType' object has no attribute 'get_legend_handles_labels'. ```. ### Versions. <details>. ```. Package Version. ----------------------------- ---------------. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aiosignal 1.3.1. alabaster 0.7.13. anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 202",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:3342,deployability,Version,Version,3342,",. 2947 ). 2949 elif kind == ""boxen"":. 2951 plot_kws = kwargs.copy(). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:1153, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1151 legend_artist = _get_patch_legend_artist(fill). 1152 common_kws = {**plot_kws, ""linewidth"": linewidth, ""edgecolor"": linecolor}. -> 1153 self._configure_legend(ax, legend_artist, common_kws). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:420, in _CategoricalPlotter._configure_legend(self, ax, func, common_kws, semantic_kws). 418 if show_legend:. 419 self.add_legend_data(ax, func, common_kws, semantic_kws=semantic_kws). --> 420 handles, _ = ax.get_legend_handles_labels(). 421 if handles:. 422 ax.legend(title=self.legend_title). AttributeError: 'NoneType' object has no attribute 'get_legend_handles_labels'. ```. ### Versions. <details>. ```. Package Version. ----------------------------- ---------------. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aiosignal 1.3.1. alabaster 0.7.13. anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:3774,deployability,api,api-compat,3774," linecolor}. -> 1153 self._configure_legend(ax, legend_artist, common_kws). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:420, in _CategoricalPlotter._configure_legend(self, ax, func, common_kws, semantic_kws). 418 if show_legend:. 419 self.add_legend_data(ax, func, common_kws, semantic_kws=semantic_kws). --> 420 handles, _ = ax.get_legend_handles_labels(). 421 if handles:. 422 ax.legend(title=self.legend_title). AttributeError: 'NoneType' object has no attribute 'get_legend_handles_labels'. ```. ### Versions. <details>. ```. Package Version. ----------------------------- ---------------. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aiosignal 1.3.1. alabaster 0.7.13. anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:3796,deployability,api,api-compat,3796,"elf._configure_legend(ax, legend_artist, common_kws). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:420, in _CategoricalPlotter._configure_legend(self, ax, func, common_kws, semantic_kws). 418 if show_legend:. 419 self.add_legend_data(ax, func, common_kws, semantic_kws=semantic_kws). --> 420 handles, _ = ax.get_legend_handles_labels(). 421 if handles:. 422 ax.legend(title=self.legend_title). AttributeError: 'NoneType' object has no attribute 'get_legend_handles_labels'. ```. ### Versions. <details>. ```. Package Version. ----------------------------- ---------------. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aiosignal 1.3.1. alabaster 0.7.13. anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. coo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:3945,deployability,Automat,Automat,3945,"er._configure_legend(self, ax, func, common_kws, semantic_kws). 418 if show_legend:. 419 self.add_legend_data(ax, func, common_kws, semantic_kws=semantic_kws). --> 420 handles, _ = ax.get_legend_handles_labels(). 421 if handles:. 422 ax.legend(title=self.legend_title). AttributeError: 'NoneType' object has no attribute 'get_legend_handles_labels'. ```. ### Versions. <details>. ```. Package Version. ----------------------------- ---------------. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aiosignal 1.3.1. alabaster 0.7.13. anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:4484,deployability,build,build,4484, anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. g,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:5082,deployability,patch,patch,5082,f 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. gmpy2 2.1.2. greenlet 3.0.0. h5py 3.9.0. holoviews 1.17.1. huggingface-hub 0.17.3. humanfriendly 10.0. hvplot 0.8.4. hyperlink 21.0.0. idna 3.4. igraph 0.10.4. imagecodecs 2023.1.23. imageio 2.31.1. imagesize 1.4.1. imbalanced-learn 0.11.0. importlib-metadata 6.8.0. importlib-resources 6.1.0. incremental 22.10.0. inflection 0.5.1. iniconfig 2.0.0. intake 0.7.0. intervaltree 3.1.0. ipykernel 6.25.2. ipython 8.16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsdangerous 2.1.2. jaraco.classes 3.3.0. jedi 0.18.1. jeepney 0.8,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:5763,deployability,resourc,resources,5763,ntly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. gmpy2 2.1.2. greenlet 3.0.0. h5py 3.9.0. holoviews 1.17.1. huggingface-hub 0.17.3. humanfriendly 10.0. hvplot 0.8.4. hyperlink 21.0.0. idna 3.4. igraph 0.10.4. imagecodecs 2023.1.23. imageio 2.31.1. imagesize 1.4.1. imbalanced-learn 0.11.0. importlib-metadata 6.8.0. importlib-resources 6.1.0. incremental 22.10.0. inflection 0.5.1. iniconfig 2.0.0. intake 0.7.0. intervaltree 3.1.0. ipykernel 6.25.2. ipython 8.16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsdangerous 2.1.2. jaraco.classes 3.3.0. jedi 0.18.1. jeepney 0.8.0. jellyfish 1.0.1. Jinja2 3.1.2. jmespath 1.0.1. joblib 1.3.2. json5 0.9.14. jsonpatch 1.33. jsonpointer 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1.0.0. jupyter_client 8.3.1. jupyter-console 6.6.3. jupyter_core 5.3.2. jupyter-events 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. Mark,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:6894,deployability,servic,service,6894,16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsdangerous 2.1.2. jaraco.classes 3.3.0. jedi 0.18.1. jeepney 0.8.0. jellyfish 1.0.1. Jinja2 3.1.2. jmespath 1.0.1. joblib 1.3.2. json5 0.9.14. jsonpatch 1.33. jsonpointer 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1.0.0. jupyter_client 8.3.1. jupyter-console 6.6.3. jupyter_core 5.3.2. jupyter-events 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. MarkupSafe 2.1.3. matplotlib 3.8.0. matplotlib-inline 0.1.6. mccabe 0.7.0. mdit-py-plugins 0.4.0. mdurl 0.1.0. mistune 3.0.1. mkl-service 2.4.0. more-itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. packaging 23.2. pandas 2.1.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:7102,deployability,updat,updater,7102,Jinja2 3.1.2. jmespath 1.0.1. joblib 1.3.2. json5 0.9.14. jsonpatch 1.33. jsonpointer 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1.0.0. jupyter_client 8.3.1. jupyter-console 6.6.3. jupyter_core 5.3.2. jupyter-events 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. MarkupSafe 2.1.3. matplotlib 3.8.0. matplotlib-inline 0.1.6. mccabe 0.7.0. mdit-py-plugins 0.4.0. mdurl 0.1.0. mistune 3.0.1. mkl-service 2.4.0. more-itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. packaging 23.2. pandas 2.1.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:7910,deployability,modul,modules,7910,itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. packaging 23.2. pandas 2.1.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1. Pygments 2.16.1. PyJWT 2.8.0. pylint 2.17.5. pylint-venv 3.0.2. pyls-spyder 0.4.0. pynndescent 0.5.10. pyodbc 4.0.39. pyOpenSSL 23.2.0. pyparsing 3.1.1. PyQt5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:8364,deployability,log,logger,8364,.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1. Pygments 2.16.1. PyJWT 2.8.0. pylint 2.17.5. pylint-venv 3.0.2. pyls-spyder 0.4.0. pynndescent 0.5.10. pyodbc 4.0.39. pyOpenSSL 23.2.0. pyparsing 3.1.1. PyQt5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:9256,deployability,servic,service-identity,9256,5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.2. tblib 2.0.0. tenacity 8.2.3. terminado 0.17.1. text-unidecode 1.3. textdistance 4.5.0. texttable 1.7.0. threadpoolctl 3.2.0. three-merge 0.1.1. throttler 1.2.2. tifffile 2023.4.12. tinycss2 1.2.1. tldextract 3.6.0. tokenizers 0.14.0. toml 0.10.2. tomli 2.0.1. tomlkit 0.12.1. toolz 0.12.0. toposort 1.10. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. transformers 4.34.0. truststore 0.8.0. Twisted 22.10.0. types-python-d,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:9721,deployability,stack,stack-data,9721,uests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.2. tblib 2.0.0. tenacity 8.2.3. terminado 0.17.1. text-unidecode 1.3. textdistance 4.5.0. texttable 1.7.0. threadpoolctl 3.2.0. three-merge 0.1.1. throttler 1.2.2. tifffile 2023.4.12. tinycss2 1.2.1. tldextract 3.6.0. tokenizers 0.14.0. toml 0.10.2. tomli 2.0.1. tomlkit 0.12.1. toolz 0.12.0. toposort 1.10. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. transformers 4.34.0. truststore 0.8.0. Twisted 22.10.0. types-python-dateutil 2.8.19.14. typing_extensions 4.8.0. typing-utils 0.1.0. tzdata 2023.3. uc-micro-py 1.0.1. ujson 5.8.0. umap-learn 0.5.4. uri-template 1.3.0. urllib3 1.26.15. virtualenv 20.24.5. w3lib 2.1.2. watchdog 3.0.0. wcwidth 0.2.8. webcolors 1.13. webencodings 0.5.1. websocket-client 1.6.4. Werkzeug 3.0.0. whatthepatch 1.0.5. wheel 0.38.4. widgetsnbextension 4.0.9. wrapt 1.15.0. wurlitzer 3.0.3. xarray 2023.9.0. xxhash 3.4.1. xyzservices 2023.10.0. yapf 0.24.0,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:987,energy efficiency,scale,scale,987,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1163,energy efficiency,adapt,adapting,1163,"d. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 294",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1172,energy efficiency,scale,scales,1172," I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 2940 linewi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1321,energy efficiency,scale,scale,1321,"### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 2940 linewidth=linewidth,. 2941 inner=inner,. 2942 density_norm=density_norm,. 2943 common_norm=common_norm,. 2944 kde_kws=kde_kws,. 2945 inner_kws=inner_kws,. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1327,energy efficiency,scale,scale,1327,"at happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 2940 linewidth=linewidth,. 2941 inner=inner,. 2942 density_norm=density_norm,. 2943 common_norm=common_norm,. 2944 kde_kws=kde_kws,. 2945 inner_kws=inner_kws,. 2946 p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1629,energy efficiency,estimat,estimator,1629,"--------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 2940 linewidth=linewidth,. 2941 inner=inner,. 2942 density_norm=density_norm,. 2943 common_norm=common_norm,. 2944 kde_kws=kde_kws,. 2945 inner_kws=inner_kws,. 2946 plot_kws=plot_kws,. 2947 ). 2949 elif kind == ""boxen"":. 2951 plot_kws = kwargs.copy(). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:1153, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kw",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:3573,energy efficiency,cloud,cloud-auth,3573,"lor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1151 legend_artist = _get_patch_legend_artist(fill). 1152 common_kws = {**plot_kws, ""linewidth"": linewidth, ""edgecolor"": linecolor}. -> 1153 self._configure_legend(ax, legend_artist, common_kws). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:420, in _CategoricalPlotter._configure_legend(self, ax, func, common_kws, semantic_kws). 418 if show_legend:. 419 self.add_legend_data(ax, func, common_kws, semantic_kws=semantic_kws). --> 420 handles, _ = ax.get_legend_handles_labels(). 421 if handles:. 422 ax.legend(title=self.legend_title). AttributeError: 'NoneType' object has no attribute 'get_legend_handles_labels'. ```. ### Versions. <details>. ```. Package Version. ----------------------------- ---------------. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aiosignal 1.3.1. alabaster 0.7.13. anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:4387,energy efficiency,cloud,cloudpickle,4387,---. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aiosignal 1.3.1. alabaster 0.7.13. anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. fro,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:5499,energy efficiency,green,greenlet,5499,-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. gmpy2 2.1.2. greenlet 3.0.0. h5py 3.9.0. holoviews 1.17.1. huggingface-hub 0.17.3. humanfriendly 10.0. hvplot 0.8.4. hyperlink 21.0.0. idna 3.4. igraph 0.10.4. imagecodecs 2023.1.23. imageio 2.31.1. imagesize 1.4.1. imbalanced-learn 0.11.0. importlib-metadata 6.8.0. importlib-resources 6.1.0. incremental 22.10.0. inflection 0.5.1. iniconfig 2.0.0. intake 0.7.0. intervaltree 3.1.0. ipykernel 6.25.2. ipython 8.16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsdangerous 2.1.2. jaraco.classes 3.3.0. jedi 0.18.1. jeepney 0.8.0. jellyfish 1.0.1. Jinja2 3.1.2. jmespath 1.0.1. joblib 1.3.2. json5 0.9.14. jsonpatch 1.33. jsonpointer 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1.0.0. jupyter_client 8.3.1. jupyter-console 6.6.3. jupyter_core 5.3.2. jupyter-events 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyt,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:5763,energy efficiency,resourc,resources,5763,ntly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. gmpy2 2.1.2. greenlet 3.0.0. h5py 3.9.0. holoviews 1.17.1. huggingface-hub 0.17.3. humanfriendly 10.0. hvplot 0.8.4. hyperlink 21.0.0. idna 3.4. igraph 0.10.4. imagecodecs 2023.1.23. imageio 2.31.1. imagesize 1.4.1. imbalanced-learn 0.11.0. importlib-metadata 6.8.0. importlib-resources 6.1.0. incremental 22.10.0. inflection 0.5.1. iniconfig 2.0.0. intake 0.7.0. intervaltree 3.1.0. ipykernel 6.25.2. ipython 8.16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsdangerous 2.1.2. jaraco.classes 3.3.0. jedi 0.18.1. jeepney 0.8.0. jellyfish 1.0.1. Jinja2 3.1.2. jmespath 1.0.1. joblib 1.3.2. json5 0.9.14. jsonpatch 1.33. jsonpointer 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1.0.0. jupyter_client 8.3.1. jupyter-console 6.6.3. jupyter_core 5.3.2. jupyter-events 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. Mark,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:7858,energy efficiency,cpu,cpuinfo,7858,mdurl 0.1.0. mistune 3.0.1. mkl-service 2.4.0. more-itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. packaging 23.2. pandas 2.1.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1. Pygments 2.16.1. PyJWT 2.8.0. pylint 2.17.5. pylint-venv 3.0.2. pyls-spyder 0.4.0. pynndescent 0.5.10. pyodbc 4.0.39. pyOpenSSL 23.2.0. pyparsing 3.1.1. PyQt5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:223,integrability,version,version,223,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1163,integrability,adapt,adapting,1163,"d. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 294",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:3308,integrability,Version,Versions,3308,"inner_kws,. 2946 plot_kws=plot_kws,. 2947 ). 2949 elif kind == ""boxen"":. 2951 plot_kws = kwargs.copy(). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:1153, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1151 legend_artist = _get_patch_legend_artist(fill). 1152 common_kws = {**plot_kws, ""linewidth"": linewidth, ""edgecolor"": linecolor}. -> 1153 self._configure_legend(ax, legend_artist, common_kws). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:420, in _CategoricalPlotter._configure_legend(self, ax, func, common_kws, semantic_kws). 418 if show_legend:. 419 self.add_legend_data(ax, func, common_kws, semantic_kws=semantic_kws). --> 420 handles, _ = ax.get_legend_handles_labels(). 421 if handles:. 422 ax.legend(title=self.legend_title). AttributeError: 'NoneType' object has no attribute 'get_legend_handles_labels'. ```. ### Versions. <details>. ```. Package Version. ----------------------------- ---------------. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aiosignal 1.3.1. alabaster 0.7.13. anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 202",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:3342,integrability,Version,Version,3342,",. 2947 ). 2949 elif kind == ""boxen"":. 2951 plot_kws = kwargs.copy(). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:1153, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1151 legend_artist = _get_patch_legend_artist(fill). 1152 common_kws = {**plot_kws, ""linewidth"": linewidth, ""edgecolor"": linecolor}. -> 1153 self._configure_legend(ax, legend_artist, common_kws). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:420, in _CategoricalPlotter._configure_legend(self, ax, func, common_kws, semantic_kws). 418 if show_legend:. 419 self.add_legend_data(ax, func, common_kws, semantic_kws=semantic_kws). --> 420 handles, _ = ax.get_legend_handles_labels(). 421 if handles:. 422 ax.legend(title=self.legend_title). AttributeError: 'NoneType' object has no attribute 'get_legend_handles_labels'. ```. ### Versions. <details>. ```. Package Version. ----------------------------- ---------------. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aiosignal 1.3.1. alabaster 0.7.13. anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:3774,integrability,api,api-compat,3774," linecolor}. -> 1153 self._configure_legend(ax, legend_artist, common_kws). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:420, in _CategoricalPlotter._configure_legend(self, ax, func, common_kws, semantic_kws). 418 if show_legend:. 419 self.add_legend_data(ax, func, common_kws, semantic_kws=semantic_kws). --> 420 handles, _ = ax.get_legend_handles_labels(). 421 if handles:. 422 ax.legend(title=self.legend_title). AttributeError: 'NoneType' object has no attribute 'get_legend_handles_labels'. ```. ### Versions. <details>. ```. Package Version. ----------------------------- ---------------. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aiosignal 1.3.1. alabaster 0.7.13. anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:3796,integrability,api,api-compat,3796,"elf._configure_legend(ax, legend_artist, common_kws). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:420, in _CategoricalPlotter._configure_legend(self, ax, func, common_kws, semantic_kws). 418 if show_legend:. 419 self.add_legend_data(ax, func, common_kws, semantic_kws=semantic_kws). --> 420 handles, _ = ax.get_legend_handles_labels(). 421 if handles:. 422 ax.legend(title=self.legend_title). AttributeError: 'NoneType' object has no attribute 'get_legend_handles_labels'. ```. ### Versions. <details>. ```. Package Version. ----------------------------- ---------------. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aiosignal 1.3.1. alabaster 0.7.13. anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. coo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:6340,integrability,event,events,6340,.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. gmpy2 2.1.2. greenlet 3.0.0. h5py 3.9.0. holoviews 1.17.1. huggingface-hub 0.17.3. humanfriendly 10.0. hvplot 0.8.4. hyperlink 21.0.0. idna 3.4. igraph 0.10.4. imagecodecs 2023.1.23. imageio 2.31.1. imagesize 1.4.1. imbalanced-learn 0.11.0. importlib-metadata 6.8.0. importlib-resources 6.1.0. incremental 22.10.0. inflection 0.5.1. iniconfig 2.0.0. intake 0.7.0. intervaltree 3.1.0. ipykernel 6.25.2. ipython 8.16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsdangerous 2.1.2. jaraco.classes 3.3.0. jedi 0.18.1. jeepney 0.8.0. jellyfish 1.0.1. Jinja2 3.1.2. jmespath 1.0.1. joblib 1.3.2. json5 0.9.14. jsonpatch 1.33. jsonpointer 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1.0.0. jupyter_client 8.3.1. jupyter-console 6.6.3. jupyter_core 5.3.2. jupyter-events 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. MarkupSafe 2.1.3. matplotlib 3.8.0. matplotlib-inline 0.1.6. mccabe 0.7.0. mdit-py-plugins 0.4.0. mdurl 0.1.0. mistune 3.0.1. mkl-service 2.4.0. more-itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. pa,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:6894,integrability,servic,service,6894,16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsdangerous 2.1.2. jaraco.classes 3.3.0. jedi 0.18.1. jeepney 0.8.0. jellyfish 1.0.1. Jinja2 3.1.2. jmespath 1.0.1. joblib 1.3.2. json5 0.9.14. jsonpatch 1.33. jsonpointer 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1.0.0. jupyter_client 8.3.1. jupyter-console 6.6.3. jupyter_core 5.3.2. jupyter-events 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. MarkupSafe 2.1.3. matplotlib 3.8.0. matplotlib-inline 0.1.6. mccabe 0.7.0. mdit-py-plugins 0.4.0. mdurl 0.1.0. mistune 3.0.1. mkl-service 2.4.0. more-itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. packaging 23.2. pandas 2.1.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:8670,integrability,queue,queuelib,8670,.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1. Pygments 2.16.1. PyJWT 2.8.0. pylint 2.17.5. pylint-venv 3.0.2. pyls-spyder 0.4.0. pynndescent 0.5.10. pyodbc 4.0.39. pyOpenSSL 23.2.0. pyparsing 3.1.1. PyQt5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:9256,integrability,servic,service-identity,9256,5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.2. tblib 2.0.0. tenacity 8.2.3. terminado 0.17.1. text-unidecode 1.3. textdistance 4.5.0. texttable 1.7.0. threadpoolctl 3.2.0. three-merge 0.1.1. throttler 1.2.2. tifffile 2023.4.12. tinycss2 1.2.1. tldextract 3.6.0. tokenizers 0.14.0. toml 0.10.2. tomli 2.0.1. tomlkit 0.12.1. toolz 0.12.0. toposort 1.10. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. transformers 4.34.0. truststore 0.8.0. Twisted 22.10.0. types-python-d,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:10194,integrability,transform,transformers,10194,3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.2. tblib 2.0.0. tenacity 8.2.3. terminado 0.17.1. text-unidecode 1.3. textdistance 4.5.0. texttable 1.7.0. threadpoolctl 3.2.0. three-merge 0.1.1. throttler 1.2.2. tifffile 2023.4.12. tinycss2 1.2.1. tldextract 3.6.0. tokenizers 0.14.0. toml 0.10.2. tomli 2.0.1. tomlkit 0.12.1. toolz 0.12.0. toposort 1.10. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. transformers 4.34.0. truststore 0.8.0. Twisted 22.10.0. types-python-dateutil 2.8.19.14. typing_extensions 4.8.0. typing-utils 0.1.0. tzdata 2023.3. uc-micro-py 1.0.1. ujson 5.8.0. umap-learn 0.5.4. uri-template 1.3.0. urllib3 1.26.15. virtualenv 20.24.5. w3lib 2.1.2. watchdog 3.0.0. wcwidth 0.2.8. webcolors 1.13. webencodings 0.5.1. websocket-client 1.6.4. Werkzeug 3.0.0. whatthepatch 1.0.5. wheel 0.38.4. widgetsnbextension 4.0.9. wrapt 1.15.0. wurlitzer 3.0.3. xarray 2023.9.0. xxhash 3.4.1. xyzservices 2023.10.0. yapf 0.24.0. yarl 1.9.2. yte 1.5.1. zict 3.0.0. zipp 3.17.0. zope.interface 6.1. zstandard 0.21.0. ```. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:10630,integrability,wrap,wrapt,10630,3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.2. tblib 2.0.0. tenacity 8.2.3. terminado 0.17.1. text-unidecode 1.3. textdistance 4.5.0. texttable 1.7.0. threadpoolctl 3.2.0. three-merge 0.1.1. throttler 1.2.2. tifffile 2023.4.12. tinycss2 1.2.1. tldextract 3.6.0. tokenizers 0.14.0. toml 0.10.2. tomli 2.0.1. tomlkit 0.12.1. toolz 0.12.0. toposort 1.10. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. transformers 4.34.0. truststore 0.8.0. Twisted 22.10.0. types-python-dateutil 2.8.19.14. typing_extensions 4.8.0. typing-utils 0.1.0. tzdata 2023.3. uc-micro-py 1.0.1. ujson 5.8.0. umap-learn 0.5.4. uri-template 1.3.0. urllib3 1.26.15. virtualenv 20.24.5. w3lib 2.1.2. watchdog 3.0.0. wcwidth 0.2.8. webcolors 1.13. webencodings 0.5.1. websocket-client 1.6.4. Werkzeug 3.0.0. whatthepatch 1.0.5. wheel 0.38.4. widgetsnbextension 4.0.9. wrapt 1.15.0. wurlitzer 3.0.3. xarray 2023.9.0. xxhash 3.4.1. xyzservices 2023.10.0. yapf 0.24.0. yarl 1.9.2. yte 1.5.1. zict 3.0.0. zipp 3.17.0. zope.interface 6.1. zstandard 0.21.0. ```. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:10781,integrability,interfac,interface,10781,3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.2. tblib 2.0.0. tenacity 8.2.3. terminado 0.17.1. text-unidecode 1.3. textdistance 4.5.0. texttable 1.7.0. threadpoolctl 3.2.0. three-merge 0.1.1. throttler 1.2.2. tifffile 2023.4.12. tinycss2 1.2.1. tldextract 3.6.0. tokenizers 0.14.0. toml 0.10.2. tomli 2.0.1. tomlkit 0.12.1. toolz 0.12.0. toposort 1.10. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. transformers 4.34.0. truststore 0.8.0. Twisted 22.10.0. types-python-dateutil 2.8.19.14. typing_extensions 4.8.0. typing-utils 0.1.0. tzdata 2023.3. uc-micro-py 1.0.1. ujson 5.8.0. umap-learn 0.5.4. uri-template 1.3.0. urllib3 1.26.15. virtualenv 20.24.5. w3lib 2.1.2. watchdog 3.0.0. wcwidth 0.2.8. webcolors 1.13. webencodings 0.5.1. websocket-client 1.6.4. Werkzeug 3.0.0. whatthepatch 1.0.5. wheel 0.38.4. widgetsnbextension 4.0.9. wrapt 1.15.0. wurlitzer 3.0.3. xarray 2023.9.0. xxhash 3.4.1. xyzservices 2023.10.0. yapf 0.24.0. yarl 1.9.2. yte 1.5.1. zict 3.0.0. zipp 3.17.0. zope.interface 6.1. zstandard 0.21.0. ```. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1163,interoperability,adapt,adapting,1163,"d. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 294",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1372,interoperability,share,sharey,1372,"tribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 2940 linewidth=linewidth,. 2941 inner=inner,. 2942 density_norm=density_norm,. 2943 common_norm=common_norm,. 2944 kde_kws=kde_kws,. 2945 inner_kws=inner_kws,. 2946 plot_kws=plot_kws,. 2947 ). 2949 elif kind == ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1762,interoperability,format,formatter,1762,"otal_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 2940 linewidth=linewidth,. 2941 inner=inner,. 2942 density_norm=density_norm,. 2943 common_norm=common_norm,. 2944 kde_kws=kde_kws,. 2945 inner_kws=inner_kws,. 2946 plot_kws=plot_kws,. 2947 ). 2949 elif kind == ""boxen"":. 2951 plot_kws = kwargs.copy(). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:1153, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1151 legend_artist = _get_patch_legend_artist(fill). 1152 common_kws = {**plot_kws, ""linewidth"": linewidth, ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1827,interoperability,share,sharex,1827,"File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 2940 linewidth=linewidth,. 2941 inner=inner,. 2942 density_norm=density_norm,. 2943 common_norm=common_norm,. 2944 kde_kws=kde_kws,. 2945 inner_kws=inner_kws,. 2946 plot_kws=plot_kws,. 2947 ). 2949 elif kind == ""boxen"":. 2951 plot_kws = kwargs.copy(). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:1153, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1151 legend_artist = _get_patch_legend_artist(fill). 1152 common_kws = {**plot_kws, ""linewidth"": linewidth, ""edgecolor"": linecolor}. -> 1153 self._configure_legend(ax, leg",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1835,interoperability,share,sharey,1835,"naconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 2940 linewidth=linewidth,. 2941 inner=inner,. 2942 density_norm=density_norm,. 2943 common_norm=common_norm,. 2944 kde_kws=kde_kws,. 2945 inner_kws=inner_kws,. 2946 plot_kws=plot_kws,. 2947 ). 2949 elif kind == ""boxen"":. 2951 plot_kws = kwargs.copy(). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:1153, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1151 legend_artist = _get_patch_legend_artist(fill). 1152 common_kws = {**plot_kws, ""linewidth"": linewidth, ""edgecolor"": linecolor}. -> 1153 self._configure_legend(ax, legend_arti",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:3751,interoperability,bind,bindings,3751," linewidth, ""edgecolor"": linecolor}. -> 1153 self._configure_legend(ax, legend_artist, common_kws). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:420, in _CategoricalPlotter._configure_legend(self, ax, func, common_kws, semantic_kws). 418 if show_legend:. 419 self.add_legend_data(ax, func, common_kws, semantic_kws=semantic_kws). --> 420 handles, _ = ax.get_legend_handles_labels(). 421 if handles:. 422 ax.legend(title=self.legend_title). AttributeError: 'NoneType' object has no attribute 'get_legend_handles_labels'. ```. ### Versions. <details>. ```. Package Version. ----------------------------- ---------------. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aiosignal 1.3.1. alabaster 0.7.13. anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:3774,interoperability,api,api-compat,3774," linecolor}. -> 1153 self._configure_legend(ax, legend_artist, common_kws). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:420, in _CategoricalPlotter._configure_legend(self, ax, func, common_kws, semantic_kws). 418 if show_legend:. 419 self.add_legend_data(ax, func, common_kws, semantic_kws=semantic_kws). --> 420 handles, _ = ax.get_legend_handles_labels(). 421 if handles:. 422 ax.legend(title=self.legend_title). AttributeError: 'NoneType' object has no attribute 'get_legend_handles_labels'. ```. ### Versions. <details>. ```. Package Version. ----------------------------- ---------------. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aiosignal 1.3.1. alabaster 0.7.13. anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:3796,interoperability,api,api-compat,3796,"elf._configure_legend(ax, legend_artist, common_kws). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:420, in _CategoricalPlotter._configure_legend(self, ax, func, common_kws, semantic_kws). 418 if show_legend:. 419 self.add_legend_data(ax, func, common_kws, semantic_kws=semantic_kws). --> 420 handles, _ = ax.get_legend_handles_labels(). 421 if handles:. 422 ax.legend(title=self.legend_title). AttributeError: 'NoneType' object has no attribute 'get_legend_handles_labels'. ```. ### Versions. <details>. ```. Package Version. ----------------------------- ---------------. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aiosignal 1.3.1. alabaster 0.7.13. anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. coo",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:5125,interoperability,distribut,distributed,5125,.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. gmpy2 2.1.2. greenlet 3.0.0. h5py 3.9.0. holoviews 1.17.1. huggingface-hub 0.17.3. humanfriendly 10.0. hvplot 0.8.4. hyperlink 21.0.0. idna 3.4. igraph 0.10.4. imagecodecs 2023.1.23. imageio 2.31.1. imagesize 1.4.1. imbalanced-learn 0.11.0. importlib-metadata 6.8.0. importlib-resources 6.1.0. incremental 22.10.0. inflection 0.5.1. iniconfig 2.0.0. intake 0.7.0. intervaltree 3.1.0. ipykernel 6.25.2. ipython 8.16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsdangerous 2.1.2. jaraco.classes 3.3.0. jedi 0.18.1. jeepney 0.8.0. jellyfish 1.0.1. Jinja2 3.1.2. jmespath 1.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:5239,interoperability,xml,xmlfile,5239, brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. gmpy2 2.1.2. greenlet 3.0.0. h5py 3.9.0. holoviews 1.17.1. huggingface-hub 0.17.3. humanfriendly 10.0. hvplot 0.8.4. hyperlink 21.0.0. idna 3.4. igraph 0.10.4. imagecodecs 2023.1.23. imageio 2.31.1. imagesize 1.4.1. imbalanced-learn 0.11.0. importlib-metadata 6.8.0. importlib-resources 6.1.0. incremental 22.10.0. inflection 0.5.1. iniconfig 2.0.0. intake 0.7.0. intervaltree 3.1.0. ipykernel 6.25.2. ipython 8.16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsdangerous 2.1.2. jaraco.classes 3.3.0. jedi 0.18.1. jeepney 0.8.0. jellyfish 1.0.1. Jinja2 3.1.2. jmespath 1.0.1. joblib 1.3.2. json5 0.9.14. jsonpatch 1.33. jsonpointer 2.4. jsonschema 4.19.1. jsonschema-specifications 2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:6227,interoperability,specif,specifications,6227,. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. gmpy2 2.1.2. greenlet 3.0.0. h5py 3.9.0. holoviews 1.17.1. huggingface-hub 0.17.3. humanfriendly 10.0. hvplot 0.8.4. hyperlink 21.0.0. idna 3.4. igraph 0.10.4. imagecodecs 2023.1.23. imageio 2.31.1. imagesize 1.4.1. imbalanced-learn 0.11.0. importlib-metadata 6.8.0. importlib-resources 6.1.0. incremental 22.10.0. inflection 0.5.1. iniconfig 2.0.0. intake 0.7.0. intervaltree 3.1.0. ipykernel 6.25.2. ipython 8.16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsdangerous 2.1.2. jaraco.classes 3.3.0. jedi 0.18.1. jeepney 0.8.0. jellyfish 1.0.1. Jinja2 3.1.2. jmespath 1.0.1. joblib 1.3.2. json5 0.9.14. jsonpatch 1.33. jsonpointer 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1.0.0. jupyter_client 8.3.1. jupyter-console 6.6.3. jupyter_core 5.3.2. jupyter-events 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. MarkupSafe 2.1.3. matplotlib 3.8.0. matplotlib-inline 0.1.6. mccabe 0.7.0. mdit-py-plugins 0.4.0. mdurl 0.1.0. mistune 3.0.1. mkl-service 2.4.0. more-itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebo,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:6587,interoperability,prox,proxy,6587,vplot 0.8.4. hyperlink 21.0.0. idna 3.4. igraph 0.10.4. imagecodecs 2023.1.23. imageio 2.31.1. imagesize 1.4.1. imbalanced-learn 0.11.0. importlib-metadata 6.8.0. importlib-resources 6.1.0. incremental 22.10.0. inflection 0.5.1. iniconfig 2.0.0. intake 0.7.0. intervaltree 3.1.0. ipykernel 6.25.2. ipython 8.16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsdangerous 2.1.2. jaraco.classes 3.3.0. jedi 0.18.1. jeepney 0.8.0. jellyfish 1.0.1. Jinja2 3.1.2. jmespath 1.0.1. joblib 1.3.2. json5 0.9.14. jsonpatch 1.33. jsonpointer 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1.0.0. jupyter_client 8.3.1. jupyter-console 6.6.3. jupyter_core 5.3.2. jupyter-events 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. MarkupSafe 2.1.3. matplotlib 3.8.0. matplotlib-inline 0.1.6. mccabe 0.7.0. mdit-py-plugins 0.4.0. mdurl 0.1.0. mistune 3.0.1. mkl-service 2.4.0. more-itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. packaging 23.2. pandas 2.1.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. p,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:6847,interoperability,plug,plugins,6847,ntervaltree 3.1.0. ipykernel 6.25.2. ipython 8.16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsdangerous 2.1.2. jaraco.classes 3.3.0. jedi 0.18.1. jeepney 0.8.0. jellyfish 1.0.1. Jinja2 3.1.2. jmespath 1.0.1. joblib 1.3.2. json5 0.9.14. jsonpatch 1.33. jsonpointer 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1.0.0. jupyter_client 8.3.1. jupyter-console 6.6.3. jupyter_core 5.3.2. jupyter-events 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. MarkupSafe 2.1.3. matplotlib 3.8.0. matplotlib-inline 0.1.6. mccabe 0.7.0. mdit-py-plugins 0.4.0. mdurl 0.1.0. mistune 3.0.1. mkl-service 2.4.0. more-itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. packaging 23.2. pandas 2.1.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:7657,interoperability,platform,platformdirs,7657,-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. MarkupSafe 2.1.3. matplotlib 3.8.0. matplotlib-inline 0.1.6. mccabe 0.7.0. mdit-py-plugins 0.4.0. mdurl 0.1.0. mistune 3.0.1. mkl-service 2.4.0. more-itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. packaging 23.2. pandas 2.1.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1. Pygments 2.16.1. PyJWT 2.8.0. pylint 2.17.5. pylint-venv 3.0.2. pyls-spyder 0.4.0. pynndescent 0.5.10. pyodbc 4.0.39. pyOpenSSL 23.2.0. pyparsing 3.1.1. PyQt5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:7693,interoperability,plug,pluggy,7693,t 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. MarkupSafe 2.1.3. matplotlib 3.8.0. matplotlib-inline 0.1.6. mccabe 0.7.0. mdit-py-plugins 0.4.0. mdurl 0.1.0. mistune 3.0.1. mkl-service 2.4.0. more-itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. packaging 23.2. pandas 2.1.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1. Pygments 2.16.1. PyJWT 2.8.0. pylint 2.17.5. pylint-venv 3.0.2. pyls-spyder 0.4.0. pynndescent 0.5.10. pyodbc 4.0.39. pyOpenSSL 23.2.0. pyparsing 3.1.1. PyQt5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencin,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:10194,interoperability,transform,transformers,10194,3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.2. tblib 2.0.0. tenacity 8.2.3. terminado 0.17.1. text-unidecode 1.3. textdistance 4.5.0. texttable 1.7.0. threadpoolctl 3.2.0. three-merge 0.1.1. throttler 1.2.2. tifffile 2023.4.12. tinycss2 1.2.1. tldextract 3.6.0. tokenizers 0.14.0. toml 0.10.2. tomli 2.0.1. tomlkit 0.12.1. toolz 0.12.0. toposort 1.10. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. transformers 4.34.0. truststore 0.8.0. Twisted 22.10.0. types-python-dateutil 2.8.19.14. typing_extensions 4.8.0. typing-utils 0.1.0. tzdata 2023.3. uc-micro-py 1.0.1. ujson 5.8.0. umap-learn 0.5.4. uri-template 1.3.0. urllib3 1.26.15. virtualenv 20.24.5. w3lib 2.1.2. watchdog 3.0.0. wcwidth 0.2.8. webcolors 1.13. webencodings 0.5.1. websocket-client 1.6.4. Werkzeug 3.0.0. whatthepatch 1.0.5. wheel 0.38.4. widgetsnbextension 4.0.9. wrapt 1.15.0. wurlitzer 3.0.3. xarray 2023.9.0. xxhash 3.4.1. xyzservices 2023.10.0. yapf 0.24.0. yarl 1.9.2. yte 1.5.1. zict 3.0.0. zipp 3.17.0. zope.interface 6.1. zstandard 0.21.0. ```. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:10781,interoperability,interfac,interface,10781,3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.2. tblib 2.0.0. tenacity 8.2.3. terminado 0.17.1. text-unidecode 1.3. textdistance 4.5.0. texttable 1.7.0. threadpoolctl 3.2.0. three-merge 0.1.1. throttler 1.2.2. tifffile 2023.4.12. tinycss2 1.2.1. tldextract 3.6.0. tokenizers 0.14.0. toml 0.10.2. tomli 2.0.1. tomlkit 0.12.1. toolz 0.12.0. toposort 1.10. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. transformers 4.34.0. truststore 0.8.0. Twisted 22.10.0. types-python-dateutil 2.8.19.14. typing_extensions 4.8.0. typing-utils 0.1.0. tzdata 2023.3. uc-micro-py 1.0.1. ujson 5.8.0. umap-learn 0.5.4. uri-template 1.3.0. urllib3 1.26.15. virtualenv 20.24.5. w3lib 2.1.2. watchdog 3.0.0. wcwidth 0.2.8. webcolors 1.13. webencodings 0.5.1. websocket-client 1.6.4. Werkzeug 3.0.0. whatthepatch 1.0.5. wheel 0.38.4. widgetsnbextension 4.0.9. wrapt 1.15.0. wurlitzer 3.0.3. xarray 2023.9.0. xxhash 3.4.1. xyzservices 2023.10.0. yapf 0.24.0. yarl 1.9.2. yte 1.5.1. zict 3.0.0. zipp 3.17.0. zope.interface 6.1. zstandard 0.21.0. ```. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:223,modifiability,version,version,223,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:867,modifiability,pac,packages,867,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:980,modifiability,layer,layer,980,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:987,modifiability,scal,scale,987,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1163,modifiability,adapt,adapting,1163,"d. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 294",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1172,modifiability,scal,scales,1172," I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 2940 linewi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1321,modifiability,scal,scale,1321,"### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 2940 linewidth=linewidth,. 2941 inner=inner,. 2942 density_norm=density_norm,. 2943 common_norm=common_norm,. 2944 kde_kws=kde_kws,. 2945 inner_kws=inner_kws,. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1327,modifiability,scal,scale,1327,"at happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 2940 linewidth=linewidth,. 2941 inner=inner,. 2942 density_norm=density_norm,. 2943 common_norm=common_norm,. 2944 kde_kws=kde_kws,. 2945 inner_kws=inner_kws,. 2946 p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1547,modifiability,pac,packages,1547,"utput. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 2940 linewidth=linewidth,. 2941 inner=inner,. 2942 density_norm=density_norm,. 2943 common_norm=common_norm,. 2944 kde_kws=kde_kws,. 2945 inner_kws=inner_kws,. 2946 plot_kws=plot_kws,. 2947 ). 2949 elif kind == ""boxen"":. 2951 plot_kws = kwargs.copy(). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:1153, in _CategoricalPlotter.plot_violins(self, width, dodge, gap,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:2453,modifiability,pac,packages,2453,"if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 2940 linewidth=linewidth,. 2941 inner=inner,. 2942 density_norm=density_norm,. 2943 common_norm=common_norm,. 2944 kde_kws=kde_kws,. 2945 inner_kws=inner_kws,. 2946 plot_kws=plot_kws,. 2947 ). 2949 elif kind == ""boxen"":. 2951 plot_kws = kwargs.copy(). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:1153, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1151 legend_artist = _get_patch_legend_artist(fill). 1152 common_kws = {**plot_kws, ""linewidth"": linewidth, ""edgecolor"": linecolor}. -> 1153 self._configure_legend(ax, legend_artist, common_kws). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:420, in _CategoricalPlotter._configure_legend(self, ax, func, common_kws, semantic_kws). 418 if show_legend:. 419 self.add_legend_data(ax, func, common_kws, semantic_kws=semantic_kws). --> 420 handles, _ = ax.get_legend_handles_labels(). 421 if handles:. 422 ax.legend(title=self.legend_title). AttributeError: 'NoneType' object has no attribute 'get_legend_handles_labels'. ```. ### Versions. <details>. ```. Package Version. ----------------------------- ---------------. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aios",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:2892,modifiability,pac,packages,2892,"or = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 2940 linewidth=linewidth,. 2941 inner=inner,. 2942 density_norm=density_norm,. 2943 common_norm=common_norm,. 2944 kde_kws=kde_kws,. 2945 inner_kws=inner_kws,. 2946 plot_kws=plot_kws,. 2947 ). 2949 elif kind == ""boxen"":. 2951 plot_kws = kwargs.copy(). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:1153, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1151 legend_artist = _get_patch_legend_artist(fill). 1152 common_kws = {**plot_kws, ""linewidth"": linewidth, ""edgecolor"": linecolor}. -> 1153 self._configure_legend(ax, legend_artist, common_kws). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:420, in _CategoricalPlotter._configure_legend(self, ax, func, common_kws, semantic_kws). 418 if show_legend:. 419 self.add_legend_data(ax, func, common_kws, semantic_kws=semantic_kws). --> 420 handles, _ = ax.get_legend_handles_labels(). 421 if handles:. 422 ax.legend(title=self.legend_title). AttributeError: 'NoneType' object has no attribute 'get_legend_handles_labels'. ```. ### Versions. <details>. ```. Package Version. ----------------------------- ---------------. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aiosignal 1.3.1. alabaster 0.7.13. anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:3308,modifiability,Version,Versions,3308,"inner_kws,. 2946 plot_kws=plot_kws,. 2947 ). 2949 elif kind == ""boxen"":. 2951 plot_kws = kwargs.copy(). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:1153, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1151 legend_artist = _get_patch_legend_artist(fill). 1152 common_kws = {**plot_kws, ""linewidth"": linewidth, ""edgecolor"": linecolor}. -> 1153 self._configure_legend(ax, legend_artist, common_kws). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:420, in _CategoricalPlotter._configure_legend(self, ax, func, common_kws, semantic_kws). 418 if show_legend:. 419 self.add_legend_data(ax, func, common_kws, semantic_kws=semantic_kws). --> 420 handles, _ = ax.get_legend_handles_labels(). 421 if handles:. 422 ax.legend(title=self.legend_title). AttributeError: 'NoneType' object has no attribute 'get_legend_handles_labels'. ```. ### Versions. <details>. ```. Package Version. ----------------------------- ---------------. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aiosignal 1.3.1. alabaster 0.7.13. anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 202",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:3334,modifiability,Pac,Package,3334,"plot_kws,. 2947 ). 2949 elif kind == ""boxen"":. 2951 plot_kws = kwargs.copy(). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:1153, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1151 legend_artist = _get_patch_legend_artist(fill). 1152 common_kws = {**plot_kws, ""linewidth"": linewidth, ""edgecolor"": linecolor}. -> 1153 self._configure_legend(ax, legend_artist, common_kws). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:420, in _CategoricalPlotter._configure_legend(self, ax, func, common_kws, semantic_kws). 418 if show_legend:. 419 self.add_legend_data(ax, func, common_kws, semantic_kws=semantic_kws). --> 420 handles, _ = ax.get_legend_handles_labels(). 421 if handles:. 422 ax.legend(title=self.legend_title). AttributeError: 'NoneType' object has no attribute 'get_legend_handles_labels'. ```. ### Versions. <details>. ```. Package Version. ----------------------------- ---------------. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aiosignal 1.3.1. alabaster 0.7.13. anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chard",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:3342,modifiability,Version,Version,3342,",. 2947 ). 2949 elif kind == ""boxen"":. 2951 plot_kws = kwargs.copy(). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:1153, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1151 legend_artist = _get_patch_legend_artist(fill). 1152 common_kws = {**plot_kws, ""linewidth"": linewidth, ""edgecolor"": linecolor}. -> 1153 self._configure_legend(ax, legend_artist, common_kws). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:420, in _CategoricalPlotter._configure_legend(self, ax, func, common_kws, semantic_kws). 418 if show_legend:. 419 self.add_legend_data(ax, func, common_kws, semantic_kws=semantic_kws). --> 420 handles, _ = ax.get_legend_handles_labels(). 421 if handles:. 422 ax.legend(title=self.legend_title). AttributeError: 'NoneType' object has no attribute 'get_legend_handles_labels'. ```. ### Versions. <details>. ```. Package Version. ----------------------------- ---------------. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aiosignal 1.3.1. alabaster 0.7.13. anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:3751,modifiability,bind,bindings,3751," linewidth, ""edgecolor"": linecolor}. -> 1153 self._configure_legend(ax, legend_artist, common_kws). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:420, in _CategoricalPlotter._configure_legend(self, ax, func, common_kws, semantic_kws). 418 if show_legend:. 419 self.add_legend_data(ax, func, common_kws, semantic_kws=semantic_kws). --> 420 handles, _ = ax.get_legend_handles_labels(). 421 if handles:. 422 ax.legend(title=self.legend_title). AttributeError: 'NoneType' object has no attribute 'get_legend_handles_labels'. ```. ### Versions. <details>. ```. Package Version. ----------------------------- ---------------. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aiosignal 1.3.1. alabaster 0.7.13. anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:4584,modifiability,pac,pack,4584,1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. gmpy2 2.1.2. greenlet 3.0.0. h5py 3.9.0. holoviews 1.17.1. huggingface-hub 0.17.3. humanfriendly 10.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:4602,modifiability,pac,package-handling,4602,2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. gmpy2 2.1.2. greenlet 3.0.0. h5py 3.9.0. holoviews 1.17.1. huggingface-hub 0.17.3. humanfriendly 10.0. hvplot 0.8.4. hyperli,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:5019,modifiability,deco,decorator,5019,ols-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. gmpy2 2.1.2. greenlet 3.0.0. h5py 3.9.0. holoviews 1.17.1. huggingface-hub 0.17.3. humanfriendly 10.0. hvplot 0.8.4. hyperlink 21.0.0. idna 3.4. igraph 0.10.4. imagecodecs 2023.1.23. imageio 2.31.1. imagesize 1.4.1. imbalanced-learn 0.11.0. importlib-metadata 6.8.0. importlib-resources 6.1.0. incremental 22.10.0. inflection 0.5.1. iniconfig 2.0.0. intake 0.7.0. intervaltree 3.1.0. ipykernel 6.25.2. ipython 8.16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsda,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:5036,modifiability,deco,decoupler,5036,.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. gmpy2 2.1.2. greenlet 3.0.0. h5py 3.9.0. holoviews 1.17.1. huggingface-hub 0.17.3. humanfriendly 10.0. hvplot 0.8.4. hyperlink 21.0.0. idna 3.4. igraph 0.10.4. imagecodecs 2023.1.23. imageio 2.31.1. imagesize 1.4.1. imbalanced-learn 0.11.0. importlib-metadata 6.8.0. importlib-resources 6.1.0. incremental 22.10.0. inflection 0.5.1. iniconfig 2.0.0. intake 0.7.0. intervaltree 3.1.0. ipykernel 6.25.2. ipython 8.16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsdangerous 2.1.2. ja,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:6894,modifiability,servic,service,6894,16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsdangerous 2.1.2. jaraco.classes 3.3.0. jedi 0.18.1. jeepney 0.8.0. jellyfish 1.0.1. Jinja2 3.1.2. jmespath 1.0.1. joblib 1.3.2. json5 0.9.14. jsonpatch 1.33. jsonpointer 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1.0.0. jupyter_client 8.3.1. jupyter-console 6.6.3. jupyter_core 5.3.2. jupyter-events 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. MarkupSafe 2.1.3. matplotlib 3.8.0. matplotlib-inline 0.1.6. mccabe 0.7.0. mdit-py-plugins 0.4.0. mdurl 0.1.0. mistune 3.0.1. mkl-service 2.4.0. more-itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. packaging 23.2. pandas 2.1.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:7044,modifiability,extens,extensions,7044,sses 3.3.0. jedi 0.18.1. jeepney 0.8.0. jellyfish 1.0.1. Jinja2 3.1.2. jmespath 1.0.1. joblib 1.3.2. json5 0.9.14. jsonpatch 1.33. jsonpointer 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1.0.0. jupyter_client 8.3.1. jupyter-console 6.6.3. jupyter_core 5.3.2. jupyter-events 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. MarkupSafe 2.1.3. matplotlib 3.8.0. matplotlib-inline 0.1.6. mccabe 0.7.0. mdit-py-plugins 0.4.0. mdurl 0.1.0. mistune 3.0.1. mkl-service 2.4.0. more-itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. packaging 23.2. pandas 2.1.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:7341,modifiability,pac,packaging,7341, 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. MarkupSafe 2.1.3. matplotlib 3.8.0. matplotlib-inline 0.1.6. mccabe 0.7.0. mdit-py-plugins 0.4.0. mdurl 0.1.0. mistune 3.0.1. mkl-service 2.4.0. more-itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. packaging 23.2. pandas 2.1.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1. Pygments 2.16.1. PyJWT 2.8.0. pylint 2.17.5. pylint-venv 3.0.2. pyls-spyder 0.4.0. pynndescent 0.5.10. pyodbc 4.0.39. pyOpenSSL 23.2.0. pyparsing 3.1.1. PyQt5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:7910,modifiability,modul,modules,7910,itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. packaging 23.2. pandas 2.1.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1. Pygments 2.16.1. PyJWT 2.8.0. pylint 2.17.5. pylint-venv 3.0.2. pyls-spyder 0.4.0. pynndescent 0.5.10. pyodbc 4.0.39. pyOpenSSL 23.2.0. pyparsing 3.1.1. PyQt5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:9256,modifiability,servic,service-identity,9256,5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.2. tblib 2.0.0. tenacity 8.2.3. terminado 0.17.1. text-unidecode 1.3. textdistance 4.5.0. texttable 1.7.0. threadpoolctl 3.2.0. three-merge 0.1.1. throttler 1.2.2. tifffile 2023.4.12. tinycss2 1.2.1. tldextract 3.6.0. tokenizers 0.14.0. toml 0.10.2. tomli 2.0.1. tomlkit 0.12.1. toolz 0.12.0. toposort 1.10. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. transformers 4.34.0. truststore 0.8.0. Twisted 22.10.0. types-python-d,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:10781,modifiability,interfac,interface,10781,3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.2. tblib 2.0.0. tenacity 8.2.3. terminado 0.17.1. text-unidecode 1.3. textdistance 4.5.0. texttable 1.7.0. threadpoolctl 3.2.0. three-merge 0.1.1. throttler 1.2.2. tifffile 2023.4.12. tinycss2 1.2.1. tldextract 3.6.0. tokenizers 0.14.0. toml 0.10.2. tomli 2.0.1. tomlkit 0.12.1. toolz 0.12.0. toposort 1.10. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. transformers 4.34.0. truststore 0.8.0. Twisted 22.10.0. types-python-dateutil 2.8.19.14. typing_extensions 4.8.0. typing-utils 0.1.0. tzdata 2023.3. uc-micro-py 1.0.1. ujson 5.8.0. umap-learn 0.5.4. uri-template 1.3.0. urllib3 1.26.15. virtualenv 20.24.5. w3lib 2.1.2. watchdog 3.0.0. wcwidth 0.2.8. webcolors 1.13. webencodings 0.5.1. websocket-client 1.6.4. Werkzeug 3.0.0. whatthepatch 1.0.5. wheel 0.38.4. widgetsnbextension 4.0.9. wrapt 1.15.0. wurlitzer 3.0.3. xarray 2023.9.0. xxhash 3.4.1. xyzservices 2023.10.0. yapf 0.24.0. yarl 1.9.2. yte 1.5.1. zict 3.0.0. zipp 3.17.0. zope.interface 6.1. zstandard 0.21.0. ```. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:46,performance,error,error,46,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:383,performance,error,error,383,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:544,performance,Error,Error,544,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:987,performance,scale,scale,987,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1172,performance,scale,scales,1172," I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 2940 linewi",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1321,performance,scale,scale,1321,"### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 2940 linewidth=linewidth,. 2941 inner=inner,. 2942 density_norm=density_norm,. 2943 common_norm=common_norm,. 2944 kde_kws=kde_kws,. 2945 inner_kws=inner_kws,. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1327,performance,scale,scale,1327,"at happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 2940 linewidth=linewidth,. 2941 inner=inner,. 2942 density_norm=density_norm,. 2943 common_norm=common_norm,. 2944 kde_kws=kde_kws,. 2945 inner_kws=inner_kws,. 2946 p",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1640,performance,error,errorbar,1640,"AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 2940 linewidth=linewidth,. 2941 inner=inner,. 2942 density_norm=density_norm,. 2943 common_norm=common_norm,. 2944 kde_kws=kde_kws,. 2945 inner_kws=inner_kws,. 2946 plot_kws=plot_kws,. 2947 ). 2949 elif kind == ""boxen"":. 2951 plot_kws = kwargs.copy(). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:1153, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:3896,performance,time,timeout,3896,"/seaborn/categorical.py:420, in _CategoricalPlotter._configure_legend(self, ax, func, common_kws, semantic_kws). 418 if show_legend:. 419 self.add_legend_data(ax, func, common_kws, semantic_kws=semantic_kws). --> 420 handles, _ = ax.get_legend_handles_labels(). 421 if handles:. 422 ax.legend(title=self.legend_title). AttributeError: 'NoneType' object has no attribute 'get_legend_handles_labels'. ```. ### Versions. <details>. ```. Package Version. ----------------------------- ---------------. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aiosignal 1.3.1. alabaster 0.7.13. anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:4032,performance,cach,cache,4032,"19 self.add_legend_data(ax, func, common_kws, semantic_kws=semantic_kws). --> 420 handles, _ = ax.get_legend_handles_labels(). 421 if handles:. 422 ax.legend(title=self.legend_title). AttributeError: 'NoneType' object has no attribute 'get_legend_handles_labels'. ```. ### Versions. <details>. ```. Package Version. ----------------------------- ---------------. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aiosignal 1.3.1. alabaster 0.7.13. anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:4260,performance,cach,cached-property,4260,e 'get_legend_handles_labels'. ```. ### Versions. <details>. ```. Package Version. ----------------------------- ---------------. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aiosignal 1.3.1. alabaster 0.7.13. anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:4504,performance,content,content-trust,4504,.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. gmpy2 2.1.2. greenlet 3.0,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:5763,performance,resourc,resources,5763,ntly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. gmpy2 2.1.2. greenlet 3.0.0. h5py 3.9.0. holoviews 1.17.1. huggingface-hub 0.17.3. humanfriendly 10.0. hvplot 0.8.4. hyperlink 21.0.0. idna 3.4. igraph 0.10.4. imagecodecs 2023.1.23. imageio 2.31.1. imagesize 1.4.1. imbalanced-learn 0.11.0. importlib-metadata 6.8.0. importlib-resources 6.1.0. incremental 22.10.0. inflection 0.5.1. iniconfig 2.0.0. intake 0.7.0. intervaltree 3.1.0. ipykernel 6.25.2. ipython 8.16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsdangerous 2.1.2. jaraco.classes 3.3.0. jedi 0.18.1. jeepney 0.8.0. jellyfish 1.0.1. Jinja2 3.1.2. jmespath 1.0.1. joblib 1.3.2. json5 0.9.14. jsonpatch 1.33. jsonpointer 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1.0.0. jupyter_client 8.3.1. jupyter-console 6.6.3. jupyter_core 5.3.2. jupyter-events 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. Mark,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:6691,performance,lock,locket,6691, 1.4.1. imbalanced-learn 0.11.0. importlib-metadata 6.8.0. importlib-resources 6.1.0. incremental 22.10.0. inflection 0.5.1. iniconfig 2.0.0. intake 0.7.0. intervaltree 3.1.0. ipykernel 6.25.2. ipython 8.16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsdangerous 2.1.2. jaraco.classes 3.3.0. jedi 0.18.1. jeepney 0.8.0. jellyfish 1.0.1. Jinja2 3.1.2. jmespath 1.0.1. joblib 1.3.2. json5 0.9.14. jsonpatch 1.33. jsonpointer 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1.0.0. jupyter_client 8.3.1. jupyter-console 6.6.3. jupyter_core 5.3.2. jupyter-events 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. MarkupSafe 2.1.3. matplotlib 3.8.0. matplotlib-inline 0.1.6. mccabe 0.7.0. mdit-py-plugins 0.4.0. mdurl 0.1.0. mistune 3.0.1. mkl-service 2.4.0. more-itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. packaging 23.2. pandas 2.1.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. p,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:7186,performance,network,networkx,7186,r 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1.0.0. jupyter_client 8.3.1. jupyter-console 6.6.3. jupyter_core 5.3.2. jupyter-events 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. MarkupSafe 2.1.3. matplotlib 3.8.0. matplotlib-inline 0.1.6. mccabe 0.7.0. mdit-py-plugins 0.4.0. mdurl 0.1.0. mistune 3.0.1. mkl-service 2.4.0. more-itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. packaging 23.2. pandas 2.1.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1. Pygments 2.16.1. PyJWT 2.8.0. pylint 2.17.5. pylint-venv 3.0.2. pyls-spyder 0.4.0. ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:7405,performance,parallel,parallel-fastq-dump,7405,nals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. MarkupSafe 2.1.3. matplotlib 3.8.0. matplotlib-inline 0.1.6. mccabe 0.7.0. mdit-py-plugins 0.4.0. mdurl 0.1.0. mistune 3.0.1. mkl-service 2.4.0. more-itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. packaging 23.2. pandas 2.1.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1. Pygments 2.16.1. PyJWT 2.8.0. pylint 2.17.5. pylint-venv 3.0.2. pyls-spyder 0.4.0. pynndescent 0.5.10. pyodbc 4.0.39. pyOpenSSL 23.2.0. pyparsing 3.1.1. PyQt5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-js,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:7858,performance,cpu,cpuinfo,7858,mdurl 0.1.0. mistune 3.0.1. mkl-service 2.4.0. more-itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. packaging 23.2. pandas 2.1.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1. Pygments 2.16.1. PyJWT 2.8.0. pylint 2.17.5. pylint-venv 3.0.2. pyls-spyder 0.4.0. pynndescent 0.5.10. pyodbc 4.0.39. pyOpenSSL 23.2.0. pyparsing 3.1.1. PyQt5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:8670,performance,queue,queuelib,8670,.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1. Pygments 2.16.1. PyJWT 2.8.0. pylint 2.17.5. pylint-venv 3.0.2. pyls-spyder 0.4.0. pynndescent 0.5.10. pyodbc 4.0.39. pyOpenSSL 23.2.0. pyparsing 3.1.1. PyQt5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:9987,performance,throttl,throttler,9987,3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.2. tblib 2.0.0. tenacity 8.2.3. terminado 0.17.1. text-unidecode 1.3. textdistance 4.5.0. texttable 1.7.0. threadpoolctl 3.2.0. three-merge 0.1.1. throttler 1.2.2. tifffile 2023.4.12. tinycss2 1.2.1. tldextract 3.6.0. tokenizers 0.14.0. toml 0.10.2. tomli 2.0.1. tomlkit 0.12.1. toolz 0.12.0. toposort 1.10. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. transformers 4.34.0. truststore 0.8.0. Twisted 22.10.0. types-python-dateutil 2.8.19.14. typing_extensions 4.8.0. typing-utils 0.1.0. tzdata 2023.3. uc-micro-py 1.0.1. ujson 5.8.0. umap-learn 0.5.4. uri-template 1.3.0. urllib3 1.26.15. virtualenv 20.24.5. w3lib 2.1.2. watchdog 3.0.0. wcwidth 0.2.8. webcolors 1.13. webencodings 0.5.1. websocket-client 1.6.4. Werkzeug 3.0.0. whatthepatch 1.0.5. wheel 0.38.4. widgetsnbextension 4.0.9. wrapt 1.15.0. wurlitzer 3.0.3. xarray 2023.9.0. xxhash 3.4.1. xyzservices 2023.10.0. yapf 0.24.0. yarl 1.9.2. yte 1.5.1. zict 3.0.0. zipp 3.17.0. zope.interface 6.1. zstandard 0.21.0. ```. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:46,safety,error,error,46,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:383,safety,error,error,383,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:544,safety,Error,Error,544,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:941,safety,log,log,941,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1640,safety,error,errorbar,1640,"AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 2940 linewidth=linewidth,. 2941 inner=inner,. 2942 density_norm=density_norm,. 2943 common_norm=common_norm,. 2944 kde_kws=kde_kws,. 2945 inner_kws=inner_kws,. 2946 plot_kws=plot_kws,. 2947 ). 2949 elif kind == ""boxen"":. 2951 plot_kws = kwargs.copy(). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:1153, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:3896,safety,timeout,timeout,3896,"/seaborn/categorical.py:420, in _CategoricalPlotter._configure_legend(self, ax, func, common_kws, semantic_kws). 418 if show_legend:. 419 self.add_legend_data(ax, func, common_kws, semantic_kws=semantic_kws). --> 420 handles, _ = ax.get_legend_handles_labels(). 421 if handles:. 422 ax.legend(title=self.legend_title). AttributeError: 'NoneType' object has no attribute 'get_legend_handles_labels'. ```. ### Versions. <details>. ```. Package Version. ----------------------------- ---------------. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aiosignal 1.3.1. alabaster 0.7.13. anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:5082,safety,patch,patch,5082,f 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. gmpy2 2.1.2. greenlet 3.0.0. h5py 3.9.0. holoviews 1.17.1. huggingface-hub 0.17.3. humanfriendly 10.0. hvplot 0.8.4. hyperlink 21.0.0. idna 3.4. igraph 0.10.4. imagecodecs 2023.1.23. imageio 2.31.1. imagesize 1.4.1. imbalanced-learn 0.11.0. importlib-metadata 6.8.0. importlib-resources 6.1.0. incremental 22.10.0. inflection 0.5.1. iniconfig 2.0.0. intake 0.7.0. intervaltree 3.1.0. ipykernel 6.25.2. ipython 8.16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsdangerous 2.1.2. jaraco.classes 3.3.0. jedi 0.18.1. jeepney 0.8,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:5254,safety,except,exceptiongroup,5254,ached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. gmpy2 2.1.2. greenlet 3.0.0. h5py 3.9.0. holoviews 1.17.1. huggingface-hub 0.17.3. humanfriendly 10.0. hvplot 0.8.4. hyperlink 21.0.0. idna 3.4. igraph 0.10.4. imagecodecs 2023.1.23. imageio 2.31.1. imagesize 1.4.1. imbalanced-learn 0.11.0. importlib-metadata 6.8.0. importlib-resources 6.1.0. incremental 22.10.0. inflection 0.5.1. iniconfig 2.0.0. intake 0.7.0. intervaltree 3.1.0. ipykernel 6.25.2. ipython 8.16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsdangerous 2.1.2. jaraco.classes 3.3.0. jedi 0.18.1. jeepney 0.8.0. jellyfish 1.0.1. Jinja2 3.1.2. jmespath 1.0.1. joblib 1.3.2. json5 0.9.14. jsonpatch 1.33. jsonpointer 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:5763,safety,resourc,resources,5763,ntly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. gmpy2 2.1.2. greenlet 3.0.0. h5py 3.9.0. holoviews 1.17.1. huggingface-hub 0.17.3. humanfriendly 10.0. hvplot 0.8.4. hyperlink 21.0.0. idna 3.4. igraph 0.10.4. imagecodecs 2023.1.23. imageio 2.31.1. imagesize 1.4.1. imbalanced-learn 0.11.0. importlib-metadata 6.8.0. importlib-resources 6.1.0. incremental 22.10.0. inflection 0.5.1. iniconfig 2.0.0. intake 0.7.0. intervaltree 3.1.0. ipykernel 6.25.2. ipython 8.16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsdangerous 2.1.2. jaraco.classes 3.3.0. jedi 0.18.1. jeepney 0.8.0. jellyfish 1.0.1. Jinja2 3.1.2. jmespath 1.0.1. joblib 1.3.2. json5 0.9.14. jsonpatch 1.33. jsonpointer 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1.0.0. jupyter_client 8.3.1. jupyter-console 6.6.3. jupyter_core 5.3.2. jupyter-events 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. Mark,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:7102,safety,updat,updater,7102,Jinja2 3.1.2. jmespath 1.0.1. joblib 1.3.2. json5 0.9.14. jsonpatch 1.33. jsonpointer 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1.0.0. jupyter_client 8.3.1. jupyter-console 6.6.3. jupyter_core 5.3.2. jupyter-events 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. MarkupSafe 2.1.3. matplotlib 3.8.0. matplotlib-inline 0.1.6. mccabe 0.7.0. mdit-py-plugins 0.4.0. mdurl 0.1.0. mistune 3.0.1. mkl-service 2.4.0. more-itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. packaging 23.2. pandas 2.1.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:7910,safety,modul,modules,7910,itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. packaging 23.2. pandas 2.1.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1. Pygments 2.16.1. PyJWT 2.8.0. pylint 2.17.5. pylint-venv 3.0.2. pyls-spyder 0.4.0. pynndescent 0.5.10. pyodbc 4.0.39. pyOpenSSL 23.2.0. pyparsing 3.1.1. PyQt5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:8364,safety,log,logger,8364,.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1. Pygments 2.16.1. PyJWT 2.8.0. pylint 2.17.5. pylint-venv 3.0.2. pyls-spyder 0.4.0. pynndescent 0.5.10. pyodbc 4.0.39. pyOpenSSL 23.2.0. pyparsing 3.1.1. PyQt5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:8810,safety,valid,validator,8810,ess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1. Pygments 2.16.1. PyJWT 2.8.0. pylint 2.17.5. pylint-venv 3.0.2. pyls-spyder 0.4.0. pynndescent 0.5.10. pyodbc 4.0.39. pyOpenSSL 23.2.0. pyparsing 3.1.1. PyQt5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:8835,safety,valid,validator,8835,re-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1. Pygments 2.16.1. PyJWT 2.8.0. pylint 2.17.5. pylint-venv 3.0.2. pyls-spyder 0.4.0. pynndescent 0.5.10. pyodbc 4.0.39. pyOpenSSL 23.2.0. pyparsing 3.1.1. PyQt5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:9010,safety,safe,safetensors,9010,.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1. Pygments 2.16.1. PyJWT 2.8.0. pylint 2.17.5. pylint-venv 3.0.2. pyls-spyder 0.4.0. pynndescent 0.5.10. pyodbc 4.0.39. pyOpenSSL 23.2.0. pyparsing 3.1.1. PyQt5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.2. tblib 2.0.0. tenacity 8.2.3. terminado 0.17.1. text-unidecode 1.3. textdistance 4.5.0. texttable 1.7.0. threadpoolctl 3.2.0. three-merge 0.1.1. throttler 1.2.2. tifffile 202,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:10463,safety,watchdog,watchdog,10463,3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.2. tblib 2.0.0. tenacity 8.2.3. terminado 0.17.1. text-unidecode 1.3. textdistance 4.5.0. texttable 1.7.0. threadpoolctl 3.2.0. three-merge 0.1.1. throttler 1.2.2. tifffile 2023.4.12. tinycss2 1.2.1. tldextract 3.6.0. tokenizers 0.14.0. toml 0.10.2. tomli 2.0.1. tomlkit 0.12.1. toolz 0.12.0. toposort 1.10. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. transformers 4.34.0. truststore 0.8.0. Twisted 22.10.0. types-python-dateutil 2.8.19.14. typing_extensions 4.8.0. typing-utils 0.1.0. tzdata 2023.3. uc-micro-py 1.0.1. ujson 5.8.0. umap-learn 0.5.4. uri-template 1.3.0. urllib3 1.26.15. virtualenv 20.24.5. w3lib 2.1.2. watchdog 3.0.0. wcwidth 0.2.8. webcolors 1.13. webencodings 0.5.1. websocket-client 1.6.4. Werkzeug 3.0.0. whatthepatch 1.0.5. wheel 0.38.4. widgetsnbextension 4.0.9. wrapt 1.15.0. wurlitzer 3.0.3. xarray 2023.9.0. xxhash 3.4.1. xyzservices 2023.10.0. yapf 0.24.0. yarl 1.9.2. yte 1.5.1. zict 3.0.0. zipp 3.17.0. zope.interface 6.1. zstandard 0.21.0. ```. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:941,security,log,log,941,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1030,security,rotat,rotation,1030,"s attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:3579,security,auth,auth,3579,", linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 1151 legend_artist = _get_patch_legend_artist(fill). 1152 common_kws = {**plot_kws, ""linewidth"": linewidth, ""edgecolor"": linecolor}. -> 1153 self._configure_legend(ax, legend_artist, common_kws). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:420, in _CategoricalPlotter._configure_legend(self, ax, func, common_kws, semantic_kws). 418 if show_legend:. 419 self.add_legend_data(ax, func, common_kws, semantic_kws=semantic_kws). --> 420 handles, _ = ax.get_legend_handles_labels(). 421 if handles:. 422 ax.legend(title=self.legend_title). AttributeError: 'NoneType' object has no attribute 'get_legend_handles_labels'. ```. ### Versions. <details>. ```. Package Version. ----------------------------- ---------------. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aiosignal 1.3.1. alabaster 0.7.13. anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. con",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:4301,security,certif,certifi,4301,## Versions. <details>. ```. Package Version. ----------------------------- ---------------. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aiosignal 1.3.1. alabaster 0.7.13. anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonsche,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:4512,security,trust,trust,4512,anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. gmpy2 2.1.2. greenlet 3.0.0. ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:4686,security,token,token,4686,. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. gmpy2 2.1.2. greenlet 3.0.0. h5py 3.9.0. holoviews 1.17.1. huggingface-hub 0.17.3. humanfriendly 10.0. hvplot 0.8.4. hyperlink 21.0.0. idna 3.4. igraph 0.10.4. imagecodecs 2023.1.23. imageio 2.31.1. imag,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:4798,security,cookie,cookiecutter,4798,at 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. gmpy2 2.1.2. greenlet 3.0.0. h5py 3.9.0. holoviews 1.17.1. huggingface-hub 0.17.3. humanfriendly 10.0. hvplot 0.8.4. hyperlink 21.0.0. idna 3.4. igraph 0.10.4. imagecodecs 2023.1.23. imageio 2.31.1. imagesize 1.4.1. imbalanced-learn 0.11.0. importlib-metadata 6.8.0. importlib-resources 6.1.0. incremental 22.10.0. inf,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:4818,security,cryptograph,cryptography,4818, astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. gmpy2 2.1.2. greenlet 3.0.0. h5py 3.9.0. holoviews 1.17.1. huggingface-hub 0.17.3. humanfriendly 10.0. hvplot 0.8.4. hyperlink 21.0.0. idna 3.4. igraph 0.10.4. imagecodecs 2023.1.23. imageio 2.31.1. imagesize 1.4.1. imbalanced-learn 0.11.0. importlib-metadata 6.8.0. importlib-resources 6.1.0. incremental 22.10.0. inflection 0.5.1. inico,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:5082,security,patch,patch,5082,f 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. gmpy2 2.1.2. greenlet 3.0.0. h5py 3.9.0. holoviews 1.17.1. huggingface-hub 0.17.3. humanfriendly 10.0. hvplot 0.8.4. hyperlink 21.0.0. idna 3.4. igraph 0.10.4. imagecodecs 2023.1.23. imageio 2.31.1. imagesize 1.4.1. imbalanced-learn 0.11.0. importlib-metadata 6.8.0. importlib-resources 6.1.0. incremental 22.10.0. inflection 0.5.1. iniconfig 2.0.0. intake 0.7.0. intervaltree 3.1.0. ipykernel 6.25.2. ipython 8.16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsdangerous 2.1.2. jaraco.classes 3.3.0. jedi 0.18.1. jeepney 0.8,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:5946,security,iso,isoduration,5946,. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. gmpy2 2.1.2. greenlet 3.0.0. h5py 3.9.0. holoviews 1.17.1. huggingface-hub 0.17.3. humanfriendly 10.0. hvplot 0.8.4. hyperlink 21.0.0. idna 3.4. igraph 0.10.4. imagecodecs 2023.1.23. imageio 2.31.1. imagesize 1.4.1. imbalanced-learn 0.11.0. importlib-metadata 6.8.0. importlib-resources 6.1.0. incremental 22.10.0. inflection 0.5.1. iniconfig 2.0.0. intake 0.7.0. intervaltree 3.1.0. ipykernel 6.25.2. ipython 8.16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsdangerous 2.1.2. jaraco.classes 3.3.0. jedi 0.18.1. jeepney 0.8.0. jellyfish 1.0.1. Jinja2 3.1.2. jmespath 1.0.1. joblib 1.3.2. json5 0.9.14. jsonpatch 1.33. jsonpointer 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1.0.0. jupyter_client 8.3.1. jupyter-console 6.6.3. jupyter_core 5.3.2. jupyter-events 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. MarkupSafe 2.1.3. matplotlib 3.8.0. matplotlib-inline 0.1.6. mccabe 0.7.0. mdit-py-plugins 0.4.0. mdurl 0.1.0. mistune 3.0.1. mkl-service 2.4.0. more-itertools 10.1.0. mpmath 1.3.0. msgpac,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:5967,security,iso,isort,5967,2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. gmpy2 2.1.2. greenlet 3.0.0. h5py 3.9.0. holoviews 1.17.1. huggingface-hub 0.17.3. humanfriendly 10.0. hvplot 0.8.4. hyperlink 21.0.0. idna 3.4. igraph 0.10.4. imagecodecs 2023.1.23. imageio 2.31.1. imagesize 1.4.1. imbalanced-learn 0.11.0. importlib-metadata 6.8.0. importlib-resources 6.1.0. incremental 22.10.0. inflection 0.5.1. iniconfig 2.0.0. intake 0.7.0. intervaltree 3.1.0. ipykernel 6.25.2. ipython 8.16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsdangerous 2.1.2. jaraco.classes 3.3.0. jedi 0.18.1. jeepney 0.8.0. jellyfish 1.0.1. Jinja2 3.1.2. jmespath 1.0.1. joblib 1.3.2. json5 0.9.14. jsonpatch 1.33. jsonpointer 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1.0.0. jupyter_client 8.3.1. jupyter-console 6.6.3. jupyter_core 5.3.2. jupyter-events 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. MarkupSafe 2.1.3. matplotlib 3.8.0. matplotlib-inline 0.1.6. mccabe 0.7.0. mdit-py-plugins 0.4.0. mdurl 0.1.0. mistune 3.0.1. mkl-service 2.4.0. more-itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:6691,security,lock,locket,6691, 1.4.1. imbalanced-learn 0.11.0. importlib-metadata 6.8.0. importlib-resources 6.1.0. incremental 22.10.0. inflection 0.5.1. iniconfig 2.0.0. intake 0.7.0. intervaltree 3.1.0. ipykernel 6.25.2. ipython 8.16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsdangerous 2.1.2. jaraco.classes 3.3.0. jedi 0.18.1. jeepney 0.8.0. jellyfish 1.0.1. Jinja2 3.1.2. jmespath 1.0.1. joblib 1.3.2. json5 0.9.14. jsonpatch 1.33. jsonpointer 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1.0.0. jupyter_client 8.3.1. jupyter-console 6.6.3. jupyter_core 5.3.2. jupyter-events 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. MarkupSafe 2.1.3. matplotlib 3.8.0. matplotlib-inline 0.1.6. mccabe 0.7.0. mdit-py-plugins 0.4.0. mdurl 0.1.0. mistune 3.0.1. mkl-service 2.4.0. more-itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. packaging 23.2. pandas 2.1.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. p,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:7102,security,updat,updater,7102,Jinja2 3.1.2. jmespath 1.0.1. joblib 1.3.2. json5 0.9.14. jsonpatch 1.33. jsonpointer 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1.0.0. jupyter_client 8.3.1. jupyter-console 6.6.3. jupyter_core 5.3.2. jupyter-events 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. MarkupSafe 2.1.3. matplotlib 3.8.0. matplotlib-inline 0.1.6. mccabe 0.7.0. mdit-py-plugins 0.4.0. mdurl 0.1.0. mistune 3.0.1. mkl-service 2.4.0. more-itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. packaging 23.2. pandas 2.1.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:7186,security,network,networkx,7186,r 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1.0.0. jupyter_client 8.3.1. jupyter-console 6.6.3. jupyter_core 5.3.2. jupyter-events 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. MarkupSafe 2.1.3. matplotlib 3.8.0. matplotlib-inline 0.1.6. mccabe 0.7.0. mdit-py-plugins 0.4.0. mdurl 0.1.0. mistune 3.0.1. mkl-service 2.4.0. more-itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. packaging 23.2. pandas 2.1.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1. Pygments 2.16.1. PyJWT 2.8.0. pylint 2.17.5. pylint-venv 3.0.2. pyls-spyder 0.4.0. ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:8364,security,log,logger,8364,.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1. Pygments 2.16.1. PyJWT 2.8.0. pylint 2.17.5. pylint-venv 3.0.2. pyls-spyder 0.4.0. pynndescent 0.5.10. pyodbc 4.0.39. pyOpenSSL 23.2.0. pyparsing 3.1.1. PyQt5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:8810,security,validat,validator,8810,ess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1. Pygments 2.16.1. PyJWT 2.8.0. pylint 2.17.5. pylint-venv 3.0.2. pyls-spyder 0.4.0. pynndescent 0.5.10. pyodbc 4.0.39. pyOpenSSL 23.2.0. pyparsing 3.1.1. PyQt5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:8835,security,validat,validator,8835,re-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1. Pygments 2.16.1. PyJWT 2.8.0. pylint 2.17.5. pylint-venv 3.0.2. pyls-spyder 0.4.0. pynndescent 0.5.10. pyodbc 4.0.39. pyOpenSSL 23.2.0. pyparsing 3.1.1. PyQt5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:9264,security,ident,identity,9264,p 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.2. tblib 2.0.0. tenacity 8.2.3. terminado 0.17.1. text-unidecode 1.3. textdistance 4.5.0. texttable 1.7.0. threadpoolctl 3.2.0. three-merge 0.1.1. throttler 1.2.2. tifffile 2023.4.12. tinycss2 1.2.1. tldextract 3.6.0. tokenizers 0.14.0. toml 0.10.2. tomli 2.0.1. tomlkit 0.12.1. toolz 0.12.0. toposort 1.10. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. transformers 4.34.0. truststore 0.8.0. Twisted 22.10.0. types-python-dateu,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:9281,security,session,session-info,9281,1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.2. tblib 2.0.0. tenacity 8.2.3. terminado 0.17.1. text-unidecode 1.3. textdistance 4.5.0. texttable 1.7.0. threadpoolctl 3.2.0. three-merge 0.1.1. throttler 1.2.2. tifffile 2023.4.12. tinycss2 1.2.1. tldextract 3.6.0. tokenizers 0.14.0. toml 0.10.2. tomli 2.0.1. tomlkit 0.12.1. toolz 0.12.0. toposort 1.10. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. transformers 4.34.0. truststore 0.8.0. Twisted 22.10.0. types-python-dateutil 2.8.19.14. typi,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:10058,security,token,tokenizers,10058,3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.2. tblib 2.0.0. tenacity 8.2.3. terminado 0.17.1. text-unidecode 1.3. textdistance 4.5.0. texttable 1.7.0. threadpoolctl 3.2.0. three-merge 0.1.1. throttler 1.2.2. tifffile 2023.4.12. tinycss2 1.2.1. tldextract 3.6.0. tokenizers 0.14.0. toml 0.10.2. tomli 2.0.1. tomlkit 0.12.1. toolz 0.12.0. toposort 1.10. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. transformers 4.34.0. truststore 0.8.0. Twisted 22.10.0. types-python-dateutil 2.8.19.14. typing_extensions 4.8.0. typing-utils 0.1.0. tzdata 2023.3. uc-micro-py 1.0.1. ujson 5.8.0. umap-learn 0.5.4. uri-template 1.3.0. urllib3 1.26.15. virtualenv 20.24.5. w3lib 2.1.2. watchdog 3.0.0. wcwidth 0.2.8. webcolors 1.13. webencodings 0.5.1. websocket-client 1.6.4. Werkzeug 3.0.0. whatthepatch 1.0.5. wheel 0.38.4. widgetsnbextension 4.0.9. wrapt 1.15.0. wurlitzer 3.0.3. xarray 2023.9.0. xxhash 3.4.1. xyzservices 2023.10.0. yapf 0.24.0. yarl 1.9.2. yte 1.5.1. zict 3.0.0. zipp 3.17.0. zope.interface 6.1. zstandard 0.21.0. ```. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:10215,security,trust,truststore,10215,3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.2. tblib 2.0.0. tenacity 8.2.3. terminado 0.17.1. text-unidecode 1.3. textdistance 4.5.0. texttable 1.7.0. threadpoolctl 3.2.0. three-merge 0.1.1. throttler 1.2.2. tifffile 2023.4.12. tinycss2 1.2.1. tldextract 3.6.0. tokenizers 0.14.0. toml 0.10.2. tomli 2.0.1. tomlkit 0.12.1. toolz 0.12.0. toposort 1.10. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. transformers 4.34.0. truststore 0.8.0. Twisted 22.10.0. types-python-dateutil 2.8.19.14. typing_extensions 4.8.0. typing-utils 0.1.0. tzdata 2023.3. uc-micro-py 1.0.1. ujson 5.8.0. umap-learn 0.5.4. uri-template 1.3.0. urllib3 1.26.15. virtualenv 20.24.5. w3lib 2.1.2. watchdog 3.0.0. wcwidth 0.2.8. webcolors 1.13. webencodings 0.5.1. websocket-client 1.6.4. Werkzeug 3.0.0. whatthepatch 1.0.5. wheel 0.38.4. widgetsnbextension 4.0.9. wrapt 1.15.0. wurlitzer 3.0.3. xarray 2023.9.0. xxhash 3.4.1. xyzservices 2023.10.0. yapf 0.24.0. yarl 1.9.2. yte 1.5.1. zict 3.0.0. zipp 3.17.0. zope.interface 6.1. zstandard 0.21.0. ```. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:659,testability,Trace,Traceback,659,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:941,testability,log,log,941,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1658,testability,unit,units,1658,"aceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 2940 linewidth=linewidth,. 2941 inner=inner,. 2942 density_norm=density_norm,. 2943 common_norm=common_norm,. 2944 kde_kws=kde_kws,. 2945 inner_kws=inner_kws,. 2946 plot_kws=plot_kws,. 2947 ). 2949 elif kind == ""boxen"":. 2951 plot_kws = kwargs.copy(). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:1153, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_kws, plot_kws). 11",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:3945,testability,Automat,Automat,3945,"er._configure_legend(self, ax, func, common_kws, semantic_kws). 418 if show_legend:. 419 self.add_legend_data(ax, func, common_kws, semantic_kws=semantic_kws). --> 420 handles, _ = ax.get_legend_handles_labels(). 421 if handles:. 422 ax.legend(title=self.legend_title). AttributeError: 'NoneType' object has no attribute 'get_legend_handles_labels'. ```. ### Versions. <details>. ```. Package Version. ----------------------------- ---------------. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aiosignal 1.3.1. alabaster 0.7.13. anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.1",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:4705,testability,verif,verify,4705,irs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-package-handling 2.2.0. conda_package_streaming 0.9.0. conda-repo-cli 1.0.75. conda-token 0.4.0. conda-verify 3.4.2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. gmpy2 2.1.2. greenlet 3.0.0. h5py 3.9.0. holoviews 1.17.1. huggingface-hub 0.17.3. humanfriendly 10.0. hvplot 0.8.4. hyperlink 21.0.0. idna 3.4. igraph 0.10.4. imagecodecs 2023.1.23. imageio 2.31.1. imagesize 1.4.1. imbala,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:5763,testability,resourc,resources,5763,ntly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. gmpy2 2.1.2. greenlet 3.0.0. h5py 3.9.0. holoviews 1.17.1. huggingface-hub 0.17.3. humanfriendly 10.0. hvplot 0.8.4. hyperlink 21.0.0. idna 3.4. igraph 0.10.4. imagecodecs 2023.1.23. imageio 2.31.1. imagesize 1.4.1. imbalanced-learn 0.11.0. importlib-metadata 6.8.0. importlib-resources 6.1.0. incremental 22.10.0. inflection 0.5.1. iniconfig 2.0.0. intake 0.7.0. intervaltree 3.1.0. ipykernel 6.25.2. ipython 8.16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsdangerous 2.1.2. jaraco.classes 3.3.0. jedi 0.18.1. jeepney 0.8.0. jellyfish 1.0.1. Jinja2 3.1.2. jmespath 1.0.1. joblib 1.3.2. json5 0.9.14. jsonpatch 1.33. jsonpointer 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1.0.0. jupyter_client 8.3.1. jupyter-console 6.6.3. jupyter_core 5.3.2. jupyter-events 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. Mark,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:8176,testability,spy,spyder,8176,1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. packaging 23.2. pandas 2.1.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1. Pygments 2.16.1. PyJWT 2.8.0. pylint 2.17.5. pylint-venv 3.0.2. pyls-spyder 0.4.0. pynndescent 0.5.10. pyodbc 4.0.39. pyOpenSSL 23.2.0. pyparsing 3.1.1. PyQt5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. sc,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:8364,testability,log,logger,8364,.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1. Pygments 2.16.1. PyJWT 2.8.0. pylint 2.17.5. pylint-venv 3.0.2. pyls-spyder 0.4.0. pynndescent 0.5.10. pyodbc 4.0.39. pyOpenSSL 23.2.0. pyparsing 3.1.1. PyQt5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap ,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:9666,testability,spy,spyder,9666, queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.2. tblib 2.0.0. tenacity 8.2.3. terminado 0.17.1. text-unidecode 1.3. textdistance 4.5.0. texttable 1.7.0. threadpoolctl 3.2.0. three-merge 0.1.1. throttler 1.2.2. tifffile 2023.4.12. tinycss2 1.2.1. tldextract 3.6.0. tokenizers 0.14.0. toml 0.10.2. tomli 2.0.1. tomlkit 0.12.1. toolz 0.12.0. toposort 1.10. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. transformers 4.34.0. truststore 0.8.0. Twisted 22.10.0. types-python-dateutil 2.8.19.14. typing_extensions 4.8.0. typing-utils 0.1.0. tzdata 2023.3. uc-micro-py 1.0.1. ujson 5.8.0. umap-learn 0.5.4. uri-template 1.3.0. urllib3 1.26.15. virtualenv 20.24.5. w3lib 2.1.2. watchdog 3.0.0. wcwidth 0.2.8. webcolors 1.13. webencodings 0.5.1. websocket-client 1.6.4. Werkzeug 3.0.0. whatthepatch 1.0.5. wheel 0.38.4. widgetsnbextension 4.0.9. wrapt 1.15.0. wurlitzer 3.0.3. xarray 2,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:9680,testability,spy,spyder-kernels,9680,eferencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.2. tblib 2.0.0. tenacity 8.2.3. terminado 0.17.1. text-unidecode 1.3. textdistance 4.5.0. texttable 1.7.0. threadpoolctl 3.2.0. three-merge 0.1.1. throttler 1.2.2. tifffile 2023.4.12. tinycss2 1.2.1. tldextract 3.6.0. tokenizers 0.14.0. toml 0.10.2. tomli 2.0.1. tomlkit 0.12.1. toolz 0.12.0. toposort 1.10. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. transformers 4.34.0. truststore 0.8.0. Twisted 22.10.0. types-python-dateutil 2.8.19.14. typing_extensions 4.8.0. typing-utils 0.1.0. tzdata 2023.3. uc-micro-py 1.0.1. ujson 5.8.0. umap-learn 0.5.4. uri-template 1.3.0. urllib3 1.26.15. virtualenv 20.24.5. w3lib 2.1.2. watchdog 3.0.0. wcwidth 0.2.8. webcolors 1.13. webencodings 0.5.1. websocket-client 1.6.4. Werkzeug 3.0.0. whatthepatch 1.0.5. wheel 0.38.4. widgetsnbextension 4.0.9. wrapt 1.15.0. wurlitzer 3.0.3. xarray 2023.9.0. xxhash 3.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:46,usability,error,error,46,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:183,usability,confirm,confirmed,183,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:266,usability,confirm,confirmed,266,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:383,usability,error,error,383,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:396,usability,Minim,Minimal,396,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:544,usability,Error,Error,544,"Plotting with using scanpy.pl gives attribute error. ; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [ ] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Plotting with scanpy.pl gives attribute error. . ### Minimal code sample. ```python. sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). ```. ### Error output. ```pytb. ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_ma",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:1640,usability,error,errorbar,1640,"AttributeError Traceback (most recent call last). Cell In[47], line 1. ----> 1 sc.pl.violin(adata, [""n_genes_by_counts"", ""total_counts"", ""pct_counts_mt""], jitter=0.4, multi_panel=True). File ~/anaconda3/lib/python3.11/site-packages/scanpy/plotting/_anndata.py:795, in violin(adata, keys, groupby, log, use_raw, stripplot, jitter, size, layer, scale, order, multi_panel, xlabel, ylabel, rotation, show, save, ax, **kwds). 790 if multi_panel and groupby is None and len(ys) == 1:. 791 # This is a quick and dirty way for adapting scales across several. 792 # keys if groupby is None. 793 y = ys[0]. --> 795 g = sns.catplot(. 796 y=y,. 797 data=obs_tidy,. 798 kind=""violin"",. 799 scale=scale,. 800 col=x,. 801 col_order=keys,. 802 sharey=False,. 803 order=keys,. 804 cut=0,. 805 inner=None,. 806 **kwds,. 807 ). 809 if stripplot:. 810 grouped_df = obs_tidy.groupby(x). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:2932, in catplot(data, x, y, hue, row, col, kind, estimator, errorbar, n_boot, units, seed, order, hue_order, row_order, col_order, col_wrap, height, aspect, log_scale, native_scale, formatter, orient, color, palette, hue_norm, legend, legend_out, sharex, sharey, margin_titles, facet_kws, ci, **kwargs). 2929 linecolor = plot_kws.pop(""linecolor"", ""auto""). 2930 linecolor = p._complement_color(linecolor, color, p._hue_map). -> 2932 p.plot_violins(. 2933 width=width,. 2934 dodge=dodge,. 2935 gap=gap,. 2936 split=split,. 2937 color=color,. 2938 fill=fill,. 2939 linecolor=linecolor,. 2940 linewidth=linewidth,. 2941 inner=inner,. 2942 density_norm=density_norm,. 2943 common_norm=common_norm,. 2944 kde_kws=kde_kws,. 2945 inner_kws=inner_kws,. 2946 plot_kws=plot_kws,. 2947 ). 2949 elif kind == ""boxen"":. 2951 plot_kws = kwargs.copy(). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:1153, in _CategoricalPlotter.plot_violins(self, width, dodge, gap, split, color, fill, linecolor, linewidth, inner, density_norm, common_norm, kde_kws, inner_k",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:3600,usability,navigat,navigator,3600,"ity_norm, common_norm, kde_kws, inner_kws, plot_kws). 1151 legend_artist = _get_patch_legend_artist(fill). 1152 common_kws = {**plot_kws, ""linewidth"": linewidth, ""edgecolor"": linecolor}. -> 1153 self._configure_legend(ax, legend_artist, common_kws). File ~/anaconda3/lib/python3.11/site-packages/seaborn/categorical.py:420, in _CategoricalPlotter._configure_legend(self, ax, func, common_kws, semantic_kws). 418 if show_legend:. 419 self.add_legend_data(ax, func, common_kws, semantic_kws=semantic_kws). --> 420 handles, _ = ax.get_legend_handles_labels(). 421 if handles:. 422 ax.legend(title=self.legend_title). AttributeError: 'NoneType' object has no attribute 'get_legend_handles_labels'. ```. ### Versions. <details>. ```. Package Version. ----------------------------- ---------------. aiobotocore 2.6.0. aiohttp 3.8.6. aioitertools 0.11.0. aiosignal 1.3.1. alabaster 0.7.13. anaconda-anon-usage 0.4.2. anaconda-catalogs 0.2.0. anaconda-client 1.12.0. anaconda-cloud-auth 0.1.4. anaconda-navigator 2.5.0. anaconda-project 0.11.1. anndata 0.10.1. anndata 0.10.0rc1. annoy 1.17.2. anyio 4.0.0. appdirs 1.4.4. argon2-cffi 23.1.0. argon2-cffi-bindings 21.2.0. array-api-compat 1.4. array-api-compat 1.4. arrow 1.3.0. astroid 2.15.7. astropy 5.3.4. asttokens 2.4.0. async-lru 2.0.4. async-timeout 4.0.3. atomicwrites 1.4.1. attrs 23.1.0. Automat 22.10.0. autopep8 2.0.4. Babel 2.12.1. backcall 0.2.0. backports.functools-lru-cache 1.6.5. backports.tempfile 1.0. backports.weakref 1.0.post1. bcrypt 4.0.1. beautifulsoup4 4.12.2. binaryornot 0.4.4. black 23.9.1. bleach 6.1.0. blinker 1.6.3. bokeh 3.2.2. boltons 23.0.0. botocore 1.31.17. brotlipy 0.7.0. cached-property 1.5.2. celltypist 1.6.1. certifi 2023.7.22. cffi 1.16.0. chardet 5.2.0. charset-normalizer 3.3.0. click 8.1.7. cloudpickle 2.2.1. clyent 1.2.2. colorama 0.4.6. colorcet 3.0.1. comm 0.1.4. conda 23.9.0. conda-build 3.27.0. conda-content-trust 0+unknown. conda_index 0.2.3. conda-libmamba-solver 23.9.1. conda-pack 0.6.0. conda-pac",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:5713,usability,learn,learn,5713,2. ConfigArgParse 1.7. connection-pool 0.0.3. constantly 15.1.0. contourpy 1.1.1. cookiecutter 2.4.0. cryptography 40.0.1. cssselect 1.2.0. cycler 0.12.1. cytoolz 0.12.2. daal4py 2023.2.1. dask 2023.9.3. dataclasses 0.8. datasets 2.14.5. datashader 0.15.2. datashape 0.5.4. datrie 0.8.2. debugpy 1.8.0. decorator 5.1.1. decoupler 1.5.0. defusedxml 0.7.1. diff-match-patch 20230430. dill 0.3.7. distlib 0.3.7. distributed 2023.9.3. docopt 0.6.2. docstring-to-markdown 0.12. docutils 0.20.1. dpath 2.1.6. entrypoints 0.4. et-xmlfile 1.1.0. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema 2.18.1. filelock 3.12.4. flake8 6.0.0. Flask 3.0.0. fonttools 4.43.1. fqdn 1.5.1. frozenlist 1.4.0. fsspec 2023.6.0. future 0.18.3. gensim 4.3.2. gitdb 4.0.10. GitPython 3.1.36. gmpy2 2.1.2. greenlet 3.0.0. h5py 3.9.0. holoviews 1.17.1. huggingface-hub 0.17.3. humanfriendly 10.0. hvplot 0.8.4. hyperlink 21.0.0. idna 3.4. igraph 0.10.4. imagecodecs 2023.1.23. imageio 2.31.1. imagesize 1.4.1. imbalanced-learn 0.11.0. importlib-metadata 6.8.0. importlib-resources 6.1.0. incremental 22.10.0. inflection 0.5.1. iniconfig 2.0.0. intake 0.7.0. intervaltree 3.1.0. ipykernel 6.25.2. ipython 8.16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsdangerous 2.1.2. jaraco.classes 3.3.0. jedi 0.18.1. jeepney 0.8.0. jellyfish 1.0.1. Jinja2 3.1.2. jmespath 1.0.1. joblib 1.3.2. json5 0.9.14. jsonpatch 1.33. jsonpointer 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1.0.0. jupyter_client 8.3.1. jupyter-console 6.6.3. jupyter_core 5.3.2. jupyter-events 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:6509,usability,widget,widgets,6509,. h5py 3.9.0. holoviews 1.17.1. huggingface-hub 0.17.3. humanfriendly 10.0. hvplot 0.8.4. hyperlink 21.0.0. idna 3.4. igraph 0.10.4. imagecodecs 2023.1.23. imageio 2.31.1. imagesize 1.4.1. imbalanced-learn 0.11.0. importlib-metadata 6.8.0. importlib-resources 6.1.0. incremental 22.10.0. inflection 0.5.1. iniconfig 2.0.0. intake 0.7.0. intervaltree 3.1.0. ipykernel 6.25.2. ipython 8.16.1. ipython-genutils 0.2.0. ipywidgets 8.1.1. isoduration 20.11.0. isort 5.12.0. itemadapter 0.8.0. itemloaders 1.1.0. itsdangerous 2.1.2. jaraco.classes 3.3.0. jedi 0.18.1. jeepney 0.8.0. jellyfish 1.0.1. Jinja2 3.1.2. jmespath 1.0.1. joblib 1.3.2. json5 0.9.14. jsonpatch 1.33. jsonpointer 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1.0.0. jupyter_client 8.3.1. jupyter-console 6.6.3. jupyter_core 5.3.2. jupyter-events 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. MarkupSafe 2.1.3. matplotlib 3.8.0. matplotlib-inline 0.1.6. mccabe 0.7.0. mdit-py-plugins 0.4.0. mdurl 0.1.0. mistune 3.0.1. mkl-service 2.4.0. more-itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. packaging 23.2. pandas 2.1.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:7092,usability,navigat,navigator-updater,7092,0.1. Jinja2 3.1.2. jmespath 1.0.1. joblib 1.3.2. json5 0.9.14. jsonpatch 1.33. jsonpointer 2.4. jsonschema 4.19.1. jsonschema-specifications 2023.7.1. jupyter 1.0.0. jupyter_client 8.3.1. jupyter-console 6.6.3. jupyter_core 5.3.2. jupyter-events 0.7.0. jupyter-lsp 2.2.0. jupyter_server 2.7.3. jupyter_server_terminals 0.4.4. jupyterlab 4.0.6. jupyterlab-pygments 0.2.2. jupyterlab_server 2.25.0. jupyterlab-widgets 3.0.9. keyring 24.2.0. kiwisolver 1.4.5. lazy_loader 0.3. lazy-object-proxy 1.9.0. leidenalg 0.9.1. libarchive-c 5.0. libmambapy 1.5.1. linkify-it-py 2.0.0. llvmlite 0.40.1. locket 1.0.0. lxml 4.9.2. lz4 4.3.2. Markdown 3.5. markdown-it-py 3.0.0. MarkupSafe 2.1.3. matplotlib 3.8.0. matplotlib-inline 0.1.6. mccabe 0.7.0. mdit-py-plugins 0.4.0. mdurl 0.1.0. mistune 3.0.1. mkl-service 2.4.0. more-itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. packaging 23.2. pandas 2.1.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:7763,usability,tool,toolkit,7763,kupSafe 2.1.3. matplotlib 3.8.0. matplotlib-inline 0.1.6. mccabe 0.7.0. mdit-py-plugins 0.4.0. mdurl 0.1.0. mistune 3.0.1. mkl-service 2.4.0. more-itertools 10.1.0. mpmath 1.3.0. msgpack 1.0.6. multidict 6.0.4. multipledispatch 0.6.0. multiprocess 0.70.15. munkres 1.1.4. mypy-extensions 1.0.0. natsort 8.4.0. natsort 8.4.0. navigator-updater 0.4.0. nbclient 0.8.0. nbconvert 7.9.2. nbformat 5.9.2. nest-asyncio 1.5.6. networkx 3.1. nltk 3.8.1. notebook 7.0.4. notebook_shim 0.2.3. numba 0.57.1. numexpr 2.8.7. numpy 1.24.4. numpydoc 1.5.0. openpyxl 3.1.2. overrides 7.4.0. packaging 23.2. pandas 2.1.1. pandocfilters 1.5.0. panel 1.2.3. parallel-fastq-dump 0.6.7. param 1.13.0. parsel 1.8.1. parso 0.8.3. partd 1.4.1. pathspec 0.11.2. patsy 0.5.3. pep8 1.7.1. pexpect 4.8.0. pickleshare 0.7.5. Pillow 10.0.1. pip 23.2.1. pkce 1.0.3. pkginfo 1.9.6. pkgutil_resolve_name 1.3.10. plac 1.3.5. platformdirs 3.11.0. plotly 5.17.0. pluggy 1.3.0. ply 3.11. pooch 1.7.0. prometheus-client 0.17.1. prompt-toolkit 3.0.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1. Pygments 2.16.1. PyJWT 2.8.0. pylint 2.17.5. pylint-venv 3.0.2. pyls-spyder 0.4.0. pynndescent 0.5.10. pyodbc 4.0.39. pyOpenSSL 23.2.0. pyparsing 3.1.1. PyQt5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. reques,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:8770,usability,tool,toolbelt,8770,.39. Protego 0.3.0. psutil 5.9.5. ptyprocess 0.7.0. PuLP 2.7.0. pure-eval 0.2.2. py-cpuinfo 9.0.0. pyarrow 13.0.0. pyasn1 0.5.0. pyasn1-modules 0.3.0. pycodestyle 2.10.0. pycosat 0.6.6. pycparser 2.21. pyct 0.4.6. pycurl 7.45.1. pydantic 1.10.13. pydeseq2 0.4.1. PyDispatcher 2.0.5. pydocstyle 6.3.0. pyerfa 2.0.0.3. pyflakes 3.0.1. Pygments 2.16.1. PyJWT 2.8.0. pylint 2.17.5. pylint-venv 3.0.2. pyls-spyder 0.4.0. pynndescent 0.5.10. pyodbc 4.0.39. pyOpenSSL 23.2.0. pyparsing 3.1.1. PyQt5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:9071,usability,learn,learn,9071, pyerfa 2.0.0.3. pyflakes 3.0.1. Pygments 2.16.1. PyJWT 2.8.0. pylint 2.17.5. pylint-venv 3.0.2. pyls-spyder 0.4.0. pynndescent 0.5.10. pyodbc 4.0.39. pyOpenSSL 23.2.0. pyparsing 3.1.1. PyQt5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.2. tblib 2.0.0. tenacity 8.2.3. terminado 0.17.1. text-unidecode 1.3. textdistance 4.5.0. texttable 1.7.0. threadpoolctl 3.2.0. three-merge 0.1.1. throttler 1.2.2. tifffile 2023.4.12. tinycss2 1.2.1. tldextract 3.6.0. tokenizers 0.14.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:9091,usability,learn,learn-intelex,9091,s 3.0.1. Pygments 2.16.1. PyJWT 2.8.0. pylint 2.17.5. pylint-venv 3.0.2. pyls-spyder 0.4.0. pynndescent 0.5.10. pyodbc 4.0.39. pyOpenSSL 23.2.0. pyparsing 3.1.1. PyQt5-sip 12.11.0. PySocks 1.7.1. pytest 7.4.2. python-dateutil 2.8.2. python-dotenv 1.0.0. python-json-logger 2.0.7. python-lsp-black 1.3.0. python-lsp-jsonrpc 1.1.2. python-lsp-server 1.7.2. python-slugify 8.0.1. pytoolconfig 1.2.5. pytz 2023.3.post1. pyviz_comms 3.0.0. PyWavelets 1.4.1. pyxdg 0.28. PyYAML 6.0.1. pyzmq 25.1.1. QDarkStyle 3.1. qstylizer 0.2.2. QtAwesome 1.2.3. qtconsole 5.4.4. QtPy 2.4.0. queuelib 1.6.2. referencing 0.30.2. regex 2023.10.3. requests 2.31.0. requests-file 1.5.1. requests-toolbelt 1.0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.2. tblib 2.0.0. tenacity 8.2.3. terminado 0.17.1. text-unidecode 1.3. textdistance 4.5.0. texttable 1.7.0. threadpoolctl 3.2.0. three-merge 0.1.1. throttler 1.2.2. tifffile 2023.4.12. tinycss2 1.2.1. tldextract 3.6.0. tokenizers 0.14.0. toml 0.10.2. tomli 2.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:9778,usability,stop,stopit,9778,0.0. reretry 0.11.8. rfc3339-validator 0.1.4. rfc3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.2. tblib 2.0.0. tenacity 8.2.3. terminado 0.17.1. text-unidecode 1.3. textdistance 4.5.0. texttable 1.7.0. threadpoolctl 3.2.0. three-merge 0.1.1. throttler 1.2.2. tifffile 2023.4.12. tinycss2 1.2.1. tldextract 3.6.0. tokenizers 0.14.0. toml 0.10.2. tomli 2.0.1. tomlkit 0.12.1. toolz 0.12.0. toposort 1.10. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. transformers 4.34.0. truststore 0.8.0. Twisted 22.10.0. types-python-dateutil 2.8.19.14. typing_extensions 4.8.0. typing-utils 0.1.0. tzdata 2023.3. uc-micro-py 1.0.1. ujson 5.8.0. umap-learn 0.5.4. uri-template 1.3.0. urllib3 1.26.15. virtualenv 20.24.5. w3lib 2.1.2. watchdog 3.0.0. wcwidth 0.2.8. webcolors 1.13. webencodings 0.5.1. websocket-client 1.6.4. Werkzeug 3.0.0. whatthepatch 1.0.5. wheel 0.38.4. widgetsnbextension 4.0.9. wrapt 1.15.0. wurlitzer 3.0.3. xarray 2023.9.0. xxhash 3.4.1. xyzservices 2023.10.0. yapf 0.24.0. yarl 1.9.2. yte 1.5.1. zict 3.0.0. zipp 3.17.0. zope.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:10119,usability,tool,toolz,10119,3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.2. tblib 2.0.0. tenacity 8.2.3. terminado 0.17.1. text-unidecode 1.3. textdistance 4.5.0. texttable 1.7.0. threadpoolctl 3.2.0. three-merge 0.1.1. throttler 1.2.2. tifffile 2023.4.12. tinycss2 1.2.1. tldextract 3.6.0. tokenizers 0.14.0. toml 0.10.2. tomli 2.0.1. tomlkit 0.12.1. toolz 0.12.0. toposort 1.10. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. transformers 4.34.0. truststore 0.8.0. Twisted 22.10.0. types-python-dateutil 2.8.19.14. typing_extensions 4.8.0. typing-utils 0.1.0. tzdata 2023.3. uc-micro-py 1.0.1. ujson 5.8.0. umap-learn 0.5.4. uri-template 1.3.0. urllib3 1.26.15. virtualenv 20.24.5. w3lib 2.1.2. watchdog 3.0.0. wcwidth 0.2.8. webcolors 1.13. webencodings 0.5.1. websocket-client 1.6.4. Werkzeug 3.0.0. whatthepatch 1.0.5. wheel 0.38.4. widgetsnbextension 4.0.9. wrapt 1.15.0. wurlitzer 3.0.3. xarray 2023.9.0. xxhash 3.4.1. xyzservices 2023.10.0. yapf 0.24.0. yarl 1.9.2. yte 1.5.1. zict 3.0.0. zipp 3.17.0. zope.interface 6.1. zstandard 0.21.0. ```. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:10380,usability,learn,learn,10380,3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.2. tblib 2.0.0. tenacity 8.2.3. terminado 0.17.1. text-unidecode 1.3. textdistance 4.5.0. texttable 1.7.0. threadpoolctl 3.2.0. three-merge 0.1.1. throttler 1.2.2. tifffile 2023.4.12. tinycss2 1.2.1. tldextract 3.6.0. tokenizers 0.14.0. toml 0.10.2. tomli 2.0.1. tomlkit 0.12.1. toolz 0.12.0. toposort 1.10. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. transformers 4.34.0. truststore 0.8.0. Twisted 22.10.0. types-python-dateutil 2.8.19.14. typing_extensions 4.8.0. typing-utils 0.1.0. tzdata 2023.3. uc-micro-py 1.0.1. ujson 5.8.0. umap-learn 0.5.4. uri-template 1.3.0. urllib3 1.26.15. virtualenv 20.24.5. w3lib 2.1.2. watchdog 3.0.0. wcwidth 0.2.8. webcolors 1.13. webencodings 0.5.1. websocket-client 1.6.4. Werkzeug 3.0.0. whatthepatch 1.0.5. wheel 0.38.4. widgetsnbextension 4.0.9. wrapt 1.15.0. wurlitzer 3.0.3. xarray 2023.9.0. xxhash 3.4.1. xyzservices 2023.10.0. yapf 0.24.0. yarl 1.9.2. yte 1.5.1. zict 3.0.0. zipp 3.17.0. zope.interface 6.1. zstandard 0.21.0. ```. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2680:10604,usability,widget,widgetsnbextension,10604,3986-validator 0.1.1. rich 13.6.0. rope 1.10.0. rpds-py 0.10.4. Rtree 1.0.1. ruamel.yaml 0.17.35. ruamel.yaml.clib 0.2.7. ruamel-yaml-conda 0.15.80. s3fs 0.5.1. sacremoses 0.0.53. safetensors 0.3.3. scanpy 1.9.5. scikit-image 0.21.0. scikit-learn 1.3.1. scikit-learn-intelex 20230725.122106. scipy 1.11.3. Scrapy 2.11.0. scrublet 0.2.3. scTE 1.0. scTE 1.0. seaborn 0.13.0. SecretStorage 3.3.3. semver 3.0.1. Send2Trash 1.8.2. service-identity 18.1.0. session-info 1.0.0. setuptools 68.0.0. sip 6.6.2. six 1.16.0. smart-open 6.4.0. smmap 5.0.0. snakemake 7.32.3. sniffio 1.3.0. snowballstemmer 2.2.0. sortedcontainers 2.4.0. soupsieve 2.5. Sphinx 7.2.6. sphinxcontrib-applehelp 1.0.7. sphinxcontrib-devhelp 1.0.5. sphinxcontrib-htmlhelp 2.0.4. sphinxcontrib-jsmath 1.0.1. sphinxcontrib-qthelp 1.0.6. sphinxcontrib-serializinghtml 1.1.9. spyder 5.4.3. spyder-kernels 2.4.4. SQLAlchemy 2.0.21. stack-data 0.6.2. statsmodels 0.14.0. stdlib-list 0.8.0. stopit 1.1.2. sympy 1.12. tables 3.9.1. tabulate 0.9.0. TBB 0.2. tblib 2.0.0. tenacity 8.2.3. terminado 0.17.1. text-unidecode 1.3. textdistance 4.5.0. texttable 1.7.0. threadpoolctl 3.2.0. three-merge 0.1.1. throttler 1.2.2. tifffile 2023.4.12. tinycss2 1.2.1. tldextract 3.6.0. tokenizers 0.14.0. toml 0.10.2. tomli 2.0.1. tomlkit 0.12.1. toolz 0.12.0. toposort 1.10. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. transformers 4.34.0. truststore 0.8.0. Twisted 22.10.0. types-python-dateutil 2.8.19.14. typing_extensions 4.8.0. typing-utils 0.1.0. tzdata 2023.3. uc-micro-py 1.0.1. ujson 5.8.0. umap-learn 0.5.4. uri-template 1.3.0. urllib3 1.26.15. virtualenv 20.24.5. w3lib 2.1.2. watchdog 3.0.0. wcwidth 0.2.8. webcolors 1.13. webencodings 0.5.1. websocket-client 1.6.4. Werkzeug 3.0.0. whatthepatch 1.0.5. wheel 0.38.4. widgetsnbextension 4.0.9. wrapt 1.15.0. wurlitzer 3.0.3. xarray 2023.9.0. xxhash 3.4.1. xyzservices 2023.10.0. yapf 0.24.0. yarl 1.9.2. yte 1.5.1. zict 3.0.0. zipp 3.17.0. zope.interface 6.1. zstandard 0.21.0. ```. </details>.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2680
https://github.com/scverse/scanpy/issues/2681:1268,availability,Error,Error,1268,"ional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.3. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.1.3. threadpoolctl 3.1.0. typing_extensions NA. zoneinfo NA. -----. Python 3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]. macOS-<redacted>-arm64-arm-64bit. -----.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:10,deployability,fail,fails,10,"PCA color fails when return_fig = True and annotate_var_explained = True; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:242,deployability,version,version,242,"PCA color fails when return_fig = True and annotate_var_explained = True; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:514,deployability,fail,fails,514,"PCA color fails when return_fig = True and annotate_var_explained = True; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:837,deployability,fail,fail,837,"PCA color fails when return_fig = True and annotate_var_explained = True; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:1355,deployability,modul,module,1355,"anpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.3. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.1.3. threadpoolctl 3.1.0. typing_extensions NA. zoneinfo NA. -----. Python 3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]. macOS-<redacted>-arm64-arm-64bit. -----. Session information updated at 2023-10-11 14:45. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:1516,deployability,Version,Versions,1516,"anpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.3. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.1.3. threadpoolctl 3.1.0. typing_extensions NA. zoneinfo NA. -----. Python 3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]. macOS-<redacted>-arm64-arm-64bit. -----. Session information updated at 2023-10-11 14:45. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:2292,deployability,updat,updated,2292,"anpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.3. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.1.3. threadpoolctl 3.1.0. typing_extensions NA. zoneinfo NA. -----. Python 3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]. macOS-<redacted>-arm64-arm-64bit. -----. Session information updated at 2023-10-11 14:45. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:242,integrability,version,version,242,"PCA color fails when return_fig = True and annotate_var_explained = True; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:1516,integrability,Version,Versions,1516,"anpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.3. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.1.3. threadpoolctl 3.1.0. typing_extensions NA. zoneinfo NA. -----. Python 3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]. macOS-<redacted>-arm64-arm-64bit. -----. Session information updated at 2023-10-11 14:45. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:572,interoperability,Specif,Specifically,572,"PCA color fails when return_fig = True and annotate_var_explained = True; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:1071,interoperability,format,format,1071,"### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.3. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:242,modifiability,version,version,242,"PCA color fails when return_fig = True and annotate_var_explained = True; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:1355,modifiability,modul,module,1355,"anpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.3. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.1.3. threadpoolctl 3.1.0. typing_extensions NA. zoneinfo NA. -----. Python 3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]. macOS-<redacted>-arm64-arm-64bit. -----. Session information updated at 2023-10-11 14:45. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:1516,modifiability,Version,Versions,1516,"anpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.3. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.1.3. threadpoolctl 3.1.0. typing_extensions NA. zoneinfo NA. -----. Python 3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]. macOS-<redacted>-arm64-arm-64bit. -----. Session information updated at 2023-10-11 14:45. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:1901,modifiability,pac,packaging,1901,"anpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.3. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.1.3. threadpoolctl 3.1.0. typing_extensions NA. zoneinfo NA. -----. Python 3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]. macOS-<redacted>-arm64-arm-64bit. -----. Session information updated at 2023-10-11 14:45. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:2158,modifiability,pac,packaged,2158,"anpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.3. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.1.3. threadpoolctl 3.1.0. typing_extensions NA. zoneinfo NA. -----. Python 3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]. macOS-<redacted>-arm64-arm-64bit. -----. Session information updated at 2023-10-11 14:45. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:1268,performance,Error,Error,1268,"ional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.3. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.1.3. threadpoolctl 3.1.0. typing_extensions NA. zoneinfo NA. -----. Python 3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]. macOS-<redacted>-arm64-arm-64bit. -----.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:10,reliability,fail,fails,10,"PCA color fails when return_fig = True and annotate_var_explained = True; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:514,reliability,fail,fails,514,"PCA color fails when return_fig = True and annotate_var_explained = True; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:759,reliability,doe,does,759,"PCA color fails when return_fig = True and annotate_var_explained = True; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:837,reliability,fail,fail,837,"PCA color fails when return_fig = True and annotate_var_explained = True; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:1268,safety,Error,Error,1268,"ional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.3. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.1.3. threadpoolctl 3.1.0. typing_extensions NA. zoneinfo NA. -----. Python 3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]. macOS-<redacted>-arm64-arm-64bit. -----.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:1355,safety,modul,module,1355,"anpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.3. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.1.3. threadpoolctl 3.1.0. typing_extensions NA. zoneinfo NA. -----. Python 3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]. macOS-<redacted>-arm64-arm-64bit. -----. Session information updated at 2023-10-11 14:45. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:2292,safety,updat,updated,2292,"anpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.3. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.1.3. threadpoolctl 3.1.0. typing_extensions NA. zoneinfo NA. -----. Python 3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]. macOS-<redacted>-arm64-arm-64bit. -----. Session information updated at 2023-10-11 14:45. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:2272,security,Session,Session,2272,"anpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.3. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.1.3. threadpoolctl 3.1.0. typing_extensions NA. zoneinfo NA. -----. Python 3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]. macOS-<redacted>-arm64-arm-64bit. -----. Session information updated at 2023-10-11 14:45. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:2292,security,updat,updated,2292,"anpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.3. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.1.3. threadpoolctl 3.1.0. typing_extensions NA. zoneinfo NA. -----. Python 3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]. macOS-<redacted>-arm64-arm-64bit. -----. Session information updated at 2023-10-11 14:45. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:1291,testability,Trace,Traceback,1291,"his bug exists on the master branch of scanpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.3. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.1.3. threadpoolctl 3.1.0. typing_extensions NA. zoneinfo NA. -----. Python 3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]. macOS-<redacted>-arm64-arm-64bit. -----. Session information upda",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:202,usability,confirm,confirmed,202,"PCA color fails when return_fig = True and annotate_var_explained = True; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:285,usability,confirm,confirmed,285,"PCA color fails when return_fig = True and annotate_var_explained = True; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:885,usability,Minim,Minimal,885,"PCA color fails when return_fig = True and annotate_var_explained = True; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [X] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/issues/2681:1268,usability,Error,Error,1268,"ional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? When using `sc.pl.pca` with a combination of:. - Enabled `annotate_var_explained`. - Enabled `return_fig`. - A colored-by column. The plotting function fails because it is trying to set the name on color bars. Specifically, [this loop](https://github.com/scverse/scanpy/blob/master/scanpy/plotting/_tools/scatterplots.py#L893) will encounter both, the actual plot as well as the colorbar. When it does hit the colorbar, it tries to look it up in the `label_dict`, which will fail (those axes are labeled `<colorbar>`). ### Minimal code sample. ```python. import scanpy as sc. import anndata as ad. import pandas as pd. import numpy as np. obs = pd.DataFrame(np.arange(100), . columns=['a'], . index=['cell{}'.format(i) for i in range(100)]). X = np.random.rand(100, 5). adata = ad.AnnData(X=X, obs=obs). sc.tl.pca(adata). sc.pl.pca(adata, color='a', return_fig=True, annotate_var_explained=True). ```. ### Error output. ```pytb. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File "".../scanpy/plotting/_tools/scatterplots.py"", line 894, in pca. ax.set_xlabel(label_dict[ax.xaxis.get_label().get_text()]). KeyError: ''. ```. ### Versions. <details>. ```. -----. anndata 0.8.0. scanpy 1.10.0.dev128+g616d5803. -----. PIL 9.2.0. beta_ufunc NA. binom_ufunc NA. colorama 0.4.6. cycler 0.10.0. cython_runtime NA. dateutil 2.8.2. h5py 3.7.0. hypergeom_ufunc NA. joblib 1.2.0. kiwisolver 1.4.4. llvmlite 0.39.1. matplotlib 3.6.2. mpl_toolkits NA. natsort 8.2.0. nbinom_ufunc NA. ncf_ufunc NA. numba 0.56.3. numpy 1.23.4. packaging 21.3. pandas 1.5.1. pkg_resources NA. pynndescent 0.5.8. pyparsing 3.0.9. pytz 2022.2.1. scipy 1.9.3. session_info 1.0.0. setuptools 65.5.1. six 1.16.0. sklearn 1.1.3. threadpoolctl 3.1.0. typing_extensions NA. zoneinfo NA. -----. Python 3.10.6 | packaged by conda-forge | (main, Aug 22 2022, 20:38:29) [Clang 13.0.1 ]. macOS-<redacted>-arm64-arm-64bit. -----.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2681
https://github.com/scverse/scanpy/pull/2682:141,deployability,integr,integrate,141,"Fix #2681; Checks if current axis is colorbar before trying to set the name, see #2681. This might not be the best solution and does not yet integrate a unit test. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2682
https://github.com/scverse/scanpy/pull/2682:21,energy efficiency,current,current,21,"Fix #2681; Checks if current axis is colorbar before trying to set the name, see #2681. This might not be the best solution and does not yet integrate a unit test. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2682
https://github.com/scverse/scanpy/pull/2682:141,integrability,integr,integrate,141,"Fix #2681; Checks if current axis is colorbar before trying to set the name, see #2681. This might not be the best solution and does not yet integrate a unit test. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2682
https://github.com/scverse/scanpy/pull/2682:141,interoperability,integr,integrate,141,"Fix #2681; Checks if current axis is colorbar before trying to set the name, see #2681. This might not be the best solution and does not yet integrate a unit test. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2682
https://github.com/scverse/scanpy/pull/2682:141,modifiability,integr,integrate,141,"Fix #2681; Checks if current axis is colorbar before trying to set the name, see #2681. This might not be the best solution and does not yet integrate a unit test. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2682
https://github.com/scverse/scanpy/pull/2682:128,reliability,doe,does,128,"Fix #2681; Checks if current axis is colorbar before trying to set the name, see #2681. This might not be the best solution and does not yet integrate a unit test. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2682
https://github.com/scverse/scanpy/pull/2682:141,reliability,integr,integrate,141,"Fix #2681; Checks if current axis is colorbar before trying to set the name, see #2681. This might not be the best solution and does not yet integrate a unit test. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2682
https://github.com/scverse/scanpy/pull/2682:158,safety,test,test,158,"Fix #2681; Checks if current axis is colorbar before trying to set the name, see #2681. This might not be the best solution and does not yet integrate a unit test. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2682
https://github.com/scverse/scanpy/pull/2682:383,safety,review,review,383,"Fix #2681; Checks if current axis is colorbar before trying to set the name, see #2681. This might not be the best solution and does not yet integrate a unit test. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2682
https://github.com/scverse/scanpy/pull/2682:141,security,integr,integrate,141,"Fix #2681; Checks if current axis is colorbar before trying to set the name, see #2681. This might not be the best solution and does not yet integrate a unit test. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2682
https://github.com/scverse/scanpy/pull/2682:141,testability,integr,integrate,141,"Fix #2681; Checks if current axis is colorbar before trying to set the name, see #2681. This might not be the best solution and does not yet integrate a unit test. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2682
https://github.com/scverse/scanpy/pull/2682:153,testability,unit,unit,153,"Fix #2681; Checks if current axis is colorbar before trying to set the name, see #2681. This might not be the best solution and does not yet integrate a unit test. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2682
https://github.com/scverse/scanpy/pull/2682:158,testability,test,test,158,"Fix #2681; Checks if current axis is colorbar before trying to set the name, see #2681. This might not be the best solution and does not yet integrate a unit test. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2682
https://github.com/scverse/scanpy/pull/2682:383,testability,review,review,383,"Fix #2681; Checks if current axis is colorbar before trying to set the name, see #2681. This might not be the best solution and does not yet integrate a unit test. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2682
https://github.com/scverse/scanpy/pull/2682:234,usability,guid,guidelines,234,"Fix #2681; Checks if current axis is colorbar before trying to set the name, see #2681. This might not be the best solution and does not yet integrate a unit test. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2682
https://github.com/scverse/scanpy/pull/2682:265,usability,guid,guide,265,"Fix #2681; Checks if current axis is colorbar before trying to set the name, see #2681. This might not be the best solution and does not yet integrate a unit test. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2682
https://github.com/scverse/scanpy/pull/2682:361,usability,workflow,workflow,361,"Fix #2681; Checks if current axis is colorbar before trying to set the name, see #2681. This might not be the best solution and does not yet integrate a unit test. <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2682
https://github.com/scverse/scanpy/pull/2683:13,availability,state,state,13,allow random state in blobs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Resolves #1429.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2683
https://github.com/scverse/scanpy/pull/2683:13,integrability,state,state,13,allow random state in blobs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Resolves #1429.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2683
https://github.com/scverse/scanpy/pull/2683:248,safety,review,review,248,allow random state in blobs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Resolves #1429.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2683
https://github.com/scverse/scanpy/pull/2683:248,testability,review,review,248,allow random state in blobs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Resolves #1429.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2683
https://github.com/scverse/scanpy/pull/2683:99,usability,guid,guidelines,99,allow random state in blobs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Resolves #1429.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2683
https://github.com/scverse/scanpy/pull/2683:130,usability,guid,guide,130,allow random state in blobs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Resolves #1429.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2683
https://github.com/scverse/scanpy/pull/2683:226,usability,workflow,workflow,226,allow random state in blobs; <!--. Thanks for opening a PR to scanpy! Please be sure to follow the guidelines in our contribution guide (https://scanpy.readthedocs.io/en/latest/dev/index.html) to familiarize yourself with our workflow and speed up review. -->. Resolves #1429.,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2683
https://github.com/scverse/scanpy/pull/2684:45,modifiability,paramet,parameter,45,"DensMAP support; I added an optional boolean parameter to scanpy.tl.umap for DensMAP. Since umap 0.5, ``simplicial_set_embedding`` takes ``densmap`` and ``densmap_kwds`` parameters, and tools/_umap is using this function, so DensMAP support is easily implemented.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2684
https://github.com/scverse/scanpy/pull/2684:170,modifiability,paramet,parameters,170,"DensMAP support; I added an optional boolean parameter to scanpy.tl.umap for DensMAP. Since umap 0.5, ``simplicial_set_embedding`` takes ``densmap`` and ``densmap_kwds`` parameters, and tools/_umap is using this function, so DensMAP support is easily implemented.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2684
https://github.com/scverse/scanpy/pull/2684:8,usability,support,support,8,"DensMAP support; I added an optional boolean parameter to scanpy.tl.umap for DensMAP. Since umap 0.5, ``simplicial_set_embedding`` takes ``densmap`` and ``densmap_kwds`` parameters, and tools/_umap is using this function, so DensMAP support is easily implemented.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2684
https://github.com/scverse/scanpy/pull/2684:186,usability,tool,tools,186,"DensMAP support; I added an optional boolean parameter to scanpy.tl.umap for DensMAP. Since umap 0.5, ``simplicial_set_embedding`` takes ``densmap`` and ``densmap_kwds`` parameters, and tools/_umap is using this function, so DensMAP support is easily implemented.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2684
https://github.com/scverse/scanpy/pull/2684:233,usability,support,support,233,"DensMAP support; I added an optional boolean parameter to scanpy.tl.umap for DensMAP. Since umap 0.5, ``simplicial_set_embedding`` takes ``densmap`` and ``densmap_kwds`` parameters, and tools/_umap is using this function, so DensMAP support is easily implemented.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2684
https://github.com/scverse/scanpy/issues/2685:0,availability,Error,Error,0,"Error running https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Obj",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:515,availability,error,error,515,"Error running https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Obj",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:1045,availability,ERROR,ERROR,1045,"preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = SoupChannel(data_tod, data,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:2271,availability,cluster,cluster,2271,"). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data to the SoupChannel object. soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data)). sc = setSoupProfile(sc, soupProf). # Set cluster information in SoupChannel. sc = setClusters(sc, soupx_groups). # Estimate contamination fraction. sc = autoEstCont(sc, doPlot=FALSE). # Infer corrected table of counts and rount to integer. out = adjustCounts(sc, roundToInt = TRUE). ```. ### Error output. ```pytb. Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : . duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B. ```. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.9.5. -----. PIL 10.0.1. anndata2ri 1.2. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. attr 23.1.0. babel 2.13.0. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. gmpy2 2.1.2. h5py 3.10.0. idna 3.4. igraph 0.11.2. importlib_r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:2522,availability,Error,Error,2522,"_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data to the SoupChannel object. soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data)). sc = setSoupProfile(sc, soupProf). # Set cluster information in SoupChannel. sc = setClusters(sc, soupx_groups). # Estimate contamination fraction. sc = autoEstCont(sc, doPlot=FALSE). # Infer corrected table of counts and rount to integer. out = adjustCounts(sc, roundToInt = TRUE). ```. ### Error output. ```pytb. Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : . duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B. ```. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.9.5. -----. PIL 10.0.1. anndata2ri 1.2. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. attr 23.1.0. babel 2.13.0. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. gmpy2 2.1.2. h5py 3.10.0. idna 3.4. igraph 0.11.2. importlib_resources NA. ipykernel 6.25.2. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.7.3. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:2545,availability,Error,Error,2545,"_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data to the SoupChannel object. soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data)). sc = setSoupProfile(sc, soupProf). # Set cluster information in SoupChannel. sc = setClusters(sc, soupx_groups). # Estimate contamination fraction. sc = autoEstCont(sc, doPlot=FALSE). # Infer corrected table of counts and rount to integer. out = adjustCounts(sc, roundToInt = TRUE). ```. ### Error output. ```pytb. Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : . duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B. ```. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.9.5. -----. PIL 10.0.1. anndata2ri 1.2. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. attr 23.1.0. babel 2.13.0. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. gmpy2 2.1.2. h5py 3.10.0. idna 3.4. igraph 0.11.2. importlib_resources NA. ipykernel 6.25.2. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.7.3. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. markupsafe 2.1.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:267,deployability,version,version,267,"Error running https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Obj",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:935,deployability,log,logging,935,"Error running https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Obj",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:1021,deployability,log,logger,1021,"w.sc-best-practices.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = Sou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:1037,deployability,log,logging,1037,"es.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = SoupChannel(data_tod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:2271,deployability,cluster,cluster,2271,"). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data to the SoupChannel object. soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data)). sc = setSoupProfile(sc, soupProf). # Set cluster information in SoupChannel. sc = setClusters(sc, soupx_groups). # Estimate contamination fraction. sc = autoEstCont(sc, doPlot=FALSE). # Infer corrected table of counts and rount to integer. out = adjustCounts(sc, roundToInt = TRUE). ```. ### Error output. ```pytb. Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : . duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B. ```. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.9.5. -----. PIL 10.0.1. anndata2ri 1.2. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. attr 23.1.0. babel 2.13.0. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. gmpy2 2.1.2. h5py 3.10.0. idna 3.4. igraph 0.11.2. importlib_r",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:2751,deployability,Version,Versions,2751,"olumn names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data to the SoupChannel object. soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data)). sc = setSoupProfile(sc, soupProf). # Set cluster information in SoupChannel. sc = setClusters(sc, soupx_groups). # Estimate contamination fraction. sc = autoEstCont(sc, doPlot=FALSE). # Infer corrected table of counts and rount to integer. out = adjustCounts(sc, roundToInt = TRUE). ```. ### Error output. ```pytb. Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : . duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B. ```. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.9.5. -----. PIL 10.0.1. anndata2ri 1.2. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. attr 23.1.0. babel 2.13.0. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. gmpy2 2.1.2. h5py 3.10.0. idna 3.4. igraph 0.11.2. importlib_resources NA. ipykernel 6.25.2. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.7.3. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. opt_einsum v3.3.0. overrides NA. packaging 23.2. pandas 2.1.1. parso 0.8",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:5005,deployability,updat,updated,5005,"er 0.12.1. cython_runtime NA. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. gmpy2 2.1.2. h5py 3.10.0. idna 3.4. igraph 0.11.2. importlib_resources NA. ipykernel 6.25.2. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.7.3. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. opt_einsum v3.3.0. overrides NA. packaging 23.2. pandas 2.1.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.11.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pynndescent 0.5.10. pyparsing 3.1.1. pyrsistent NA. pythonjsonlogger NA. pytz 2023.3. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpy2 3.5.11. scipy 1.11.3. seaborn 0.13.0. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. socks 1.7.1. sparse 0.14.0. stack_data 0.6.2. statsmodels 0.14.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.0. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. typing_extensions NA. tzdata 2023.3. tzlocal NA. umap 0.5.4. uri_template NA. urllib3 2.0.6. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.4. yaml 6.0.1. zipp NA. zmq 25.1.1. zoneinfo NA. -----. IPython 8.16.1. jupyter_client 8.4.0. jupyter_core 5.4.0. jupyterlab 4.0.7. notebook 7.0.5. -----. Python 3.9.18 | packaged by conda-forge | (main, Aug 30 2023, 03:49:32) [GCC 12.3.0]. Linux-3.10.0-1160.95.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2023-10-16 08:14. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:2345,energy efficiency,Estimat,Estimate,2345,"s for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data to the SoupChannel object. soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data)). sc = setSoupProfile(sc, soupProf). # Set cluster information in SoupChannel. sc = setClusters(sc, soupx_groups). # Estimate contamination fraction. sc = autoEstCont(sc, doPlot=FALSE). # Infer corrected table of counts and rount to integer. out = adjustCounts(sc, roundToInt = TRUE). ```. ### Error output. ```pytb. Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : . duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B. ```. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.9.5. -----. PIL 10.0.1. anndata2ri 1.2. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. attr 23.1.0. babel 2.13.0. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. gmpy2 2.1.2. h5py 3.10.0. idna 3.4. igraph 0.11.2. importlib_resources NA. ipykernel 6.25.2. isoduration NA. jedi 0.19.1. jinja2 3.1.2. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:267,integrability,version,version,267,"Error running https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Obj",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:2751,integrability,Version,Versions,2751,"olumn names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data to the SoupChannel object. soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data)). sc = setSoupProfile(sc, soupProf). # Set cluster information in SoupChannel. sc = setClusters(sc, soupx_groups). # Estimate contamination fraction. sc = autoEstCont(sc, doPlot=FALSE). # Infer corrected table of counts and rount to integer. out = adjustCounts(sc, roundToInt = TRUE). ```. ### Error output. ```pytb. Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : . duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B. ```. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.9.5. -----. PIL 10.0.1. anndata2ri 1.2. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. attr 23.1.0. babel 2.13.0. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. gmpy2 2.1.2. h5py 3.10.0. idna 3.4. igraph 0.11.2. importlib_resources NA. ipykernel 6.25.2. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.7.3. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. opt_einsum v3.3.0. overrides NA. packaging 23.2. pandas 2.1.1. parso 0.8",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:1738,interoperability,specif,specify,1738,"lor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data to the SoupChannel object. soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data)). sc = setSoupProfile(sc, soupProf). # Set cluster information in SoupChannel. sc = setClusters(sc, soupx_groups). # Estimate contamination fraction. sc = autoEstCont(sc, doPlot=FALSE). # Infer corrected table of counts and rount to integer. out = adjustCounts(sc, roundToInt = TRUE). ```. ### Error output. ```pytb. Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : . duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B. ",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:1848,interoperability,format,format,1848,"rl=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data to the SoupChannel object. soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data)). sc = setSoupProfile(sc, soupProf). # Set cluster information in SoupChannel. sc = setClusters(sc, soupx_groups). # Estimate contamination fraction. sc = autoEstCont(sc, doPlot=FALSE). # Infer corrected table of counts and rount to integer. out = adjustCounts(sc, roundToInt = TRUE). ```. ### Error output. ```pytb. Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : . duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B. ```. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.9.5. -----. PIL 10.0.1. anndata2ri 1.2. an",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:3824,interoperability,platform,platformdirs,3824,1. anndata2ri 1.2. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. attr 23.1.0. babel 2.13.0. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. gmpy2 2.1.2. h5py 3.10.0. idna 3.4. igraph 0.11.2. importlib_resources NA. ipykernel 6.25.2. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.7.3. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. opt_einsum v3.3.0. overrides NA. packaging 23.2. pandas 2.1.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.11.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pynndescent 0.5.10. pyparsing 3.1.1. pyrsistent NA. pythonjsonlogger NA. pytz 2023.3. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpy2 3.5.11. scipy 1.11.3. seaborn 0.13.0. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. socks 1.7.1. sparse 0.14.0. stack_data 0.6.2. statsmodels 0.14.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.0. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. typing_extensions NA. tzdata 2023.3. tzlocal NA. umap 0.5.4. uri_template NA. urllib3 2.0.6. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.4. yaml 6.0.1. zipp NA. zmq 25.1.1. zoneinfo NA. -----. IPython 8.16.1. jupyter_client 8.4.0. jupyter_core 5.4.0. jupyterlab 4.0.7. notebook 7.0.5. --,MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:267,modifiability,version,version,267,"Error running https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Obj",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:1341,modifiability,variab,variables,1341,"ter branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data to the SoupChannel object. soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data)). sc = setSoupProfile(sc, soupProf). # Set cluster information in SoupChannel. sc = setClusters(sc, soupx_groups). # E",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:2751,modifiability,Version,Versions,2751,"olumn names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data to the SoupChannel object. soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data)). sc = setSoupProfile(sc, soupProf). # Set cluster information in SoupChannel. sc = setClusters(sc, soupx_groups). # Estimate contamination fraction. sc = autoEstCont(sc, doPlot=FALSE). # Infer corrected table of counts and rount to integer. out = adjustCounts(sc, roundToInt = TRUE). ```. ### Error output. ```pytb. Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : . duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B. ```. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.9.5. -----. PIL 10.0.1. anndata2ri 1.2. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. attr 23.1.0. babel 2.13.0. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. gmpy2 2.1.2. h5py 3.10.0. idna 3.4. igraph 0.11.2. importlib_resources NA. ipykernel 6.25.2. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.7.3. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. opt_einsum v3.3.0. overrides NA. packaging 23.2. pandas 2.1.1. parso 0.8",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:3111,modifiability,deco,decorator,3111,"object. soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data)). sc = setSoupProfile(sc, soupProf). # Set cluster information in SoupChannel. sc = setClusters(sc, soupx_groups). # Estimate contamination fraction. sc = autoEstCont(sc, doPlot=FALSE). # Infer corrected table of counts and rount to integer. out = adjustCounts(sc, roundToInt = TRUE). ```. ### Error output. ```pytb. Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : . duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B. ```. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.9.5. -----. PIL 10.0.1. anndata2ri 1.2. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. attr 23.1.0. babel 2.13.0. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. gmpy2 2.1.2. h5py 3.10.0. idna 3.4. igraph 0.11.2. importlib_resources NA. ipykernel 6.25.2. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.7.3. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. opt_einsum v3.3.0. overrides NA. packaging 23.2. pandas 2.1.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.11.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pynndescent 0.5.10. py",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:3716,modifiability,pac,packaging,3716,"X5-GPRASP2, TMSB15B. ```. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.9.5. -----. PIL 10.0.1. anndata2ri 1.2. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. attr 23.1.0. babel 2.13.0. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. gmpy2 2.1.2. h5py 3.10.0. idna 3.4. igraph 0.11.2. importlib_resources NA. ipykernel 6.25.2. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.7.3. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. opt_einsum v3.3.0. overrides NA. packaging 23.2. pandas 2.1.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.11.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pynndescent 0.5.10. pyparsing 3.1.1. pyrsistent NA. pythonjsonlogger NA. pytz 2023.3. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpy2 3.5.11. scipy 1.11.3. seaborn 0.13.0. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. socks 1.7.1. sparse 0.14.0. stack_data 0.6.2. statsmodels 0.14.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.0. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. typing_extensions NA. tzdata 2023.3. tzlocal NA. umap 0.5.4. uri_template NA. urllib3 2.0.6. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.4. yaml 6.0.1. zipp NA. zmq 25.1.1. zonei",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:4851,modifiability,pac,packaged,4851,"er 0.12.1. cython_runtime NA. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. gmpy2 2.1.2. h5py 3.10.0. idna 3.4. igraph 0.11.2. importlib_resources NA. ipykernel 6.25.2. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.7.3. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. opt_einsum v3.3.0. overrides NA. packaging 23.2. pandas 2.1.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.11.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pynndescent 0.5.10. pyparsing 3.1.1. pyrsistent NA. pythonjsonlogger NA. pytz 2023.3. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpy2 3.5.11. scipy 1.11.3. seaborn 0.13.0. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. socks 1.7.1. sparse 0.14.0. stack_data 0.6.2. statsmodels 0.14.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.0. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. typing_extensions NA. tzdata 2023.3. tzlocal NA. umap 0.5.4. uri_template NA. urllib3 2.0.6. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.4. yaml 6.0.1. zipp NA. zmq 25.1.1. zoneinfo NA. -----. IPython 8.16.1. jupyter_client 8.4.0. jupyter_core 5.4.0. jupyterlab 4.0.7. notebook 7.0.5. -----. Python 3.9.18 | packaged by conda-forge | (main, Aug 30 2023, 03:49:32) [GCC 12.3.0]. Linux-3.10.0-1160.95.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2023-10-16 08:14. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:0,performance,Error,Error,0,"Error running https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Obj",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:515,performance,error,error,515,"Error running https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Obj",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:1045,performance,ERROR,ERROR,1045,"preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = SoupChannel(data_tod, data,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:2522,performance,Error,Error,2522,"_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data to the SoupChannel object. soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data)). sc = setSoupProfile(sc, soupProf). # Set cluster information in SoupChannel. sc = setClusters(sc, soupx_groups). # Estimate contamination fraction. sc = autoEstCont(sc, doPlot=FALSE). # Infer corrected table of counts and rount to integer. out = adjustCounts(sc, roundToInt = TRUE). ```. ### Error output. ```pytb. Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : . duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B. ```. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.9.5. -----. PIL 10.0.1. anndata2ri 1.2. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. attr 23.1.0. babel 2.13.0. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. gmpy2 2.1.2. h5py 3.10.0. idna 3.4. igraph 0.11.2. importlib_resources NA. ipykernel 6.25.2. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.7.3. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:2545,performance,Error,Error,2545,"_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data to the SoupChannel object. soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data)). sc = setSoupProfile(sc, soupProf). # Set cluster information in SoupChannel. sc = setClusters(sc, soupx_groups). # Estimate contamination fraction. sc = autoEstCont(sc, doPlot=FALSE). # Infer corrected table of counts and rount to integer. out = adjustCounts(sc, roundToInt = TRUE). ```. ### Error output. ```pytb. Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : . duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B. ```. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.9.5. -----. PIL 10.0.1. anndata2ri 1.2. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. attr 23.1.0. babel 2.13.0. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. gmpy2 2.1.2. h5py 3.10.0. idna 3.4. igraph 0.11.2. importlib_resources NA. ipykernel 6.25.2. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.7.3. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. markupsafe 2.1.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:34,reliability,pra,practices,34,"Error running https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Obj",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:442,reliability,pra,practices,442,"Error running https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Obj",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:0,safety,Error,Error,0,"Error running https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Obj",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:515,safety,error,error,515,"Error running https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Obj",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:935,safety,log,logging,935,"Error running https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Obj",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:1021,safety,log,logger,1021,"w.sc-best-practices.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = Sou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:1037,safety,log,logging,1037,"es.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = SoupChannel(data_tod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:1045,safety,ERROR,ERROR,1045,"preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = SoupChannel(data_tod, data,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:2522,safety,Error,Error,2522,"_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data to the SoupChannel object. soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data)). sc = setSoupProfile(sc, soupProf). # Set cluster information in SoupChannel. sc = setClusters(sc, soupx_groups). # Estimate contamination fraction. sc = autoEstCont(sc, doPlot=FALSE). # Infer corrected table of counts and rount to integer. out = adjustCounts(sc, roundToInt = TRUE). ```. ### Error output. ```pytb. Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : . duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B. ```. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.9.5. -----. PIL 10.0.1. anndata2ri 1.2. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. attr 23.1.0. babel 2.13.0. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. gmpy2 2.1.2. h5py 3.10.0. idna 3.4. igraph 0.11.2. importlib_resources NA. ipykernel 6.25.2. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.7.3. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:2545,safety,Error,Error,2545,"_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data to the SoupChannel object. soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data)). sc = setSoupProfile(sc, soupProf). # Set cluster information in SoupChannel. sc = setClusters(sc, soupx_groups). # Estimate contamination fraction. sc = autoEstCont(sc, doPlot=FALSE). # Infer corrected table of counts and rount to integer. out = adjustCounts(sc, roundToInt = TRUE). ```. ### Error output. ```pytb. Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : . duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B. ```. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.9.5. -----. PIL 10.0.1. anndata2ri 1.2. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. attr 23.1.0. babel 2.13.0. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. gmpy2 2.1.2. h5py 3.10.0. idna 3.4. igraph 0.11.2. importlib_resources NA. ipykernel 6.25.2. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.7.3. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. markupsafe 2.1.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:3146,safety,except,exceptiongroup,3146,"es = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data)). sc = setSoupProfile(sc, soupProf). # Set cluster information in SoupChannel. sc = setClusters(sc, soupx_groups). # Estimate contamination fraction. sc = autoEstCont(sc, doPlot=FALSE). # Infer corrected table of counts and rount to integer. out = adjustCounts(sc, roundToInt = TRUE). ```. ### Error output. ```pytb. Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : . duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B. ```. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.9.5. -----. PIL 10.0.1. anndata2ri 1.2. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. attr 23.1.0. babel 2.13.0. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. gmpy2 2.1.2. h5py 3.10.0. idna 3.4. igraph 0.11.2. importlib_resources NA. ipykernel 6.25.2. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.7.3. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. opt_einsum v3.3.0. overrides NA. packaging 23.2. pandas 2.1.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.11.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pynndescent 0.5.10. pyparsing 3.1.1. pyrsistent NA. pythonj",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:5005,safety,updat,updated,5005,"er 0.12.1. cython_runtime NA. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. gmpy2 2.1.2. h5py 3.10.0. idna 3.4. igraph 0.11.2. importlib_resources NA. ipykernel 6.25.2. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.7.3. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. opt_einsum v3.3.0. overrides NA. packaging 23.2. pandas 2.1.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.11.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pynndescent 0.5.10. pyparsing 3.1.1. pyrsistent NA. pythonjsonlogger NA. pytz 2023.3. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpy2 3.5.11. scipy 1.11.3. seaborn 0.13.0. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. socks 1.7.1. sparse 0.14.0. stack_data 0.6.2. statsmodels 0.14.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.0. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. typing_extensions NA. tzdata 2023.3. tzlocal NA. umap 0.5.4. uri_template NA. urllib3 2.0.6. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.4. yaml 6.0.1. zipp NA. zmq 25.1.1. zoneinfo NA. -----. IPython 8.16.1. jupyter_client 8.4.0. jupyter_core 5.4.0. jupyterlab 4.0.7. notebook 7.0.5. -----. Python 3.9.18 | packaged by conda-forge | (main, Aug 30 2023, 03:49:32) [GCC 12.3.0]. Linux-3.10.0-1160.95.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2023-10-16 08:14. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:935,security,log,logging,935,"Error running https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Obj",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:1021,security,log,logger,1021,"w.sc-best-practices.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = Sou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:1037,security,log,logging,1037,"es.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = SoupChannel(data_tod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:2959,security,certif,certifi,2959,"eMatrix""). # Generate SoupChannel Object for SoupX . sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data to the SoupChannel object. soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data)). sc = setSoupProfile(sc, soupProf). # Set cluster information in SoupChannel. sc = setClusters(sc, soupx_groups). # Estimate contamination fraction. sc = autoEstCont(sc, doPlot=FALSE). # Infer corrected table of counts and rount to integer. out = adjustCounts(sc, roundToInt = TRUE). ```. ### Error output. ```pytb. Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : . duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B. ```. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.9.5. -----. PIL 10.0.1. anndata2ri 1.2. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. attr 23.1.0. babel 2.13.0. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. gmpy2 2.1.2. h5py 3.10.0. idna 3.4. igraph 0.11.2. importlib_resources NA. ipykernel 6.25.2. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.7.3. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. opt_einsum v3.3.0. overrides NA. packaging 23.2. pandas 2.1.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.11.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:3306,security,iso,isoduration,3306,"setClusters(sc, soupx_groups). # Estimate contamination fraction. sc = autoEstCont(sc, doPlot=FALSE). # Infer corrected table of counts and rount to integer. out = adjustCounts(sc, roundToInt = TRUE). ```. ### Error output. ```pytb. Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : . duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B. ```. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.9.5. -----. PIL 10.0.1. anndata2ri 1.2. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. attr 23.1.0. babel 2.13.0. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. gmpy2 2.1.2. h5py 3.10.0. idna 3.4. igraph 0.11.2. importlib_resources NA. ipykernel 6.25.2. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.7.3. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. opt_einsum v3.3.0. overrides NA. packaging 23.2. pandas 2.1.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.11.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pynndescent 0.5.10. pyparsing 3.1.1. pyrsistent NA. pythonjsonlogger NA. pytz 2023.3. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpy2 3.5.11. scipy 1.11.3. seaborn 0.13.0. send2trash NA. session",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:4367,security,soc,socks,4367,"er 0.12.1. cython_runtime NA. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. gmpy2 2.1.2. h5py 3.10.0. idna 3.4. igraph 0.11.2. importlib_resources NA. ipykernel 6.25.2. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.7.3. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. opt_einsum v3.3.0. overrides NA. packaging 23.2. pandas 2.1.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.11.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pynndescent 0.5.10. pyparsing 3.1.1. pyrsistent NA. pythonjsonlogger NA. pytz 2023.3. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpy2 3.5.11. scipy 1.11.3. seaborn 0.13.0. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. socks 1.7.1. sparse 0.14.0. stack_data 0.6.2. statsmodels 0.14.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.0. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. typing_extensions NA. tzdata 2023.3. tzlocal NA. umap 0.5.4. uri_template NA. urllib3 2.0.6. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.4. yaml 6.0.1. zipp NA. zmq 25.1.1. zoneinfo NA. -----. IPython 8.16.1. jupyter_client 8.4.0. jupyter_core 5.4.0. jupyterlab 4.0.7. notebook 7.0.5. -----. Python 3.9.18 | packaged by conda-forge | (main, Aug 30 2023, 03:49:32) [GCC 12.3.0]. Linux-3.10.0-1160.95.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2023-10-16 08:14. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:4985,security,Session,Session,4985,"er 0.12.1. cython_runtime NA. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. gmpy2 2.1.2. h5py 3.10.0. idna 3.4. igraph 0.11.2. importlib_resources NA. ipykernel 6.25.2. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.7.3. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. opt_einsum v3.3.0. overrides NA. packaging 23.2. pandas 2.1.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.11.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pynndescent 0.5.10. pyparsing 3.1.1. pyrsistent NA. pythonjsonlogger NA. pytz 2023.3. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpy2 3.5.11. scipy 1.11.3. seaborn 0.13.0. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. socks 1.7.1. sparse 0.14.0. stack_data 0.6.2. statsmodels 0.14.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.0. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. typing_extensions NA. tzdata 2023.3. tzlocal NA. umap 0.5.4. uri_template NA. urllib3 2.0.6. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.4. yaml 6.0.1. zipp NA. zmq 25.1.1. zoneinfo NA. -----. IPython 8.16.1. jupyter_client 8.4.0. jupyter_core 5.4.0. jupyterlab 4.0.7. notebook 7.0.5. -----. Python 3.9.18 | packaged by conda-forge | (main, Aug 30 2023, 03:49:32) [GCC 12.3.0]. Linux-3.10.0-1160.95.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2023-10-16 08:14. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:5005,security,updat,updated,5005,"er 0.12.1. cython_runtime NA. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. gmpy2 2.1.2. h5py 3.10.0. idna 3.4. igraph 0.11.2. importlib_resources NA. ipykernel 6.25.2. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.7.3. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. markupsafe 2.1.3. matplotlib 3.8.0. matplotlib_inline 0.1.6. mpl_toolkits NA. mpmath 1.3.0. natsort 8.4.0. nbformat 5.9.2. numba 0.57.1. numpy 1.24.4. opt_einsum v3.3.0. overrides NA. packaging 23.2. pandas 2.1.1. parso 0.8.3. patsy 0.5.3. pexpect 4.8.0. pickleshare 0.7.5. pkg_resources NA. platformdirs 3.11.0. prometheus_client NA. prompt_toolkit 3.0.39. psutil 5.9.5. ptyprocess 0.7.0. pure_eval 0.2.2. pvectorc NA. pycparser 2.21. pydev_ipython NA. pydevconsole NA. pydevd 2.9.5. pydevd_file_utils NA. pydevd_plugins NA. pydevd_tracing NA. pygments 2.16.1. pynndescent 0.5.10. pyparsing 3.1.1. pyrsistent NA. pythonjsonlogger NA. pytz 2023.3. requests 2.31.0. rfc3339_validator 0.1.4. rfc3986_validator 0.1.1. rpy2 3.5.11. scipy 1.11.3. seaborn 0.13.0. send2trash NA. session_info 1.0.0. six 1.16.0. sklearn 1.3.1. sniffio 1.3.0. socks 1.7.1. sparse 0.14.0. stack_data 0.6.2. statsmodels 0.14.0. sympy 1.12. texttable 1.7.0. threadpoolctl 3.2.0. torch 2.0.0. tornado 6.3.3. tqdm 4.66.1. traitlets 5.11.2. typing_extensions NA. tzdata 2023.3. tzlocal NA. umap 0.5.4. uri_template NA. urllib3 2.0.6. wcwidth 0.2.8. webcolors 1.13. websocket 1.6.4. yaml 6.0.1. zipp NA. zmq 25.1.1. zoneinfo NA. -----. IPython 8.16.1. jupyter_client 8.4.0. jupyter_core 5.4.0. jupyterlab 4.0.7. notebook 7.0.5. -----. Python 3.9.18 | packaged by conda-forge | (main, Aug 30 2023, 03:49:32) [GCC 12.3.0]. Linux-3.10.0-1160.95.1.el7.x86_64-x86_64-with-glibc2.17. -----. Session information updated at 2023-10-16 08:14. ```. </details>.",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:935,testability,log,logging,935,"Error running https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Obj",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:1021,testability,log,logger,1021,"w.sc-best-practices.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = Sou",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:1037,testability,log,logging,1037,"es.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = SoupChannel(data_tod",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:0,usability,Error,Error,0,"Error running https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Obj",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:227,usability,confirm,confirmed,227,"Error running https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Obj",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:310,usability,confirm,confirmed,310,"Error running https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Obj",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:515,usability,error,error,515,"Error running https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Obj",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:526,usability,Minim,Minimal,526,"Error running https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Obj",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:1045,usability,ERROR,ERROR,1045,"preprocessing_visualization/quality_control.html#; ### Please make sure these conditions are met. - [X] I have checked that this issue has not already been reported. - [X] I have confirmed this bug exists on the latest version of scanpy. - [x] (optional) I have confirmed this bug exists on the master branch of scanpy. ### What happened? Hi,. When I try to run the code in https://www.sc-best-practices.org/preprocessing_visualization/quality_control.html# I get an error. ### Minimal code sample. ```python. import numpy as np. import scanpy as sc. import seaborn as sns. from scipy.stats import median_abs_deviation. sc.settings.verbosity = 0. sc.settings.set_figure_params(. dpi=80,. facecolor=""white"",. frameon=False,. ). adata = sc.read_10x_h5(. filename=""filtered_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546196"",. ). import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. %%R. library(SoupX). adata_pp = adata.copy(). sc.pp.normalize_per_cell(adata_pp). sc.pp.log1p(adata_pp). sc.pp.pca(adata_pp). sc.pp.neighbors(adata_pp). sc.tl.leiden(adata_pp, key_added=""soupx_groups""). # Preprocess variables for SoupX. soupx_groups = adata_pp.obs[""soupx_groups""]. cells = adata.obs_names. genes = adata.var_names. data = adata.X.T. adata_raw = sc.read_10x_h5(. filename=""raw_feature_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = SoupChannel(data_tod, data,",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:2522,usability,Error,Error,2522,"_bc_matrix.h5"",. backup_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data to the SoupChannel object. soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data)). sc = setSoupProfile(sc, soupProf). # Set cluster information in SoupChannel. sc = setClusters(sc, soupx_groups). # Estimate contamination fraction. sc = autoEstCont(sc, doPlot=FALSE). # Infer corrected table of counts and rount to integer. out = adjustCounts(sc, roundToInt = TRUE). ```. ### Error output. ```pytb. Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : . duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B. ```. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.9.5. -----. PIL 10.0.1. anndata2ri 1.2. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. attr 23.1.0. babel 2.13.0. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. gmpy2 2.1.2. h5py 3.10.0. idna 3.4. igraph 0.11.2. importlib_resources NA. ipykernel 6.25.2. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.7.3. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/issues/2685:2545,usability,Error,Error,2545,"_url=""https://figshare.com/ndownloader/files/39546217"",. ). adata_raw.var_names_make_unique(). data_tod = adata_raw.X.T. %%R -i data -i data_tod -i genes -i cells -i soupx_groups -o out . # specify row and column names of data. rownames(data) = genes. colnames(data) = cells. # ensure correct sparse format for table of counts and table of droplets. data <- as(data, ""sparseMatrix""). data_tod <- as(data_tod, ""sparseMatrix""). # Generate SoupChannel Object for SoupX . sc = SoupChannel(data_tod, data, calcSoupProfile = FALSE). # Add extra meta data to the SoupChannel object. soupProf = data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), counts = rowSums(data)). sc = setSoupProfile(sc, soupProf). # Set cluster information in SoupChannel. sc = setClusters(sc, soupx_groups). # Estimate contamination fraction. sc = autoEstCont(sc, doPlot=FALSE). # Infer corrected table of counts and rount to integer. out = adjustCounts(sc, roundToInt = TRUE). ```. ### Error output. ```pytb. Error in data.frame(row.names = rownames(data), est = rowSums(data)/sum(data), : . duplicate row.names: TBCE, LINC01238, CYB561D2, MATR3, LINC01505, HSPA14, GOLGA8M, GGT1, ARMCX5-GPRASP2, TMSB15B. ```. ### Versions. <details>. ```. -----. anndata 0.10.2. scanpy 1.9.5. -----. PIL 10.0.1. anndata2ri 1.2. anyio NA. argcomplete NA. arrow 1.3.0. asttokens NA. attr 23.1.0. babel 2.13.0. backcall 0.2.0. brotli 1.1.0. certifi 2023.07.22. cffi 1.16.0. charset_normalizer 3.3.0. colorama 0.4.6. comm 0.1.4. cycler 0.12.1. cython_runtime NA. dateutil 2.8.2. debugpy 1.8.0. decorator 5.1.1. defusedxml 0.7.1. exceptiongroup 1.1.3. executing 1.2.0. fastjsonschema NA. fqdn NA. gmpy2 2.1.2. h5py 3.10.0. idna 3.4. igraph 0.11.2. importlib_resources NA. ipykernel 6.25.2. isoduration NA. jedi 0.19.1. jinja2 3.1.2. joblib 1.3.2. json5 NA. jsonpointer 2.4. jsonschema 4.17.3. jupyter_events 0.6.3. jupyter_server 2.7.3. jupyterlab_server 2.24.0. kiwisolver 1.4.5. leidenalg 0.10.1. llvmlite 0.40.1. markupsafe 2.1.3",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/2685
https://github.com/scverse/scanpy/pull/2687:141,availability,consist,consistent,141,"Loosen exact equality restriction; They kept failing. Something upstream (likely numba) or Azures testing machines seem to have become less consistent in calculating this. [This thread](https://github.com/scverse/scanpy/pull/1740#discussion_r596827747) came across that. @ivirshups final statement was. > This bug seems to be based on having nested parallelism and certain reductions. We can avoid it by just not having nested parallelism, which is what I've done for gearys_c. I dont think exact float equality is a reasonable assumption, but if we want to continue to test for it, we need to be able to force numba to be predictable or so. Needs no release note. Added https://github.com/scverse/scanpy/issues/2688 to track this regression",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2687
https://github.com/scverse/scanpy/pull/2687:290,availability,state,statement,290,"Loosen exact equality restriction; They kept failing. Something upstream (likely numba) or Azures testing machines seem to have become less consistent in calculating this. [This thread](https://github.com/scverse/scanpy/pull/1740#discussion_r596827747) came across that. @ivirshups final statement was. > This bug seems to be based on having nested parallelism and certain reductions. We can avoid it by just not having nested parallelism, which is what I've done for gearys_c. I dont think exact float equality is a reasonable assumption, but if we want to continue to test for it, we need to be able to force numba to be predictable or so. Needs no release note. Added https://github.com/scverse/scanpy/issues/2688 to track this regression",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2687
https://github.com/scverse/scanpy/pull/2687:45,deployability,fail,failing,45,"Loosen exact equality restriction; They kept failing. Something upstream (likely numba) or Azures testing machines seem to have become less consistent in calculating this. [This thread](https://github.com/scverse/scanpy/pull/1740#discussion_r596827747) came across that. @ivirshups final statement was. > This bug seems to be based on having nested parallelism and certain reductions. We can avoid it by just not having nested parallelism, which is what I've done for gearys_c. I dont think exact float equality is a reasonable assumption, but if we want to continue to test for it, we need to be able to force numba to be predictable or so. Needs no release note. Added https://github.com/scverse/scanpy/issues/2688 to track this regression",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2687
https://github.com/scverse/scanpy/pull/2687:561,deployability,continu,continue,561,"Loosen exact equality restriction; They kept failing. Something upstream (likely numba) or Azures testing machines seem to have become less consistent in calculating this. [This thread](https://github.com/scverse/scanpy/pull/1740#discussion_r596827747) came across that. @ivirshups final statement was. > This bug seems to be based on having nested parallelism and certain reductions. We can avoid it by just not having nested parallelism, which is what I've done for gearys_c. I dont think exact float equality is a reasonable assumption, but if we want to continue to test for it, we need to be able to force numba to be predictable or so. Needs no release note. Added https://github.com/scverse/scanpy/issues/2688 to track this regression",MatchSource.ISSUE,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/2687
