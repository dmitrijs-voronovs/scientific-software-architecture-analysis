id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/issues/480:759,availability,cluster,cluster,759,"Thanks for reporting. I will take a look. On Wed, Feb 13, 2019 at 2:19 AM tsotnech <notifications@github.com> wrote:. > Hi guys,. >. > sorry for opening so many issues, I really love using tracksplot for. > visualizing the expression in different clusters, but the small issue I. > have is that tracks actually never align well with the clusters ""timeline"". > at the bottom. especially the first and last tracks are always misaligned. > I couldn't find the list of arguments that I can pass through. > sc.pl.tracksplot command maybe just changing margins or size of the plot. > might make it better. > [image: tracksplotin_final]. > <https://user-images.githubusercontent.com/43454880/52679490-1f11dc80-2eea-11e9-8a6e-511beefb4c1d.png>. >. > in this example, cluster 0, 8,9,10 tracks are misaligned to the timeline. > below. >. > Thanks a lot,. >. > Tsotne. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/480>, or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1Zm16jiUoHyCrqHwaX6yuA2EcnT_ks5vM2gxgaJpZM4a4ZBv>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/480:247,deployability,cluster,clusters,247,"Thanks for reporting. I will take a look. On Wed, Feb 13, 2019 at 2:19 AM tsotnech <notifications@github.com> wrote:. > Hi guys,. >. > sorry for opening so many issues, I really love using tracksplot for. > visualizing the expression in different clusters, but the small issue I. > have is that tracks actually never align well with the clusters ""timeline"". > at the bottom. especially the first and last tracks are always misaligned. > I couldn't find the list of arguments that I can pass through. > sc.pl.tracksplot command maybe just changing margins or size of the plot. > might make it better. > [image: tracksplotin_final]. > <https://user-images.githubusercontent.com/43454880/52679490-1f11dc80-2eea-11e9-8a6e-511beefb4c1d.png>. >. > in this example, cluster 0, 8,9,10 tracks are misaligned to the timeline. > below. >. > Thanks a lot,. >. > Tsotne. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/480>, or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1Zm16jiUoHyCrqHwaX6yuA2EcnT_ks5vM2gxgaJpZM4a4ZBv>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/480:337,deployability,cluster,clusters,337,"Thanks for reporting. I will take a look. On Wed, Feb 13, 2019 at 2:19 AM tsotnech <notifications@github.com> wrote:. > Hi guys,. >. > sorry for opening so many issues, I really love using tracksplot for. > visualizing the expression in different clusters, but the small issue I. > have is that tracks actually never align well with the clusters ""timeline"". > at the bottom. especially the first and last tracks are always misaligned. > I couldn't find the list of arguments that I can pass through. > sc.pl.tracksplot command maybe just changing margins or size of the plot. > might make it better. > [image: tracksplotin_final]. > <https://user-images.githubusercontent.com/43454880/52679490-1f11dc80-2eea-11e9-8a6e-511beefb4c1d.png>. >. > in this example, cluster 0, 8,9,10 tracks are misaligned to the timeline. > below. >. > Thanks a lot,. >. > Tsotne. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/480>, or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1Zm16jiUoHyCrqHwaX6yuA2EcnT_ks5vM2gxgaJpZM4a4ZBv>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/480:759,deployability,cluster,cluster,759,"Thanks for reporting. I will take a look. On Wed, Feb 13, 2019 at 2:19 AM tsotnech <notifications@github.com> wrote:. > Hi guys,. >. > sorry for opening so many issues, I really love using tracksplot for. > visualizing the expression in different clusters, but the small issue I. > have is that tracks actually never align well with the clusters ""timeline"". > at the bottom. especially the first and last tracks are always misaligned. > I couldn't find the list of arguments that I can pass through. > sc.pl.tracksplot command maybe just changing margins or size of the plot. > might make it better. > [image: tracksplotin_final]. > <https://user-images.githubusercontent.com/43454880/52679490-1f11dc80-2eea-11e9-8a6e-511beefb4c1d.png>. >. > in this example, cluster 0, 8,9,10 tracks are misaligned to the timeline. > below. >. > Thanks a lot,. >. > Tsotne. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/480>, or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1Zm16jiUoHyCrqHwaX6yuA2EcnT_ks5vM2gxgaJpZM4a4ZBv>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/480:907,integrability,sub,subscribed,907,"Thanks for reporting. I will take a look. On Wed, Feb 13, 2019 at 2:19 AM tsotnech <notifications@github.com> wrote:. > Hi guys,. >. > sorry for opening so many issues, I really love using tracksplot for. > visualizing the expression in different clusters, but the small issue I. > have is that tracks actually never align well with the clusters ""timeline"". > at the bottom. especially the first and last tracks are always misaligned. > I couldn't find the list of arguments that I can pass through. > sc.pl.tracksplot command maybe just changing margins or size of the plot. > might make it better. > [image: tracksplotin_final]. > <https://user-images.githubusercontent.com/43454880/52679490-1f11dc80-2eea-11e9-8a6e-511beefb4c1d.png>. >. > in this example, cluster 0, 8,9,10 tracks are misaligned to the timeline. > below. >. > Thanks a lot,. >. > Tsotne. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/480>, or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1Zm16jiUoHyCrqHwaX6yuA2EcnT_ks5vM2gxgaJpZM4a4ZBv>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/480:347,performance,time,timeline,347,"Thanks for reporting. I will take a look. On Wed, Feb 13, 2019 at 2:19 AM tsotnech <notifications@github.com> wrote:. > Hi guys,. >. > sorry for opening so many issues, I really love using tracksplot for. > visualizing the expression in different clusters, but the small issue I. > have is that tracks actually never align well with the clusters ""timeline"". > at the bottom. especially the first and last tracks are always misaligned. > I couldn't find the list of arguments that I can pass through. > sc.pl.tracksplot command maybe just changing margins or size of the plot. > might make it better. > [image: tracksplotin_final]. > <https://user-images.githubusercontent.com/43454880/52679490-1f11dc80-2eea-11e9-8a6e-511beefb4c1d.png>. >. > in this example, cluster 0, 8,9,10 tracks are misaligned to the timeline. > below. >. > Thanks a lot,. >. > Tsotne. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/480>, or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1Zm16jiUoHyCrqHwaX6yuA2EcnT_ks5vM2gxgaJpZM4a4ZBv>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/480:806,performance,time,timeline,806,"Thanks for reporting. I will take a look. On Wed, Feb 13, 2019 at 2:19 AM tsotnech <notifications@github.com> wrote:. > Hi guys,. >. > sorry for opening so many issues, I really love using tracksplot for. > visualizing the expression in different clusters, but the small issue I. > have is that tracks actually never align well with the clusters ""timeline"". > at the bottom. especially the first and last tracks are always misaligned. > I couldn't find the list of arguments that I can pass through. > sc.pl.tracksplot command maybe just changing margins or size of the plot. > might make it better. > [image: tracksplotin_final]. > <https://user-images.githubusercontent.com/43454880/52679490-1f11dc80-2eea-11e9-8a6e-511beefb4c1d.png>. >. > in this example, cluster 0, 8,9,10 tracks are misaligned to the timeline. > below. >. > Thanks a lot,. >. > Tsotne. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/480>, or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1Zm16jiUoHyCrqHwaX6yuA2EcnT_ks5vM2gxgaJpZM4a4ZBv>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/480:1104,security,auth,auth,1104,"Thanks for reporting. I will take a look. On Wed, Feb 13, 2019 at 2:19 AM tsotnech <notifications@github.com> wrote:. > Hi guys,. >. > sorry for opening so many issues, I really love using tracksplot for. > visualizing the expression in different clusters, but the small issue I. > have is that tracks actually never align well with the clusters ""timeline"". > at the bottom. especially the first and last tracks are always misaligned. > I couldn't find the list of arguments that I can pass through. > sc.pl.tracksplot command maybe just changing margins or size of the plot. > might make it better. > [image: tracksplotin_final]. > <https://user-images.githubusercontent.com/43454880/52679490-1f11dc80-2eea-11e9-8a6e-511beefb4c1d.png>. >. > in this example, cluster 0, 8,9,10 tracks are misaligned to the timeline. > below. >. > Thanks a lot,. >. > Tsotne. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/480>, or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1Zm16jiUoHyCrqHwaX6yuA2EcnT_ks5vM2gxgaJpZM4a4ZBv>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/480:207,usability,visual,visualizing,207,"Thanks for reporting. I will take a look. On Wed, Feb 13, 2019 at 2:19 AM tsotnech <notifications@github.com> wrote:. > Hi guys,. >. > sorry for opening so many issues, I really love using tracksplot for. > visualizing the expression in different clusters, but the small issue I. > have is that tracks actually never align well with the clusters ""timeline"". > at the bottom. especially the first and last tracks are always misaligned. > I couldn't find the list of arguments that I can pass through. > sc.pl.tracksplot command maybe just changing margins or size of the plot. > might make it better. > [image: tracksplotin_final]. > <https://user-images.githubusercontent.com/43454880/52679490-1f11dc80-2eea-11e9-8a6e-511beefb4c1d.png>. >. > in this example, cluster 0, 8,9,10 tracks are misaligned to the timeline. > below. >. > Thanks a lot,. >. > Tsotne. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/480>, or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1Zm16jiUoHyCrqHwaX6yuA2EcnT_ks5vM2gxgaJpZM4a4ZBv>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/480:519,usability,command,command,519,"Thanks for reporting. I will take a look. On Wed, Feb 13, 2019 at 2:19 AM tsotnech <notifications@github.com> wrote:. > Hi guys,. >. > sorry for opening so many issues, I really love using tracksplot for. > visualizing the expression in different clusters, but the small issue I. > have is that tracks actually never align well with the clusters ""timeline"". > at the bottom. especially the first and last tracks are always misaligned. > I couldn't find the list of arguments that I can pass through. > sc.pl.tracksplot command maybe just changing margins or size of the plot. > might make it better. > [image: tracksplotin_final]. > <https://user-images.githubusercontent.com/43454880/52679490-1f11dc80-2eea-11e9-8a6e-511beefb4c1d.png>. >. > in this example, cluster 0, 8,9,10 tracks are misaligned to the timeline. > below. >. > Thanks a lot,. >. > Tsotne. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/480>, or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1Zm16jiUoHyCrqHwaX6yuA2EcnT_ks5vM2gxgaJpZM4a4ZBv>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/480:642,usability,user,user-images,642,"Thanks for reporting. I will take a look. On Wed, Feb 13, 2019 at 2:19 AM tsotnech <notifications@github.com> wrote:. > Hi guys,. >. > sorry for opening so many issues, I really love using tracksplot for. > visualizing the expression in different clusters, but the small issue I. > have is that tracks actually never align well with the clusters ""timeline"". > at the bottom. especially the first and last tracks are always misaligned. > I couldn't find the list of arguments that I can pass through. > sc.pl.tracksplot command maybe just changing margins or size of the plot. > might make it better. > [image: tracksplotin_final]. > <https://user-images.githubusercontent.com/43454880/52679490-1f11dc80-2eea-11e9-8a6e-511beefb4c1d.png>. >. > in this example, cluster 0, 8,9,10 tracks are misaligned to the timeline. > below. >. > Thanks a lot,. >. > Tsotne. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/480>, or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1Zm16jiUoHyCrqHwaX6yuA2EcnT_ks5vM2gxgaJpZM4a4ZBv>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/480:371,deployability,version,version,371,"I can not reproduce the problem. Does this works for you? ```. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. ax = sc.pl.tracksplot(pbmc,marker_genes, groupby='louvain'). ```. ![image](https://user-images.githubusercontent.com/4964309/52697496-dc93e280-2f71-11e9-8d01-65305c5d3c5d.png). What is your version of matplotlib?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/480:371,integrability,version,version,371,"I can not reproduce the problem. Does this works for you? ```. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. ax = sc.pl.tracksplot(pbmc,marker_genes, groupby='louvain'). ```. ![image](https://user-images.githubusercontent.com/4964309/52697496-dc93e280-2f71-11e9-8d01-65305c5d3c5d.png). What is your version of matplotlib?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/480:371,modifiability,version,version,371,"I can not reproduce the problem. Does this works for you? ```. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. ax = sc.pl.tracksplot(pbmc,marker_genes, groupby='louvain'). ```. ![image](https://user-images.githubusercontent.com/4964309/52697496-dc93e280-2f71-11e9-8d01-65305c5d3c5d.png). What is your version of matplotlib?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/480:33,reliability,Doe,Does,33,"I can not reproduce the problem. Does this works for you? ```. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. ax = sc.pl.tracksplot(pbmc,marker_genes, groupby='louvain'). ```. ![image](https://user-images.githubusercontent.com/4964309/52697496-dc93e280-2f71-11e9-8d01-65305c5d3c5d.png). What is your version of matplotlib?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/480:264,usability,user,user-images,264,"I can not reproduce the problem. Does this works for you? ```. pbmc = sc.datasets.pbmc68k_reduced(). marker_genes = ['S100A8', 'GNLY', 'NKG7', 'KLRB1', 'FCGR3A', 'FCER1A', 'CST3']. ax = sc.pl.tracksplot(pbmc,marker_genes, groupby='louvain'). ```. ![image](https://user-images.githubusercontent.com/4964309/52697496-dc93e280-2f71-11e9-8d01-65305c5d3c5d.png). What is your version of matplotlib?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/480:27,deployability,Updat,Update,27,I have matplotlib 2.2.2. . Update! I just updated my matplotlib to the latest version and it works well there is no misalignment any more! . thanks again,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/480:42,deployability,updat,updated,42,I have matplotlib 2.2.2. . Update! I just updated my matplotlib to the latest version and it works well there is no misalignment any more! . thanks again,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/480:78,deployability,version,version,78,I have matplotlib 2.2.2. . Update! I just updated my matplotlib to the latest version and it works well there is no misalignment any more! . thanks again,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/480:78,integrability,version,version,78,I have matplotlib 2.2.2. . Update! I just updated my matplotlib to the latest version and it works well there is no misalignment any more! . thanks again,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/480:78,modifiability,version,version,78,I have matplotlib 2.2.2. . Update! I just updated my matplotlib to the latest version and it works well there is no misalignment any more! . thanks again,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/480:27,safety,Updat,Update,27,I have matplotlib 2.2.2. . Update! I just updated my matplotlib to the latest version and it works well there is no misalignment any more! . thanks again,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/480:42,safety,updat,updated,42,I have matplotlib 2.2.2. . Update! I just updated my matplotlib to the latest version and it works well there is no misalignment any more! . thanks again,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/480:27,security,Updat,Update,27,I have matplotlib 2.2.2. . Update! I just updated my matplotlib to the latest version and it works well there is no misalignment any more! . thanks again,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/480:42,security,updat,updated,42,I have matplotlib 2.2.2. . Update! I just updated my matplotlib to the latest version and it works well there is no misalignment any more! . thanks again,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/480:127,deployability,updat,updated,127,"Glad that it worked, and thanks for reporting the issue. I realized that the requirement for scanpy was `matplotlib>=2.2.2`. I updated it to 3.0.0.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/480:127,safety,updat,updated,127,"Glad that it worked, and thanks for reporting the issue. I realized that the requirement for scanpy was `matplotlib>=2.2.2`. I updated it to 3.0.0.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/480:127,security,updat,updated,127,"Glad that it worked, and thanks for reporting the issue. I realized that the requirement for scanpy was `matplotlib>=2.2.2`. I updated it to 3.0.0.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/480
https://github.com/scverse/scanpy/issues/482:29,deployability,instal,install,29,"In any case, running: `$ pip install anndata -U --no-deps` solves the problem, as then the problematic part of utils.py is not run.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/482
https://github.com/scverse/scanpy/issues/483:167,modifiability,variab,variable,167,Already fixed in 6c3e92924ea09ef288e422b283c6e03410d64a0b. > This may result in passing an empty `adj_tree` to the `_compute_pos()` function. empty? you mean an unset variable.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/483
https://github.com/scverse/scanpy/issues/488:355,availability,sli,slightly,355,"`n_genes` was calculated when you filtered cells. I agree that this implicit behavior can be confusing. btw, if your expression is in a sparse matrix, this would be a more efficient way to count the number of expressed genes:. ```python. adata.X.eliminate_zeros() # Removes explicit zeros. n_genes = adata.X.getnnz(axis=1) # Counts explicit values. # or, slightly less efficient but still more efficient than making a dense array. np.ravel((adata.X != 0).sum(axis=1)). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/488
https://github.com/scverse/scanpy/issues/488:34,integrability,filter,filtered,34,"`n_genes` was calculated when you filtered cells. I agree that this implicit behavior can be confusing. btw, if your expression is in a sparse matrix, this would be a more efficient way to count the number of expressed genes:. ```python. adata.X.eliminate_zeros() # Removes explicit zeros. n_genes = adata.X.getnnz(axis=1) # Counts explicit values. # or, slightly less efficient but still more efficient than making a dense array. np.ravel((adata.X != 0).sum(axis=1)). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/488
https://github.com/scverse/scanpy/issues/488:355,reliability,sli,slightly,355,"`n_genes` was calculated when you filtered cells. I agree that this implicit behavior can be confusing. btw, if your expression is in a sparse matrix, this would be a more efficient way to count the number of expressed genes:. ```python. adata.X.eliminate_zeros() # Removes explicit zeros. n_genes = adata.X.getnnz(axis=1) # Counts explicit values. # or, slightly less efficient but still more efficient than making a dense array. np.ravel((adata.X != 0).sum(axis=1)). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/488
https://github.com/scverse/scanpy/issues/488:77,usability,behavi,behavior,77,"`n_genes` was calculated when you filtered cells. I agree that this implicit behavior can be confusing. btw, if your expression is in a sparse matrix, this would be a more efficient way to count the number of expressed genes:. ```python. adata.X.eliminate_zeros() # Removes explicit zeros. n_genes = adata.X.getnnz(axis=1) # Counts explicit values. # or, slightly less efficient but still more efficient than making a dense array. np.ravel((adata.X != 0).sum(axis=1)). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/488
https://github.com/scverse/scanpy/issues/488:172,usability,efficien,efficient,172,"`n_genes` was calculated when you filtered cells. I agree that this implicit behavior can be confusing. btw, if your expression is in a sparse matrix, this would be a more efficient way to count the number of expressed genes:. ```python. adata.X.eliminate_zeros() # Removes explicit zeros. n_genes = adata.X.getnnz(axis=1) # Counts explicit values. # or, slightly less efficient but still more efficient than making a dense array. np.ravel((adata.X != 0).sum(axis=1)). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/488
https://github.com/scverse/scanpy/issues/488:369,usability,efficien,efficient,369,"`n_genes` was calculated when you filtered cells. I agree that this implicit behavior can be confusing. btw, if your expression is in a sparse matrix, this would be a more efficient way to count the number of expressed genes:. ```python. adata.X.eliminate_zeros() # Removes explicit zeros. n_genes = adata.X.getnnz(axis=1) # Counts explicit values. # or, slightly less efficient but still more efficient than making a dense array. np.ravel((adata.X != 0).sum(axis=1)). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/488
https://github.com/scverse/scanpy/issues/488:394,usability,efficien,efficient,394,"`n_genes` was calculated when you filtered cells. I agree that this implicit behavior can be confusing. btw, if your expression is in a sparse matrix, this would be a more efficient way to count the number of expressed genes:. ```python. adata.X.eliminate_zeros() # Removes explicit zeros. n_genes = adata.X.getnnz(axis=1) # Counts explicit values. # or, slightly less efficient but still more efficient than making a dense array. np.ravel((adata.X != 0).sum(axis=1)). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/488
https://github.com/scverse/scanpy/issues/488:38,integrability,filter,filter,38,"Oh, thank you. When I comment out the filter genes step I get sensible counts. It completely makes sense!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/488
https://github.com/scverse/scanpy/issues/488:82,safety,compl,completely,82,"Oh, thank you. When I comment out the filter genes step I get sensible counts. It completely makes sense!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/488
https://github.com/scverse/scanpy/issues/488:82,security,compl,completely,82,"Oh, thank you. When I comment out the filter genes step I get sensible counts. It completely makes sense!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/488
https://github.com/scverse/scanpy/issues/489:168,safety,compl,complete,168,"Awesome idea! :). Sorry that I haven't merged all your other PRs, yet. I got back to work on Scanpy yesterday or so after being sick for 2 weeks and another 2 weeks of complete chaos (sick babies)... ;). You'll get feedback very soon, but at first sight, all of them looked fine, anyway. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/489
https://github.com/scverse/scanpy/issues/489:168,security,compl,complete,168,"Awesome idea! :). Sorry that I haven't merged all your other PRs, yet. I got back to work on Scanpy yesterday or so after being sick for 2 weeks and another 2 weeks of complete chaos (sick babies)... ;). You'll get feedback very soon, but at first sight, all of them looked fine, anyway. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/489
https://github.com/scverse/scanpy/issues/489:215,usability,feedback,feedback,215,"Awesome idea! :). Sorry that I haven't merged all your other PRs, yet. I got back to work on Scanpy yesterday or so after being sick for 2 weeks and another 2 weeks of complete chaos (sick babies)... ;). You'll get feedback very soon, but at first sight, all of them looked fine, anyway. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/489
https://github.com/scverse/scanpy/issues/490:388,availability,slo,slot,388,"I know the question is quite old, but maybe someone else will stumble upon it and in that case, I'd like to give a solution I used with my data. . To check for expression you need to access raw matrix of counts in your data. That is, it can be log transformed and normalised, but shouldn't be scaled or regressed. Following many of the tutorials you should have the matrix in your `.raw` slot. ```. gene1 = 'XXX'. gene2 = 'YYY. adata.obs['CoEx'] = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). ```. That will add to your anndata object one more metric, which you can then use to colour your umap plot (i.e. `sc.pl.umap(adata, color='CoEx')`). . One thing quite annoying with this solution is that you'll end up with a meaningless colorbar on your umap plots. I welcome suggestions on how to improve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:244,deployability,log,log,244,"I know the question is quite old, but maybe someone else will stumble upon it and in that case, I'd like to give a solution I used with my data. . To check for expression you need to access raw matrix of counts in your data. That is, it can be log transformed and normalised, but shouldn't be scaled or regressed. Following many of the tutorials you should have the matrix in your `.raw` slot. ```. gene1 = 'XXX'. gene2 = 'YYY. adata.obs['CoEx'] = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). ```. That will add to your anndata object one more metric, which you can then use to colour your umap plot (i.e. `sc.pl.umap(adata, color='CoEx')`). . One thing quite annoying with this solution is that you'll end up with a meaningless colorbar on your umap plots. I welcome suggestions on how to improve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:293,deployability,scale,scaled,293,"I know the question is quite old, but maybe someone else will stumble upon it and in that case, I'd like to give a solution I used with my data. . To check for expression you need to access raw matrix of counts in your data. That is, it can be log transformed and normalised, but shouldn't be scaled or regressed. Following many of the tutorials you should have the matrix in your `.raw` slot. ```. gene1 = 'XXX'. gene2 = 'YYY. adata.obs['CoEx'] = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). ```. That will add to your anndata object one more metric, which you can then use to colour your umap plot (i.e. `sc.pl.umap(adata, color='CoEx')`). . One thing quite annoying with this solution is that you'll end up with a meaningless colorbar on your umap plots. I welcome suggestions on how to improve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:293,energy efficiency,scale,scaled,293,"I know the question is quite old, but maybe someone else will stumble upon it and in that case, I'd like to give a solution I used with my data. . To check for expression you need to access raw matrix of counts in your data. That is, it can be log transformed and normalised, but shouldn't be scaled or regressed. Following many of the tutorials you should have the matrix in your `.raw` slot. ```. gene1 = 'XXX'. gene2 = 'YYY. adata.obs['CoEx'] = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). ```. That will add to your anndata object one more metric, which you can then use to colour your umap plot (i.e. `sc.pl.umap(adata, color='CoEx')`). . One thing quite annoying with this solution is that you'll end up with a meaningless colorbar on your umap plots. I welcome suggestions on how to improve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:248,integrability,transform,transformed,248,"I know the question is quite old, but maybe someone else will stumble upon it and in that case, I'd like to give a solution I used with my data. . To check for expression you need to access raw matrix of counts in your data. That is, it can be log transformed and normalised, but shouldn't be scaled or regressed. Following many of the tutorials you should have the matrix in your `.raw` slot. ```. gene1 = 'XXX'. gene2 = 'YYY. adata.obs['CoEx'] = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). ```. That will add to your anndata object one more metric, which you can then use to colour your umap plot (i.e. `sc.pl.umap(adata, color='CoEx')`). . One thing quite annoying with this solution is that you'll end up with a meaningless colorbar on your umap plots. I welcome suggestions on how to improve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:248,interoperability,transform,transformed,248,"I know the question is quite old, but maybe someone else will stumble upon it and in that case, I'd like to give a solution I used with my data. . To check for expression you need to access raw matrix of counts in your data. That is, it can be log transformed and normalised, but shouldn't be scaled or regressed. Following many of the tutorials you should have the matrix in your `.raw` slot. ```. gene1 = 'XXX'. gene2 = 'YYY. adata.obs['CoEx'] = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). ```. That will add to your anndata object one more metric, which you can then use to colour your umap plot (i.e. `sc.pl.umap(adata, color='CoEx')`). . One thing quite annoying with this solution is that you'll end up with a meaningless colorbar on your umap plots. I welcome suggestions on how to improve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:466,interoperability,format,format,466,"I know the question is quite old, but maybe someone else will stumble upon it and in that case, I'd like to give a solution I used with my data. . To check for expression you need to access raw matrix of counts in your data. That is, it can be log transformed and normalised, but shouldn't be scaled or regressed. Following many of the tutorials you should have the matrix in your `.raw` slot. ```. gene1 = 'XXX'. gene2 = 'YYY. adata.obs['CoEx'] = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). ```. That will add to your anndata object one more metric, which you can then use to colour your umap plot (i.e. `sc.pl.umap(adata, color='CoEx')`). . One thing quite annoying with this solution is that you'll end up with a meaningless colorbar on your umap plots. I welcome suggestions on how to improve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:519,interoperability,format,format,519,"I know the question is quite old, but maybe someone else will stumble upon it and in that case, I'd like to give a solution I used with my data. . To check for expression you need to access raw matrix of counts in your data. That is, it can be log transformed and normalised, but shouldn't be scaled or regressed. Following many of the tutorials you should have the matrix in your `.raw` slot. ```. gene1 = 'XXX'. gene2 = 'YYY. adata.obs['CoEx'] = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). ```. That will add to your anndata object one more metric, which you can then use to colour your umap plot (i.e. `sc.pl.umap(adata, color='CoEx')`). . One thing quite annoying with this solution is that you'll end up with a meaningless colorbar on your umap plots. I welcome suggestions on how to improve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:293,modifiability,scal,scaled,293,"I know the question is quite old, but maybe someone else will stumble upon it and in that case, I'd like to give a solution I used with my data. . To check for expression you need to access raw matrix of counts in your data. That is, it can be log transformed and normalised, but shouldn't be scaled or regressed. Following many of the tutorials you should have the matrix in your `.raw` slot. ```. gene1 = 'XXX'. gene2 = 'YYY. adata.obs['CoEx'] = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). ```. That will add to your anndata object one more metric, which you can then use to colour your umap plot (i.e. `sc.pl.umap(adata, color='CoEx')`). . One thing quite annoying with this solution is that you'll end up with a meaningless colorbar on your umap plots. I welcome suggestions on how to improve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:293,performance,scale,scaled,293,"I know the question is quite old, but maybe someone else will stumble upon it and in that case, I'd like to give a solution I used with my data. . To check for expression you need to access raw matrix of counts in your data. That is, it can be log transformed and normalised, but shouldn't be scaled or regressed. Following many of the tutorials you should have the matrix in your `.raw` slot. ```. gene1 = 'XXX'. gene2 = 'YYY. adata.obs['CoEx'] = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). ```. That will add to your anndata object one more metric, which you can then use to colour your umap plot (i.e. `sc.pl.umap(adata, color='CoEx')`). . One thing quite annoying with this solution is that you'll end up with a meaningless colorbar on your umap plots. I welcome suggestions on how to improve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:388,reliability,slo,slot,388,"I know the question is quite old, but maybe someone else will stumble upon it and in that case, I'd like to give a solution I used with my data. . To check for expression you need to access raw matrix of counts in your data. That is, it can be log transformed and normalised, but shouldn't be scaled or regressed. Following many of the tutorials you should have the matrix in your `.raw` slot. ```. gene1 = 'XXX'. gene2 = 'YYY. adata.obs['CoEx'] = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). ```. That will add to your anndata object one more metric, which you can then use to colour your umap plot (i.e. `sc.pl.umap(adata, color='CoEx')`). . One thing quite annoying with this solution is that you'll end up with a meaningless colorbar on your umap plots. I welcome suggestions on how to improve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:244,safety,log,log,244,"I know the question is quite old, but maybe someone else will stumble upon it and in that case, I'd like to give a solution I used with my data. . To check for expression you need to access raw matrix of counts in your data. That is, it can be log transformed and normalised, but shouldn't be scaled or regressed. Following many of the tutorials you should have the matrix in your `.raw` slot. ```. gene1 = 'XXX'. gene2 = 'YYY. adata.obs['CoEx'] = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). ```. That will add to your anndata object one more metric, which you can then use to colour your umap plot (i.e. `sc.pl.umap(adata, color='CoEx')`). . One thing quite annoying with this solution is that you'll end up with a meaningless colorbar on your umap plots. I welcome suggestions on how to improve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:183,security,access,access,183,"I know the question is quite old, but maybe someone else will stumble upon it and in that case, I'd like to give a solution I used with my data. . To check for expression you need to access raw matrix of counts in your data. That is, it can be log transformed and normalised, but shouldn't be scaled or regressed. Following many of the tutorials you should have the matrix in your `.raw` slot. ```. gene1 = 'XXX'. gene2 = 'YYY. adata.obs['CoEx'] = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). ```. That will add to your anndata object one more metric, which you can then use to colour your umap plot (i.e. `sc.pl.umap(adata, color='CoEx')`). . One thing quite annoying with this solution is that you'll end up with a meaningless colorbar on your umap plots. I welcome suggestions on how to improve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:244,security,log,log,244,"I know the question is quite old, but maybe someone else will stumble upon it and in that case, I'd like to give a solution I used with my data. . To check for expression you need to access raw matrix of counts in your data. That is, it can be log transformed and normalised, but shouldn't be scaled or regressed. Following many of the tutorials you should have the matrix in your `.raw` slot. ```. gene1 = 'XXX'. gene2 = 'YYY. adata.obs['CoEx'] = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). ```. That will add to your anndata object one more metric, which you can then use to colour your umap plot (i.e. `sc.pl.umap(adata, color='CoEx')`). . One thing quite annoying with this solution is that you'll end up with a meaningless colorbar on your umap plots. I welcome suggestions on how to improve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:244,testability,log,log,244,"I know the question is quite old, but maybe someone else will stumble upon it and in that case, I'd like to give a solution I used with my data. . To check for expression you need to access raw matrix of counts in your data. That is, it can be log transformed and normalised, but shouldn't be scaled or regressed. Following many of the tutorials you should have the matrix in your `.raw` slot. ```. gene1 = 'XXX'. gene2 = 'YYY. adata.obs['CoEx'] = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). ```. That will add to your anndata object one more metric, which you can then use to colour your umap plot (i.e. `sc.pl.umap(adata, color='CoEx')`). . One thing quite annoying with this solution is that you'll end up with a meaningless colorbar on your umap plots. I welcome suggestions on how to improve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:303,testability,regress,regressed,303,"I know the question is quite old, but maybe someone else will stumble upon it and in that case, I'd like to give a solution I used with my data. . To check for expression you need to access raw matrix of counts in your data. That is, it can be log transformed and normalised, but shouldn't be scaled or regressed. Following many of the tutorials you should have the matrix in your `.raw` slot. ```. gene1 = 'XXX'. gene2 = 'YYY. adata.obs['CoEx'] = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). ```. That will add to your anndata object one more metric, which you can then use to colour your umap plot (i.e. `sc.pl.umap(adata, color='CoEx')`). . One thing quite annoying with this solution is that you'll end up with a meaningless colorbar on your umap plots. I welcome suggestions on how to improve it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:264,integrability,sub,subplot,264,"Thank you! I hope this helps people stumbling upon this. By now we have https://scanpy.discourse.group which is the better place for questions like that :+1: . About the colorbar thing, you could just deep-dive into the plot object and remove it:. ```py. ax = plt.subplot(). sc.pl.xx(..., ax=ax). ax.images.im[-1].colorbar.remove(). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:23,usability,help,helps,23,"Thank you! I hope this helps people stumbling upon this. By now we have https://scanpy.discourse.group which is the better place for questions like that :+1: . About the colorbar thing, you could just deep-dive into the plot object and remove it:. ```py. ax = plt.subplot(). sc.pl.xx(..., ax=ax). ax.images.im[-1].colorbar.remove(). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:32,testability,simpl,simple,32,"Hi @GMaciag,. This looks like a simple function that people may like to use. Do you want to write a small helper function for this maybe? This might be nice to add to `sc.tl`. One way you could make it display nicely in `sc.pl.umap()` is by turning the values into `pd.Categorical`. In the end you want to show which cells are co-expressing your genes. . Also, this may be a good use for imputation methods. Otherwise you may struggle with the sparsity of the data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:32,usability,simpl,simple,32,"Hi @GMaciag,. This looks like a simple function that people may like to use. Do you want to write a small helper function for this maybe? This might be nice to add to `sc.tl`. One way you could make it display nicely in `sc.pl.umap()` is by turning the values into `pd.Categorical`. In the end you want to show which cells are co-expressing your genes. . Also, this may be a good use for imputation methods. Otherwise you may struggle with the sparsity of the data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:106,usability,help,helper,106,"Hi @GMaciag,. This looks like a simple function that people may like to use. Do you want to write a small helper function for this maybe? This might be nice to add to `sc.tl`. One way you could make it display nicely in `sc.pl.umap()` is by turning the values into `pd.Categorical`. In the end you want to show which cells are co-expressing your genes. . Also, this may be a good use for imputation methods. Otherwise you may struggle with the sparsity of the data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:798,availability,avail,available,798,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)? 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression? 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. . 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already? And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:155,deployability,modul,module,155,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)? 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression? 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. . 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already? And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:391,deployability,integr,integrated,391,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)? 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression? 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. . 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already? And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:78,integrability,coupl,couple,78,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)? 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression? 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. . 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already? And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:391,integrability,integr,integrated,391,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)? 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression? 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. . 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already? And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:391,interoperability,integr,integrated,391,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)? 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression? 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. . 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already? And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:78,modifiability,coupl,couple,78,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)? 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression? 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. . 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already? And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:155,modifiability,modul,module,155,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)? 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression? 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. . 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already? And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:391,modifiability,integr,integrated,391,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)? 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression? 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. . 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already? And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:40,performance,time,time,40,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)? 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression? 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. . 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already? And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:391,reliability,integr,integrated,391,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)? 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression? 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. . 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already? And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:659,reliability,doe,doesn,659,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)? 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression? 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. . 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already? And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:798,reliability,availab,available,798,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)? 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression? 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. . 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already? And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:155,safety,modul,module,155,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)? 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression? 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. . 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already? And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:798,safety,avail,available,798,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)? 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression? 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. . 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already? And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:391,security,integr,integrated,391,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)? 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression? 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. . 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already? And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:798,security,availab,available,798,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)? 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression? 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. . 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already? And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:78,testability,coupl,couple,78,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)? 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression? 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. . 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already? And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:391,testability,integr,integrated,391,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)? 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression? 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. . 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already? And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:149,usability,tool,tools,149,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)? 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression? 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. . 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already? And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:667,usability,help,help,667,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)? 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression? 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. . 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already? And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:954,usability,help,helps,954,"Hi @LuckyMD,. Sure, I'll work on it, as time allows. Before however, I have a couple of questions. . 1. Do you want it as a separate .py file in the tools module (similar to _dendrogram.py)? 2. I also found interesting to look at exclusive expression of one gene and not the other. Would you be interested in adding a function for that as well and if so, should be a separate one or somehow integrated with coexpression? 3. Turning values into categorical works, however now I have problem that the True (coexpressing) cells are not always plotted on top. Do you know how to do it in scanpy? I tried by setting `pd.Categorical(ordered = True)`, however, that doesn't help. . 4. Could you elucidate on how you want to implement the imputation methods? I've never used them myself. Is there anything available in scanpy already? And thanks @flying-sheep for showing how to remove the colourbar. I wanted to do it for some of my other plots, so that really helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:121,deployability,continu,continuous,121,"Regarding Q3 from my previous comment, I tried few things and I think it is the easiest to keep the coexpression data as continuous and remove the colorbar afterwards. . I have, however, correction to what what was written before. `ax.images.im[-1].colorbar.remove()` doesn't work (in the case of umap) since it is a scatter plot. `ax.collections[-1].colorbar.remove()` needs to be used instead.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:268,reliability,doe,doesn,268,"Regarding Q3 from my previous comment, I tried few things and I think it is the easiest to keep the coexpression data as continuous and remove the colorbar afterwards. . I have, however, correction to what what was written before. `ax.images.im[-1].colorbar.remove()` doesn't work (in the case of umap) since it is a scatter plot. `ax.collections[-1].colorbar.remove()` needs to be used instead.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:288,deployability,continu,continuous,288,"Hey! Sorry for the late reply:. 1. Yes, a separate file, please. 2. Put both in the same function. I wouldn't call it coexpression though. Something along the lines of `cell_selection_by_genes()` or just `cell_selection()`. 3. There is a `sort_order` keyword for plotting which works for continuous covariates. I imagine that should work. 4. That may be overkill... but it would definitely be interesting. I think MAGIC is in `sc.external` and DCA is also easily usable in this framework. They are not part of the core package though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:514,energy efficiency,core,core,514,"Hey! Sorry for the late reply:. 1. Yes, a separate file, please. 2. Put both in the same function. I wouldn't call it coexpression though. Something along the lines of `cell_selection_by_genes()` or just `cell_selection()`. 3. There is a `sort_order` keyword for plotting which works for continuous covariates. I imagine that should work. 4. That may be overkill... but it would definitely be interesting. I think MAGIC is in `sc.external` and DCA is also easily usable in this framework. They are not part of the core package though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:519,modifiability,pac,package,519,"Hey! Sorry for the late reply:. 1. Yes, a separate file, please. 2. Put both in the same function. I wouldn't call it coexpression though. Something along the lines of `cell_selection_by_genes()` or just `cell_selection()`. 3. There is a `sort_order` keyword for plotting which works for continuous covariates. I imagine that should work. 4. That may be overkill... but it would definitely be interesting. I think MAGIC is in `sc.external` and DCA is also easily usable in this framework. They are not part of the core package though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:463,usability,usab,usable,463,"Hey! Sorry for the late reply:. 1. Yes, a separate file, please. 2. Put both in the same function. I wouldn't call it coexpression though. Something along the lines of `cell_selection_by_genes()` or just `cell_selection()`. 3. There is a `sort_order` keyword for plotting which works for continuous covariates. I imagine that should work. 4. That may be overkill... but it would definitely be interesting. I think MAGIC is in `sc.external` and DCA is also easily usable in this framework. They are not part of the core package though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:418,availability,cluster,clusters,418,"Hey! . This. ```. gene1 = 'XXX'. gene2 = 'YYY. adata.obs['CoEx'] = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). ```. was very helpful, thanks for posting, @GMaciag ! Is there a similar way to split the dataset into gene1/gene2+ and gene1/gene2- cells, so that both of the categories are within 'CoEx' and you could compare them to each other just like leiden clusters for example?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:418,deployability,cluster,clusters,418,"Hey! . This. ```. gene1 = 'XXX'. gene2 = 'YYY. adata.obs['CoEx'] = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). ```. was very helpful, thanks for posting, @GMaciag ! Is there a similar way to split the dataset into gene1/gene2+ and gene1/gene2- cells, so that both of the categories are within 'CoEx' and you could compare them to each other just like leiden clusters for example?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:85,interoperability,format,format,85,"Hey! . This. ```. gene1 = 'XXX'. gene2 = 'YYY. adata.obs['CoEx'] = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). ```. was very helpful, thanks for posting, @GMaciag ! Is there a similar way to split the dataset into gene1/gene2+ and gene1/gene2- cells, so that both of the categories are within 'CoEx' and you could compare them to each other just like leiden clusters for example?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:138,interoperability,format,format,138,"Hey! . This. ```. gene1 = 'XXX'. gene2 = 'YYY. adata.obs['CoEx'] = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). ```. was very helpful, thanks for posting, @GMaciag ! Is there a similar way to split the dataset into gene1/gene2+ and gene1/gene2- cells, so that both of the categories are within 'CoEx' and you could compare them to each other just like leiden clusters for example?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:185,usability,help,helpful,185,"Hey! . This. ```. gene1 = 'XXX'. gene2 = 'YYY. adata.obs['CoEx'] = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). ```. was very helpful, thanks for posting, @GMaciag ! Is there a similar way to split the dataset into gene1/gene2+ and gene1/gene2- cells, so that both of the categories are within 'CoEx' and you could compare them to each other just like leiden clusters for example?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:67,deployability,continu,continuous,67,"Hi @natalkon . If you mean to plot them as categories instead of a continuous scale, then the solution is to turn the values into `pd.Categorical` like LuckyMD mentioned. . ```. coex = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). coex_list = [item for sublist in coex.tolist() for item in sublist]. adata.obs['CoEx'] = pd.Categorical(coex_list, categories=[True, False]). ``` . Like I mentioned before, one problem is that the `True` (coexpressing) cells are not always plotted on top when plotting both categories with umap. A better way of visualising is to make use of the `groups` parameter:. ```. sc.pl.umap(adata, color='CoEx', groups=[True]). ```. It will then grey out all the `False` cells and put them in the background.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:78,deployability,scale,scale,78,"Hi @natalkon . If you mean to plot them as categories instead of a continuous scale, then the solution is to turn the values into `pd.Categorical` like LuckyMD mentioned. . ```. coex = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). coex_list = [item for sublist in coex.tolist() for item in sublist]. adata.obs['CoEx'] = pd.Categorical(coex_list, categories=[True, False]). ``` . Like I mentioned before, one problem is that the `True` (coexpressing) cells are not always plotted on top when plotting both categories with umap. A better way of visualising is to make use of the `groups` parameter:. ```. sc.pl.umap(adata, color='CoEx', groups=[True]). ```. It will then grey out all the `False` cells and put them in the background.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:78,energy efficiency,scale,scale,78,"Hi @natalkon . If you mean to plot them as categories instead of a continuous scale, then the solution is to turn the values into `pd.Categorical` like LuckyMD mentioned. . ```. coex = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). coex_list = [item for sublist in coex.tolist() for item in sublist]. adata.obs['CoEx'] = pd.Categorical(coex_list, categories=[True, False]). ``` . Like I mentioned before, one problem is that the `True` (coexpressing) cells are not always plotted on top when plotting both categories with umap. A better way of visualising is to make use of the `groups` parameter:. ```. sc.pl.umap(adata, color='CoEx', groups=[True]). ```. It will then grey out all the `False` cells and put them in the background.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:311,integrability,sub,sublist,311,"Hi @natalkon . If you mean to plot them as categories instead of a continuous scale, then the solution is to turn the values into `pd.Categorical` like LuckyMD mentioned. . ```. coex = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). coex_list = [item for sublist in coex.tolist() for item in sublist]. adata.obs['CoEx'] = pd.Categorical(coex_list, categories=[True, False]). ``` . Like I mentioned before, one problem is that the `True` (coexpressing) cells are not always plotted on top when plotting both categories with umap. A better way of visualising is to make use of the `groups` parameter:. ```. sc.pl.umap(adata, color='CoEx', groups=[True]). ```. It will then grey out all the `False` cells and put them in the background.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:348,integrability,sub,sublist,348,"Hi @natalkon . If you mean to plot them as categories instead of a continuous scale, then the solution is to turn the values into `pd.Categorical` like LuckyMD mentioned. . ```. coex = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). coex_list = [item for sublist in coex.tolist() for item in sublist]. adata.obs['CoEx'] = pd.Categorical(coex_list, categories=[True, False]). ``` . Like I mentioned before, one problem is that the `True` (coexpressing) cells are not always plotted on top when plotting both categories with umap. A better way of visualising is to make use of the `groups` parameter:. ```. sc.pl.umap(adata, color='CoEx', groups=[True]). ```. It will then grey out all the `False` cells and put them in the background.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:203,interoperability,format,format,203,"Hi @natalkon . If you mean to plot them as categories instead of a continuous scale, then the solution is to turn the values into `pd.Categorical` like LuckyMD mentioned. . ```. coex = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). coex_list = [item for sublist in coex.tolist() for item in sublist]. adata.obs['CoEx'] = pd.Categorical(coex_list, categories=[True, False]). ``` . Like I mentioned before, one problem is that the `True` (coexpressing) cells are not always plotted on top when plotting both categories with umap. A better way of visualising is to make use of the `groups` parameter:. ```. sc.pl.umap(adata, color='CoEx', groups=[True]). ```. It will then grey out all the `False` cells and put them in the background.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:256,interoperability,format,format,256,"Hi @natalkon . If you mean to plot them as categories instead of a continuous scale, then the solution is to turn the values into `pd.Categorical` like LuckyMD mentioned. . ```. coex = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). coex_list = [item for sublist in coex.tolist() for item in sublist]. adata.obs['CoEx'] = pd.Categorical(coex_list, categories=[True, False]). ``` . Like I mentioned before, one problem is that the `True` (coexpressing) cells are not always plotted on top when plotting both categories with umap. A better way of visualising is to make use of the `groups` parameter:. ```. sc.pl.umap(adata, color='CoEx', groups=[True]). ```. It will then grey out all the `False` cells and put them in the background.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:78,modifiability,scal,scale,78,"Hi @natalkon . If you mean to plot them as categories instead of a continuous scale, then the solution is to turn the values into `pd.Categorical` like LuckyMD mentioned. . ```. coex = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). coex_list = [item for sublist in coex.tolist() for item in sublist]. adata.obs['CoEx'] = pd.Categorical(coex_list, categories=[True, False]). ``` . Like I mentioned before, one problem is that the `True` (coexpressing) cells are not always plotted on top when plotting both categories with umap. A better way of visualising is to make use of the `groups` parameter:. ```. sc.pl.umap(adata, color='CoEx', groups=[True]). ```. It will then grey out all the `False` cells and put them in the background.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:644,modifiability,paramet,parameter,644,"Hi @natalkon . If you mean to plot them as categories instead of a continuous scale, then the solution is to turn the values into `pd.Categorical` like LuckyMD mentioned. . ```. coex = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). coex_list = [item for sublist in coex.tolist() for item in sublist]. adata.obs['CoEx'] = pd.Categorical(coex_list, categories=[True, False]). ``` . Like I mentioned before, one problem is that the `True` (coexpressing) cells are not always plotted on top when plotting both categories with umap. A better way of visualising is to make use of the `groups` parameter:. ```. sc.pl.umap(adata, color='CoEx', groups=[True]). ```. It will then grey out all the `False` cells and put them in the background.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:78,performance,scale,scale,78,"Hi @natalkon . If you mean to plot them as categories instead of a continuous scale, then the solution is to turn the values into `pd.Categorical` like LuckyMD mentioned. . ```. coex = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). coex_list = [item for sublist in coex.tolist() for item in sublist]. adata.obs['CoEx'] = pd.Categorical(coex_list, categories=[True, False]). ``` . Like I mentioned before, one problem is that the `True` (coexpressing) cells are not always plotted on top when plotting both categories with umap. A better way of visualising is to make use of the `groups` parameter:. ```. sc.pl.umap(adata, color='CoEx', groups=[True]). ```. It will then grey out all the `False` cells and put them in the background.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:601,usability,visual,visualising,601,"Hi @natalkon . If you mean to plot them as categories instead of a continuous scale, then the solution is to turn the values into `pd.Categorical` like LuckyMD mentioned. . ```. coex = (adata.raw[:,'{}'.format(gene1)].X.todense() > 0) &. (adata.raw[:,'{}'.format(gene2)].X.todense() > 0). coex_list = [item for sublist in coex.tolist() for item in sublist]. adata.obs['CoEx'] = pd.Categorical(coex_list, categories=[True, False]). ``` . Like I mentioned before, one problem is that the `True` (coexpressing) cells are not always plotted on top when plotting both categories with umap. A better way of visualising is to make use of the `groups` parameter:. ```. sc.pl.umap(adata, color='CoEx', groups=[True]). ```. It will then grey out all the `False` cells and put them in the background.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:336,modifiability,pac,package,336,"Hi. It's been a long time since the initial talk about writing a function addressing this issue, but with the whole pandemic situation I totally forgot about it. But the recent comments made me remember and so I finished writing it and put it in the PR #1657. I hope it can be useful to other people and maybe even included in the main package :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:21,performance,time,time,21,"Hi. It's been a long time since the initial talk about writing a function addressing this issue, but with the whole pandemic situation I totally forgot about it. But the recent comments made me remember and so I finished writing it and put it in the PR #1657. I hope it can be useful to other people and maybe even included in the main package :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/490:194,safety,reme,remember,194,"Hi. It's been a long time since the initial talk about writing a function addressing this issue, but with the whole pandemic situation I totally forgot about it. But the recent comments made me remember and so I finished writing it and put it in the PR #1657. I hope it can be useful to other people and maybe even included in the main package :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/490
https://github.com/scverse/scanpy/issues/491:174,availability,cluster,clustering,174,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:224,availability,cluster,clusters,224,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:237,availability,cluster,clusters,237,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:414,availability,cluster,clustering,414,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:587,availability,cluster,cluster,587,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:754,availability,cluster,clusters,754,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:905,availability,cluster,clusters,905,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:1029,availability,cluster,clusters,1029,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:61,deployability,depend,depends,61,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:115,deployability,depend,depending,115,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:174,deployability,cluster,clustering,174,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:224,deployability,cluster,clusters,224,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:237,deployability,cluster,clusters,237,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:414,deployability,cluster,clustering,414,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:587,deployability,cluster,cluster,587,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:754,deployability,cluster,clusters,754,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:905,deployability,cluster,clusters,905,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:1029,deployability,cluster,clusters,1029,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:566,energy efficiency,model,model,566,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:1403,energy efficiency,measur,measure,1403,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:61,integrability,depend,depends,61,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:115,integrability,depend,depending,115,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:268,integrability,sub,sub-structure,268,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:312,integrability,sub,sub,312,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:865,integrability,sub,sub,865,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:1124,interoperability,distribut,distribution,1124,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:61,modifiability,depend,depends,61,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:115,modifiability,depend,depending,115,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:155,modifiability,paramet,parameter,155,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:619,reliability,doe,does,619,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:838,reliability,doe,does,838,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:1243,reliability,doe,does,1243,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:61,safety,depend,depends,61,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:115,safety,depend,depending,115,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:92,security,ident,identity,92,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:458,security,assess,assessment,458,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:566,security,model,model,566,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:795,security,sign,signatures,795,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:999,security,assess,assessing,999,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:61,testability,depend,depends,61,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:115,testability,depend,depending,115,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:961,usability,clear,clearer,961,"Hi,. Your question is actually quite difficult to answer. It depends on how you define cell identity. For example, depending on how you set the resolution parameter for your clustering you can get a very different number of clusters. As clusters often have super- and sub-structure, you cannot easily say when a sub- or superstructure is not meaningful (e.g., T-cells vs CD4+ and CD8+ T-cells). Unfortunately many clustering techniques do not incorporate an assessment of uncertainty to tell you when you are fitting noise. And even when they do, this is based on a model of what a cell cluster should look like, which does not have to conform to the biological reality. The heuristic that tends to be used is that if you can biologically interpret your clusters based on marker genes and other signatures, then they are meaningful. That does however not mean that sub- or superstructures involving these clusters are not also meaningful. Sorry, I can't give a clearer answer than that. In terms of assessing differences between clusters, this is a somewhat related problem. An approach that you could use is to look at the distribution of Euclidean distances in gene- or PCA-space. However, that comes with the caveat that Euclidean distance does not take into account the biological manifold on which the cells lie (and on which distances will be more informative). You can try to use pseudotime as a measure for distance over this manifold, however that would require you to have sampled enough of the manifold to fit it in your data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/491:122,usability,help,helps,122,@LuckyMD Thanks for your detailed reply. I will try some of the approaches mentioned in the 2nd paragraph and see if that helps us answer our question. Thanks.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/491
https://github.com/scverse/scanpy/issues/492:522,deployability,scale,scale,522,"Hi,. I'm not entirely sure how Seurat does it, but I assume you could take the mean expression level (or mean z-score) of a couple of genes, store that in a `.var` column, and regress that out by `sc.pp.regress_out(adata, var_col)`? Something like this:. ```. adata.var['genes_of_interest'] = adata.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. If you want to ensure an equal contribution of all the genes to the gene score without weighting by mean gene expression, you could first use `sc.pp.scale()` on a copy of the `adata` object like this:. ```. adata_tmp = adata.copy(). sc.pp.scale(adata_tmp). adata.var['genes_of_interest'] = adata_tmp.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. Note that I have not tested this code... so no guarantees ;).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/492
https://github.com/scverse/scanpy/issues/492:612,deployability,scale,scale,612,"Hi,. I'm not entirely sure how Seurat does it, but I assume you could take the mean expression level (or mean z-score) of a couple of genes, store that in a `.var` column, and regress that out by `sc.pp.regress_out(adata, var_col)`? Something like this:. ```. adata.var['genes_of_interest'] = adata.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. If you want to ensure an equal contribution of all the genes to the gene score without weighting by mean gene expression, you could first use `sc.pp.scale()` on a copy of the `adata` object like this:. ```. adata_tmp = adata.copy(). sc.pp.scale(adata_tmp). adata.var['genes_of_interest'] = adata_tmp.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. Note that I have not tested this code... so no guarantees ;).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/492
https://github.com/scverse/scanpy/issues/492:522,energy efficiency,scale,scale,522,"Hi,. I'm not entirely sure how Seurat does it, but I assume you could take the mean expression level (or mean z-score) of a couple of genes, store that in a `.var` column, and regress that out by `sc.pp.regress_out(adata, var_col)`? Something like this:. ```. adata.var['genes_of_interest'] = adata.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. If you want to ensure an equal contribution of all the genes to the gene score without weighting by mean gene expression, you could first use `sc.pp.scale()` on a copy of the `adata` object like this:. ```. adata_tmp = adata.copy(). sc.pp.scale(adata_tmp). adata.var['genes_of_interest'] = adata_tmp.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. Note that I have not tested this code... so no guarantees ;).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/492
https://github.com/scverse/scanpy/issues/492:612,energy efficiency,scale,scale,612,"Hi,. I'm not entirely sure how Seurat does it, but I assume you could take the mean expression level (or mean z-score) of a couple of genes, store that in a `.var` column, and regress that out by `sc.pp.regress_out(adata, var_col)`? Something like this:. ```. adata.var['genes_of_interest'] = adata.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. If you want to ensure an equal contribution of all the genes to the gene score without weighting by mean gene expression, you could first use `sc.pp.scale()` on a copy of the `adata` object like this:. ```. adata_tmp = adata.copy(). sc.pp.scale(adata_tmp). adata.var['genes_of_interest'] = adata_tmp.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. Note that I have not tested this code... so no guarantees ;).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/492
https://github.com/scverse/scanpy/issues/492:124,integrability,coupl,couple,124,"Hi,. I'm not entirely sure how Seurat does it, but I assume you could take the mean expression level (or mean z-score) of a couple of genes, store that in a `.var` column, and regress that out by `sc.pp.regress_out(adata, var_col)`? Something like this:. ```. adata.var['genes_of_interest'] = adata.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. If you want to ensure an equal contribution of all the genes to the gene score without weighting by mean gene expression, you could first use `sc.pp.scale()` on a copy of the `adata` object like this:. ```. adata_tmp = adata.copy(). sc.pp.scale(adata_tmp). adata.var['genes_of_interest'] = adata_tmp.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. Note that I have not tested this code... so no guarantees ;).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/492
https://github.com/scverse/scanpy/issues/492:124,modifiability,coupl,couple,124,"Hi,. I'm not entirely sure how Seurat does it, but I assume you could take the mean expression level (or mean z-score) of a couple of genes, store that in a `.var` column, and regress that out by `sc.pp.regress_out(adata, var_col)`? Something like this:. ```. adata.var['genes_of_interest'] = adata.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. If you want to ensure an equal contribution of all the genes to the gene score without weighting by mean gene expression, you could first use `sc.pp.scale()` on a copy of the `adata` object like this:. ```. adata_tmp = adata.copy(). sc.pp.scale(adata_tmp). adata.var['genes_of_interest'] = adata_tmp.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. Note that I have not tested this code... so no guarantees ;).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/492
https://github.com/scverse/scanpy/issues/492:522,modifiability,scal,scale,522,"Hi,. I'm not entirely sure how Seurat does it, but I assume you could take the mean expression level (or mean z-score) of a couple of genes, store that in a `.var` column, and regress that out by `sc.pp.regress_out(adata, var_col)`? Something like this:. ```. adata.var['genes_of_interest'] = adata.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. If you want to ensure an equal contribution of all the genes to the gene score without weighting by mean gene expression, you could first use `sc.pp.scale()` on a copy of the `adata` object like this:. ```. adata_tmp = adata.copy(). sc.pp.scale(adata_tmp). adata.var['genes_of_interest'] = adata_tmp.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. Note that I have not tested this code... so no guarantees ;).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/492
https://github.com/scverse/scanpy/issues/492:612,modifiability,scal,scale,612,"Hi,. I'm not entirely sure how Seurat does it, but I assume you could take the mean expression level (or mean z-score) of a couple of genes, store that in a `.var` column, and regress that out by `sc.pp.regress_out(adata, var_col)`? Something like this:. ```. adata.var['genes_of_interest'] = adata.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. If you want to ensure an equal contribution of all the genes to the gene score without weighting by mean gene expression, you could first use `sc.pp.scale()` on a copy of the `adata` object like this:. ```. adata_tmp = adata.copy(). sc.pp.scale(adata_tmp). adata.var['genes_of_interest'] = adata_tmp.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. Note that I have not tested this code... so no guarantees ;).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/492
https://github.com/scverse/scanpy/issues/492:522,performance,scale,scale,522,"Hi,. I'm not entirely sure how Seurat does it, but I assume you could take the mean expression level (or mean z-score) of a couple of genes, store that in a `.var` column, and regress that out by `sc.pp.regress_out(adata, var_col)`? Something like this:. ```. adata.var['genes_of_interest'] = adata.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. If you want to ensure an equal contribution of all the genes to the gene score without weighting by mean gene expression, you could first use `sc.pp.scale()` on a copy of the `adata` object like this:. ```. adata_tmp = adata.copy(). sc.pp.scale(adata_tmp). adata.var['genes_of_interest'] = adata_tmp.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. Note that I have not tested this code... so no guarantees ;).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/492
https://github.com/scverse/scanpy/issues/492:612,performance,scale,scale,612,"Hi,. I'm not entirely sure how Seurat does it, but I assume you could take the mean expression level (or mean z-score) of a couple of genes, store that in a `.var` column, and regress that out by `sc.pp.regress_out(adata, var_col)`? Something like this:. ```. adata.var['genes_of_interest'] = adata.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. If you want to ensure an equal contribution of all the genes to the gene score without weighting by mean gene expression, you could first use `sc.pp.scale()` on a copy of the `adata` object like this:. ```. adata_tmp = adata.copy(). sc.pp.scale(adata_tmp). adata.var['genes_of_interest'] = adata_tmp.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. Note that I have not tested this code... so no guarantees ;).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/492
https://github.com/scverse/scanpy/issues/492:38,reliability,doe,does,38,"Hi,. I'm not entirely sure how Seurat does it, but I assume you could take the mean expression level (or mean z-score) of a couple of genes, store that in a `.var` column, and regress that out by `sc.pp.regress_out(adata, var_col)`? Something like this:. ```. adata.var['genes_of_interest'] = adata.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. If you want to ensure an equal contribution of all the genes to the gene score without weighting by mean gene expression, you could first use `sc.pp.scale()` on a copy of the `adata` object like this:. ```. adata_tmp = adata.copy(). sc.pp.scale(adata_tmp). adata.var['genes_of_interest'] = adata_tmp.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. Note that I have not tested this code... so no guarantees ;).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/492
https://github.com/scverse/scanpy/issues/492:768,safety,test,tested,768,"Hi,. I'm not entirely sure how Seurat does it, but I assume you could take the mean expression level (or mean z-score) of a couple of genes, store that in a `.var` column, and regress that out by `sc.pp.regress_out(adata, var_col)`? Something like this:. ```. adata.var['genes_of_interest'] = adata.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. If you want to ensure an equal contribution of all the genes to the gene score without weighting by mean gene expression, you could first use `sc.pp.scale()` on a copy of the `adata` object like this:. ```. adata_tmp = adata.copy(). sc.pp.scale(adata_tmp). adata.var['genes_of_interest'] = adata_tmp.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. Note that I have not tested this code... so no guarantees ;).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/492
https://github.com/scverse/scanpy/issues/492:124,testability,coupl,couple,124,"Hi,. I'm not entirely sure how Seurat does it, but I assume you could take the mean expression level (or mean z-score) of a couple of genes, store that in a `.var` column, and regress that out by `sc.pp.regress_out(adata, var_col)`? Something like this:. ```. adata.var['genes_of_interest'] = adata.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. If you want to ensure an equal contribution of all the genes to the gene score without weighting by mean gene expression, you could first use `sc.pp.scale()` on a copy of the `adata` object like this:. ```. adata_tmp = adata.copy(). sc.pp.scale(adata_tmp). adata.var['genes_of_interest'] = adata_tmp.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. Note that I have not tested this code... so no guarantees ;).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/492
https://github.com/scverse/scanpy/issues/492:176,testability,regress,regress,176,"Hi,. I'm not entirely sure how Seurat does it, but I assume you could take the mean expression level (or mean z-score) of a couple of genes, store that in a `.var` column, and regress that out by `sc.pp.regress_out(adata, var_col)`? Something like this:. ```. adata.var['genes_of_interest'] = adata.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. If you want to ensure an equal contribution of all the genes to the gene score without weighting by mean gene expression, you could first use `sc.pp.scale()` on a copy of the `adata` object like this:. ```. adata_tmp = adata.copy(). sc.pp.scale(adata_tmp). adata.var['genes_of_interest'] = adata_tmp.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. Note that I have not tested this code... so no guarantees ;).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/492
https://github.com/scverse/scanpy/issues/492:768,testability,test,tested,768,"Hi,. I'm not entirely sure how Seurat does it, but I assume you could take the mean expression level (or mean z-score) of a couple of genes, store that in a `.var` column, and regress that out by `sc.pp.regress_out(adata, var_col)`? Something like this:. ```. adata.var['genes_of_interest'] = adata.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. If you want to ensure an equal contribution of all the genes to the gene score without weighting by mean gene expression, you could first use `sc.pp.scale()` on a copy of the `adata` object like this:. ```. adata_tmp = adata.copy(). sc.pp.scale(adata_tmp). adata.var['genes_of_interest'] = adata_tmp.X[:,gene_list].mean(0). sc.pp.regress_out(adata, genes_of_interest). ```. Note that I have not tested this code... so no guarantees ;).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/492
https://github.com/scverse/scanpy/issues/492:143,availability,error,errors,143,"This would be very easy to implement with: `sc.get.obs_df(adata, keys)`. That would not solve the problem of (I believe) constant genes giving errors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/492
https://github.com/scverse/scanpy/issues/492:143,performance,error,errors,143,"This would be very easy to implement with: `sc.get.obs_df(adata, keys)`. That would not solve the problem of (I believe) constant genes giving errors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/492
https://github.com/scverse/scanpy/issues/492:143,safety,error,errors,143,"This would be very easy to implement with: `sc.get.obs_df(adata, keys)`. That would not solve the problem of (I believe) constant genes giving errors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/492
https://github.com/scverse/scanpy/issues/492:143,usability,error,errors,143,"This would be very easy to implement with: `sc.get.obs_df(adata, keys)`. That would not solve the problem of (I believe) constant genes giving errors.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/492
https://github.com/scverse/scanpy/pull/493:152,integrability,wrap,wrapper,152,"Thank you for this, @awnimo! I added a few small comments. Could you move the whole code into `scanpy/external/_tools`, please? We'll transition to all wrapper code for external code to be in that directory. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:152,interoperability,wrapper,wrapper,152,"Thank you for this, @awnimo! I added a few small comments. Could you move the whole code into `scanpy/external/_tools`, please? We'll transition to all wrapper code for external code to be in that directory. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:160,integrability,wrap,wrapper,160,"> Thank you for this, @awnimo! I added a few small comments. > . > Could you move the whole code into `scanpy/external/_tools`, please? We'll transition to all wrapper code for external code to be in that directory. Thank you! Hey @falexwolf ,. I have completed the changes you requestedI. Please let me know if there are any other issues. Thank you",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:160,interoperability,wrapper,wrapper,160,"> Thank you for this, @awnimo! I added a few small comments. > . > Could you move the whole code into `scanpy/external/_tools`, please? We'll transition to all wrapper code for external code to be in that directory. Thank you! Hey @falexwolf ,. I have completed the changes you requestedI. Please let me know if there are any other issues. Thank you",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:252,safety,compl,completed,252,"> Thank you for this, @awnimo! I added a few small comments. > . > Could you move the whole code into `scanpy/external/_tools`, please? We'll transition to all wrapper code for external code to be in that directory. Thank you! Hey @falexwolf ,. I have completed the changes you requestedI. Please let me know if there are any other issues. Thank you",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:252,security,compl,completed,252,"> Thank you for this, @awnimo! I added a few small comments. > . > Could you move the whole code into `scanpy/external/_tools`, please? We'll transition to all wrapper code for external code to be in that directory. Thank you! Hey @falexwolf ,. I have completed the changes you requestedI. Please let me know if there are any other issues. Thank you",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:155,availability,error,error,155,"Hi, I am trying to use palantir. I've updated by `pip install git+https://github.com/theislab/scanpy.git`. when I try to import scanpy I get the following error: . ModuleNotFoundError: No module named 'scanpy.external._tools'. I'm fairly new to python packaging. Apologies if this is an issue with my install method. also not an expert with github project managment. Will gladly post this elsewhere if better. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:38,deployability,updat,updated,38,"Hi, I am trying to use palantir. I've updated by `pip install git+https://github.com/theislab/scanpy.git`. when I try to import scanpy I get the following error: . ModuleNotFoundError: No module named 'scanpy.external._tools'. I'm fairly new to python packaging. Apologies if this is an issue with my install method. also not an expert with github project managment. Will gladly post this elsewhere if better. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:54,deployability,instal,install,54,"Hi, I am trying to use palantir. I've updated by `pip install git+https://github.com/theislab/scanpy.git`. when I try to import scanpy I get the following error: . ModuleNotFoundError: No module named 'scanpy.external._tools'. I'm fairly new to python packaging. Apologies if this is an issue with my install method. also not an expert with github project managment. Will gladly post this elsewhere if better. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:164,deployability,Modul,ModuleNotFoundError,164,"Hi, I am trying to use palantir. I've updated by `pip install git+https://github.com/theislab/scanpy.git`. when I try to import scanpy I get the following error: . ModuleNotFoundError: No module named 'scanpy.external._tools'. I'm fairly new to python packaging. Apologies if this is an issue with my install method. also not an expert with github project managment. Will gladly post this elsewhere if better. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:188,deployability,modul,module,188,"Hi, I am trying to use palantir. I've updated by `pip install git+https://github.com/theislab/scanpy.git`. when I try to import scanpy I get the following error: . ModuleNotFoundError: No module named 'scanpy.external._tools'. I'm fairly new to python packaging. Apologies if this is an issue with my install method. also not an expert with github project managment. Will gladly post this elsewhere if better. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:301,deployability,instal,install,301,"Hi, I am trying to use palantir. I've updated by `pip install git+https://github.com/theislab/scanpy.git`. when I try to import scanpy I get the following error: . ModuleNotFoundError: No module named 'scanpy.external._tools'. I'm fairly new to python packaging. Apologies if this is an issue with my install method. also not an expert with github project managment. Will gladly post this elsewhere if better. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:356,deployability,manag,managment,356,"Hi, I am trying to use palantir. I've updated by `pip install git+https://github.com/theislab/scanpy.git`. when I try to import scanpy I get the following error: . ModuleNotFoundError: No module named 'scanpy.external._tools'. I'm fairly new to python packaging. Apologies if this is an issue with my install method. also not an expert with github project managment. Will gladly post this elsewhere if better. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:356,energy efficiency,manag,managment,356,"Hi, I am trying to use palantir. I've updated by `pip install git+https://github.com/theislab/scanpy.git`. when I try to import scanpy I get the following error: . ModuleNotFoundError: No module named 'scanpy.external._tools'. I'm fairly new to python packaging. Apologies if this is an issue with my install method. also not an expert with github project managment. Will gladly post this elsewhere if better. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:164,modifiability,Modul,ModuleNotFoundError,164,"Hi, I am trying to use palantir. I've updated by `pip install git+https://github.com/theislab/scanpy.git`. when I try to import scanpy I get the following error: . ModuleNotFoundError: No module named 'scanpy.external._tools'. I'm fairly new to python packaging. Apologies if this is an issue with my install method. also not an expert with github project managment. Will gladly post this elsewhere if better. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:188,modifiability,modul,module,188,"Hi, I am trying to use palantir. I've updated by `pip install git+https://github.com/theislab/scanpy.git`. when I try to import scanpy I get the following error: . ModuleNotFoundError: No module named 'scanpy.external._tools'. I'm fairly new to python packaging. Apologies if this is an issue with my install method. also not an expert with github project managment. Will gladly post this elsewhere if better. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:252,modifiability,pac,packaging,252,"Hi, I am trying to use palantir. I've updated by `pip install git+https://github.com/theislab/scanpy.git`. when I try to import scanpy I get the following error: . ModuleNotFoundError: No module named 'scanpy.external._tools'. I'm fairly new to python packaging. Apologies if this is an issue with my install method. also not an expert with github project managment. Will gladly post this elsewhere if better. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:155,performance,error,error,155,"Hi, I am trying to use palantir. I've updated by `pip install git+https://github.com/theislab/scanpy.git`. when I try to import scanpy I get the following error: . ModuleNotFoundError: No module named 'scanpy.external._tools'. I'm fairly new to python packaging. Apologies if this is an issue with my install method. also not an expert with github project managment. Will gladly post this elsewhere if better. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:38,safety,updat,updated,38,"Hi, I am trying to use palantir. I've updated by `pip install git+https://github.com/theislab/scanpy.git`. when I try to import scanpy I get the following error: . ModuleNotFoundError: No module named 'scanpy.external._tools'. I'm fairly new to python packaging. Apologies if this is an issue with my install method. also not an expert with github project managment. Will gladly post this elsewhere if better. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:155,safety,error,error,155,"Hi, I am trying to use palantir. I've updated by `pip install git+https://github.com/theislab/scanpy.git`. when I try to import scanpy I get the following error: . ModuleNotFoundError: No module named 'scanpy.external._tools'. I'm fairly new to python packaging. Apologies if this is an issue with my install method. also not an expert with github project managment. Will gladly post this elsewhere if better. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:164,safety,Modul,ModuleNotFoundError,164,"Hi, I am trying to use palantir. I've updated by `pip install git+https://github.com/theislab/scanpy.git`. when I try to import scanpy I get the following error: . ModuleNotFoundError: No module named 'scanpy.external._tools'. I'm fairly new to python packaging. Apologies if this is an issue with my install method. also not an expert with github project managment. Will gladly post this elsewhere if better. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:188,safety,modul,module,188,"Hi, I am trying to use palantir. I've updated by `pip install git+https://github.com/theislab/scanpy.git`. when I try to import scanpy I get the following error: . ModuleNotFoundError: No module named 'scanpy.external._tools'. I'm fairly new to python packaging. Apologies if this is an issue with my install method. also not an expert with github project managment. Will gladly post this elsewhere if better. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:356,safety,manag,managment,356,"Hi, I am trying to use palantir. I've updated by `pip install git+https://github.com/theislab/scanpy.git`. when I try to import scanpy I get the following error: . ModuleNotFoundError: No module named 'scanpy.external._tools'. I'm fairly new to python packaging. Apologies if this is an issue with my install method. also not an expert with github project managment. Will gladly post this elsewhere if better. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:38,security,updat,updated,38,"Hi, I am trying to use palantir. I've updated by `pip install git+https://github.com/theislab/scanpy.git`. when I try to import scanpy I get the following error: . ModuleNotFoundError: No module named 'scanpy.external._tools'. I'm fairly new to python packaging. Apologies if this is an issue with my install method. also not an expert with github project managment. Will gladly post this elsewhere if better. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:155,usability,error,error,155,"Hi, I am trying to use palantir. I've updated by `pip install git+https://github.com/theislab/scanpy.git`. when I try to import scanpy I get the following error: . ModuleNotFoundError: No module named 'scanpy.external._tools'. I'm fairly new to python packaging. Apologies if this is an issue with my install method. also not an expert with github project managment. Will gladly post this elsewhere if better. . Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:25,deployability,releas,released,25,"Palantir is not yet in a released version: https://scanpy.readthedocs.io/en/latest/#on-master-march-21-2019. We'll soon have 1.4.1. Until then, you need to install from GitHub as described in the installation section. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:34,deployability,version,version,34,"Palantir is not yet in a released version: https://scanpy.readthedocs.io/en/latest/#on-master-march-21-2019. We'll soon have 1.4.1. Until then, you need to install from GitHub as described in the installation section. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:156,deployability,instal,install,156,"Palantir is not yet in a released version: https://scanpy.readthedocs.io/en/latest/#on-master-march-21-2019. We'll soon have 1.4.1. Until then, you need to install from GitHub as described in the installation section. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:196,deployability,instal,installation,196,"Palantir is not yet in a released version: https://scanpy.readthedocs.io/en/latest/#on-master-march-21-2019. We'll soon have 1.4.1. Until then, you need to install from GitHub as described in the installation section. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:34,integrability,version,version,34,"Palantir is not yet in a released version: https://scanpy.readthedocs.io/en/latest/#on-master-march-21-2019. We'll soon have 1.4.1. Until then, you need to install from GitHub as described in the installation section. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:34,modifiability,version,version,34,"Palantir is not yet in a released version: https://scanpy.readthedocs.io/en/latest/#on-master-march-21-2019. We'll soon have 1.4.1. Until then, you need to install from GitHub as described in the installation section. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/493:31,deployability,instal,installation,31,Should’ve checked the docs for installation. Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/493
https://github.com/scverse/scanpy/pull/494:15,safety,test,test,15,Great! so that test succeeded because it was testing the wrong thing?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/494
https://github.com/scverse/scanpy/pull/494:45,safety,test,testing,45,Great! so that test succeeded because it was testing the wrong thing?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/494
https://github.com/scverse/scanpy/pull/494:15,testability,test,test,15,Great! so that test succeeded because it was testing the wrong thing?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/494
https://github.com/scverse/scanpy/pull/494:45,testability,test,testing,45,Great! so that test succeeded because it was testing the wrong thing?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/494
https://github.com/scverse/scanpy/pull/494:46,safety,test,testing,46,"It would've succeeded anyways, it just wasn't testing the right thing",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/494
https://github.com/scverse/scanpy/pull/494:46,testability,test,testing,46,"It would've succeeded anyways, it just wasn't testing the right thing",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/494
https://github.com/scverse/scanpy/issues/498:21,energy efficiency,Current,Currently,21,This would be great. Currently I have no reference for what color value corresponds to what color. Any plans on adding it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/498
https://github.com/scverse/scanpy/issues/498:103,testability,plan,plans,103,This would be great. Currently I have no reference for what color value corresponds to what color. Any plans on adding it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/498
https://github.com/scverse/scanpy/issues/501:168,deployability,api,api,168,"@juje11, sorry about the late response. When I try `sc.pp.filter_genes` on `v1.3.7` and `v1.4.0` I get similar results. Here's what I've run:. ```python. import scanpy.api as sc # For v1.3.7. import scanpy as sc # For v1.4+. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_counts=2, copy=True). ```. In both v1.3.7 and v1.4 I get an AnnData object with 14745 genes. If this issue is still occurring, could you please make a [minimal example](http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) of it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:168,integrability,api,api,168,"@juje11, sorry about the late response. When I try `sc.pp.filter_genes` on `v1.3.7` and `v1.4.0` I get similar results. Here's what I've run:. ```python. import scanpy.api as sc # For v1.3.7. import scanpy as sc # For v1.4+. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_counts=2, copy=True). ```. In both v1.3.7 and v1.4 I get an AnnData object with 14745 genes. If this issue is still occurring, could you please make a [minimal example](http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) of it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:168,interoperability,api,api,168,"@juje11, sorry about the late response. When I try `sc.pp.filter_genes` on `v1.3.7` and `v1.4.0` I get similar results. Here's what I've run:. ```python. import scanpy.api as sc # For v1.3.7. import scanpy as sc # For v1.4+. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_counts=2, copy=True). ```. In both v1.3.7 and v1.4 I get an AnnData object with 14745 genes. If this issue is still occurring, could you please make a [minimal example](http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) of it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:437,usability,minim,minimal,437,"@juje11, sorry about the late response. When I try `sc.pp.filter_genes` on `v1.3.7` and `v1.4.0` I get similar results. Here's what I've run:. ```python. import scanpy.api as sc # For v1.3.7. import scanpy as sc # For v1.4+. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_counts=2, copy=True). ```. In both v1.3.7 and v1.4 I get an AnnData object with 14745 genes. If this issue is still occurring, could you please make a [minimal example](http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) of it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:501,usability,minim,minimal-bug-reports,501,"@juje11, sorry about the late response. When I try `sc.pp.filter_genes` on `v1.3.7` and `v1.4.0` I get similar results. Here's what I've run:. ```python. import scanpy.api as sc # For v1.3.7. import scanpy as sc # For v1.4+. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_counts=2, copy=True). ```. In both v1.3.7 and v1.4 I get an AnnData object with 14745 genes. If this issue is still occurring, could you please make a [minimal example](http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) of it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:2655,availability,operat,operated,2655,"tps-3A__github.com_juje11&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=5bKOSfSlkv9Uce14pst-S4M9PLk9PbUDb-KLnmlG1XQ&e=>, sorry about the late response. When I try sc.pp.filter_genes on v1.3.7 and v1.4.0 I get similar results. Here's what I've run:. import scanpy.api as sc # For v1.3.7. import scanpy as sc # For v1.4+. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_counts=2, copy=True). In both v1.3.7 and v1.4 I get an AnnData object with 14745 genes. If this issue is still occurring, could you please make a minimal example<https://urldefense.proofpoint.com/v2/url?u=http-3A__matthewrocklin.com_blog_work_2018_02_28_minimal-2Dbug-2Dreports&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=oJMtygAOyhk8ZPZcm62kP5CexheJuyltsmNZvUlUUJc&e=> of it? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_issues_501-23issuecomment-2D478308491&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=aB9cPrQNETcGloYdbFBtgQwH6PNEJ2uCaq6qo20M-14&e=>, or mute the thread<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_AoHInGDcz6S1cG3BkoNqcx4W7nD44kdrks5vcCosgaJpZM4bJs2l&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=E9-QONI3u257owTiYKSUmNqyODuD4airosKV1vUji-Q&e=>. -- . The Wellcome Sanger Institute is operated by Genome Research . Limited, a charity registered in England with number 1021457 and a . company registered in England with number 2742969, whose registered . office is 215 Euston Road, London, NW1 2BE.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:39,deployability,version,version,39,"Hey,. I had to fully switch to the new version to pursue my analysis. I have not tried since. The thing is the minimum count of genes to have the function running was not the same between the 2 versions. For v1.3.7 I could do min_counts=2. For v1.4.0, I had to go for min_counts=4 otherwise the function was not running. I have fully switch to the version 4 now, but this seems weird to me. Thank you very much. Best regards. Julie. From: Isaac Virshup <notifications@github.com>. Reply-To: theislab/scanpy <reply@reply.github.com>. Date: Sunday, March 31, 2019 at 4:23 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Julie Jerber <jj11@sanger.ac.uk>, Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] sc.pp.filter don't filter the same number between sc.1.3.7 and sc.1.4 (#501) [EXT]. @juje11<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_juje11&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=5bKOSfSlkv9Uce14pst-S4M9PLk9PbUDb-KLnmlG1XQ&e=>, sorry about the late response. When I try sc.pp.filter_genes on v1.3.7 and v1.4.0 I get similar results. Here's what I've run:. import scanpy.api as sc # For v1.3.7. import scanpy as sc # For v1.4+. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_counts=2, copy=True). In both v1.3.7 and v1.4 I get an AnnData object with 14745 genes. If this issue is still occurring, could you please make a minimal example<https://urldefense.proofpoint.com/v2/url?u=http-3A__matthewrocklin.com_blog_work_2018_02_28_minimal-2Dbug-2Dreports&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=oJMtygAOyhk8ZPZcm62kP5CexheJuyltsmNZvUlUUJc&e=> of it? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_th",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:194,deployability,version,versions,194,"Hey,. I had to fully switch to the new version to pursue my analysis. I have not tried since. The thing is the minimum count of genes to have the function running was not the same between the 2 versions. For v1.3.7 I could do min_counts=2. For v1.4.0, I had to go for min_counts=4 otherwise the function was not running. I have fully switch to the version 4 now, but this seems weird to me. Thank you very much. Best regards. Julie. From: Isaac Virshup <notifications@github.com>. Reply-To: theislab/scanpy <reply@reply.github.com>. Date: Sunday, March 31, 2019 at 4:23 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Julie Jerber <jj11@sanger.ac.uk>, Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] sc.pp.filter don't filter the same number between sc.1.3.7 and sc.1.4 (#501) [EXT]. @juje11<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_juje11&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=5bKOSfSlkv9Uce14pst-S4M9PLk9PbUDb-KLnmlG1XQ&e=>, sorry about the late response. When I try sc.pp.filter_genes on v1.3.7 and v1.4.0 I get similar results. Here's what I've run:. import scanpy.api as sc # For v1.3.7. import scanpy as sc # For v1.4+. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_counts=2, copy=True). In both v1.3.7 and v1.4 I get an AnnData object with 14745 genes. If this issue is still occurring, could you please make a minimal example<https://urldefense.proofpoint.com/v2/url?u=http-3A__matthewrocklin.com_blog_work_2018_02_28_minimal-2Dbug-2Dreports&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=oJMtygAOyhk8ZPZcm62kP5CexheJuyltsmNZvUlUUJc&e=> of it? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_th",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:348,deployability,version,version,348,"Hey,. I had to fully switch to the new version to pursue my analysis. I have not tried since. The thing is the minimum count of genes to have the function running was not the same between the 2 versions. For v1.3.7 I could do min_counts=2. For v1.4.0, I had to go for min_counts=4 otherwise the function was not running. I have fully switch to the version 4 now, but this seems weird to me. Thank you very much. Best regards. Julie. From: Isaac Virshup <notifications@github.com>. Reply-To: theislab/scanpy <reply@reply.github.com>. Date: Sunday, March 31, 2019 at 4:23 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Julie Jerber <jj11@sanger.ac.uk>, Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] sc.pp.filter don't filter the same number between sc.1.3.7 and sc.1.4 (#501) [EXT]. @juje11<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_juje11&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=5bKOSfSlkv9Uce14pst-S4M9PLk9PbUDb-KLnmlG1XQ&e=>, sorry about the late response. When I try sc.pp.filter_genes on v1.3.7 and v1.4.0 I get similar results. Here's what I've run:. import scanpy.api as sc # For v1.3.7. import scanpy as sc # For v1.4+. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_counts=2, copy=True). In both v1.3.7 and v1.4 I get an AnnData object with 14745 genes. If this issue is still occurring, could you please make a minimal example<https://urldefense.proofpoint.com/v2/url?u=http-3A__matthewrocklin.com_blog_work_2018_02_28_minimal-2Dbug-2Dreports&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=oJMtygAOyhk8ZPZcm62kP5CexheJuyltsmNZvUlUUJc&e=> of it? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_th",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:1233,deployability,api,api,1233,"s=2. For v1.4.0, I had to go for min_counts=4 otherwise the function was not running. I have fully switch to the version 4 now, but this seems weird to me. Thank you very much. Best regards. Julie. From: Isaac Virshup <notifications@github.com>. Reply-To: theislab/scanpy <reply@reply.github.com>. Date: Sunday, March 31, 2019 at 4:23 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Julie Jerber <jj11@sanger.ac.uk>, Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] sc.pp.filter don't filter the same number between sc.1.3.7 and sc.1.4 (#501) [EXT]. @juje11<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_juje11&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=5bKOSfSlkv9Uce14pst-S4M9PLk9PbUDb-KLnmlG1XQ&e=>, sorry about the late response. When I try sc.pp.filter_genes on v1.3.7 and v1.4.0 I get similar results. Here's what I've run:. import scanpy.api as sc # For v1.3.7. import scanpy as sc # For v1.4+. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_counts=2, copy=True). In both v1.3.7 and v1.4 I get an AnnData object with 14745 genes. If this issue is still occurring, could you please make a minimal example<https://urldefense.proofpoint.com/v2/url?u=http-3A__matthewrocklin.com_blog_work_2018_02_28_minimal-2Dbug-2Dreports&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=oJMtygAOyhk8ZPZcm62kP5CexheJuyltsmNZvUlUUJc&e=> of it? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_issues_501-23issuecomment-2D478308491&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=aB9cPrQNETcGloYdbFBtgQwH6PNEJ2uCaq",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:39,integrability,version,version,39,"Hey,. I had to fully switch to the new version to pursue my analysis. I have not tried since. The thing is the minimum count of genes to have the function running was not the same between the 2 versions. For v1.3.7 I could do min_counts=2. For v1.4.0, I had to go for min_counts=4 otherwise the function was not running. I have fully switch to the version 4 now, but this seems weird to me. Thank you very much. Best regards. Julie. From: Isaac Virshup <notifications@github.com>. Reply-To: theislab/scanpy <reply@reply.github.com>. Date: Sunday, March 31, 2019 at 4:23 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Julie Jerber <jj11@sanger.ac.uk>, Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] sc.pp.filter don't filter the same number between sc.1.3.7 and sc.1.4 (#501) [EXT]. @juje11<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_juje11&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=5bKOSfSlkv9Uce14pst-S4M9PLk9PbUDb-KLnmlG1XQ&e=>, sorry about the late response. When I try sc.pp.filter_genes on v1.3.7 and v1.4.0 I get similar results. Here's what I've run:. import scanpy.api as sc # For v1.3.7. import scanpy as sc # For v1.4+. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_counts=2, copy=True). In both v1.3.7 and v1.4 I get an AnnData object with 14745 genes. If this issue is still occurring, could you please make a minimal example<https://urldefense.proofpoint.com/v2/url?u=http-3A__matthewrocklin.com_blog_work_2018_02_28_minimal-2Dbug-2Dreports&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=oJMtygAOyhk8ZPZcm62kP5CexheJuyltsmNZvUlUUJc&e=> of it? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_th",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:194,integrability,version,versions,194,"Hey,. I had to fully switch to the new version to pursue my analysis. I have not tried since. The thing is the minimum count of genes to have the function running was not the same between the 2 versions. For v1.3.7 I could do min_counts=2. For v1.4.0, I had to go for min_counts=4 otherwise the function was not running. I have fully switch to the version 4 now, but this seems weird to me. Thank you very much. Best regards. Julie. From: Isaac Virshup <notifications@github.com>. Reply-To: theislab/scanpy <reply@reply.github.com>. Date: Sunday, March 31, 2019 at 4:23 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Julie Jerber <jj11@sanger.ac.uk>, Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] sc.pp.filter don't filter the same number between sc.1.3.7 and sc.1.4 (#501) [EXT]. @juje11<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_juje11&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=5bKOSfSlkv9Uce14pst-S4M9PLk9PbUDb-KLnmlG1XQ&e=>, sorry about the late response. When I try sc.pp.filter_genes on v1.3.7 and v1.4.0 I get similar results. Here's what I've run:. import scanpy.api as sc # For v1.3.7. import scanpy as sc # For v1.4+. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_counts=2, copy=True). In both v1.3.7 and v1.4 I get an AnnData object with 14745 genes. If this issue is still occurring, could you please make a minimal example<https://urldefense.proofpoint.com/v2/url?u=http-3A__matthewrocklin.com_blog_work_2018_02_28_minimal-2Dbug-2Dreports&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=oJMtygAOyhk8ZPZcm62kP5CexheJuyltsmNZvUlUUJc&e=> of it? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_th",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:348,integrability,version,version,348,"Hey,. I had to fully switch to the new version to pursue my analysis. I have not tried since. The thing is the minimum count of genes to have the function running was not the same between the 2 versions. For v1.3.7 I could do min_counts=2. For v1.4.0, I had to go for min_counts=4 otherwise the function was not running. I have fully switch to the version 4 now, but this seems weird to me. Thank you very much. Best regards. Julie. From: Isaac Virshup <notifications@github.com>. Reply-To: theislab/scanpy <reply@reply.github.com>. Date: Sunday, March 31, 2019 at 4:23 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Julie Jerber <jj11@sanger.ac.uk>, Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] sc.pp.filter don't filter the same number between sc.1.3.7 and sc.1.4 (#501) [EXT]. @juje11<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_juje11&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=5bKOSfSlkv9Uce14pst-S4M9PLk9PbUDb-KLnmlG1XQ&e=>, sorry about the late response. When I try sc.pp.filter_genes on v1.3.7 and v1.4.0 I get similar results. Here's what I've run:. import scanpy.api as sc # For v1.3.7. import scanpy as sc # For v1.4+. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_counts=2, copy=True). In both v1.3.7 and v1.4 I get an AnnData object with 14745 genes. If this issue is still occurring, could you please make a minimal example<https://urldefense.proofpoint.com/v2/url?u=http-3A__matthewrocklin.com_blog_work_2018_02_28_minimal-2Dbug-2Dreports&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=oJMtygAOyhk8ZPZcm62kP5CexheJuyltsmNZvUlUUJc&e=> of it? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_th",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:699,integrability,Sub,Subject,699,"Hey,. I had to fully switch to the new version to pursue my analysis. I have not tried since. The thing is the minimum count of genes to have the function running was not the same between the 2 versions. For v1.3.7 I could do min_counts=2. For v1.4.0, I had to go for min_counts=4 otherwise the function was not running. I have fully switch to the version 4 now, but this seems weird to me. Thank you very much. Best regards. Julie. From: Isaac Virshup <notifications@github.com>. Reply-To: theislab/scanpy <reply@reply.github.com>. Date: Sunday, March 31, 2019 at 4:23 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Julie Jerber <jj11@sanger.ac.uk>, Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] sc.pp.filter don't filter the same number between sc.1.3.7 and sc.1.4 (#501) [EXT]. @juje11<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_juje11&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=5bKOSfSlkv9Uce14pst-S4M9PLk9PbUDb-KLnmlG1XQ&e=>, sorry about the late response. When I try sc.pp.filter_genes on v1.3.7 and v1.4.0 I get similar results. Here's what I've run:. import scanpy.api as sc # For v1.3.7. import scanpy as sc # For v1.4+. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_counts=2, copy=True). In both v1.3.7 and v1.4 I get an AnnData object with 14745 genes. If this issue is still occurring, could you please make a minimal example<https://urldefense.proofpoint.com/v2/url?u=http-3A__matthewrocklin.com_blog_work_2018_02_28_minimal-2Dbug-2Dreports&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=oJMtygAOyhk8ZPZcm62kP5CexheJuyltsmNZvUlUUJc&e=> of it? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_th",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:736,integrability,filter,filter,736,"Hey,. I had to fully switch to the new version to pursue my analysis. I have not tried since. The thing is the minimum count of genes to have the function running was not the same between the 2 versions. For v1.3.7 I could do min_counts=2. For v1.4.0, I had to go for min_counts=4 otherwise the function was not running. I have fully switch to the version 4 now, but this seems weird to me. Thank you very much. Best regards. Julie. From: Isaac Virshup <notifications@github.com>. Reply-To: theislab/scanpy <reply@reply.github.com>. Date: Sunday, March 31, 2019 at 4:23 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Julie Jerber <jj11@sanger.ac.uk>, Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] sc.pp.filter don't filter the same number between sc.1.3.7 and sc.1.4 (#501) [EXT]. @juje11<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_juje11&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=5bKOSfSlkv9Uce14pst-S4M9PLk9PbUDb-KLnmlG1XQ&e=>, sorry about the late response. When I try sc.pp.filter_genes on v1.3.7 and v1.4.0 I get similar results. Here's what I've run:. import scanpy.api as sc # For v1.3.7. import scanpy as sc # For v1.4+. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_counts=2, copy=True). In both v1.3.7 and v1.4 I get an AnnData object with 14745 genes. If this issue is still occurring, could you please make a minimal example<https://urldefense.proofpoint.com/v2/url?u=http-3A__matthewrocklin.com_blog_work_2018_02_28_minimal-2Dbug-2Dreports&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=oJMtygAOyhk8ZPZcm62kP5CexheJuyltsmNZvUlUUJc&e=> of it? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_th",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:749,integrability,filter,filter,749,"Hey,. I had to fully switch to the new version to pursue my analysis. I have not tried since. The thing is the minimum count of genes to have the function running was not the same between the 2 versions. For v1.3.7 I could do min_counts=2. For v1.4.0, I had to go for min_counts=4 otherwise the function was not running. I have fully switch to the version 4 now, but this seems weird to me. Thank you very much. Best regards. Julie. From: Isaac Virshup <notifications@github.com>. Reply-To: theislab/scanpy <reply@reply.github.com>. Date: Sunday, March 31, 2019 at 4:23 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Julie Jerber <jj11@sanger.ac.uk>, Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] sc.pp.filter don't filter the same number between sc.1.3.7 and sc.1.4 (#501) [EXT]. @juje11<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_juje11&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=5bKOSfSlkv9Uce14pst-S4M9PLk9PbUDb-KLnmlG1XQ&e=>, sorry about the late response. When I try sc.pp.filter_genes on v1.3.7 and v1.4.0 I get similar results. Here's what I've run:. import scanpy.api as sc # For v1.3.7. import scanpy as sc # For v1.4+. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_counts=2, copy=True). In both v1.3.7 and v1.4 I get an AnnData object with 14745 genes. If this issue is still occurring, could you please make a minimal example<https://urldefense.proofpoint.com/v2/url?u=http-3A__matthewrocklin.com_blog_work_2018_02_28_minimal-2Dbug-2Dreports&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=oJMtygAOyhk8ZPZcm62kP5CexheJuyltsmNZvUlUUJc&e=> of it? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_th",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:1233,integrability,api,api,1233,"s=2. For v1.4.0, I had to go for min_counts=4 otherwise the function was not running. I have fully switch to the version 4 now, but this seems weird to me. Thank you very much. Best regards. Julie. From: Isaac Virshup <notifications@github.com>. Reply-To: theislab/scanpy <reply@reply.github.com>. Date: Sunday, March 31, 2019 at 4:23 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Julie Jerber <jj11@sanger.ac.uk>, Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] sc.pp.filter don't filter the same number between sc.1.3.7 and sc.1.4 (#501) [EXT]. @juje11<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_juje11&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=5bKOSfSlkv9Uce14pst-S4M9PLk9PbUDb-KLnmlG1XQ&e=>, sorry about the late response. When I try sc.pp.filter_genes on v1.3.7 and v1.4.0 I get similar results. Here's what I've run:. import scanpy.api as sc # For v1.3.7. import scanpy as sc # For v1.4+. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_counts=2, copy=True). In both v1.3.7 and v1.4 I get an AnnData object with 14745 genes. If this issue is still occurring, could you please make a minimal example<https://urldefense.proofpoint.com/v2/url?u=http-3A__matthewrocklin.com_blog_work_2018_02_28_minimal-2Dbug-2Dreports&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=oJMtygAOyhk8ZPZcm62kP5CexheJuyltsmNZvUlUUJc&e=> of it? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_issues_501-23issuecomment-2D478308491&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=aB9cPrQNETcGloYdbFBtgQwH6PNEJ2uCaq",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:1233,interoperability,api,api,1233,"s=2. For v1.4.0, I had to go for min_counts=4 otherwise the function was not running. I have fully switch to the version 4 now, but this seems weird to me. Thank you very much. Best regards. Julie. From: Isaac Virshup <notifications@github.com>. Reply-To: theislab/scanpy <reply@reply.github.com>. Date: Sunday, March 31, 2019 at 4:23 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Julie Jerber <jj11@sanger.ac.uk>, Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] sc.pp.filter don't filter the same number between sc.1.3.7 and sc.1.4 (#501) [EXT]. @juje11<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_juje11&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=5bKOSfSlkv9Uce14pst-S4M9PLk9PbUDb-KLnmlG1XQ&e=>, sorry about the late response. When I try sc.pp.filter_genes on v1.3.7 and v1.4.0 I get similar results. Here's what I've run:. import scanpy.api as sc # For v1.3.7. import scanpy as sc # For v1.4+. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_counts=2, copy=True). In both v1.3.7 and v1.4 I get an AnnData object with 14745 genes. If this issue is still occurring, could you please make a minimal example<https://urldefense.proofpoint.com/v2/url?u=http-3A__matthewrocklin.com_blog_work_2018_02_28_minimal-2Dbug-2Dreports&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=oJMtygAOyhk8ZPZcm62kP5CexheJuyltsmNZvUlUUJc&e=> of it? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_issues_501-23issuecomment-2D478308491&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=aB9cPrQNETcGloYdbFBtgQwH6PNEJ2uCaq",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:39,modifiability,version,version,39,"Hey,. I had to fully switch to the new version to pursue my analysis. I have not tried since. The thing is the minimum count of genes to have the function running was not the same between the 2 versions. For v1.3.7 I could do min_counts=2. For v1.4.0, I had to go for min_counts=4 otherwise the function was not running. I have fully switch to the version 4 now, but this seems weird to me. Thank you very much. Best regards. Julie. From: Isaac Virshup <notifications@github.com>. Reply-To: theislab/scanpy <reply@reply.github.com>. Date: Sunday, March 31, 2019 at 4:23 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Julie Jerber <jj11@sanger.ac.uk>, Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] sc.pp.filter don't filter the same number between sc.1.3.7 and sc.1.4 (#501) [EXT]. @juje11<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_juje11&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=5bKOSfSlkv9Uce14pst-S4M9PLk9PbUDb-KLnmlG1XQ&e=>, sorry about the late response. When I try sc.pp.filter_genes on v1.3.7 and v1.4.0 I get similar results. Here's what I've run:. import scanpy.api as sc # For v1.3.7. import scanpy as sc # For v1.4+. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_counts=2, copy=True). In both v1.3.7 and v1.4 I get an AnnData object with 14745 genes. If this issue is still occurring, could you please make a minimal example<https://urldefense.proofpoint.com/v2/url?u=http-3A__matthewrocklin.com_blog_work_2018_02_28_minimal-2Dbug-2Dreports&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=oJMtygAOyhk8ZPZcm62kP5CexheJuyltsmNZvUlUUJc&e=> of it? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_th",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:194,modifiability,version,versions,194,"Hey,. I had to fully switch to the new version to pursue my analysis. I have not tried since. The thing is the minimum count of genes to have the function running was not the same between the 2 versions. For v1.3.7 I could do min_counts=2. For v1.4.0, I had to go for min_counts=4 otherwise the function was not running. I have fully switch to the version 4 now, but this seems weird to me. Thank you very much. Best regards. Julie. From: Isaac Virshup <notifications@github.com>. Reply-To: theislab/scanpy <reply@reply.github.com>. Date: Sunday, March 31, 2019 at 4:23 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Julie Jerber <jj11@sanger.ac.uk>, Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] sc.pp.filter don't filter the same number between sc.1.3.7 and sc.1.4 (#501) [EXT]. @juje11<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_juje11&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=5bKOSfSlkv9Uce14pst-S4M9PLk9PbUDb-KLnmlG1XQ&e=>, sorry about the late response. When I try sc.pp.filter_genes on v1.3.7 and v1.4.0 I get similar results. Here's what I've run:. import scanpy.api as sc # For v1.3.7. import scanpy as sc # For v1.4+. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_counts=2, copy=True). In both v1.3.7 and v1.4 I get an AnnData object with 14745 genes. If this issue is still occurring, could you please make a minimal example<https://urldefense.proofpoint.com/v2/url?u=http-3A__matthewrocklin.com_blog_work_2018_02_28_minimal-2Dbug-2Dreports&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=oJMtygAOyhk8ZPZcm62kP5CexheJuyltsmNZvUlUUJc&e=> of it? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_th",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:348,modifiability,version,version,348,"Hey,. I had to fully switch to the new version to pursue my analysis. I have not tried since. The thing is the minimum count of genes to have the function running was not the same between the 2 versions. For v1.3.7 I could do min_counts=2. For v1.4.0, I had to go for min_counts=4 otherwise the function was not running. I have fully switch to the version 4 now, but this seems weird to me. Thank you very much. Best regards. Julie. From: Isaac Virshup <notifications@github.com>. Reply-To: theislab/scanpy <reply@reply.github.com>. Date: Sunday, March 31, 2019 at 4:23 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Julie Jerber <jj11@sanger.ac.uk>, Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] sc.pp.filter don't filter the same number between sc.1.3.7 and sc.1.4 (#501) [EXT]. @juje11<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_juje11&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=5bKOSfSlkv9Uce14pst-S4M9PLk9PbUDb-KLnmlG1XQ&e=>, sorry about the late response. When I try sc.pp.filter_genes on v1.3.7 and v1.4.0 I get similar results. Here's what I've run:. import scanpy.api as sc # For v1.3.7. import scanpy as sc # For v1.4+. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_counts=2, copy=True). In both v1.3.7 and v1.4 I get an AnnData object with 14745 genes. If this issue is still occurring, could you please make a minimal example<https://urldefense.proofpoint.com/v2/url?u=http-3A__matthewrocklin.com_blog_work_2018_02_28_minimal-2Dbug-2Dreports&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=oJMtygAOyhk8ZPZcm62kP5CexheJuyltsmNZvUlUUJc&e=> of it? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_th",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:111,usability,minim,minimum,111,"Hey,. I had to fully switch to the new version to pursue my analysis. I have not tried since. The thing is the minimum count of genes to have the function running was not the same between the 2 versions. For v1.3.7 I could do min_counts=2. For v1.4.0, I had to go for min_counts=4 otherwise the function was not running. I have fully switch to the version 4 now, but this seems weird to me. Thank you very much. Best regards. Julie. From: Isaac Virshup <notifications@github.com>. Reply-To: theislab/scanpy <reply@reply.github.com>. Date: Sunday, March 31, 2019 at 4:23 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Julie Jerber <jj11@sanger.ac.uk>, Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] sc.pp.filter don't filter the same number between sc.1.3.7 and sc.1.4 (#501) [EXT]. @juje11<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_juje11&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=5bKOSfSlkv9Uce14pst-S4M9PLk9PbUDb-KLnmlG1XQ&e=>, sorry about the late response. When I try sc.pp.filter_genes on v1.3.7 and v1.4.0 I get similar results. Here's what I've run:. import scanpy.api as sc # For v1.3.7. import scanpy as sc # For v1.4+. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_counts=2, copy=True). In both v1.3.7 and v1.4 I get an AnnData object with 14745 genes. If this issue is still occurring, could you please make a minimal example<https://urldefense.proofpoint.com/v2/url?u=http-3A__matthewrocklin.com_blog_work_2018_02_28_minimal-2Dbug-2Dreports&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=oJMtygAOyhk8ZPZcm62kP5CexheJuyltsmNZvUlUUJc&e=> of it? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_th",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:1496,usability,minim,minimal,1496,"scanpy <reply@reply.github.com>. Date: Sunday, March 31, 2019 at 4:23 AM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Julie Jerber <jj11@sanger.ac.uk>, Mention <mention@noreply.github.com>. Subject: Re: [theislab/scanpy] sc.pp.filter don't filter the same number between sc.1.3.7 and sc.1.4 (#501) [EXT]. @juje11<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_juje11&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=5bKOSfSlkv9Uce14pst-S4M9PLk9PbUDb-KLnmlG1XQ&e=>, sorry about the late response. When I try sc.pp.filter_genes on v1.3.7 and v1.4.0 I get similar results. Here's what I've run:. import scanpy.api as sc # For v1.3.7. import scanpy as sc # For v1.4+. adata = sc.datasets.pbmc3k(). sc.pp.filter_genes(adata, min_counts=2, copy=True). In both v1.3.7 and v1.4 I get an AnnData object with 14745 genes. If this issue is still occurring, could you please make a minimal example<https://urldefense.proofpoint.com/v2/url?u=http-3A__matthewrocklin.com_blog_work_2018_02_28_minimal-2Dbug-2Dreports&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=oJMtygAOyhk8ZPZcm62kP5CexheJuyltsmNZvUlUUJc&e=> of it? —. You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_theislab_scanpy_issues_501-23issuecomment-2D478308491&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLqFBDi2-dzqKkGr2omow4&m=fUrr9FKs_IHJat8-KnrKtMZ9rvr6Uj_iRwwW3bbDIWA&s=aB9cPrQNETcGloYdbFBtgQwH6PNEJ2uCaq6qo20M-14&e=>, or mute the thread<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_AoHInGDcz6S1cG3BkoNqcx4W7nD44kdrks5vcCosgaJpZM4bJs2l&d=DwMFaQ&c=D7ByGjS34AllFgecYw0iC6Zq7qlm8uclZFI0SqQnqBo&r=dbbJvBBVCmCDhD23DINgCQLq",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:363,availability,error,error,363,"Hi Julie,. Could it be that you saved your dataset after running `min_counts=2` so that when you reloaded it there were no more genes with `min_counts<2` in the dataset to filter out? . Regarding the minimal example.. it would be good to show the different behaviour in a reproducible way (for example using a dataset from `sc.datasets`). We do not have the same error you do when running the function between scanpy 1.3.7 and 1.4.0.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:172,integrability,filter,filter,172,"Hi Julie,. Could it be that you saved your dataset after running `min_counts=2` so that when you reloaded it there were no more genes with `min_counts<2` in the dataset to filter out? . Regarding the minimal example.. it would be good to show the different behaviour in a reproducible way (for example using a dataset from `sc.datasets`). We do not have the same error you do when running the function between scanpy 1.3.7 and 1.4.0.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:363,performance,error,error,363,"Hi Julie,. Could it be that you saved your dataset after running `min_counts=2` so that when you reloaded it there were no more genes with `min_counts<2` in the dataset to filter out? . Regarding the minimal example.. it would be good to show the different behaviour in a reproducible way (for example using a dataset from `sc.datasets`). We do not have the same error you do when running the function between scanpy 1.3.7 and 1.4.0.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:363,safety,error,error,363,"Hi Julie,. Could it be that you saved your dataset after running `min_counts=2` so that when you reloaded it there were no more genes with `min_counts<2` in the dataset to filter out? . Regarding the minimal example.. it would be good to show the different behaviour in a reproducible way (for example using a dataset from `sc.datasets`). We do not have the same error you do when running the function between scanpy 1.3.7 and 1.4.0.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:200,usability,minim,minimal,200,"Hi Julie,. Could it be that you saved your dataset after running `min_counts=2` so that when you reloaded it there were no more genes with `min_counts<2` in the dataset to filter out? . Regarding the minimal example.. it would be good to show the different behaviour in a reproducible way (for example using a dataset from `sc.datasets`). We do not have the same error you do when running the function between scanpy 1.3.7 and 1.4.0.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:257,usability,behavi,behaviour,257,"Hi Julie,. Could it be that you saved your dataset after running `min_counts=2` so that when you reloaded it there were no more genes with `min_counts<2` in the dataset to filter out? . Regarding the minimal example.. it would be good to show the different behaviour in a reproducible way (for example using a dataset from `sc.datasets`). We do not have the same error you do when running the function between scanpy 1.3.7 and 1.4.0.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:363,usability,error,error,363,"Hi Julie,. Could it be that you saved your dataset after running `min_counts=2` so that when you reloaded it there were no more genes with `min_counts<2` in the dataset to filter out? . Regarding the minimal example.. it would be good to show the different behaviour in a reproducible way (for example using a dataset from `sc.datasets`). We do not have the same error you do when running the function between scanpy 1.3.7 and 1.4.0.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:105,usability,close,close,105,"Just came across this - as we haven't heard back after the followup, and its been quite a while, we will close the issue for now, hopefully you obtained the expected behaviour in the end :). Thanks for being a part of our community! :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/501:166,usability,behavi,behaviour,166,"Just came across this - as we haven't heard back after the followup, and its been quite a while, we will close the issue for now, hopefully you obtained the expected behaviour in the end :). Thanks for being a part of our community! :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/501
https://github.com/scverse/scanpy/issues/502:138,availability,error,error,138,"Just delete MY2L, or use sc.pl.dotplot . . > On 25 Feb 2019, at 18:37, rojin <notifications@github.com> wrote:. > . > I get the following error when I tun dotplot:. > . > `ValueError Traceback (most recent call last). > in (). > ----> 1 sc.pl.rank_genes_groups_dotplot(vitro,['MYL2'], groupby='louvain'). > . > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, key, show, save, **kwds). > 409. > 410 _rank_genes_groups_plot(adata, plot_type='dotplot', groups=groups, n_genes=n_genes,. > --> 411 groupby=groupby, key=key, show=show, save=save, **kwds). > 412. > 413. > . > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). > 291. > 292 # sum(list, []) is used to flatten the gene list. > --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []). > 294. > 295 if plot_type == 'dotplot':. > . > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in (.0). > 291. > 292 # sum(list, []) is used to flatten the gene list. > --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []). > 294. > 295 if plot_type == 'dotplot':. > . > ValueError: no field of name MYL2. > `. > . > Do we need to store marker genes within the adata object? > . > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/502
https://github.com/scverse/scanpy/issues/502:1610,integrability,sub,subscribed,1610,"Just delete MY2L, or use sc.pl.dotplot . . > On 25 Feb 2019, at 18:37, rojin <notifications@github.com> wrote:. > . > I get the following error when I tun dotplot:. > . > `ValueError Traceback (most recent call last). > in (). > ----> 1 sc.pl.rank_genes_groups_dotplot(vitro,['MYL2'], groupby='louvain'). > . > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, key, show, save, **kwds). > 409. > 410 _rank_genes_groups_plot(adata, plot_type='dotplot', groups=groups, n_genes=n_genes,. > --> 411 groupby=groupby, key=key, show=show, save=save, **kwds). > 412. > 413. > . > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). > 291. > 292 # sum(list, []) is used to flatten the gene list. > --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []). > 294. > 295 if plot_type == 'dotplot':. > . > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in (.0). > 291. > 292 # sum(list, []) is used to flatten the gene list. > --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []). > 294. > 295 if plot_type == 'dotplot':. > . > ValueError: no field of name MYL2. > `. > . > Do we need to store marker genes within the adata object? > . > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/502
https://github.com/scverse/scanpy/issues/502:387,modifiability,pac,packages,387,"Just delete MY2L, or use sc.pl.dotplot . . > On 25 Feb 2019, at 18:37, rojin <notifications@github.com> wrote:. > . > I get the following error when I tun dotplot:. > . > `ValueError Traceback (most recent call last). > in (). > ----> 1 sc.pl.rank_genes_groups_dotplot(vitro,['MYL2'], groupby='louvain'). > . > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, key, show, save, **kwds). > 409. > 410 _rank_genes_groups_plot(adata, plot_type='dotplot', groups=groups, n_genes=n_genes,. > --> 411 groupby=groupby, key=key, show=show, save=save, **kwds). > 412. > 413. > . > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). > 291. > 292 # sum(list, []) is used to flatten the gene list. > --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []). > 294. > 295 if plot_type == 'dotplot':. > . > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in (.0). > 291. > 292 # sum(list, []) is used to flatten the gene list. > --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []). > 294. > 295 if plot_type == 'dotplot':. > . > ValueError: no field of name MYL2. > `. > . > Do we need to store marker genes within the adata object? > . > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/502
https://github.com/scverse/scanpy/issues/502:776,modifiability,pac,packages,776,"Just delete MY2L, or use sc.pl.dotplot . . > On 25 Feb 2019, at 18:37, rojin <notifications@github.com> wrote:. > . > I get the following error when I tun dotplot:. > . > `ValueError Traceback (most recent call last). > in (). > ----> 1 sc.pl.rank_genes_groups_dotplot(vitro,['MYL2'], groupby='louvain'). > . > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, key, show, save, **kwds). > 409. > 410 _rank_genes_groups_plot(adata, plot_type='dotplot', groups=groups, n_genes=n_genes,. > --> 411 groupby=groupby, key=key, show=show, save=save, **kwds). > 412. > 413. > . > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). > 291. > 292 # sum(list, []) is used to flatten the gene list. > --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []). > 294. > 295 if plot_type == 'dotplot':. > . > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in (.0). > 291. > 292 # sum(list, []) is used to flatten the gene list. > --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []). > 294. > 295 if plot_type == 'dotplot':. > . > ValueError: no field of name MYL2. > `. > . > Do we need to store marker genes within the adata object? > . > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/502
https://github.com/scverse/scanpy/issues/502:1198,modifiability,pac,packages,1198,"Just delete MY2L, or use sc.pl.dotplot . . > On 25 Feb 2019, at 18:37, rojin <notifications@github.com> wrote:. > . > I get the following error when I tun dotplot:. > . > `ValueError Traceback (most recent call last). > in (). > ----> 1 sc.pl.rank_genes_groups_dotplot(vitro,['MYL2'], groupby='louvain'). > . > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, key, show, save, **kwds). > 409. > 410 _rank_genes_groups_plot(adata, plot_type='dotplot', groups=groups, n_genes=n_genes,. > --> 411 groupby=groupby, key=key, show=show, save=save, **kwds). > 412. > 413. > . > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). > 291. > 292 # sum(list, []) is used to flatten the gene list. > --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []). > 294. > 295 if plot_type == 'dotplot':. > . > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in (.0). > 291. > 292 # sum(list, []) is used to flatten the gene list. > --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []). > 294. > 295 if plot_type == 'dotplot':. > . > ValueError: no field of name MYL2. > `. > . > Do we need to store marker genes within the adata object? > . > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/502
https://github.com/scverse/scanpy/issues/502:138,performance,error,error,138,"Just delete MY2L, or use sc.pl.dotplot . . > On 25 Feb 2019, at 18:37, rojin <notifications@github.com> wrote:. > . > I get the following error when I tun dotplot:. > . > `ValueError Traceback (most recent call last). > in (). > ----> 1 sc.pl.rank_genes_groups_dotplot(vitro,['MYL2'], groupby='louvain'). > . > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, key, show, save, **kwds). > 409. > 410 _rank_genes_groups_plot(adata, plot_type='dotplot', groups=groups, n_genes=n_genes,. > --> 411 groupby=groupby, key=key, show=show, save=save, **kwds). > 412. > 413. > . > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). > 291. > 292 # sum(list, []) is used to flatten the gene list. > --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []). > 294. > 295 if plot_type == 'dotplot':. > . > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in (.0). > 291. > 292 # sum(list, []) is used to flatten the gene list. > --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []). > 294. > 295 if plot_type == 'dotplot':. > . > ValueError: no field of name MYL2. > `. > . > Do we need to store marker genes within the adata object? > . > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/502
https://github.com/scverse/scanpy/issues/502:138,safety,error,error,138,"Just delete MY2L, or use sc.pl.dotplot . . > On 25 Feb 2019, at 18:37, rojin <notifications@github.com> wrote:. > . > I get the following error when I tun dotplot:. > . > `ValueError Traceback (most recent call last). > in (). > ----> 1 sc.pl.rank_genes_groups_dotplot(vitro,['MYL2'], groupby='louvain'). > . > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, key, show, save, **kwds). > 409. > 410 _rank_genes_groups_plot(adata, plot_type='dotplot', groups=groups, n_genes=n_genes,. > --> 411 groupby=groupby, key=key, show=show, save=save, **kwds). > 412. > 413. > . > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). > 291. > 292 # sum(list, []) is used to flatten the gene list. > --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []). > 294. > 295 if plot_type == 'dotplot':. > . > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in (.0). > 291. > 292 # sum(list, []) is used to flatten the gene list. > --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []). > 294. > 295 if plot_type == 'dotplot':. > . > ValueError: no field of name MYL2. > `. > . > Do we need to store marker genes within the adata object? > . > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/502
https://github.com/scverse/scanpy/issues/502:183,testability,Trace,Traceback,183,"Just delete MY2L, or use sc.pl.dotplot . . > On 25 Feb 2019, at 18:37, rojin <notifications@github.com> wrote:. > . > I get the following error when I tun dotplot:. > . > `ValueError Traceback (most recent call last). > in (). > ----> 1 sc.pl.rank_genes_groups_dotplot(vitro,['MYL2'], groupby='louvain'). > . > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, key, show, save, **kwds). > 409. > 410 _rank_genes_groups_plot(adata, plot_type='dotplot', groups=groups, n_genes=n_genes,. > --> 411 groupby=groupby, key=key, show=show, save=save, **kwds). > 412. > 413. > . > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). > 291. > 292 # sum(list, []) is used to flatten the gene list. > --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []). > 294. > 295 if plot_type == 'dotplot':. > . > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in (.0). > 291. > 292 # sum(list, []) is used to flatten the gene list. > --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []). > 294. > 295 if plot_type == 'dotplot':. > . > ValueError: no field of name MYL2. > `. > . > Do we need to store marker genes within the adata object? > . > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/502
https://github.com/scverse/scanpy/issues/502:138,usability,error,error,138,"Just delete MY2L, or use sc.pl.dotplot . . > On 25 Feb 2019, at 18:37, rojin <notifications@github.com> wrote:. > . > I get the following error when I tun dotplot:. > . > `ValueError Traceback (most recent call last). > in (). > ----> 1 sc.pl.rank_genes_groups_dotplot(vitro,['MYL2'], groupby='louvain'). > . > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in rank_genes_groups_dotplot(adata, groups, n_genes, groupby, key, show, save, **kwds). > 409. > 410 _rank_genes_groups_plot(adata, plot_type='dotplot', groups=groups, n_genes=n_genes,. > --> 411 groupby=groupby, key=key, show=show, save=save, **kwds). > 412. > 413. > . > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in _rank_genes_groups_plot(adata, plot_type, groups, n_genes, groupby, key, show, save, **kwds). > 291. > 292 # sum(list, []) is used to flatten the gene list. > --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []). > 294. > 295 if plot_type == 'dotplot':. > . > /projects/sysbio/projects/czi/immune/anaconda2/envs/py36/lib/python3.6/site-packages/scanpy/plotting/_tools/init.py in (.0). > 291. > 292 # sum(list, []) is used to flatten the gene list. > --> 293 gene_names = sum([list(adata.uns[key]['names'][x][:n_genes]) for x in group_names], []). > 294. > 295 if plot_type == 'dotplot':. > . > ValueError: no field of name MYL2. > `. > . > Do we need to store marker genes within the adata object? > . > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/502
https://github.com/scverse/scanpy/issues/502:9,usability,help,help,9,did that help?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/502
https://github.com/scverse/scanpy/pull/503:86,integrability,batch,batch,86,Perhaps the name should be more specific to avoid confusion with [harmony package for batch correction](https://github.com/immunogenomics/harmony)? That code has a C++ backend for which a Python front end might be written.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:32,interoperability,specif,specific,32,Perhaps the name should be more specific to avoid confusion with [harmony package for batch correction](https://github.com/immunogenomics/harmony)? That code has a C++ backend for which a Python front end might be written.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:74,modifiability,pac,package,74,Perhaps the name should be more specific to avoid confusion with [harmony package for batch correction](https://github.com/immunogenomics/harmony)? That code has a C++ backend for which a Python front end might be written.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:86,performance,batch,batch,86,Perhaps the name should be more specific to avoid confusion with [harmony package for batch correction](https://github.com/immunogenomics/harmony)? That code has a C++ backend for which a Python front end might be written.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:44,safety,avoid,avoid,44,Perhaps the name should be more specific to avoid confusion with [harmony package for batch correction](https://github.com/immunogenomics/harmony)? That code has a C++ backend for which a Python front end might be written.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:209,deployability,modul,module,209,"Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! To me, this looks pretty close to ready. Just a few things to address:. * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? * Any thoughts on solutions for the name collision? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:379,interoperability,format,format,379,"Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! To me, this looks pretty close to ready. Just a few things to address:. * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? * Any thoughts on solutions for the name collision? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:209,modifiability,modul,module,209,"Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! To me, this looks pretty close to ready. Just a few things to address:. * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? * Any thoughts on solutions for the name collision? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:63,safety,review,review,63,"Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! To me, this looks pretty close to ready. Just a few things to address:. * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? * Any thoughts on solutions for the name collision? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:194,safety,test,test,194,"Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! To me, this looks pretty close to ready. Just a few things to address:. * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? * Any thoughts on solutions for the name collision? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:209,safety,modul,module,209,"Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! To me, this looks pretty close to ready. Just a few things to address:. * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? * Any thoughts on solutions for the name collision? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:327,safety,valid,valid,327,"Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! To me, this looks pretty close to ready. Just a few things to address:. * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? * Any thoughts on solutions for the name collision? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:333,safety,input,input,333,"Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! To me, this looks pretty close to ready. Just a few things to address:. * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? * Any thoughts on solutions for the name collision? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:63,testability,review,review,63,"Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! To me, this looks pretty close to ready. Just a few things to address:. * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? * Any thoughts on solutions for the name collision? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:194,testability,test,test,194,"Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! To me, this looks pretty close to ready. Just a few things to address:. * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? * Any thoughts on solutions for the name collision? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:129,usability,close,close,129,"Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! To me, this looks pretty close to ready. Just a few things to address:. * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? * Any thoughts on solutions for the name collision? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:333,usability,input,input,333,"Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! To me, this looks pretty close to ready. Just a few things to address:. * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? * Any thoughts on solutions for the name collision? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:350,usability,document,document,350,"Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! To me, this looks pretty close to ready. Just a few things to address:. * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? * Any thoughts on solutions for the name collision? Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:223,deployability,modul,module,223,"> Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! > . > To me, this looks pretty close to ready. Just a few things to address:. > . > * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. > * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? > * Any thoughts on solutions for the name collision? > . > Thanks! Hey @ivirshup, I created a test module as requested. I also documented more details on the format of csv files. With regard to the name I spoke with the my PI, Dr. Dana Pe'er, and the author of the paper, Dr. Manu Setty, and we decided to keep the name as is. The publication can be found here https://www.nature.com/articles/s41586-019-1127-1. Please let me know if there is anything else needed to merge. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:564,deployability,modul,module,564,"> Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! > . > To me, this looks pretty close to ready. Just a few things to address:. > . > * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. > * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? > * Any thoughts on solutions for the name collision? > . > Thanks! Hey @ivirshup, I created a test module as requested. I also documented more details on the format of csv files. With regard to the name I spoke with the my PI, Dr. Dana Pe'er, and the author of the paper, Dr. Manu Setty, and we decided to keep the name as is. The publication can be found here https://www.nature.com/articles/s41586-019-1127-1. Please let me know if there is anything else needed to merge. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:796,integrability,pub,publication,796,"> Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! > . > To me, this looks pretty close to ready. Just a few things to address:. > . > * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. > * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? > * Any thoughts on solutions for the name collision? > . > Thanks! Hey @ivirshup, I created a test module as requested. I also documented more details on the format of csv files. With regard to the name I spoke with the my PI, Dr. Dana Pe'er, and the author of the paper, Dr. Manu Setty, and we decided to keep the name as is. The publication can be found here https://www.nature.com/articles/s41586-019-1127-1. Please let me know if there is anything else needed to merge. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:395,interoperability,format,format,395,"> Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! > . > To me, this looks pretty close to ready. Just a few things to address:. > . > * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. > * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? > * Any thoughts on solutions for the name collision? > . > Thanks! Hey @ivirshup, I created a test module as requested. I also documented more details on the format of csv files. With regard to the name I spoke with the my PI, Dr. Dana Pe'er, and the author of the paper, Dr. Manu Setty, and we decided to keep the name as is. The publication can be found here https://www.nature.com/articles/s41586-019-1127-1. Please let me know if there is anything else needed to merge. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:623,interoperability,format,format,623,"> Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! > . > To me, this looks pretty close to ready. Just a few things to address:. > . > * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. > * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? > * Any thoughts on solutions for the name collision? > . > Thanks! Hey @ivirshup, I created a test module as requested. I also documented more details on the format of csv files. With regard to the name I spoke with the my PI, Dr. Dana Pe'er, and the author of the paper, Dr. Manu Setty, and we decided to keep the name as is. The publication can be found here https://www.nature.com/articles/s41586-019-1127-1. Please let me know if there is anything else needed to merge. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:223,modifiability,modul,module,223,"> Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! > . > To me, this looks pretty close to ready. Just a few things to address:. > . > * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. > * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? > * Any thoughts on solutions for the name collision? > . > Thanks! Hey @ivirshup, I created a test module as requested. I also documented more details on the format of csv files. With regard to the name I spoke with the my PI, Dr. Dana Pe'er, and the author of the paper, Dr. Manu Setty, and we decided to keep the name as is. The publication can be found here https://www.nature.com/articles/s41586-019-1127-1. Please let me know if there is anything else needed to merge. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:564,modifiability,modul,module,564,"> Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! > . > To me, this looks pretty close to ready. Just a few things to address:. > . > * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. > * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? > * Any thoughts on solutions for the name collision? > . > Thanks! Hey @ivirshup, I created a test module as requested. I also documented more details on the format of csv files. With regard to the name I spoke with the my PI, Dr. Dana Pe'er, and the author of the paper, Dr. Manu Setty, and we decided to keep the name as is. The publication can be found here https://www.nature.com/articles/s41586-019-1127-1. Please let me know if there is anything else needed to merge. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:65,safety,review,review,65,"> Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! > . > To me, this looks pretty close to ready. Just a few things to address:. > . > * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. > * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? > * Any thoughts on solutions for the name collision? > . > Thanks! Hey @ivirshup, I created a test module as requested. I also documented more details on the format of csv files. With regard to the name I spoke with the my PI, Dr. Dana Pe'er, and the author of the paper, Dr. Manu Setty, and we decided to keep the name as is. The publication can be found here https://www.nature.com/articles/s41586-019-1127-1. Please let me know if there is anything else needed to merge. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:208,safety,test,test,208,"> Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! > . > To me, this looks pretty close to ready. Just a few things to address:. > . > * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. > * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? > * Any thoughts on solutions for the name collision? > . > Thanks! Hey @ivirshup, I created a test module as requested. I also documented more details on the format of csv files. With regard to the name I spoke with the my PI, Dr. Dana Pe'er, and the author of the paper, Dr. Manu Setty, and we decided to keep the name as is. The publication can be found here https://www.nature.com/articles/s41586-019-1127-1. Please let me know if there is anything else needed to merge. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:223,safety,modul,module,223,"> Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! > . > To me, this looks pretty close to ready. Just a few things to address:. > . > * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. > * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? > * Any thoughts on solutions for the name collision? > . > Thanks! Hey @ivirshup, I created a test module as requested. I also documented more details on the format of csv files. With regard to the name I spoke with the my PI, Dr. Dana Pe'er, and the author of the paper, Dr. Manu Setty, and we decided to keep the name as is. The publication can be found here https://www.nature.com/articles/s41586-019-1127-1. Please let me know if there is anything else needed to merge. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:343,safety,valid,valid,343,"> Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! > . > To me, this looks pretty close to ready. Just a few things to address:. > . > * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. > * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? > * Any thoughts on solutions for the name collision? > . > Thanks! Hey @ivirshup, I created a test module as requested. I also documented more details on the format of csv files. With regard to the name I spoke with the my PI, Dr. Dana Pe'er, and the author of the paper, Dr. Manu Setty, and we decided to keep the name as is. The publication can be found here https://www.nature.com/articles/s41586-019-1127-1. Please let me know if there is anything else needed to merge. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:349,safety,input,input,349,"> Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! > . > To me, this looks pretty close to ready. Just a few things to address:. > . > * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. > * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? > * Any thoughts on solutions for the name collision? > . > Thanks! Hey @ivirshup, I created a test module as requested. I also documented more details on the format of csv files. With regard to the name I spoke with the my PI, Dr. Dana Pe'er, and the author of the paper, Dr. Manu Setty, and we decided to keep the name as is. The publication can be found here https://www.nature.com/articles/s41586-019-1127-1. Please let me know if there is anything else needed to merge. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:559,safety,test,test,559,"> Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! > . > To me, this looks pretty close to ready. Just a few things to address:. > . > * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. > * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? > * Any thoughts on solutions for the name collision? > . > Thanks! Hey @ivirshup, I created a test module as requested. I also documented more details on the format of csv files. With regard to the name I spoke with the my PI, Dr. Dana Pe'er, and the author of the paper, Dr. Manu Setty, and we decided to keep the name as is. The publication can be found here https://www.nature.com/articles/s41586-019-1127-1. Please let me know if there is anything else needed to merge. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:564,safety,modul,module,564,"> Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! > . > To me, this looks pretty close to ready. Just a few things to address:. > . > * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. > * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? > * Any thoughts on solutions for the name collision? > . > Thanks! Hey @ivirshup, I created a test module as requested. I also documented more details on the format of csv files. With regard to the name I spoke with the my PI, Dr. Dana Pe'er, and the author of the paper, Dr. Manu Setty, and we decided to keep the name as is. The publication can be found here https://www.nature.com/articles/s41586-019-1127-1. Please let me know if there is anything else needed to merge. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:716,security,auth,author,716,"> Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! > . > To me, this looks pretty close to ready. Just a few things to address:. > . > * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. > * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? > * Any thoughts on solutions for the name collision? > . > Thanks! Hey @ivirshup, I created a test module as requested. I also documented more details on the format of csv files. With regard to the name I spoke with the my PI, Dr. Dana Pe'er, and the author of the paper, Dr. Manu Setty, and we decided to keep the name as is. The publication can be found here https://www.nature.com/articles/s41586-019-1127-1. Please let me know if there is anything else needed to merge. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:65,testability,review,review,65,"> Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! > . > To me, this looks pretty close to ready. Just a few things to address:. > . > * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. > * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? > * Any thoughts on solutions for the name collision? > . > Thanks! Hey @ivirshup, I created a test module as requested. I also documented more details on the format of csv files. With regard to the name I spoke with the my PI, Dr. Dana Pe'er, and the author of the paper, Dr. Manu Setty, and we decided to keep the name as is. The publication can be found here https://www.nature.com/articles/s41586-019-1127-1. Please let me know if there is anything else needed to merge. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:208,testability,test,test,208,"> Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! > . > To me, this looks pretty close to ready. Just a few things to address:. > . > * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. > * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? > * Any thoughts on solutions for the name collision? > . > Thanks! Hey @ivirshup, I created a test module as requested. I also documented more details on the format of csv files. With regard to the name I spoke with the my PI, Dr. Dana Pe'er, and the author of the paper, Dr. Manu Setty, and we decided to keep the name as is. The publication can be found here https://www.nature.com/articles/s41586-019-1127-1. Please let me know if there is anything else needed to merge. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:559,testability,test,test,559,"> Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! > . > To me, this looks pretty close to ready. Just a few things to address:. > . > * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. > * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? > * Any thoughts on solutions for the name collision? > . > Thanks! Hey @ivirshup, I created a test module as requested. I also documented more details on the format of csv files. With regard to the name I spoke with the my PI, Dr. Dana Pe'er, and the author of the paper, Dr. Manu Setty, and we decided to keep the name as is. The publication can be found here https://www.nature.com/articles/s41586-019-1127-1. Please let me know if there is anything else needed to merge. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:137,usability,close,close,137,"> Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! > . > To me, this looks pretty close to ready. Just a few things to address:. > . > * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. > * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? > * Any thoughts on solutions for the name collision? > . > Thanks! Hey @ivirshup, I created a test module as requested. I also documented more details on the format of csv files. With regard to the name I spoke with the my PI, Dr. Dana Pe'er, and the author of the paper, Dr. Manu Setty, and we decided to keep the name as is. The publication can be found here https://www.nature.com/articles/s41586-019-1127-1. Please let me know if there is anything else needed to merge. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:349,usability,input,input,349,"> Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! > . > To me, this looks pretty close to ready. Just a few things to address:. > . > * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. > * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? > * Any thoughts on solutions for the name collision? > . > Thanks! Hey @ivirshup, I created a test module as requested. I also documented more details on the format of csv files. With regard to the name I spoke with the my PI, Dr. Dana Pe'er, and the author of the paper, Dr. Manu Setty, and we decided to keep the name as is. The publication can be found here https://www.nature.com/articles/s41586-019-1127-1. Please let me know if there is anything else needed to merge. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:366,usability,document,document,366,"> Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! > . > To me, this looks pretty close to ready. Just a few things to address:. > . > * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. > * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? > * Any thoughts on solutions for the name collision? > . > Thanks! Hey @ivirshup, I created a test module as requested. I also documented more details on the format of csv files. With regard to the name I spoke with the my PI, Dr. Dana Pe'er, and the author of the paper, Dr. Manu Setty, and we decided to keep the name as is. The publication can be found here https://www.nature.com/articles/s41586-019-1127-1. Please let me know if there is anything else needed to merge. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:592,usability,document,documented,592,"> Hey @awnimo, I don't think we realized that this was ready for review again. Sorry about the confusion! > . > To me, this looks pretty close to ready. Just a few things to address:. > . > * Could you add a test, in a new module `test_external.py`? That way we can know if some change we make would break this. > * If a list of csv files are valid input, could you document some more about the format of the files? E.g. do you expect cells to be rows or columns? > * Any thoughts on solutions for the name collision? > . > Thanks! Hey @ivirshup, I created a test module as requested. I also documented more details on the format of csv files. With regard to the name I spoke with the my PI, Dr. Dana Pe'er, and the author of the paper, Dr. Manu Setty, and we decided to keep the name as is. The publication can be found here https://www.nature.com/articles/s41586-019-1127-1. Please let me know if there is anything else needed to merge. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:148,safety,review,review,148,"hi @falexwolf and @ivirshup,. Please let me know if there is any further actions need to be done in order to get this PR merged with Scanpy. Please review my recent response 8 days ago, as well. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/pull/503:148,testability,review,review,148,"hi @falexwolf and @ivirshup,. Please let me know if there is any further actions need to be done in order to get this PR merged with Scanpy. Please review my recent response 8 days ago, as well. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/503
https://github.com/scverse/scanpy/issues/504:184,deployability,updat,updated,184,"I did figure out what's going on. I worked on a view of an AnnData object, where the original AnnData object did not have the X_pca field and it could not be added only in the view. I updated to the latest scanpy and anndata version. > scanpy==1.4+18.gaabe446 anndata==0.6.18+3.g3e93ed7 numpy==1.15.4 scipy==1.2.1 pandas==0.24.1 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . this is my AnnData object:. ```. adata. print(adata). ```. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. if I now filter my AnnData object for highly variable genes I only got a ""View"" of my AnnData object. ```. adata2 = adata[:, adata.var['highly_variable']]. print(adata2). print(adata). ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. then on adata2, I cannot add the X_pca field. `sc.tl.pca(adata2, svd_solver='arpack')`. > ---------------------------------------------------------------------------. > ValueError Traceback (most recent call last). > <ipython-input-25-05be375bfc24> in <module>. > 5 print(adata). > 6 print(adata2). > ----> 7 sc.tl.pca(adata2, svd_solver='arpack'). > 8 print(adata2). > . > ~/miniconda3/lib/python3.7/site-packages/scanpy-1.4+18.gaabe446-py3.7.egg/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). > 504 . > 505 if data_is_AnnData:. > --> 506 adata.obsm['X_pca'] = X_pca. > 507 if use_highly_variable:. > 508 adata.varm['PCs'] = np.zeros(shape=(adat",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/504
https://github.com/scverse/scanpy/issues/504:225,deployability,version,version,225,"I did figure out what's going on. I worked on a view of an AnnData object, where the original AnnData object did not have the X_pca field and it could not be added only in the view. I updated to the latest scanpy and anndata version. > scanpy==1.4+18.gaabe446 anndata==0.6.18+3.g3e93ed7 numpy==1.15.4 scipy==1.2.1 pandas==0.24.1 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . this is my AnnData object:. ```. adata. print(adata). ```. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. if I now filter my AnnData object for highly variable genes I only got a ""View"" of my AnnData object. ```. adata2 = adata[:, adata.var['highly_variable']]. print(adata2). print(adata). ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. then on adata2, I cannot add the X_pca field. `sc.tl.pca(adata2, svd_solver='arpack')`. > ---------------------------------------------------------------------------. > ValueError Traceback (most recent call last). > <ipython-input-25-05be375bfc24> in <module>. > 5 print(adata). > 6 print(adata2). > ----> 7 sc.tl.pca(adata2, svd_solver='arpack'). > 8 print(adata2). > . > ~/miniconda3/lib/python3.7/site-packages/scanpy-1.4+18.gaabe446-py3.7.egg/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). > 504 . > 505 if data_is_AnnData:. > --> 506 adata.obsm['X_pca'] = X_pca. > 507 if use_highly_variable:. > 508 adata.varm['PCs'] = np.zeros(shape=(adat",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/504
https://github.com/scverse/scanpy/issues/504:1492,deployability,modul,module,1492," n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. if I now filter my AnnData object for highly variable genes I only got a ""View"" of my AnnData object. ```. adata2 = adata[:, adata.var['highly_variable']]. print(adata2). print(adata). ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. then on adata2, I cannot add the X_pca field. `sc.tl.pca(adata2, svd_solver='arpack')`. > ---------------------------------------------------------------------------. > ValueError Traceback (most recent call last). > <ipython-input-25-05be375bfc24> in <module>. > 5 print(adata). > 6 print(adata2). > ----> 7 sc.tl.pca(adata2, svd_solver='arpack'). > 8 print(adata2). > . > ~/miniconda3/lib/python3.7/site-packages/scanpy-1.4+18.gaabe446-py3.7.egg/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). > 504 . > 505 if data_is_AnnData:. > --> 506 adata.obsm['X_pca'] = X_pca. > 507 if use_highly_variable:. > 508 adata.varm['PCs'] = np.zeros(shape=(adata.n_vars, n_comps)). > . > ValueError: no field of name X_pca. ```. print(adata2). print(adata). ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. if",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/504
https://github.com/scverse/scanpy/issues/504:225,integrability,version,version,225,"I did figure out what's going on. I worked on a view of an AnnData object, where the original AnnData object did not have the X_pca field and it could not be added only in the view. I updated to the latest scanpy and anndata version. > scanpy==1.4+18.gaabe446 anndata==0.6.18+3.g3e93ed7 numpy==1.15.4 scipy==1.2.1 pandas==0.24.1 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . this is my AnnData object:. ```. adata. print(adata). ```. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. if I now filter my AnnData object for highly variable genes I only got a ""View"" of my AnnData object. ```. adata2 = adata[:, adata.var['highly_variable']]. print(adata2). print(adata). ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. then on adata2, I cannot add the X_pca field. `sc.tl.pca(adata2, svd_solver='arpack')`. > ---------------------------------------------------------------------------. > ValueError Traceback (most recent call last). > <ipython-input-25-05be375bfc24> in <module>. > 5 print(adata). > 6 print(adata2). > ----> 7 sc.tl.pca(adata2, svd_solver='arpack'). > 8 print(adata2). > . > ~/miniconda3/lib/python3.7/site-packages/scanpy-1.4+18.gaabe446-py3.7.egg/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). > 504 . > 505 if data_is_AnnData:. > --> 506 adata.obsm['X_pca'] = X_pca. > 507 if use_highly_variable:. > 508 adata.varm['PCs'] = np.zeros(shape=(adat",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/504
https://github.com/scverse/scanpy/issues/504:667,integrability,filter,filter,667,"I did figure out what's going on. I worked on a view of an AnnData object, where the original AnnData object did not have the X_pca field and it could not be added only in the view. I updated to the latest scanpy and anndata version. > scanpy==1.4+18.gaabe446 anndata==0.6.18+3.g3e93ed7 numpy==1.15.4 scipy==1.2.1 pandas==0.24.1 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . this is my AnnData object:. ```. adata. print(adata). ```. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. if I now filter my AnnData object for highly variable genes I only got a ""View"" of my AnnData object. ```. adata2 = adata[:, adata.var['highly_variable']]. print(adata2). print(adata). ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. then on adata2, I cannot add the X_pca field. `sc.tl.pca(adata2, svd_solver='arpack')`. > ---------------------------------------------------------------------------. > ValueError Traceback (most recent call last). > <ipython-input-25-05be375bfc24> in <module>. > 5 print(adata). > 6 print(adata2). > ----> 7 sc.tl.pca(adata2, svd_solver='arpack'). > 8 print(adata2). > . > ~/miniconda3/lib/python3.7/site-packages/scanpy-1.4+18.gaabe446-py3.7.egg/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). > 504 . > 505 if data_is_AnnData:. > --> 506 adata.obsm['X_pca'] = X_pca. > 507 if use_highly_variable:. > 508 adata.varm['PCs'] = np.zeros(shape=(adat",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/504
https://github.com/scverse/scanpy/issues/504:225,modifiability,version,version,225,"I did figure out what's going on. I worked on a view of an AnnData object, where the original AnnData object did not have the X_pca field and it could not be added only in the view. I updated to the latest scanpy and anndata version. > scanpy==1.4+18.gaabe446 anndata==0.6.18+3.g3e93ed7 numpy==1.15.4 scipy==1.2.1 pandas==0.24.1 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . this is my AnnData object:. ```. adata. print(adata). ```. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. if I now filter my AnnData object for highly variable genes I only got a ""View"" of my AnnData object. ```. adata2 = adata[:, adata.var['highly_variable']]. print(adata2). print(adata). ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. then on adata2, I cannot add the X_pca field. `sc.tl.pca(adata2, svd_solver='arpack')`. > ---------------------------------------------------------------------------. > ValueError Traceback (most recent call last). > <ipython-input-25-05be375bfc24> in <module>. > 5 print(adata). > 6 print(adata2). > ----> 7 sc.tl.pca(adata2, svd_solver='arpack'). > 8 print(adata2). > . > ~/miniconda3/lib/python3.7/site-packages/scanpy-1.4+18.gaabe446-py3.7.egg/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). > 504 . > 505 if data_is_AnnData:. > --> 506 adata.obsm['X_pca'] = X_pca. > 507 if use_highly_variable:. > 508 adata.varm['PCs'] = np.zeros(shape=(adat",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/504
https://github.com/scverse/scanpy/issues/504:703,modifiability,variab,variable,703,"I did figure out what's going on. I worked on a view of an AnnData object, where the original AnnData object did not have the X_pca field and it could not be added only in the view. I updated to the latest scanpy and anndata version. > scanpy==1.4+18.gaabe446 anndata==0.6.18+3.g3e93ed7 numpy==1.15.4 scipy==1.2.1 pandas==0.24.1 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . this is my AnnData object:. ```. adata. print(adata). ```. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. if I now filter my AnnData object for highly variable genes I only got a ""View"" of my AnnData object. ```. adata2 = adata[:, adata.var['highly_variable']]. print(adata2). print(adata). ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. then on adata2, I cannot add the X_pca field. `sc.tl.pca(adata2, svd_solver='arpack')`. > ---------------------------------------------------------------------------. > ValueError Traceback (most recent call last). > <ipython-input-25-05be375bfc24> in <module>. > 5 print(adata). > 6 print(adata2). > ----> 7 sc.tl.pca(adata2, svd_solver='arpack'). > 8 print(adata2). > . > ~/miniconda3/lib/python3.7/site-packages/scanpy-1.4+18.gaabe446-py3.7.egg/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). > 504 . > 505 if data_is_AnnData:. > --> 506 adata.obsm['X_pca'] = X_pca. > 507 if use_highly_variable:. > 508 adata.varm['PCs'] = np.zeros(shape=(adat",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/504
https://github.com/scverse/scanpy/issues/504:1492,modifiability,modul,module,1492," n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. if I now filter my AnnData object for highly variable genes I only got a ""View"" of my AnnData object. ```. adata2 = adata[:, adata.var['highly_variable']]. print(adata2). print(adata). ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. then on adata2, I cannot add the X_pca field. `sc.tl.pca(adata2, svd_solver='arpack')`. > ---------------------------------------------------------------------------. > ValueError Traceback (most recent call last). > <ipython-input-25-05be375bfc24> in <module>. > 5 print(adata). > 6 print(adata2). > ----> 7 sc.tl.pca(adata2, svd_solver='arpack'). > 8 print(adata2). > . > ~/miniconda3/lib/python3.7/site-packages/scanpy-1.4+18.gaabe446-py3.7.egg/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). > 504 . > 505 if data_is_AnnData:. > --> 506 adata.obsm['X_pca'] = X_pca. > 507 if use_highly_variable:. > 508 adata.varm['PCs'] = np.zeros(shape=(adata.n_vars, n_comps)). > . > ValueError: no field of name X_pca. ```. print(adata2). print(adata). ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. if",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/504
https://github.com/scverse/scanpy/issues/504:1645,modifiability,pac,packages,1645,"s_norm'. if I now filter my AnnData object for highly variable genes I only got a ""View"" of my AnnData object. ```. adata2 = adata[:, adata.var['highly_variable']]. print(adata2). print(adata). ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. then on adata2, I cannot add the X_pca field. `sc.tl.pca(adata2, svd_solver='arpack')`. > ---------------------------------------------------------------------------. > ValueError Traceback (most recent call last). > <ipython-input-25-05be375bfc24> in <module>. > 5 print(adata). > 6 print(adata2). > ----> 7 sc.tl.pca(adata2, svd_solver='arpack'). > 8 print(adata2). > . > ~/miniconda3/lib/python3.7/site-packages/scanpy-1.4+18.gaabe446-py3.7.egg/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). > 504 . > 505 if data_is_AnnData:. > --> 506 adata.obsm['X_pca'] = X_pca. > 507 if use_highly_variable:. > 508 adata.varm['PCs'] = np.zeros(shape=(adata.n_vars, n_comps)). > . > ValueError: no field of name X_pca. ```. print(adata2). print(adata). ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. if I do the pca on the original AnnData object for the highly variable genes, it works:. ```. sc.tl.pca(adata, use_highly_variable=True, svd_solver='arpack'",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/504
https://github.com/scverse/scanpy/issues/504:2555,modifiability,variab,variable,2555,". > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. then on adata2, I cannot add the X_pca field. `sc.tl.pca(adata2, svd_solver='arpack')`. > ---------------------------------------------------------------------------. > ValueError Traceback (most recent call last). > <ipython-input-25-05be375bfc24> in <module>. > 5 print(adata). > 6 print(adata2). > ----> 7 sc.tl.pca(adata2, svd_solver='arpack'). > 8 print(adata2). > . > ~/miniconda3/lib/python3.7/site-packages/scanpy-1.4+18.gaabe446-py3.7.egg/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). > 504 . > 505 if data_is_AnnData:. > --> 506 adata.obsm['X_pca'] = X_pca. > 507 if use_highly_variable:. > 508 adata.varm['PCs'] = np.zeros(shape=(adata.n_vars, n_comps)). > . > ValueError: no field of name X_pca. ```. print(adata2). print(adata). ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. if I do the pca on the original AnnData object for the highly variable genes, it works:. ```. sc.tl.pca(adata, use_highly_variable=True, svd_solver='arpack'). print(adata). ```. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > uns: 'pca'. > obsm: 'X_pca'. > varm: 'PCs'.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/504
https://github.com/scverse/scanpy/issues/504:184,safety,updat,updated,184,"I did figure out what's going on. I worked on a view of an AnnData object, where the original AnnData object did not have the X_pca field and it could not be added only in the view. I updated to the latest scanpy and anndata version. > scanpy==1.4+18.gaabe446 anndata==0.6.18+3.g3e93ed7 numpy==1.15.4 scipy==1.2.1 pandas==0.24.1 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . this is my AnnData object:. ```. adata. print(adata). ```. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. if I now filter my AnnData object for highly variable genes I only got a ""View"" of my AnnData object. ```. adata2 = adata[:, adata.var['highly_variable']]. print(adata2). print(adata). ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. then on adata2, I cannot add the X_pca field. `sc.tl.pca(adata2, svd_solver='arpack')`. > ---------------------------------------------------------------------------. > ValueError Traceback (most recent call last). > <ipython-input-25-05be375bfc24> in <module>. > 5 print(adata). > 6 print(adata2). > ----> 7 sc.tl.pca(adata2, svd_solver='arpack'). > 8 print(adata2). > . > ~/miniconda3/lib/python3.7/site-packages/scanpy-1.4+18.gaabe446-py3.7.egg/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). > 504 . > 505 if data_is_AnnData:. > --> 506 adata.obsm['X_pca'] = X_pca. > 507 if use_highly_variable:. > 508 adata.varm['PCs'] = np.zeros(shape=(adat",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/504
https://github.com/scverse/scanpy/issues/504:1465,safety,input,input-,1465,"AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. if I now filter my AnnData object for highly variable genes I only got a ""View"" of my AnnData object. ```. adata2 = adata[:, adata.var['highly_variable']]. print(adata2). print(adata). ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. then on adata2, I cannot add the X_pca field. `sc.tl.pca(adata2, svd_solver='arpack')`. > ---------------------------------------------------------------------------. > ValueError Traceback (most recent call last). > <ipython-input-25-05be375bfc24> in <module>. > 5 print(adata). > 6 print(adata2). > ----> 7 sc.tl.pca(adata2, svd_solver='arpack'). > 8 print(adata2). > . > ~/miniconda3/lib/python3.7/site-packages/scanpy-1.4+18.gaabe446-py3.7.egg/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). > 504 . > 505 if data_is_AnnData:. > --> 506 adata.obsm['X_pca'] = X_pca. > 507 if use_highly_variable:. > 508 adata.varm['PCs'] = np.zeros(shape=(adata.n_vars, n_comps)). > . > ValueError: no field of name X_pca. ```. print(adata2). print(adata). ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/504
https://github.com/scverse/scanpy/issues/504:1492,safety,modul,module,1492," n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. if I now filter my AnnData object for highly variable genes I only got a ""View"" of my AnnData object. ```. adata2 = adata[:, adata.var['highly_variable']]. print(adata2). print(adata). ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. then on adata2, I cannot add the X_pca field. `sc.tl.pca(adata2, svd_solver='arpack')`. > ---------------------------------------------------------------------------. > ValueError Traceback (most recent call last). > <ipython-input-25-05be375bfc24> in <module>. > 5 print(adata). > 6 print(adata2). > ----> 7 sc.tl.pca(adata2, svd_solver='arpack'). > 8 print(adata2). > . > ~/miniconda3/lib/python3.7/site-packages/scanpy-1.4+18.gaabe446-py3.7.egg/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). > 504 . > 505 if data_is_AnnData:. > --> 506 adata.obsm['X_pca'] = X_pca. > 507 if use_highly_variable:. > 508 adata.varm['PCs'] = np.zeros(shape=(adata.n_vars, n_comps)). > . > ValueError: no field of name X_pca. ```. print(adata2). print(adata). ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. if",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/504
https://github.com/scverse/scanpy/issues/504:184,security,updat,updated,184,"I did figure out what's going on. I worked on a view of an AnnData object, where the original AnnData object did not have the X_pca field and it could not be added only in the view. I updated to the latest scanpy and anndata version. > scanpy==1.4+18.gaabe446 anndata==0.6.18+3.g3e93ed7 numpy==1.15.4 scipy==1.2.1 pandas==0.24.1 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . this is my AnnData object:. ```. adata. print(adata). ```. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. if I now filter my AnnData object for highly variable genes I only got a ""View"" of my AnnData object. ```. adata2 = adata[:, adata.var['highly_variable']]. print(adata2). print(adata). ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. then on adata2, I cannot add the X_pca field. `sc.tl.pca(adata2, svd_solver='arpack')`. > ---------------------------------------------------------------------------. > ValueError Traceback (most recent call last). > <ipython-input-25-05be375bfc24> in <module>. > 5 print(adata). > 6 print(adata2). > ----> 7 sc.tl.pca(adata2, svd_solver='arpack'). > 8 print(adata2). > . > ~/miniconda3/lib/python3.7/site-packages/scanpy-1.4+18.gaabe446-py3.7.egg/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). > 504 . > 505 if data_is_AnnData:. > --> 506 adata.obsm['X_pca'] = X_pca. > 507 if use_highly_variable:. > 508 adata.varm['PCs'] = np.zeros(shape=(adat",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/504
https://github.com/scverse/scanpy/issues/504:1419,testability,Trace,Traceback,1419,"a object:. ```. adata. print(adata). ```. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. if I now filter my AnnData object for highly variable genes I only got a ""View"" of my AnnData object. ```. adata2 = adata[:, adata.var['highly_variable']]. print(adata2). print(adata). ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. then on adata2, I cannot add the X_pca field. `sc.tl.pca(adata2, svd_solver='arpack')`. > ---------------------------------------------------------------------------. > ValueError Traceback (most recent call last). > <ipython-input-25-05be375bfc24> in <module>. > 5 print(adata). > 6 print(adata2). > ----> 7 sc.tl.pca(adata2, svd_solver='arpack'). > 8 print(adata2). > . > ~/miniconda3/lib/python3.7/site-packages/scanpy-1.4+18.gaabe446-py3.7.egg/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). > 504 . > 505 if data_is_AnnData:. > --> 506 adata.obsm['X_pca'] = X_pca. > 507 if use_highly_variable:. > 508 adata.varm['PCs'] = np.zeros(shape=(adata.n_vars, n_comps)). > . > ValueError: no field of name X_pca. ```. print(adata2). print(adata). ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_ce",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/504
https://github.com/scverse/scanpy/issues/504:336,usability,learn,learn,336,"I did figure out what's going on. I worked on a view of an AnnData object, where the original AnnData object did not have the X_pca field and it could not be added only in the view. I updated to the latest scanpy and anndata version. > scanpy==1.4+18.gaabe446 anndata==0.6.18+3.g3e93ed7 numpy==1.15.4 scipy==1.2.1 pandas==0.24.1 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . this is my AnnData object:. ```. adata. print(adata). ```. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. if I now filter my AnnData object for highly variable genes I only got a ""View"" of my AnnData object. ```. adata2 = adata[:, adata.var['highly_variable']]. print(adata2). print(adata). ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. then on adata2, I cannot add the X_pca field. `sc.tl.pca(adata2, svd_solver='arpack')`. > ---------------------------------------------------------------------------. > ValueError Traceback (most recent call last). > <ipython-input-25-05be375bfc24> in <module>. > 5 print(adata). > 6 print(adata2). > ----> 7 sc.tl.pca(adata2, svd_solver='arpack'). > 8 print(adata2). > . > ~/miniconda3/lib/python3.7/site-packages/scanpy-1.4+18.gaabe446-py3.7.egg/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). > 504 . > 505 if data_is_AnnData:. > --> 506 adata.obsm['X_pca'] = X_pca. > 507 if use_highly_variable:. > 508 adata.varm['PCs'] = np.zeros(shape=(adat",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/504
https://github.com/scverse/scanpy/issues/504:1465,usability,input,input-,1465,"AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. if I now filter my AnnData object for highly variable genes I only got a ""View"" of my AnnData object. ```. adata2 = adata[:, adata.var['highly_variable']]. print(adata2). print(adata). ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. then on adata2, I cannot add the X_pca field. `sc.tl.pca(adata2, svd_solver='arpack')`. > ---------------------------------------------------------------------------. > ValueError Traceback (most recent call last). > <ipython-input-25-05be375bfc24> in <module>. > 5 print(adata). > 6 print(adata2). > ----> 7 sc.tl.pca(adata2, svd_solver='arpack'). > 8 print(adata2). > . > ~/miniconda3/lib/python3.7/site-packages/scanpy-1.4+18.gaabe446-py3.7.egg/scanpy/preprocessing/_simple.py in pca(data, n_comps, zero_center, svd_solver, random_state, return_info, use_highly_variable, dtype, copy, chunked, chunk_size). > 504 . > 505 if data_is_AnnData:. > --> 506 adata.obsm['X_pca'] = X_pca. > 507 if use_highly_variable:. > 508 adata.varm['PCs'] = np.zeros(shape=(adata.n_vars, n_comps)). > . > ValueError: no field of name X_pca. ```. print(adata2). print(adata). ```. > View of AnnData object with n_obs × n_vars = 14775 × 1999 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersions', 'dispersions_norm'. > AnnData object with n_obs × n_vars = 14775 × 25386 . > obs: 'sample', 'n_genes', 'percent_mito', 'n_counts'. > var: 'n_cells', 'highly_variable', 'means', 'dispersio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/504
https://github.com/scverse/scanpy/issues/505:584,energy efficiency,heat,heatmap,584,"for PCHeatmap I made the following function:. ```PYTHON. def pca_heatmap(adata, component, use_raw=None, layer=None):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg), . show_gene_labels=False,. swap_axes=True, cmap='viridis', . use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3)). ````. for `PCElbowPlot` you can use `sc.pl.pca_variance_ratio`. Also take a look at `sc.pl.pca_loadings`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:80,integrability,compon,component,80,"for PCHeatmap I made the following function:. ```PYTHON. def pca_heatmap(adata, component, use_raw=None, layer=None):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg), . show_gene_labels=False,. swap_axes=True, cmap='viridis', . use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3)). ````. for `PCElbowPlot` you can use `sc.pl.pca_variance_ratio`. Also take a look at `sc.pl.pca_loadings`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:187,integrability,compon,component,187,"for PCHeatmap I made the following function:. ```PYTHON. def pca_heatmap(adata, component, use_raw=None, layer=None):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg), . show_gene_labels=False,. swap_axes=True, cmap='viridis', . use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3)). ````. for `PCElbowPlot` you can use `sc.pl.pca_variance_ratio`. Also take a look at `sc.pl.pca_loadings`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:416,integrability,compon,component,416,"for PCHeatmap I made the following function:. ```PYTHON. def pca_heatmap(adata, component, use_raw=None, layer=None):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg), . show_gene_labels=False,. swap_axes=True, cmap='viridis', . use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3)). ````. for `PCElbowPlot` you can use `sc.pl.pca_variance_ratio`. Also take a look at `sc.pl.pca_loadings`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:80,interoperability,compon,component,80,"for PCHeatmap I made the following function:. ```PYTHON. def pca_heatmap(adata, component, use_raw=None, layer=None):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg), . show_gene_labels=False,. swap_axes=True, cmap='viridis', . use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3)). ````. for `PCElbowPlot` you can use `sc.pl.pca_variance_ratio`. Also take a look at `sc.pl.pca_loadings`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:187,interoperability,compon,component,187,"for PCHeatmap I made the following function:. ```PYTHON. def pca_heatmap(adata, component, use_raw=None, layer=None):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg), . show_gene_labels=False,. swap_axes=True, cmap='viridis', . use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3)). ````. for `PCElbowPlot` you can use `sc.pl.pca_variance_ratio`. Also take a look at `sc.pl.pca_loadings`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:416,interoperability,compon,component,416,"for PCHeatmap I made the following function:. ```PYTHON. def pca_heatmap(adata, component, use_raw=None, layer=None):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg), . show_gene_labels=False,. swap_axes=True, cmap='viridis', . use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3)). ````. for `PCElbowPlot` you can use `sc.pl.pca_variance_ratio`. Also take a look at `sc.pl.pca_loadings`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:80,modifiability,compon,component,80,"for PCHeatmap I made the following function:. ```PYTHON. def pca_heatmap(adata, component, use_raw=None, layer=None):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg), . show_gene_labels=False,. swap_axes=True, cmap='viridis', . use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3)). ````. for `PCElbowPlot` you can use `sc.pl.pca_variance_ratio`. Also take a look at `sc.pl.pca_loadings`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:105,modifiability,layer,layer,105,"for PCHeatmap I made the following function:. ```PYTHON. def pca_heatmap(adata, component, use_raw=None, layer=None):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg), . show_gene_labels=False,. swap_axes=True, cmap='viridis', . use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3)). ````. for `PCElbowPlot` you can use `sc.pl.pca_variance_ratio`. Also take a look at `sc.pl.pca_loadings`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:187,modifiability,compon,component,187,"for PCHeatmap I made the following function:. ```PYTHON. def pca_heatmap(adata, component, use_raw=None, layer=None):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg), . show_gene_labels=False,. swap_axes=True, cmap='viridis', . use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3)). ````. for `PCElbowPlot` you can use `sc.pl.pca_variance_ratio`. Also take a look at `sc.pl.pca_loadings`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:416,modifiability,compon,component,416,"for PCHeatmap I made the following function:. ```PYTHON. def pca_heatmap(adata, component, use_raw=None, layer=None):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg), . show_gene_labels=False,. swap_axes=True, cmap='viridis', . use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3)). ````. for `PCElbowPlot` you can use `sc.pl.pca_variance_ratio`. Also take a look at `sc.pl.pca_loadings`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:742,modifiability,layer,layer,742,"for PCHeatmap I made the following function:. ```PYTHON. def pca_heatmap(adata, component, use_raw=None, layer=None):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg), . show_gene_labels=False,. swap_axes=True, cmap='viridis', . use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3)). ````. for `PCElbowPlot` you can use `sc.pl.pca_variance_ratio`. Also take a look at `sc.pl.pca_loadings`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:748,modifiability,layer,layer,748,"for PCHeatmap I made the following function:. ```PYTHON. def pca_heatmap(adata, component, use_raw=None, layer=None):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg), . show_gene_labels=False,. swap_axes=True, cmap='viridis', . use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3)). ````. for `PCElbowPlot` you can use `sc.pl.pca_variance_ratio`. Also take a look at `sc.pl.pca_loadings`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:105,energy efficiency,draw,draw,105,"As I am a stupid freshman in both python and scanpy, I modified the code fo yours, which falitated me to draw the figure and save it. ```py. def pca_heatmap(adata, component, use_raw=None, layer=None, fig_name='_of_PC-7-3-.png'):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(. adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg),. show_gene_labels=True,. swap_axes=True, cmap='viridis',. use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3),. save=fig_name,. ). pca_heatmap(adata, 1, fig_name='_of_PC-7-3-1.png'). pca_heatmap(adata, 2, fig_name='_of_PC-7-3-2.png'). pca_heatmap(adata, 3, fig_name='_of_PC-7-3-3.png'). pca_heatmap(adata, 4, fig_name='_of_PC-7-3-4.png'). pca_heatmap(adata, 5, fig_name='_of_PC-7-3-5.png'). pca_heatmap(adata, 6, fig_name='_of_PC-7-3-6.png'). pca_heatmap(adata, 7, fig_name='_of_PC-7-3-7.png'). pca_heatmap(adata, 8, fig_name='_of_PC-7-3-8.png'). pca_heatmap(adata, 9, fig_name='_of_PC-7-3-9.png'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:696,energy efficiency,heat,heatmap,696,"As I am a stupid freshman in both python and scanpy, I modified the code fo yours, which falitated me to draw the figure and save it. ```py. def pca_heatmap(adata, component, use_raw=None, layer=None, fig_name='_of_PC-7-3-.png'):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(. adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg),. show_gene_labels=True,. swap_axes=True, cmap='viridis',. use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3),. save=fig_name,. ). pca_heatmap(adata, 1, fig_name='_of_PC-7-3-1.png'). pca_heatmap(adata, 2, fig_name='_of_PC-7-3-2.png'). pca_heatmap(adata, 3, fig_name='_of_PC-7-3-3.png'). pca_heatmap(adata, 4, fig_name='_of_PC-7-3-4.png'). pca_heatmap(adata, 5, fig_name='_of_PC-7-3-5.png'). pca_heatmap(adata, 6, fig_name='_of_PC-7-3-6.png'). pca_heatmap(adata, 7, fig_name='_of_PC-7-3-7.png'). pca_heatmap(adata, 8, fig_name='_of_PC-7-3-8.png'). pca_heatmap(adata, 9, fig_name='_of_PC-7-3-9.png'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:164,integrability,compon,component,164,"As I am a stupid freshman in both python and scanpy, I modified the code fo yours, which falitated me to draw the figure and save it. ```py. def pca_heatmap(adata, component, use_raw=None, layer=None, fig_name='_of_PC-7-3-.png'):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(. adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg),. show_gene_labels=True,. swap_axes=True, cmap='viridis',. use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3),. save=fig_name,. ). pca_heatmap(adata, 1, fig_name='_of_PC-7-3-1.png'). pca_heatmap(adata, 2, fig_name='_of_PC-7-3-2.png'). pca_heatmap(adata, 3, fig_name='_of_PC-7-3-3.png'). pca_heatmap(adata, 4, fig_name='_of_PC-7-3-4.png'). pca_heatmap(adata, 5, fig_name='_of_PC-7-3-5.png'). pca_heatmap(adata, 6, fig_name='_of_PC-7-3-6.png'). pca_heatmap(adata, 7, fig_name='_of_PC-7-3-7.png'). pca_heatmap(adata, 8, fig_name='_of_PC-7-3-8.png'). pca_heatmap(adata, 9, fig_name='_of_PC-7-3-9.png'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:299,integrability,compon,component,299,"As I am a stupid freshman in both python and scanpy, I modified the code fo yours, which falitated me to draw the figure and save it. ```py. def pca_heatmap(adata, component, use_raw=None, layer=None, fig_name='_of_PC-7-3-.png'):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(. adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg),. show_gene_labels=True,. swap_axes=True, cmap='viridis',. use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3),. save=fig_name,. ). pca_heatmap(adata, 1, fig_name='_of_PC-7-3-1.png'). pca_heatmap(adata, 2, fig_name='_of_PC-7-3-2.png'). pca_heatmap(adata, 3, fig_name='_of_PC-7-3-3.png'). pca_heatmap(adata, 4, fig_name='_of_PC-7-3-4.png'). pca_heatmap(adata, 5, fig_name='_of_PC-7-3-5.png'). pca_heatmap(adata, 6, fig_name='_of_PC-7-3-6.png'). pca_heatmap(adata, 7, fig_name='_of_PC-7-3-7.png'). pca_heatmap(adata, 8, fig_name='_of_PC-7-3-8.png'). pca_heatmap(adata, 9, fig_name='_of_PC-7-3-9.png'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:528,integrability,compon,component,528,"As I am a stupid freshman in both python and scanpy, I modified the code fo yours, which falitated me to draw the figure and save it. ```py. def pca_heatmap(adata, component, use_raw=None, layer=None, fig_name='_of_PC-7-3-.png'):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(. adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg),. show_gene_labels=True,. swap_axes=True, cmap='viridis',. use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3),. save=fig_name,. ). pca_heatmap(adata, 1, fig_name='_of_PC-7-3-1.png'). pca_heatmap(adata, 2, fig_name='_of_PC-7-3-2.png'). pca_heatmap(adata, 3, fig_name='_of_PC-7-3-3.png'). pca_heatmap(adata, 4, fig_name='_of_PC-7-3-4.png'). pca_heatmap(adata, 5, fig_name='_of_PC-7-3-5.png'). pca_heatmap(adata, 6, fig_name='_of_PC-7-3-6.png'). pca_heatmap(adata, 7, fig_name='_of_PC-7-3-7.png'). pca_heatmap(adata, 8, fig_name='_of_PC-7-3-8.png'). pca_heatmap(adata, 9, fig_name='_of_PC-7-3-9.png'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:164,interoperability,compon,component,164,"As I am a stupid freshman in both python and scanpy, I modified the code fo yours, which falitated me to draw the figure and save it. ```py. def pca_heatmap(adata, component, use_raw=None, layer=None, fig_name='_of_PC-7-3-.png'):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(. adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg),. show_gene_labels=True,. swap_axes=True, cmap='viridis',. use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3),. save=fig_name,. ). pca_heatmap(adata, 1, fig_name='_of_PC-7-3-1.png'). pca_heatmap(adata, 2, fig_name='_of_PC-7-3-2.png'). pca_heatmap(adata, 3, fig_name='_of_PC-7-3-3.png'). pca_heatmap(adata, 4, fig_name='_of_PC-7-3-4.png'). pca_heatmap(adata, 5, fig_name='_of_PC-7-3-5.png'). pca_heatmap(adata, 6, fig_name='_of_PC-7-3-6.png'). pca_heatmap(adata, 7, fig_name='_of_PC-7-3-7.png'). pca_heatmap(adata, 8, fig_name='_of_PC-7-3-8.png'). pca_heatmap(adata, 9, fig_name='_of_PC-7-3-9.png'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:299,interoperability,compon,component,299,"As I am a stupid freshman in both python and scanpy, I modified the code fo yours, which falitated me to draw the figure and save it. ```py. def pca_heatmap(adata, component, use_raw=None, layer=None, fig_name='_of_PC-7-3-.png'):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(. adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg),. show_gene_labels=True,. swap_axes=True, cmap='viridis',. use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3),. save=fig_name,. ). pca_heatmap(adata, 1, fig_name='_of_PC-7-3-1.png'). pca_heatmap(adata, 2, fig_name='_of_PC-7-3-2.png'). pca_heatmap(adata, 3, fig_name='_of_PC-7-3-3.png'). pca_heatmap(adata, 4, fig_name='_of_PC-7-3-4.png'). pca_heatmap(adata, 5, fig_name='_of_PC-7-3-5.png'). pca_heatmap(adata, 6, fig_name='_of_PC-7-3-6.png'). pca_heatmap(adata, 7, fig_name='_of_PC-7-3-7.png'). pca_heatmap(adata, 8, fig_name='_of_PC-7-3-8.png'). pca_heatmap(adata, 9, fig_name='_of_PC-7-3-9.png'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:528,interoperability,compon,component,528,"As I am a stupid freshman in both python and scanpy, I modified the code fo yours, which falitated me to draw the figure and save it. ```py. def pca_heatmap(adata, component, use_raw=None, layer=None, fig_name='_of_PC-7-3-.png'):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(. adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg),. show_gene_labels=True,. swap_axes=True, cmap='viridis',. use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3),. save=fig_name,. ). pca_heatmap(adata, 1, fig_name='_of_PC-7-3-1.png'). pca_heatmap(adata, 2, fig_name='_of_PC-7-3-2.png'). pca_heatmap(adata, 3, fig_name='_of_PC-7-3-3.png'). pca_heatmap(adata, 4, fig_name='_of_PC-7-3-4.png'). pca_heatmap(adata, 5, fig_name='_of_PC-7-3-5.png'). pca_heatmap(adata, 6, fig_name='_of_PC-7-3-6.png'). pca_heatmap(adata, 7, fig_name='_of_PC-7-3-7.png'). pca_heatmap(adata, 8, fig_name='_of_PC-7-3-8.png'). pca_heatmap(adata, 9, fig_name='_of_PC-7-3-9.png'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:164,modifiability,compon,component,164,"As I am a stupid freshman in both python and scanpy, I modified the code fo yours, which falitated me to draw the figure and save it. ```py. def pca_heatmap(adata, component, use_raw=None, layer=None, fig_name='_of_PC-7-3-.png'):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(. adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg),. show_gene_labels=True,. swap_axes=True, cmap='viridis',. use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3),. save=fig_name,. ). pca_heatmap(adata, 1, fig_name='_of_PC-7-3-1.png'). pca_heatmap(adata, 2, fig_name='_of_PC-7-3-2.png'). pca_heatmap(adata, 3, fig_name='_of_PC-7-3-3.png'). pca_heatmap(adata, 4, fig_name='_of_PC-7-3-4.png'). pca_heatmap(adata, 5, fig_name='_of_PC-7-3-5.png'). pca_heatmap(adata, 6, fig_name='_of_PC-7-3-6.png'). pca_heatmap(adata, 7, fig_name='_of_PC-7-3-7.png'). pca_heatmap(adata, 8, fig_name='_of_PC-7-3-8.png'). pca_heatmap(adata, 9, fig_name='_of_PC-7-3-9.png'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:189,modifiability,layer,layer,189,"As I am a stupid freshman in both python and scanpy, I modified the code fo yours, which falitated me to draw the figure and save it. ```py. def pca_heatmap(adata, component, use_raw=None, layer=None, fig_name='_of_PC-7-3-.png'):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(. adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg),. show_gene_labels=True,. swap_axes=True, cmap='viridis',. use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3),. save=fig_name,. ). pca_heatmap(adata, 1, fig_name='_of_PC-7-3-1.png'). pca_heatmap(adata, 2, fig_name='_of_PC-7-3-2.png'). pca_heatmap(adata, 3, fig_name='_of_PC-7-3-3.png'). pca_heatmap(adata, 4, fig_name='_of_PC-7-3-4.png'). pca_heatmap(adata, 5, fig_name='_of_PC-7-3-5.png'). pca_heatmap(adata, 6, fig_name='_of_PC-7-3-6.png'). pca_heatmap(adata, 7, fig_name='_of_PC-7-3-7.png'). pca_heatmap(adata, 8, fig_name='_of_PC-7-3-8.png'). pca_heatmap(adata, 9, fig_name='_of_PC-7-3-9.png'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:299,modifiability,compon,component,299,"As I am a stupid freshman in both python and scanpy, I modified the code fo yours, which falitated me to draw the figure and save it. ```py. def pca_heatmap(adata, component, use_raw=None, layer=None, fig_name='_of_PC-7-3-.png'):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(. adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg),. show_gene_labels=True,. swap_axes=True, cmap='viridis',. use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3),. save=fig_name,. ). pca_heatmap(adata, 1, fig_name='_of_PC-7-3-1.png'). pca_heatmap(adata, 2, fig_name='_of_PC-7-3-2.png'). pca_heatmap(adata, 3, fig_name='_of_PC-7-3-3.png'). pca_heatmap(adata, 4, fig_name='_of_PC-7-3-4.png'). pca_heatmap(adata, 5, fig_name='_of_PC-7-3-5.png'). pca_heatmap(adata, 6, fig_name='_of_PC-7-3-6.png'). pca_heatmap(adata, 7, fig_name='_of_PC-7-3-7.png'). pca_heatmap(adata, 8, fig_name='_of_PC-7-3-8.png'). pca_heatmap(adata, 9, fig_name='_of_PC-7-3-9.png'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:528,modifiability,compon,component,528,"As I am a stupid freshman in both python and scanpy, I modified the code fo yours, which falitated me to draw the figure and save it. ```py. def pca_heatmap(adata, component, use_raw=None, layer=None, fig_name='_of_PC-7-3-.png'):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(. adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg),. show_gene_labels=True,. swap_axes=True, cmap='viridis',. use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3),. save=fig_name,. ). pca_heatmap(adata, 1, fig_name='_of_PC-7-3-1.png'). pca_heatmap(adata, 2, fig_name='_of_PC-7-3-2.png'). pca_heatmap(adata, 3, fig_name='_of_PC-7-3-3.png'). pca_heatmap(adata, 4, fig_name='_of_PC-7-3-4.png'). pca_heatmap(adata, 5, fig_name='_of_PC-7-3-5.png'). pca_heatmap(adata, 6, fig_name='_of_PC-7-3-6.png'). pca_heatmap(adata, 7, fig_name='_of_PC-7-3-7.png'). pca_heatmap(adata, 8, fig_name='_of_PC-7-3-8.png'). pca_heatmap(adata, 9, fig_name='_of_PC-7-3-9.png'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:853,modifiability,layer,layer,853,"As I am a stupid freshman in both python and scanpy, I modified the code fo yours, which falitated me to draw the figure and save it. ```py. def pca_heatmap(adata, component, use_raw=None, layer=None, fig_name='_of_PC-7-3-.png'):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(. adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg),. show_gene_labels=True,. swap_axes=True, cmap='viridis',. use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3),. save=fig_name,. ). pca_heatmap(adata, 1, fig_name='_of_PC-7-3-1.png'). pca_heatmap(adata, 2, fig_name='_of_PC-7-3-2.png'). pca_heatmap(adata, 3, fig_name='_of_PC-7-3-3.png'). pca_heatmap(adata, 4, fig_name='_of_PC-7-3-4.png'). pca_heatmap(adata, 5, fig_name='_of_PC-7-3-5.png'). pca_heatmap(adata, 6, fig_name='_of_PC-7-3-6.png'). pca_heatmap(adata, 7, fig_name='_of_PC-7-3-7.png'). pca_heatmap(adata, 8, fig_name='_of_PC-7-3-8.png'). pca_heatmap(adata, 9, fig_name='_of_PC-7-3-9.png'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:859,modifiability,layer,layer,859,"As I am a stupid freshman in both python and scanpy, I modified the code fo yours, which falitated me to draw the figure and save it. ```py. def pca_heatmap(adata, component, use_raw=None, layer=None, fig_name='_of_PC-7-3-.png'):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(. adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg),. show_gene_labels=True,. swap_axes=True, cmap='viridis',. use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3),. save=fig_name,. ). pca_heatmap(adata, 1, fig_name='_of_PC-7-3-1.png'). pca_heatmap(adata, 2, fig_name='_of_PC-7-3-2.png'). pca_heatmap(adata, 3, fig_name='_of_PC-7-3-3.png'). pca_heatmap(adata, 4, fig_name='_of_PC-7-3-4.png'). pca_heatmap(adata, 5, fig_name='_of_PC-7-3-5.png'). pca_heatmap(adata, 6, fig_name='_of_PC-7-3-6.png'). pca_heatmap(adata, 7, fig_name='_of_PC-7-3-7.png'). pca_heatmap(adata, 8, fig_name='_of_PC-7-3-8.png'). pca_heatmap(adata, 9, fig_name='_of_PC-7-3-9.png'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:55,security,modif,modified,55,"As I am a stupid freshman in both python and scanpy, I modified the code fo yours, which falitated me to draw the figure and save it. ```py. def pca_heatmap(adata, component, use_raw=None, layer=None, fig_name='_of_PC-7-3-.png'):. attr = 'varm'. keys = 'PCs'. scores = getattr(adata, attr)[keys][:, component]. dd = pd.DataFrame(scores, index=adata.var_names). var_names_pos = dd.sort_values(0, ascending=False).index[:20]. var_names_neg = dd.sort_values(0, ascending=True).index[:20]. pd2 = pd.DataFrame(adata.obsm['X_pca'][:, component], index=adata.obs.index). bottom_cells = pd2.sort_values(0).index[:300].tolist(). top_cells = pd2.sort_values(0, ascending=False).index[:300].tolist(). sc.pl.heatmap(. adata[top_cells+bottom_cells], list(var_names_pos) + list(var_names_neg),. show_gene_labels=True,. swap_axes=True, cmap='viridis',. use_raw=False, layer=layer, vmin=-1, vmax=3, figsize=(3,3),. save=fig_name,. ). pca_heatmap(adata, 1, fig_name='_of_PC-7-3-1.png'). pca_heatmap(adata, 2, fig_name='_of_PC-7-3-2.png'). pca_heatmap(adata, 3, fig_name='_of_PC-7-3-3.png'). pca_heatmap(adata, 4, fig_name='_of_PC-7-3-4.png'). pca_heatmap(adata, 5, fig_name='_of_PC-7-3-5.png'). pca_heatmap(adata, 6, fig_name='_of_PC-7-3-6.png'). pca_heatmap(adata, 7, fig_name='_of_PC-7-3-7.png'). pca_heatmap(adata, 8, fig_name='_of_PC-7-3-8.png'). pca_heatmap(adata, 9, fig_name='_of_PC-7-3-9.png'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:31,usability,user,user-images,31,![heatmap_of_PC-7-3-3](https://user-images.githubusercontent.com/49429496/64930576-9e8ed200-d864-11e9-95c8-ed7cd95dd844.png). The only problem is that the gene list is a little crowded.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:96,energy efficiency,heat,heatmap,96,"Thank you for your code, but I run the code to plot and hint the following problem:. TypeError: heatmap() missing 1 required positional argument: 'groupby'. Can you tell me why? Thank you very much !!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/505:56,usability,hint,hint,56,"Thank you for your code, but I run the code to plot and hint the following problem:. TypeError: heatmap() missing 1 required positional argument: 'groupby'. Can you tell me why? Thank you very much !!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/505
https://github.com/scverse/scanpy/issues/506:78,availability,error,error,78,"Thanks for the reply, unfortunately pandas dataframe conversion gives me this error . `pd.DataFrame(adata.raw.X).to_csv(filename_raw_x)`. `ValueError: DataFrame constructor not properly called!`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:53,interoperability,convers,conversion,53,"Thanks for the reply, unfortunately pandas dataframe conversion gives me this error . `pd.DataFrame(adata.raw.X).to_csv(filename_raw_x)`. `ValueError: DataFrame constructor not properly called!`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:78,performance,error,error,78,"Thanks for the reply, unfortunately pandas dataframe conversion gives me this error . `pd.DataFrame(adata.raw.X).to_csv(filename_raw_x)`. `ValueError: DataFrame constructor not properly called!`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:78,safety,error,error,78,"Thanks for the reply, unfortunately pandas dataframe conversion gives me this error . `pd.DataFrame(adata.raw.X).to_csv(filename_raw_x)`. `ValueError: DataFrame constructor not properly called!`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:78,usability,error,error,78,"Thanks for the reply, unfortunately pandas dataframe conversion gives me this error . `pd.DataFrame(adata.raw.X).to_csv(filename_raw_x)`. `ValueError: DataFrame constructor not properly called!`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:732,availability,slo,slot,732,"@LuckyMD . Thanks a lot, that option did work, however I might have an issue somewhere else. when I ran this command it creates a data frame with different values per cell and gene. Then I went to check my raw.X and if I do . `print(adata.raw.X) `. I get this kind of values . ```. (0, 2005)	2.724785. (0, 2004)	0.8859608. (0, 2003)	2.1791992. (0, 2001)	3.498613. (0, 2000)	2.855959. (0, 1985)	0.8859608. (0, 1984)	0.5380458. (0, 1974)	0.5380458. (0, 1950)	1.3482361. ```. but if I look at adata.X it has values already after scaling and looks like this . ```. [[-0.33361623 -0.39783627 0.3157311 ... 0.74563605 1.3691179. -0.5147692 ]. [-0.2754761 -0.3423106 0.57043296 ... -0.2636034 1.3486573. 2.9965923 ]. ```. I have saved raw slot right before scaling the data, I was expected that it would have just normalized values cell/gene similar to adata.X .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:526,modifiability,scal,scaling,526,"@LuckyMD . Thanks a lot, that option did work, however I might have an issue somewhere else. when I ran this command it creates a data frame with different values per cell and gene. Then I went to check my raw.X and if I do . `print(adata.raw.X) `. I get this kind of values . ```. (0, 2005)	2.724785. (0, 2004)	0.8859608. (0, 2003)	2.1791992. (0, 2001)	3.498613. (0, 2000)	2.855959. (0, 1985)	0.8859608. (0, 1984)	0.5380458. (0, 1974)	0.5380458. (0, 1950)	1.3482361. ```. but if I look at adata.X it has values already after scaling and looks like this . ```. [[-0.33361623 -0.39783627 0.3157311 ... 0.74563605 1.3691179. -0.5147692 ]. [-0.2754761 -0.3423106 0.57043296 ... -0.2636034 1.3486573. 2.9965923 ]. ```. I have saved raw slot right before scaling the data, I was expected that it would have just normalized values cell/gene similar to adata.X .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:750,modifiability,scal,scaling,750,"@LuckyMD . Thanks a lot, that option did work, however I might have an issue somewhere else. when I ran this command it creates a data frame with different values per cell and gene. Then I went to check my raw.X and if I do . `print(adata.raw.X) `. I get this kind of values . ```. (0, 2005)	2.724785. (0, 2004)	0.8859608. (0, 2003)	2.1791992. (0, 2001)	3.498613. (0, 2000)	2.855959. (0, 1985)	0.8859608. (0, 1984)	0.5380458. (0, 1974)	0.5380458. (0, 1950)	1.3482361. ```. but if I look at adata.X it has values already after scaling and looks like this . ```. [[-0.33361623 -0.39783627 0.3157311 ... 0.74563605 1.3691179. -0.5147692 ]. [-0.2754761 -0.3423106 0.57043296 ... -0.2636034 1.3486573. 2.9965923 ]. ```. I have saved raw slot right before scaling the data, I was expected that it would have just normalized values cell/gene similar to adata.X .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:732,reliability,slo,slot,732,"@LuckyMD . Thanks a lot, that option did work, however I might have an issue somewhere else. when I ran this command it creates a data frame with different values per cell and gene. Then I went to check my raw.X and if I do . `print(adata.raw.X) `. I get this kind of values . ```. (0, 2005)	2.724785. (0, 2004)	0.8859608. (0, 2003)	2.1791992. (0, 2001)	3.498613. (0, 2000)	2.855959. (0, 1985)	0.8859608. (0, 1984)	0.5380458. (0, 1974)	0.5380458. (0, 1950)	1.3482361. ```. but if I look at adata.X it has values already after scaling and looks like this . ```. [[-0.33361623 -0.39783627 0.3157311 ... 0.74563605 1.3691179. -0.5147692 ]. [-0.2754761 -0.3423106 0.57043296 ... -0.2636034 1.3486573. 2.9965923 ]. ```. I have saved raw slot right before scaling the data, I was expected that it would have just normalized values cell/gene similar to adata.X .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:109,usability,command,command,109,"@LuckyMD . Thanks a lot, that option did work, however I might have an issue somewhere else. when I ran this command it creates a data frame with different values per cell and gene. Then I went to check my raw.X and if I do . `print(adata.raw.X) `. I get this kind of values . ```. (0, 2005)	2.724785. (0, 2004)	0.8859608. (0, 2003)	2.1791992. (0, 2001)	3.498613. (0, 2000)	2.855959. (0, 1985)	0.8859608. (0, 1984)	0.5380458. (0, 1974)	0.5380458. (0, 1950)	1.3482361. ```. but if I look at adata.X it has values already after scaling and looks like this . ```. [[-0.33361623 -0.39783627 0.3157311 ... 0.74563605 1.3691179. -0.5147692 ]. [-0.2754761 -0.3423106 0.57043296 ... -0.2636034 1.3486573. 2.9965923 ]. ```. I have saved raw slot right before scaling the data, I was expected that it would have just normalized values cell/gene similar to adata.X .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:1022,availability,slo,slot,1022,"You can also use the cellbrowser export function in tools. It will create. two tab-sep files, one with the raw matrix and one with the meta data. On Wed, Feb 27, 2019 at 11:33 PM tsotnech <notifications@github.com> wrote:. > @LuckyMD <https://github.com/LuckyMD>. > Thanks a lot, that option did work, however I might have an issue. > somewhere else. when I ran this command it creates a data frame with. > different values per cell and gene. Then I went to check my raw.X and if I. > do. >. > print(adata.raw.X). > I get this kind of values. >. > (0, 2005)	2.724785. > (0, 2004)	0.8859608. > (0, 2003)	2.1791992. > (0, 2001)	3.498613. > (0, 2000)	2.855959. > (0, 1985)	0.8859608. > (0, 1984)	0.5380458. > (0, 1974)	0.5380458. > (0, 1950)	1.3482361. >. > but if I look at adata.X it has values already after scaling and looks. > like this. >. > [[-0.33361623 -0.39783627 0.3157311 ... 0.74563605 1.3691179. > -0.5147692 ]. > [-0.2754761 -0.3423106 0.57043296 ... -0.2636034 1.3486573. > 2.9965923 ]. >. > I have saved raw slot right before scaling the data, I was expected that. > it would have just normalized values cell/gene similar to adata.X. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/506#issuecomment-468058012>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAS-TXEzjH7oDb3RfOw35VNQDQbRyndbks5vRwfKgaJpZM4bThrQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:1197,integrability,sub,subscribed,1197,"You can also use the cellbrowser export function in tools. It will create. two tab-sep files, one with the raw matrix and one with the meta data. On Wed, Feb 27, 2019 at 11:33 PM tsotnech <notifications@github.com> wrote:. > @LuckyMD <https://github.com/LuckyMD>. > Thanks a lot, that option did work, however I might have an issue. > somewhere else. when I ran this command it creates a data frame with. > different values per cell and gene. Then I went to check my raw.X and if I. > do. >. > print(adata.raw.X). > I get this kind of values. >. > (0, 2005)	2.724785. > (0, 2004)	0.8859608. > (0, 2003)	2.1791992. > (0, 2001)	3.498613. > (0, 2000)	2.855959. > (0, 1985)	0.8859608. > (0, 1984)	0.5380458. > (0, 1974)	0.5380458. > (0, 1950)	1.3482361. >. > but if I look at adata.X it has values already after scaling and looks. > like this. >. > [[-0.33361623 -0.39783627 0.3157311 ... 0.74563605 1.3691179. > -0.5147692 ]. > [-0.2754761 -0.3423106 0.57043296 ... -0.2636034 1.3486573. > 2.9965923 ]. >. > I have saved raw slot right before scaling the data, I was expected that. > it would have just normalized values cell/gene similar to adata.X. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/506#issuecomment-468058012>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAS-TXEzjH7oDb3RfOw35VNQDQbRyndbks5vRwfKgaJpZM4bThrQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:808,modifiability,scal,scaling,808,"You can also use the cellbrowser export function in tools. It will create. two tab-sep files, one with the raw matrix and one with the meta data. On Wed, Feb 27, 2019 at 11:33 PM tsotnech <notifications@github.com> wrote:. > @LuckyMD <https://github.com/LuckyMD>. > Thanks a lot, that option did work, however I might have an issue. > somewhere else. when I ran this command it creates a data frame with. > different values per cell and gene. Then I went to check my raw.X and if I. > do. >. > print(adata.raw.X). > I get this kind of values. >. > (0, 2005)	2.724785. > (0, 2004)	0.8859608. > (0, 2003)	2.1791992. > (0, 2001)	3.498613. > (0, 2000)	2.855959. > (0, 1985)	0.8859608. > (0, 1984)	0.5380458. > (0, 1974)	0.5380458. > (0, 1950)	1.3482361. >. > but if I look at adata.X it has values already after scaling and looks. > like this. >. > [[-0.33361623 -0.39783627 0.3157311 ... 0.74563605 1.3691179. > -0.5147692 ]. > [-0.2754761 -0.3423106 0.57043296 ... -0.2636034 1.3486573. > 2.9965923 ]. >. > I have saved raw slot right before scaling the data, I was expected that. > it would have just normalized values cell/gene similar to adata.X. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/506#issuecomment-468058012>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAS-TXEzjH7oDb3RfOw35VNQDQbRyndbks5vRwfKgaJpZM4bThrQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:1040,modifiability,scal,scaling,1040,"You can also use the cellbrowser export function in tools. It will create. two tab-sep files, one with the raw matrix and one with the meta data. On Wed, Feb 27, 2019 at 11:33 PM tsotnech <notifications@github.com> wrote:. > @LuckyMD <https://github.com/LuckyMD>. > Thanks a lot, that option did work, however I might have an issue. > somewhere else. when I ran this command it creates a data frame with. > different values per cell and gene. Then I went to check my raw.X and if I. > do. >. > print(adata.raw.X). > I get this kind of values. >. > (0, 2005)	2.724785. > (0, 2004)	0.8859608. > (0, 2003)	2.1791992. > (0, 2001)	3.498613. > (0, 2000)	2.855959. > (0, 1985)	0.8859608. > (0, 1984)	0.5380458. > (0, 1974)	0.5380458. > (0, 1950)	1.3482361. >. > but if I look at adata.X it has values already after scaling and looks. > like this. >. > [[-0.33361623 -0.39783627 0.3157311 ... 0.74563605 1.3691179. > -0.5147692 ]. > [-0.2754761 -0.3423106 0.57043296 ... -0.2636034 1.3486573. > 2.9965923 ]. >. > I have saved raw slot right before scaling the data, I was expected that. > it would have just normalized values cell/gene similar to adata.X. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/506#issuecomment-468058012>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAS-TXEzjH7oDb3RfOw35VNQDQbRyndbks5vRwfKgaJpZM4bThrQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:1022,reliability,slo,slot,1022,"You can also use the cellbrowser export function in tools. It will create. two tab-sep files, one with the raw matrix and one with the meta data. On Wed, Feb 27, 2019 at 11:33 PM tsotnech <notifications@github.com> wrote:. > @LuckyMD <https://github.com/LuckyMD>. > Thanks a lot, that option did work, however I might have an issue. > somewhere else. when I ran this command it creates a data frame with. > different values per cell and gene. Then I went to check my raw.X and if I. > do. >. > print(adata.raw.X). > I get this kind of values. >. > (0, 2005)	2.724785. > (0, 2004)	0.8859608. > (0, 2003)	2.1791992. > (0, 2001)	3.498613. > (0, 2000)	2.855959. > (0, 1985)	0.8859608. > (0, 1984)	0.5380458. > (0, 1974)	0.5380458. > (0, 1950)	1.3482361. >. > but if I look at adata.X it has values already after scaling and looks. > like this. >. > [[-0.33361623 -0.39783627 0.3157311 ... 0.74563605 1.3691179. > -0.5147692 ]. > [-0.2754761 -0.3423106 0.57043296 ... -0.2636034 1.3486573. > 2.9965923 ]. >. > I have saved raw slot right before scaling the data, I was expected that. > it would have just normalized values cell/gene similar to adata.X. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/506#issuecomment-468058012>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAS-TXEzjH7oDb3RfOw35VNQDQbRyndbks5vRwfKgaJpZM4bThrQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:1420,security,auth,auth,1420,"You can also use the cellbrowser export function in tools. It will create. two tab-sep files, one with the raw matrix and one with the meta data. On Wed, Feb 27, 2019 at 11:33 PM tsotnech <notifications@github.com> wrote:. > @LuckyMD <https://github.com/LuckyMD>. > Thanks a lot, that option did work, however I might have an issue. > somewhere else. when I ran this command it creates a data frame with. > different values per cell and gene. Then I went to check my raw.X and if I. > do. >. > print(adata.raw.X). > I get this kind of values. >. > (0, 2005)	2.724785. > (0, 2004)	0.8859608. > (0, 2003)	2.1791992. > (0, 2001)	3.498613. > (0, 2000)	2.855959. > (0, 1985)	0.8859608. > (0, 1984)	0.5380458. > (0, 1974)	0.5380458. > (0, 1950)	1.3482361. >. > but if I look at adata.X it has values already after scaling and looks. > like this. >. > [[-0.33361623 -0.39783627 0.3157311 ... 0.74563605 1.3691179. > -0.5147692 ]. > [-0.2754761 -0.3423106 0.57043296 ... -0.2636034 1.3486573. > 2.9965923 ]. >. > I have saved raw slot right before scaling the data, I was expected that. > it would have just normalized values cell/gene similar to adata.X. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/506#issuecomment-468058012>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAS-TXEzjH7oDb3RfOw35VNQDQbRyndbks5vRwfKgaJpZM4bThrQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:52,usability,tool,tools,52,"You can also use the cellbrowser export function in tools. It will create. two tab-sep files, one with the raw matrix and one with the meta data. On Wed, Feb 27, 2019 at 11:33 PM tsotnech <notifications@github.com> wrote:. > @LuckyMD <https://github.com/LuckyMD>. > Thanks a lot, that option did work, however I might have an issue. > somewhere else. when I ran this command it creates a data frame with. > different values per cell and gene. Then I went to check my raw.X and if I. > do. >. > print(adata.raw.X). > I get this kind of values. >. > (0, 2005)	2.724785. > (0, 2004)	0.8859608. > (0, 2003)	2.1791992. > (0, 2001)	3.498613. > (0, 2000)	2.855959. > (0, 1985)	0.8859608. > (0, 1984)	0.5380458. > (0, 1974)	0.5380458. > (0, 1950)	1.3482361. >. > but if I look at adata.X it has values already after scaling and looks. > like this. >. > [[-0.33361623 -0.39783627 0.3157311 ... 0.74563605 1.3691179. > -0.5147692 ]. > [-0.2754761 -0.3423106 0.57043296 ... -0.2636034 1.3486573. > 2.9965923 ]. >. > I have saved raw slot right before scaling the data, I was expected that. > it would have just normalized values cell/gene similar to adata.X. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/506#issuecomment-468058012>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAS-TXEzjH7oDb3RfOw35VNQDQbRyndbks5vRwfKgaJpZM4bThrQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:367,usability,command,command,367,"You can also use the cellbrowser export function in tools. It will create. two tab-sep files, one with the raw matrix and one with the meta data. On Wed, Feb 27, 2019 at 11:33 PM tsotnech <notifications@github.com> wrote:. > @LuckyMD <https://github.com/LuckyMD>. > Thanks a lot, that option did work, however I might have an issue. > somewhere else. when I ran this command it creates a data frame with. > different values per cell and gene. Then I went to check my raw.X and if I. > do. >. > print(adata.raw.X). > I get this kind of values. >. > (0, 2005)	2.724785. > (0, 2004)	0.8859608. > (0, 2003)	2.1791992. > (0, 2001)	3.498613. > (0, 2000)	2.855959. > (0, 1985)	0.8859608. > (0, 1984)	0.5380458. > (0, 1974)	0.5380458. > (0, 1950)	1.3482361. >. > but if I look at adata.X it has values already after scaling and looks. > like this. >. > [[-0.33361623 -0.39783627 0.3157311 ... 0.74563605 1.3691179. > -0.5147692 ]. > [-0.2754761 -0.3423106 0.57043296 ... -0.2636034 1.3486573. > 2.9965923 ]. >. > I have saved raw slot right before scaling the data, I was expected that. > it would have just normalized values cell/gene similar to adata.X. >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/506#issuecomment-468058012>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAS-TXEzjH7oDb3RfOw35VNQDQbRyndbks5vRwfKgaJpZM4bThrQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:72,deployability,scale,scale,72,"@tsotnech . I don't entirely understand your problem. If you use `sc.pp.scale()` on your anndata object you will scale the gene expression data to have a mean of 0 and a variance of 1 in `adata.X` while `adata.raw.X` remains unchanged. So then your data will look different. Also, it looks like @maximilianh's suggestion is a lot nicer than the code I provided.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:113,deployability,scale,scale,113,"@tsotnech . I don't entirely understand your problem. If you use `sc.pp.scale()` on your anndata object you will scale the gene expression data to have a mean of 0 and a variance of 1 in `adata.X` while `adata.raw.X` remains unchanged. So then your data will look different. Also, it looks like @maximilianh's suggestion is a lot nicer than the code I provided.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:72,energy efficiency,scale,scale,72,"@tsotnech . I don't entirely understand your problem. If you use `sc.pp.scale()` on your anndata object you will scale the gene expression data to have a mean of 0 and a variance of 1 in `adata.X` while `adata.raw.X` remains unchanged. So then your data will look different. Also, it looks like @maximilianh's suggestion is a lot nicer than the code I provided.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:113,energy efficiency,scale,scale,113,"@tsotnech . I don't entirely understand your problem. If you use `sc.pp.scale()` on your anndata object you will scale the gene expression data to have a mean of 0 and a variance of 1 in `adata.X` while `adata.raw.X` remains unchanged. So then your data will look different. Also, it looks like @maximilianh's suggestion is a lot nicer than the code I provided.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:72,modifiability,scal,scale,72,"@tsotnech . I don't entirely understand your problem. If you use `sc.pp.scale()` on your anndata object you will scale the gene expression data to have a mean of 0 and a variance of 1 in `adata.X` while `adata.raw.X` remains unchanged. So then your data will look different. Also, it looks like @maximilianh's suggestion is a lot nicer than the code I provided.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:113,modifiability,scal,scale,113,"@tsotnech . I don't entirely understand your problem. If you use `sc.pp.scale()` on your anndata object you will scale the gene expression data to have a mean of 0 and a variance of 1 in `adata.X` while `adata.raw.X` remains unchanged. So then your data will look different. Also, it looks like @maximilianh's suggestion is a lot nicer than the code I provided.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:72,performance,scale,scale,72,"@tsotnech . I don't entirely understand your problem. If you use `sc.pp.scale()` on your anndata object you will scale the gene expression data to have a mean of 0 and a variance of 1 in `adata.X` while `adata.raw.X` remains unchanged. So then your data will look different. Also, it looks like @maximilianh's suggestion is a lot nicer than the code I provided.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:113,performance,scale,scale,113,"@tsotnech . I don't entirely understand your problem. If you use `sc.pp.scale()` on your anndata object you will scale the gene expression data to have a mean of 0 and a variance of 1 in `adata.X` while `adata.raw.X` remains unchanged. So then your data will look different. Also, it looks like @maximilianh's suggestion is a lot nicer than the code I provided.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:29,testability,understand,understand,29,"@tsotnech . I don't entirely understand your problem. If you use `sc.pp.scale()` on your anndata object you will scale the gene expression data to have a mean of 0 and a variance of 1 in `adata.X` while `adata.raw.X` remains unchanged. So then your data will look different. Also, it looks like @maximilianh's suggestion is a lot nicer than the code I provided.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:258,availability,down,downstream,258,"@LuckyMD @maximilianh Thanks guys for the reply. . Sorry I'm just used to Seurat setup and kind of got lost. Long story short my issue is negative values, after data processing and scaling I have negative values in the expression matrix that throughs off my downstream analysis. But before scaling adata.X format looks completely different (as I mentioned in my previous post). I just want to have a matrix of gene/cell. . If I export using cell browser tool I get same values as processed adata.X . If I do . `adata.to_df().to_csv('./adata.csv', sep=',')`. or if I do . ```. import scanpy.external as sce. sce.exporting.cellbrowser(adata, './test', 'adata', embedding_keys=None, annot_keys=['louvain'], cluster_field='louvain'). ```. it generates exactly same expression matrix, I don't really see the raw value matrix",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:306,interoperability,format,format,306,"@LuckyMD @maximilianh Thanks guys for the reply. . Sorry I'm just used to Seurat setup and kind of got lost. Long story short my issue is negative values, after data processing and scaling I have negative values in the expression matrix that throughs off my downstream analysis. But before scaling adata.X format looks completely different (as I mentioned in my previous post). I just want to have a matrix of gene/cell. . If I export using cell browser tool I get same values as processed adata.X . If I do . `adata.to_df().to_csv('./adata.csv', sep=',')`. or if I do . ```. import scanpy.external as sce. sce.exporting.cellbrowser(adata, './test', 'adata', embedding_keys=None, annot_keys=['louvain'], cluster_field='louvain'). ```. it generates exactly same expression matrix, I don't really see the raw value matrix",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:181,modifiability,scal,scaling,181,"@LuckyMD @maximilianh Thanks guys for the reply. . Sorry I'm just used to Seurat setup and kind of got lost. Long story short my issue is negative values, after data processing and scaling I have negative values in the expression matrix that throughs off my downstream analysis. But before scaling adata.X format looks completely different (as I mentioned in my previous post). I just want to have a matrix of gene/cell. . If I export using cell browser tool I get same values as processed adata.X . If I do . `adata.to_df().to_csv('./adata.csv', sep=',')`. or if I do . ```. import scanpy.external as sce. sce.exporting.cellbrowser(adata, './test', 'adata', embedding_keys=None, annot_keys=['louvain'], cluster_field='louvain'). ```. it generates exactly same expression matrix, I don't really see the raw value matrix",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:290,modifiability,scal,scaling,290,"@LuckyMD @maximilianh Thanks guys for the reply. . Sorry I'm just used to Seurat setup and kind of got lost. Long story short my issue is negative values, after data processing and scaling I have negative values in the expression matrix that throughs off my downstream analysis. But before scaling adata.X format looks completely different (as I mentioned in my previous post). I just want to have a matrix of gene/cell. . If I export using cell browser tool I get same values as processed adata.X . If I do . `adata.to_df().to_csv('./adata.csv', sep=',')`. or if I do . ```. import scanpy.external as sce. sce.exporting.cellbrowser(adata, './test', 'adata', embedding_keys=None, annot_keys=['louvain'], cluster_field='louvain'). ```. it generates exactly same expression matrix, I don't really see the raw value matrix",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:319,safety,compl,completely,319,"@LuckyMD @maximilianh Thanks guys for the reply. . Sorry I'm just used to Seurat setup and kind of got lost. Long story short my issue is negative values, after data processing and scaling I have negative values in the expression matrix that throughs off my downstream analysis. But before scaling adata.X format looks completely different (as I mentioned in my previous post). I just want to have a matrix of gene/cell. . If I export using cell browser tool I get same values as processed adata.X . If I do . `adata.to_df().to_csv('./adata.csv', sep=',')`. or if I do . ```. import scanpy.external as sce. sce.exporting.cellbrowser(adata, './test', 'adata', embedding_keys=None, annot_keys=['louvain'], cluster_field='louvain'). ```. it generates exactly same expression matrix, I don't really see the raw value matrix",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:643,safety,test,test,643,"@LuckyMD @maximilianh Thanks guys for the reply. . Sorry I'm just used to Seurat setup and kind of got lost. Long story short my issue is negative values, after data processing and scaling I have negative values in the expression matrix that throughs off my downstream analysis. But before scaling adata.X format looks completely different (as I mentioned in my previous post). I just want to have a matrix of gene/cell. . If I export using cell browser tool I get same values as processed adata.X . If I do . `adata.to_df().to_csv('./adata.csv', sep=',')`. or if I do . ```. import scanpy.external as sce. sce.exporting.cellbrowser(adata, './test', 'adata', embedding_keys=None, annot_keys=['louvain'], cluster_field='louvain'). ```. it generates exactly same expression matrix, I don't really see the raw value matrix",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:319,security,compl,completely,319,"@LuckyMD @maximilianh Thanks guys for the reply. . Sorry I'm just used to Seurat setup and kind of got lost. Long story short my issue is negative values, after data processing and scaling I have negative values in the expression matrix that throughs off my downstream analysis. But before scaling adata.X format looks completely different (as I mentioned in my previous post). I just want to have a matrix of gene/cell. . If I export using cell browser tool I get same values as processed adata.X . If I do . `adata.to_df().to_csv('./adata.csv', sep=',')`. or if I do . ```. import scanpy.external as sce. sce.exporting.cellbrowser(adata, './test', 'adata', embedding_keys=None, annot_keys=['louvain'], cluster_field='louvain'). ```. it generates exactly same expression matrix, I don't really see the raw value matrix",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:643,testability,test,test,643,"@LuckyMD @maximilianh Thanks guys for the reply. . Sorry I'm just used to Seurat setup and kind of got lost. Long story short my issue is negative values, after data processing and scaling I have negative values in the expression matrix that throughs off my downstream analysis. But before scaling adata.X format looks completely different (as I mentioned in my previous post). I just want to have a matrix of gene/cell. . If I export using cell browser tool I get same values as processed adata.X . If I do . `adata.to_df().to_csv('./adata.csv', sep=',')`. or if I do . ```. import scanpy.external as sce. sce.exporting.cellbrowser(adata, './test', 'adata', embedding_keys=None, annot_keys=['louvain'], cluster_field='louvain'). ```. it generates exactly same expression matrix, I don't really see the raw value matrix",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:454,usability,tool,tool,454,"@LuckyMD @maximilianh Thanks guys for the reply. . Sorry I'm just used to Seurat setup and kind of got lost. Long story short my issue is negative values, after data processing and scaling I have negative values in the expression matrix that throughs off my downstream analysis. But before scaling adata.X format looks completely different (as I mentioned in my previous post). I just want to have a matrix of gene/cell. . If I export using cell browser tool I get same values as processed adata.X . If I do . `adata.to_df().to_csv('./adata.csv', sep=',')`. or if I do . ```. import scanpy.external as sce. sce.exporting.cellbrowser(adata, './test', 'adata', embedding_keys=None, annot_keys=['louvain'], cluster_field='louvain'). ```. it generates exactly same expression matrix, I don't really see the raw value matrix",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:57,deployability,scale,scale,57,"Hi again,. As I was trying to explain before, the `sc.pp.scale()` function scales gene expression values to be centred at 0 and have a variance of 1. That will necessarily produce negative expression values. Maybe the function you were intending to use is `sc.pp.normalize_per_cell()`? That would normalize the gene expression values to give counts per million (or counts per some other constant).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:75,deployability,scale,scales,75,"Hi again,. As I was trying to explain before, the `sc.pp.scale()` function scales gene expression values to be centred at 0 and have a variance of 1. That will necessarily produce negative expression values. Maybe the function you were intending to use is `sc.pp.normalize_per_cell()`? That would normalize the gene expression values to give counts per million (or counts per some other constant).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:57,energy efficiency,scale,scale,57,"Hi again,. As I was trying to explain before, the `sc.pp.scale()` function scales gene expression values to be centred at 0 and have a variance of 1. That will necessarily produce negative expression values. Maybe the function you were intending to use is `sc.pp.normalize_per_cell()`? That would normalize the gene expression values to give counts per million (or counts per some other constant).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:75,energy efficiency,scale,scales,75,"Hi again,. As I was trying to explain before, the `sc.pp.scale()` function scales gene expression values to be centred at 0 and have a variance of 1. That will necessarily produce negative expression values. Maybe the function you were intending to use is `sc.pp.normalize_per_cell()`? That would normalize the gene expression values to give counts per million (or counts per some other constant).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:57,modifiability,scal,scale,57,"Hi again,. As I was trying to explain before, the `sc.pp.scale()` function scales gene expression values to be centred at 0 and have a variance of 1. That will necessarily produce negative expression values. Maybe the function you were intending to use is `sc.pp.normalize_per_cell()`? That would normalize the gene expression values to give counts per million (or counts per some other constant).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:75,modifiability,scal,scales,75,"Hi again,. As I was trying to explain before, the `sc.pp.scale()` function scales gene expression values to be centred at 0 and have a variance of 1. That will necessarily produce negative expression values. Maybe the function you were intending to use is `sc.pp.normalize_per_cell()`? That would normalize the gene expression values to give counts per million (or counts per some other constant).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:57,performance,scale,scale,57,"Hi again,. As I was trying to explain before, the `sc.pp.scale()` function scales gene expression values to be centred at 0 and have a variance of 1. That will necessarily produce negative expression values. Maybe the function you were intending to use is `sc.pp.normalize_per_cell()`? That would normalize the gene expression values to give counts per million (or counts per some other constant).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:75,performance,scale,scales,75,"Hi again,. As I was trying to explain before, the `sc.pp.scale()` function scales gene expression values to be centred at 0 and have a variance of 1. That will necessarily produce negative expression values. Maybe the function you were intending to use is `sc.pp.normalize_per_cell()`? That would normalize the gene expression values to give counts per million (or counts per some other constant).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:168,availability,slo,slot,168,"@LuckyMD . raw data before scaling has all of these ""coordinates"" e.g. (0, 2005) basically what value is assigned to what cell and gene right? When I try to export raw slot all of these ""coordinates"" gets exported with the values in a weird way. however after scaling those coordinates are gone as I showed before I get scaled values and I understand I can be negative, which is totally fine. I just want to extract raw or pp.normalized values without those ""coordinates"". .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:320,deployability,scale,scaled,320,"@LuckyMD . raw data before scaling has all of these ""coordinates"" e.g. (0, 2005) basically what value is assigned to what cell and gene right? When I try to export raw slot all of these ""coordinates"" gets exported with the values in a weird way. however after scaling those coordinates are gone as I showed before I get scaled values and I understand I can be negative, which is totally fine. I just want to extract raw or pp.normalized values without those ""coordinates"". .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:320,energy efficiency,scale,scaled,320,"@LuckyMD . raw data before scaling has all of these ""coordinates"" e.g. (0, 2005) basically what value is assigned to what cell and gene right? When I try to export raw slot all of these ""coordinates"" gets exported with the values in a weird way. however after scaling those coordinates are gone as I showed before I get scaled values and I understand I can be negative, which is totally fine. I just want to extract raw or pp.normalized values without those ""coordinates"". .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:53,interoperability,coordinat,coordinates,53,"@LuckyMD . raw data before scaling has all of these ""coordinates"" e.g. (0, 2005) basically what value is assigned to what cell and gene right? When I try to export raw slot all of these ""coordinates"" gets exported with the values in a weird way. however after scaling those coordinates are gone as I showed before I get scaled values and I understand I can be negative, which is totally fine. I just want to extract raw or pp.normalized values without those ""coordinates"". .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:187,interoperability,coordinat,coordinates,187,"@LuckyMD . raw data before scaling has all of these ""coordinates"" e.g. (0, 2005) basically what value is assigned to what cell and gene right? When I try to export raw slot all of these ""coordinates"" gets exported with the values in a weird way. however after scaling those coordinates are gone as I showed before I get scaled values and I understand I can be negative, which is totally fine. I just want to extract raw or pp.normalized values without those ""coordinates"". .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:274,interoperability,coordinat,coordinates,274,"@LuckyMD . raw data before scaling has all of these ""coordinates"" e.g. (0, 2005) basically what value is assigned to what cell and gene right? When I try to export raw slot all of these ""coordinates"" gets exported with the values in a weird way. however after scaling those coordinates are gone as I showed before I get scaled values and I understand I can be negative, which is totally fine. I just want to extract raw or pp.normalized values without those ""coordinates"". .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:459,interoperability,coordinat,coordinates,459,"@LuckyMD . raw data before scaling has all of these ""coordinates"" e.g. (0, 2005) basically what value is assigned to what cell and gene right? When I try to export raw slot all of these ""coordinates"" gets exported with the values in a weird way. however after scaling those coordinates are gone as I showed before I get scaled values and I understand I can be negative, which is totally fine. I just want to extract raw or pp.normalized values without those ""coordinates"". .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:27,modifiability,scal,scaling,27,"@LuckyMD . raw data before scaling has all of these ""coordinates"" e.g. (0, 2005) basically what value is assigned to what cell and gene right? When I try to export raw slot all of these ""coordinates"" gets exported with the values in a weird way. however after scaling those coordinates are gone as I showed before I get scaled values and I understand I can be negative, which is totally fine. I just want to extract raw or pp.normalized values without those ""coordinates"". .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:260,modifiability,scal,scaling,260,"@LuckyMD . raw data before scaling has all of these ""coordinates"" e.g. (0, 2005) basically what value is assigned to what cell and gene right? When I try to export raw slot all of these ""coordinates"" gets exported with the values in a weird way. however after scaling those coordinates are gone as I showed before I get scaled values and I understand I can be negative, which is totally fine. I just want to extract raw or pp.normalized values without those ""coordinates"". .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:320,modifiability,scal,scaled,320,"@LuckyMD . raw data before scaling has all of these ""coordinates"" e.g. (0, 2005) basically what value is assigned to what cell and gene right? When I try to export raw slot all of these ""coordinates"" gets exported with the values in a weird way. however after scaling those coordinates are gone as I showed before I get scaled values and I understand I can be negative, which is totally fine. I just want to extract raw or pp.normalized values without those ""coordinates"". .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:320,performance,scale,scaled,320,"@LuckyMD . raw data before scaling has all of these ""coordinates"" e.g. (0, 2005) basically what value is assigned to what cell and gene right? When I try to export raw slot all of these ""coordinates"" gets exported with the values in a weird way. however after scaling those coordinates are gone as I showed before I get scaled values and I understand I can be negative, which is totally fine. I just want to extract raw or pp.normalized values without those ""coordinates"". .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:168,reliability,slo,slot,168,"@LuckyMD . raw data before scaling has all of these ""coordinates"" e.g. (0, 2005) basically what value is assigned to what cell and gene right? When I try to export raw slot all of these ""coordinates"" gets exported with the values in a weird way. however after scaling those coordinates are gone as I showed before I get scaled values and I understand I can be negative, which is totally fine. I just want to extract raw or pp.normalized values without those ""coordinates"". .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:340,testability,understand,understand,340,"@LuckyMD . raw data before scaling has all of these ""coordinates"" e.g. (0, 2005) basically what value is assigned to what cell and gene right? When I try to export raw slot all of these ""coordinates"" gets exported with the values in a weird way. however after scaling those coordinates are gone as I showed before I get scaled values and I understand I can be negative, which is totally fine. I just want to extract raw or pp.normalized values without those ""coordinates"". .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:41,interoperability,coordinat,coordinate,41,"I think I understand what you mean. The ""coordinate"" representation you are referring to is a sparse matrix format. If you don't want that representation, you can densify your data using the function:. `adata.X.toarray()`. I think you should be able to do the same with `adata.X.raw` as well. Scaling removes the sparse matrix formatting, as the matrix is no longer sparse after scaling. In other words, scaling replaces (nearly) all of the 0s, so you get a dense format. I hope that is what you're looking for.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:108,interoperability,format,format,108,"I think I understand what you mean. The ""coordinate"" representation you are referring to is a sparse matrix format. If you don't want that representation, you can densify your data using the function:. `adata.X.toarray()`. I think you should be able to do the same with `adata.X.raw` as well. Scaling removes the sparse matrix formatting, as the matrix is no longer sparse after scaling. In other words, scaling replaces (nearly) all of the 0s, so you get a dense format. I hope that is what you're looking for.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:327,interoperability,format,formatting,327,"I think I understand what you mean. The ""coordinate"" representation you are referring to is a sparse matrix format. If you don't want that representation, you can densify your data using the function:. `adata.X.toarray()`. I think you should be able to do the same with `adata.X.raw` as well. Scaling removes the sparse matrix formatting, as the matrix is no longer sparse after scaling. In other words, scaling replaces (nearly) all of the 0s, so you get a dense format. I hope that is what you're looking for.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:464,interoperability,format,format,464,"I think I understand what you mean. The ""coordinate"" representation you are referring to is a sparse matrix format. If you don't want that representation, you can densify your data using the function:. `adata.X.toarray()`. I think you should be able to do the same with `adata.X.raw` as well. Scaling removes the sparse matrix formatting, as the matrix is no longer sparse after scaling. In other words, scaling replaces (nearly) all of the 0s, so you get a dense format. I hope that is what you're looking for.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:293,modifiability,Scal,Scaling,293,"I think I understand what you mean. The ""coordinate"" representation you are referring to is a sparse matrix format. If you don't want that representation, you can densify your data using the function:. `adata.X.toarray()`. I think you should be able to do the same with `adata.X.raw` as well. Scaling removes the sparse matrix formatting, as the matrix is no longer sparse after scaling. In other words, scaling replaces (nearly) all of the 0s, so you get a dense format. I hope that is what you're looking for.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:379,modifiability,scal,scaling,379,"I think I understand what you mean. The ""coordinate"" representation you are referring to is a sparse matrix format. If you don't want that representation, you can densify your data using the function:. `adata.X.toarray()`. I think you should be able to do the same with `adata.X.raw` as well. Scaling removes the sparse matrix formatting, as the matrix is no longer sparse after scaling. In other words, scaling replaces (nearly) all of the 0s, so you get a dense format. I hope that is what you're looking for.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:404,modifiability,scal,scaling,404,"I think I understand what you mean. The ""coordinate"" representation you are referring to is a sparse matrix format. If you don't want that representation, you can densify your data using the function:. `adata.X.toarray()`. I think you should be able to do the same with `adata.X.raw` as well. Scaling removes the sparse matrix formatting, as the matrix is no longer sparse after scaling. In other words, scaling replaces (nearly) all of the 0s, so you get a dense format. I hope that is what you're looking for.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:10,testability,understand,understand,10,"I think I understand what you mean. The ""coordinate"" representation you are referring to is a sparse matrix format. If you don't want that representation, you can densify your data using the function:. `adata.X.toarray()`. I think you should be able to do the same with `adata.X.raw` as well. Scaling removes the sparse matrix formatting, as the matrix is no longer sparse after scaling. In other words, scaling replaces (nearly) all of the 0s, so you get a dense format. I hope that is what you're looking for.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:267,interoperability,coordinat,coordinate,267,"I'll modify the cell browser export function to export the raw matrix by. default. I think this has come up before and it's pretty easy to do. On Fri, Mar 1, 2019 at 5:17 PM MalteDLuecken <notifications@github.com>. wrote:. > I think I understand what you mean. The ""coordinate"" representation you. > are referring to is a sparse matrix format. If you don't want that. > representation, you can densify your data using the function:. > adata.X.toarray(). I think you should be able to do the same with. > adata.X.raw as well. >. > Scaling removes the sparse matrix formatting, as the matrix is no longer. > sparse after scaling. In other words, scaling replaces (nearly) all of the. > 0s, so you get a dense format. >. > I hope that is what you're looking for. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/506#issuecomment-468720014>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAS-TTZbYCkWB5t_P-XEj8xOgTs5O3j_ks5vSVKYgaJpZM4bThrQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:337,interoperability,format,format,337,"I'll modify the cell browser export function to export the raw matrix by. default. I think this has come up before and it's pretty easy to do. On Fri, Mar 1, 2019 at 5:17 PM MalteDLuecken <notifications@github.com>. wrote:. > I think I understand what you mean. The ""coordinate"" representation you. > are referring to is a sparse matrix format. If you don't want that. > representation, you can densify your data using the function:. > adata.X.toarray(). I think you should be able to do the same with. > adata.X.raw as well. >. > Scaling removes the sparse matrix formatting, as the matrix is no longer. > sparse after scaling. In other words, scaling replaces (nearly) all of the. > 0s, so you get a dense format. >. > I hope that is what you're looking for. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/506#issuecomment-468720014>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAS-TTZbYCkWB5t_P-XEj8xOgTs5O3j_ks5vSVKYgaJpZM4bThrQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:565,interoperability,format,formatting,565,"I'll modify the cell browser export function to export the raw matrix by. default. I think this has come up before and it's pretty easy to do. On Fri, Mar 1, 2019 at 5:17 PM MalteDLuecken <notifications@github.com>. wrote:. > I think I understand what you mean. The ""coordinate"" representation you. > are referring to is a sparse matrix format. If you don't want that. > representation, you can densify your data using the function:. > adata.X.toarray(). I think you should be able to do the same with. > adata.X.raw as well. >. > Scaling removes the sparse matrix formatting, as the matrix is no longer. > sparse after scaling. In other words, scaling replaces (nearly) all of the. > 0s, so you get a dense format. >. > I hope that is what you're looking for. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/506#issuecomment-468720014>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAS-TTZbYCkWB5t_P-XEj8xOgTs5O3j_ks5vSVKYgaJpZM4bThrQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:708,interoperability,format,format,708,"I'll modify the cell browser export function to export the raw matrix by. default. I think this has come up before and it's pretty easy to do. On Fri, Mar 1, 2019 at 5:17 PM MalteDLuecken <notifications@github.com>. wrote:. > I think I understand what you mean. The ""coordinate"" representation you. > are referring to is a sparse matrix format. If you don't want that. > representation, you can densify your data using the function:. > adata.X.toarray(). I think you should be able to do the same with. > adata.X.raw as well. >. > Scaling removes the sparse matrix formatting, as the matrix is no longer. > sparse after scaling. In other words, scaling replaces (nearly) all of the. > 0s, so you get a dense format. >. > I hope that is what you're looking for. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/506#issuecomment-468720014>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAS-TTZbYCkWB5t_P-XEj8xOgTs5O3j_ks5vSVKYgaJpZM4bThrQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:531,modifiability,Scal,Scaling,531,"I'll modify the cell browser export function to export the raw matrix by. default. I think this has come up before and it's pretty easy to do. On Fri, Mar 1, 2019 at 5:17 PM MalteDLuecken <notifications@github.com>. wrote:. > I think I understand what you mean. The ""coordinate"" representation you. > are referring to is a sparse matrix format. If you don't want that. > representation, you can densify your data using the function:. > adata.X.toarray(). I think you should be able to do the same with. > adata.X.raw as well. >. > Scaling removes the sparse matrix formatting, as the matrix is no longer. > sparse after scaling. In other words, scaling replaces (nearly) all of the. > 0s, so you get a dense format. >. > I hope that is what you're looking for. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/506#issuecomment-468720014>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAS-TTZbYCkWB5t_P-XEj8xOgTs5O3j_ks5vSVKYgaJpZM4bThrQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:620,modifiability,scal,scaling,620,"I'll modify the cell browser export function to export the raw matrix by. default. I think this has come up before and it's pretty easy to do. On Fri, Mar 1, 2019 at 5:17 PM MalteDLuecken <notifications@github.com>. wrote:. > I think I understand what you mean. The ""coordinate"" representation you. > are referring to is a sparse matrix format. If you don't want that. > representation, you can densify your data using the function:. > adata.X.toarray(). I think you should be able to do the same with. > adata.X.raw as well. >. > Scaling removes the sparse matrix formatting, as the matrix is no longer. > sparse after scaling. In other words, scaling replaces (nearly) all of the. > 0s, so you get a dense format. >. > I hope that is what you're looking for. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/506#issuecomment-468720014>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAS-TTZbYCkWB5t_P-XEj8xOgTs5O3j_ks5vSVKYgaJpZM4bThrQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:645,modifiability,scal,scaling,645,"I'll modify the cell browser export function to export the raw matrix by. default. I think this has come up before and it's pretty easy to do. On Fri, Mar 1, 2019 at 5:17 PM MalteDLuecken <notifications@github.com>. wrote:. > I think I understand what you mean. The ""coordinate"" representation you. > are referring to is a sparse matrix format. If you don't want that. > representation, you can densify your data using the function:. > adata.X.toarray(). I think you should be able to do the same with. > adata.X.raw as well. >. > Scaling removes the sparse matrix formatting, as the matrix is no longer. > sparse after scaling. In other words, scaling replaces (nearly) all of the. > 0s, so you get a dense format. >. > I hope that is what you're looking for. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/506#issuecomment-468720014>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAS-TTZbYCkWB5t_P-XEj8xOgTs5O3j_ks5vSVKYgaJpZM4bThrQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:5,security,modif,modify,5,"I'll modify the cell browser export function to export the raw matrix by. default. I think this has come up before and it's pretty easy to do. On Fri, Mar 1, 2019 at 5:17 PM MalteDLuecken <notifications@github.com>. wrote:. > I think I understand what you mean. The ""coordinate"" representation you. > are referring to is a sparse matrix format. If you don't want that. > representation, you can densify your data using the function:. > adata.X.toarray(). I think you should be able to do the same with. > adata.X.raw as well. >. > Scaling removes the sparse matrix formatting, as the matrix is no longer. > sparse after scaling. In other words, scaling replaces (nearly) all of the. > 0s, so you get a dense format. >. > I hope that is what you're looking for. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/506#issuecomment-468720014>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAS-TTZbYCkWB5t_P-XEj8xOgTs5O3j_ks5vSVKYgaJpZM4bThrQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:1018,security,auth,auth,1018,"I'll modify the cell browser export function to export the raw matrix by. default. I think this has come up before and it's pretty easy to do. On Fri, Mar 1, 2019 at 5:17 PM MalteDLuecken <notifications@github.com>. wrote:. > I think I understand what you mean. The ""coordinate"" representation you. > are referring to is a sparse matrix format. If you don't want that. > representation, you can densify your data using the function:. > adata.X.toarray(). I think you should be able to do the same with. > adata.X.raw as well. >. > Scaling removes the sparse matrix formatting, as the matrix is no longer. > sparse after scaling. In other words, scaling replaces (nearly) all of the. > 0s, so you get a dense format. >. > I hope that is what you're looking for. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/506#issuecomment-468720014>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAS-TTZbYCkWB5t_P-XEj8xOgTs5O3j_ks5vSVKYgaJpZM4bThrQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:236,testability,understand,understand,236,"I'll modify the cell browser export function to export the raw matrix by. default. I think this has come up before and it's pretty easy to do. On Fri, Mar 1, 2019 at 5:17 PM MalteDLuecken <notifications@github.com>. wrote:. > I think I understand what you mean. The ""coordinate"" representation you. > are referring to is a sparse matrix format. If you don't want that. > representation, you can densify your data using the function:. > adata.X.toarray(). I think you should be able to do the same with. > adata.X.raw as well. >. > Scaling removes the sparse matrix formatting, as the matrix is no longer. > sparse after scaling. In other words, scaling replaces (nearly) all of the. > 0s, so you get a dense format. >. > I hope that is what you're looking for. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/506#issuecomment-468720014>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAS-TTZbYCkWB5t_P-XEj8xOgTs5O3j_ks5vSVKYgaJpZM4bThrQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/506:45,usability,help,help,45,"@LuckyMD @maximilianh . Thanks guys for your help and sorry for misunderstanding I think I wasn't explaining correctly my issue. . So at the end this worked perfectly well to export raw data matrix. ```. t=adata.raw.X.toarray(). pd.DataFrame(data=t, index=adata.obs_names, columns=adata.raw.var_names).to_csv('adata_raw_x.csv'). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/506
https://github.com/scverse/scanpy/issues/507:311,integrability,filter,filtered,311,"Sorry about the late response! I think this might fit under the `.obsm` attribute of an `AnnData` object. Looking at [the docs](https://anndata.readthedocs.io/en/latest/anndata.AnnData.html), it's meant to store two dimensional annotations. . That said, I've personally put ERCCs in the expression matrix, then filtered them out for parts of the analysis where they are confounding.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/507
https://github.com/scverse/scanpy/issues/507:259,usability,person,personally,259,"Sorry about the late response! I think this might fit under the `.obsm` attribute of an `AnnData` object. Looking at [the docs](https://anndata.readthedocs.io/en/latest/anndata.AnnData.html), it's meant to store two dimensional annotations. . That said, I've personally put ERCCs in the expression matrix, then filtered them out for parts of the analysis where they are confounding.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/507
https://github.com/scverse/scanpy/issues/507:82,availability,sli,slightly,82,"Definitely both valid. Since they’re not real genes (but measured like them), I’d slightly prefer the `.obsm` solution as that can’t result in problems if you forget the ERCCs are there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/507
https://github.com/scverse/scanpy/issues/507:57,energy efficiency,measur,measured,57,"Definitely both valid. Since they’re not real genes (but measured like them), I’d slightly prefer the `.obsm` solution as that can’t result in problems if you forget the ERCCs are there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/507
https://github.com/scverse/scanpy/issues/507:82,reliability,sli,slightly,82,"Definitely both valid. Since they’re not real genes (but measured like them), I’d slightly prefer the `.obsm` solution as that can’t result in problems if you forget the ERCCs are there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/507
https://github.com/scverse/scanpy/issues/507:16,safety,valid,valid,16,"Definitely both valid. Since they’re not real genes (but measured like them), I’d slightly prefer the `.obsm` solution as that can’t result in problems if you forget the ERCCs are there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/507
https://github.com/scverse/scanpy/issues/507:91,usability,prefer,prefer,91,"Definitely both valid. Since they’re not real genes (but measured like them), I’d slightly prefer the `.obsm` solution as that can’t result in problems if you forget the ERCCs are there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/507
https://github.com/scverse/scanpy/issues/509:238,availability,avail,available,238,"Hi! It looks like you have too many 0 count genes in your dataset. I would filter genes and cells before calculating highly variable genes. In case you're interested, I've been working on a tutorial for single-cell RNA-seq analysis. It's available [here](www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:75,integrability,filter,filter,75,"Hi! It looks like you have too many 0 count genes in your dataset. I would filter genes and cells before calculating highly variable genes. In case you're interested, I've been working on a tutorial for single-cell RNA-seq analysis. It's available [here](www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:124,modifiability,variab,variable,124,"Hi! It looks like you have too many 0 count genes in your dataset. I would filter genes and cells before calculating highly variable genes. In case you're interested, I've been working on a tutorial for single-cell RNA-seq analysis. It's available [here](www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:238,reliability,availab,available,238,"Hi! It looks like you have too many 0 count genes in your dataset. I would filter genes and cells before calculating highly variable genes. In case you're interested, I've been working on a tutorial for single-cell RNA-seq analysis. It's available [here](www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:238,safety,avail,available,238,"Hi! It looks like you have too many 0 count genes in your dataset. I would filter genes and cells before calculating highly variable genes. In case you're interested, I've been working on a tutorial for single-cell RNA-seq analysis. It's available [here](www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:238,security,availab,available,238,"Hi! It looks like you have too many 0 count genes in your dataset. I would filter genes and cells before calculating highly variable genes. In case you're interested, I've been working on a tutorial for single-cell RNA-seq analysis. It's available [here](www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:24,availability,error,error,24,"I am still getting this error even after doing filtering. This was my code for filtering : . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=1). Can you please help me with this ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:47,integrability,filter,filtering,47,"I am still getting this error even after doing filtering. This was my code for filtering : . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=1). Can you please help me with this ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:79,integrability,filter,filtering,79,"I am still getting this error even after doing filtering. This was my code for filtering : . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=1). Can you please help me with this ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:24,performance,error,error,24,"I am still getting this error even after doing filtering. This was my code for filtering : . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=1). Can you please help me with this ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:24,safety,error,error,24,"I am still getting this error even after doing filtering. This was my code for filtering : . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=1). Can you please help me with this ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:24,usability,error,error,24,"I am still getting this error even after doing filtering. This was my code for filtering : . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=1). Can you please help me with this ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:190,usability,help,help,190,"I am still getting this error even after doing filtering. This was my code for filtering : . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=1). Can you please help me with this ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:22,availability,error,error,22,"Encountered this same error, not clear what is causing it. . ``` . sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.scale(adata, max_value=10). sc.pp.filter_genes(adata, min_cells=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000). . ```. With the same error:. ```. File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,. -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,. 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,. 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,. 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:323,availability,error,error,323,"Encountered this same error, not clear what is causing it. . ``` . sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.scale(adata, max_value=10). sc.pp.filter_genes(adata, min_cells=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000). . ```. With the same error:. ```. File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,. -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,. 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,. 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,. 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:949,availability,error,error,949,"Encountered this same error, not clear what is causing it. . ``` . sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.scale(adata, max_value=10). sc.pp.filter_genes(adata, min_cells=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000). . ```. With the same error:. ```. File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,. -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,. 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,. 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,. 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:158,deployability,scale,scale,158,"Encountered this same error, not clear what is causing it. . ``` . sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.scale(adata, max_value=10). sc.pp.filter_genes(adata, min_cells=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000). . ```. With the same error:. ```. File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,. -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,. 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,. 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,. 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:158,energy efficiency,scale,scale,158,"Encountered this same error, not clear what is causing it. . ``` . sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.scale(adata, max_value=10). sc.pp.filter_genes(adata, min_cells=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000). . ```. With the same error:. ```. File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,. -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,. 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,. 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,. 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:387,energy efficiency,core,core,387,"Encountered this same error, not clear what is causing it. . ``` . sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.scale(adata, max_value=10). sc.pp.filter_genes(adata, min_cells=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000). . ```. With the same error:. ```. File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,. -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,. 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,. 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,. 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:158,modifiability,scal,scale,158,"Encountered this same error, not clear what is causing it. . ``` . sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.scale(adata, max_value=10). sc.pp.filter_genes(adata, min_cells=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000). . ```. With the same error:. ```. File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,. -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,. 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,. 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,. 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:371,modifiability,pac,packages,371,"Encountered this same error, not clear what is causing it. . ``` . sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.scale(adata, max_value=10). sc.pp.filter_genes(adata, min_cells=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000). . ```. With the same error:. ```. File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,. -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,. 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,. 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,. 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:22,performance,error,error,22,"Encountered this same error, not clear what is causing it. . ``` . sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.scale(adata, max_value=10). sc.pp.filter_genes(adata, min_cells=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000). . ```. With the same error:. ```. File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,. -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,. 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,. 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,. 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:158,performance,scale,scale,158,"Encountered this same error, not clear what is causing it. . ``` . sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.scale(adata, max_value=10). sc.pp.filter_genes(adata, min_cells=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000). . ```. With the same error:. ```. File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,. -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,. 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,. 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,. 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:323,performance,error,error,323,"Encountered this same error, not clear what is causing it. . ``` . sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.scale(adata, max_value=10). sc.pp.filter_genes(adata, min_cells=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000). . ```. With the same error:. ```. File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,. -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,. 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,. 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,. 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:949,performance,error,error,949,"Encountered this same error, not clear what is causing it. . ``` . sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.scale(adata, max_value=10). sc.pp.filter_genes(adata, min_cells=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000). . ```. With the same error:. ```. File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,. -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,. 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,. 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,. 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:971,reliability,doe,doesn,971,"Encountered this same error, not clear what is causing it. . ``` . sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.scale(adata, max_value=10). sc.pp.filter_genes(adata, min_cells=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000). . ```. With the same error:. ```. File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,. -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,. 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,. 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,. 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:22,safety,error,error,22,"Encountered this same error, not clear what is causing it. . ``` . sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.scale(adata, max_value=10). sc.pp.filter_genes(adata, min_cells=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000). . ```. With the same error:. ```. File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,. -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,. 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,. 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,. 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:323,safety,error,error,323,"Encountered this same error, not clear what is causing it. . ``` . sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.scale(adata, max_value=10). sc.pp.filter_genes(adata, min_cells=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000). . ```. With the same error:. ```. File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,. -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,. 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,. 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,. 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:943,safety,input,input,943,"Encountered this same error, not clear what is causing it. . ``` . sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.scale(adata, max_value=10). sc.pp.filter_genes(adata, min_cells=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000). . ```. With the same error:. ```. File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,. -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,. 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,. 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,. 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:949,safety,error,error,949,"Encountered this same error, not clear what is causing it. . ``` . sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.scale(adata, max_value=10). sc.pp.filter_genes(adata, min_cells=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000). . ```. With the same error:. ```. File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,. -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,. 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,. 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,. 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:22,usability,error,error,22,"Encountered this same error, not clear what is causing it. . ``` . sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.scale(adata, max_value=10). sc.pp.filter_genes(adata, min_cells=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000). . ```. With the same error:. ```. File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,. -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,. 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,. 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,. 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:33,usability,clear,clear,33,"Encountered this same error, not clear what is causing it. . ``` . sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.scale(adata, max_value=10). sc.pp.filter_genes(adata, min_cells=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000). . ```. With the same error:. ```. File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,. -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,. 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,. 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,. 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:323,usability,error,error,323,"Encountered this same error, not clear what is causing it. . ``` . sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.scale(adata, max_value=10). sc.pp.filter_genes(adata, min_cells=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000). . ```. With the same error:. ```. File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,. -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,. 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,. 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,. 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:943,usability,input,input,943,"Encountered this same error, not clear what is causing it. . ``` . sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.scale(adata, max_value=10). sc.pp.filter_genes(adata, min_cells=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000). . ```. With the same error:. ```. File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,. -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,. 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,. 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,. 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/509:949,usability,error,error,949,"Encountered this same error, not clear what is causing it. . ``` . sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata.raw = adata. sc.pp.scale(adata, max_value=10). sc.pp.filter_genes(adata, min_cells=2). sc.pp.highly_variable_genes(adata, flavor='cell_ranger', n_top_genes=2000). . ```. With the same error:. ```. File ""/opt/venv/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 400, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([ -inf, -4.47034836e-08, -2.98023224e-08, -2.98023224e-08,. -1.49011612e-08, -8.38190317e-09, 1.00000000e-12, 1.00000000e-12,. 1.00000000e-12, 1.00000000e-12, 1.00000000e-12, 4.09781933e-09,. 1.49011612e-08, 1.49011612e-08, 1.49011612e-08, 1.49011612e-08,. 2.98023224e-08, 4.47034836e-08, 4.47034836e-08, 5.96046448e-08,. inf]). You can drop duplicate edges by setting the 'duplicates' kwarg. ```. Very possibly an input error, but the output doesn't point to anything useful as a starting point to debug. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/509
https://github.com/scverse/scanpy/issues/510:166,availability,cluster,clustering,166,"Thank you for the super-kind words, @biskra. (1) I agree it's useful! Why don't you subset `adata` to the genes that are interesting for you and run an embedding and clustering on them? That's definitely valid. You can keep everything else in `.raw`. I personally would either set the `highly_variable_genes` annotation to `False` for genes that I'm not interested in after calling `pp.highly_variable_genes`. As an effect, the `pca` will be computed on those and you can propagate this further. If you don't want a `pca`, you can add a gene-set representation as a representation to `adata` via . ```. adata.obsm['X_geneset1`] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). ```. (2) We don't have any multi-modal features in Scanpy yet. There will very likely be some in the near future, but right now, you need to write custom code for it. Sorry. (3) Would you make a PR about it? Thanks for the super constructive issue!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:166,deployability,cluster,clustering,166,"Thank you for the super-kind words, @biskra. (1) I agree it's useful! Why don't you subset `adata` to the genes that are interesting for you and run an embedding and clustering on them? That's definitely valid. You can keep everything else in `.raw`. I personally would either set the `highly_variable_genes` annotation to `False` for genes that I'm not interested in after calling `pp.highly_variable_genes`. As an effect, the `pca` will be computed on those and you can propagate this further. If you don't want a `pca`, you can add a gene-set representation as a representation to `adata` via . ```. adata.obsm['X_geneset1`] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). ```. (2) We don't have any multi-modal features in Scanpy yet. There will very likely be some in the near future, but right now, you need to write custom code for it. Sorry. (3) Would you make a PR about it? Thanks for the super constructive issue!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:84,integrability,sub,subset,84,"Thank you for the super-kind words, @biskra. (1) I agree it's useful! Why don't you subset `adata` to the genes that are interesting for you and run an embedding and clustering on them? That's definitely valid. You can keep everything else in `.raw`. I personally would either set the `highly_variable_genes` annotation to `False` for genes that I'm not interested in after calling `pp.highly_variable_genes`. As an effect, the `pca` will be computed on those and you can propagate this further. If you don't want a `pca`, you can add a gene-set representation as a representation to `adata` via . ```. adata.obsm['X_geneset1`] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). ```. (2) We don't have any multi-modal features in Scanpy yet. There will very likely be some in the near future, but right now, you need to write custom code for it. Sorry. (3) Would you make a PR about it? Thanks for the super constructive issue!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:204,safety,valid,valid,204,"Thank you for the super-kind words, @biskra. (1) I agree it's useful! Why don't you subset `adata` to the genes that are interesting for you and run an embedding and clustering on them? That's definitely valid. You can keep everything else in `.raw`. I personally would either set the `highly_variable_genes` annotation to `False` for genes that I'm not interested in after calling `pp.highly_variable_genes`. As an effect, the `pca` will be computed on those and you can propagate this further. If you don't want a `pca`, you can add a gene-set representation as a representation to `adata` via . ```. adata.obsm['X_geneset1`] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). ```. (2) We don't have any multi-modal features in Scanpy yet. There will very likely be some in the near future, but right now, you need to write custom code for it. Sorry. (3) Would you make a PR about it? Thanks for the super constructive issue!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:253,usability,person,personally,253,"Thank you for the super-kind words, @biskra. (1) I agree it's useful! Why don't you subset `adata` to the genes that are interesting for you and run an embedding and clustering on them? That's definitely valid. You can keep everything else in `.raw`. I personally would either set the `highly_variable_genes` annotation to `False` for genes that I'm not interested in after calling `pp.highly_variable_genes`. As an effect, the `pca` will be computed on those and you can propagate this further. If you don't want a `pca`, you can add a gene-set representation as a representation to `adata` via . ```. adata.obsm['X_geneset1`] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). ```. (2) We don't have any multi-modal features in Scanpy yet. There will very likely be some in the near future, but right now, you need to write custom code for it. Sorry. (3) Would you make a PR about it? Thanks for the super constructive issue!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:750,usability,multi-mod,multi-modal,750,"Thank you for the super-kind words, @biskra. (1) I agree it's useful! Why don't you subset `adata` to the genes that are interesting for you and run an embedding and clustering on them? That's definitely valid. You can keep everything else in `.raw`. I personally would either set the `highly_variable_genes` annotation to `False` for genes that I'm not interested in after calling `pp.highly_variable_genes`. As an effect, the `pca` will be computed on those and you can propagate this further. If you don't want a `pca`, you can add a gene-set representation as a representation to `adata` via . ```. adata.obsm['X_geneset1`] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). ```. (2) We don't have any multi-modal features in Scanpy yet. There will very likely be some in the near future, but right now, you need to write custom code for it. Sorry. (3) Would you make a PR about it? Thanks for the super constructive issue!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:870,usability,custom,custom,870,"Thank you for the super-kind words, @biskra. (1) I agree it's useful! Why don't you subset `adata` to the genes that are interesting for you and run an embedding and clustering on them? That's definitely valid. You can keep everything else in `.raw`. I personally would either set the `highly_variable_genes` annotation to `False` for genes that I'm not interested in after calling `pp.highly_variable_genes`. As an effect, the `pca` will be computed on those and you can propagate this further. If you don't want a `pca`, you can add a gene-set representation as a representation to `adata` via . ```. adata.obsm['X_geneset1`] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). ```. (2) We don't have any multi-modal features in Scanpy yet. There will very likely be some in the near future, but right now, you need to write custom code for it. Sorry. (3) Would you make a PR about it? Thanks for the super constructive issue!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:26,usability,help,help,26,"Thank you so much for the help, @falexwolf! I will give those solutions a shot. It seems like I can apply a similar solution for CytOF data. I think with your provided solution, I can work my way to multi-modal analysis with custom code. I will get to work on the PR!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:199,usability,multi-mod,multi-modal,199,"Thank you so much for the help, @falexwolf! I will give those solutions a shot. It seems like I can apply a similar solution for CytOF data. I think with your provided solution, I can work my way to multi-modal analysis with custom code. I will get to work on the PR!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:225,usability,custom,custom,225,"Thank you so much for the help, @falexwolf! I will give those solutions a shot. It seems like I can apply a similar solution for CytOF data. I think with your provided solution, I can work my way to multi-modal analysis with custom code. I will get to work on the PR!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:1082,energy efficiency,cool,cool,1082,"@biskra Just my two cents on (3), I mostly use histograms or hex bins for viewing qc metrics. I've been meaning to write this up as a tutorial for a while, but I think you can lean on whole pyviz ecosystem pretty heavily here. Something static and pretty:. ```python. # Joint distribution with marginal histograms:. sns.jointplot(. x=""log1p_total_counts"",. y=""log1p_n_genes_by_counts"",. data=adata.obs,. kind=""hex"". ). # For a single variable. sns.distplot(adata.obs[""log1p_total_counts""]). # To facet the distplot by some columns of obs, like ""batch"":. g = sns.FacetGrid(adata.obs, row=""batch"", height=1.7, aspect=3) . g.map(sns.distplot, ""pct_counts_mito"") # Sadly, this doesn't work for joint grids. # I do have a PR for a ridge plot based on this in the works. ```. If you'd like it to be interactive:. ```python. import hvplot.pandas. adata.obs.hvplot.hexbin(""log1p_total_counts"", ""log1p_n_genes_by_counts""). adata.obs.hvplot.hist(""log1p_total_counts""). # Faceting. adata.obs.hvplot.hist(""pct_counts_mito"", by=""batch"", subplots=True).cols(1). ```. Or, if you want to play with cool most-biggest-data toys:. ```python. adata.obs.hvplot.scatter(. ""log1p_total_counts"",. ""log1p_n_genes_by_counts"",. datashade=True,. dynspread=True. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:545,integrability,batch,batch,545,"@biskra Just my two cents on (3), I mostly use histograms or hex bins for viewing qc metrics. I've been meaning to write this up as a tutorial for a while, but I think you can lean on whole pyviz ecosystem pretty heavily here. Something static and pretty:. ```python. # Joint distribution with marginal histograms:. sns.jointplot(. x=""log1p_total_counts"",. y=""log1p_n_genes_by_counts"",. data=adata.obs,. kind=""hex"". ). # For a single variable. sns.distplot(adata.obs[""log1p_total_counts""]). # To facet the distplot by some columns of obs, like ""batch"":. g = sns.FacetGrid(adata.obs, row=""batch"", height=1.7, aspect=3) . g.map(sns.distplot, ""pct_counts_mito"") # Sadly, this doesn't work for joint grids. # I do have a PR for a ridge plot based on this in the works. ```. If you'd like it to be interactive:. ```python. import hvplot.pandas. adata.obs.hvplot.hexbin(""log1p_total_counts"", ""log1p_n_genes_by_counts""). adata.obs.hvplot.hist(""log1p_total_counts""). # Faceting. adata.obs.hvplot.hist(""pct_counts_mito"", by=""batch"", subplots=True).cols(1). ```. Or, if you want to play with cool most-biggest-data toys:. ```python. adata.obs.hvplot.scatter(. ""log1p_total_counts"",. ""log1p_n_genes_by_counts"",. datashade=True,. dynspread=True. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:588,integrability,batch,batch,588,"@biskra Just my two cents on (3), I mostly use histograms or hex bins for viewing qc metrics. I've been meaning to write this up as a tutorial for a while, but I think you can lean on whole pyviz ecosystem pretty heavily here. Something static and pretty:. ```python. # Joint distribution with marginal histograms:. sns.jointplot(. x=""log1p_total_counts"",. y=""log1p_n_genes_by_counts"",. data=adata.obs,. kind=""hex"". ). # For a single variable. sns.distplot(adata.obs[""log1p_total_counts""]). # To facet the distplot by some columns of obs, like ""batch"":. g = sns.FacetGrid(adata.obs, row=""batch"", height=1.7, aspect=3) . g.map(sns.distplot, ""pct_counts_mito"") # Sadly, this doesn't work for joint grids. # I do have a PR for a ridge plot based on this in the works. ```. If you'd like it to be interactive:. ```python. import hvplot.pandas. adata.obs.hvplot.hexbin(""log1p_total_counts"", ""log1p_n_genes_by_counts""). adata.obs.hvplot.hist(""log1p_total_counts""). # Faceting. adata.obs.hvplot.hist(""pct_counts_mito"", by=""batch"", subplots=True).cols(1). ```. Or, if you want to play with cool most-biggest-data toys:. ```python. adata.obs.hvplot.scatter(. ""log1p_total_counts"",. ""log1p_n_genes_by_counts"",. datashade=True,. dynspread=True. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:1016,integrability,batch,batch,1016,"@biskra Just my two cents on (3), I mostly use histograms or hex bins for viewing qc metrics. I've been meaning to write this up as a tutorial for a while, but I think you can lean on whole pyviz ecosystem pretty heavily here. Something static and pretty:. ```python. # Joint distribution with marginal histograms:. sns.jointplot(. x=""log1p_total_counts"",. y=""log1p_n_genes_by_counts"",. data=adata.obs,. kind=""hex"". ). # For a single variable. sns.distplot(adata.obs[""log1p_total_counts""]). # To facet the distplot by some columns of obs, like ""batch"":. g = sns.FacetGrid(adata.obs, row=""batch"", height=1.7, aspect=3) . g.map(sns.distplot, ""pct_counts_mito"") # Sadly, this doesn't work for joint grids. # I do have a PR for a ridge plot based on this in the works. ```. If you'd like it to be interactive:. ```python. import hvplot.pandas. adata.obs.hvplot.hexbin(""log1p_total_counts"", ""log1p_n_genes_by_counts""). adata.obs.hvplot.hist(""log1p_total_counts""). # Faceting. adata.obs.hvplot.hist(""pct_counts_mito"", by=""batch"", subplots=True).cols(1). ```. Or, if you want to play with cool most-biggest-data toys:. ```python. adata.obs.hvplot.scatter(. ""log1p_total_counts"",. ""log1p_n_genes_by_counts"",. datashade=True,. dynspread=True. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:1024,integrability,sub,subplots,1024,"@biskra Just my two cents on (3), I mostly use histograms or hex bins for viewing qc metrics. I've been meaning to write this up as a tutorial for a while, but I think you can lean on whole pyviz ecosystem pretty heavily here. Something static and pretty:. ```python. # Joint distribution with marginal histograms:. sns.jointplot(. x=""log1p_total_counts"",. y=""log1p_n_genes_by_counts"",. data=adata.obs,. kind=""hex"". ). # For a single variable. sns.distplot(adata.obs[""log1p_total_counts""]). # To facet the distplot by some columns of obs, like ""batch"":. g = sns.FacetGrid(adata.obs, row=""batch"", height=1.7, aspect=3) . g.map(sns.distplot, ""pct_counts_mito"") # Sadly, this doesn't work for joint grids. # I do have a PR for a ridge plot based on this in the works. ```. If you'd like it to be interactive:. ```python. import hvplot.pandas. adata.obs.hvplot.hexbin(""log1p_total_counts"", ""log1p_n_genes_by_counts""). adata.obs.hvplot.hist(""log1p_total_counts""). # Faceting. adata.obs.hvplot.hist(""pct_counts_mito"", by=""batch"", subplots=True).cols(1). ```. Or, if you want to play with cool most-biggest-data toys:. ```python. adata.obs.hvplot.scatter(. ""log1p_total_counts"",. ""log1p_n_genes_by_counts"",. datashade=True,. dynspread=True. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:276,interoperability,distribut,distribution,276,"@biskra Just my two cents on (3), I mostly use histograms or hex bins for viewing qc metrics. I've been meaning to write this up as a tutorial for a while, but I think you can lean on whole pyviz ecosystem pretty heavily here. Something static and pretty:. ```python. # Joint distribution with marginal histograms:. sns.jointplot(. x=""log1p_total_counts"",. y=""log1p_n_genes_by_counts"",. data=adata.obs,. kind=""hex"". ). # For a single variable. sns.distplot(adata.obs[""log1p_total_counts""]). # To facet the distplot by some columns of obs, like ""batch"":. g = sns.FacetGrid(adata.obs, row=""batch"", height=1.7, aspect=3) . g.map(sns.distplot, ""pct_counts_mito"") # Sadly, this doesn't work for joint grids. # I do have a PR for a ridge plot based on this in the works. ```. If you'd like it to be interactive:. ```python. import hvplot.pandas. adata.obs.hvplot.hexbin(""log1p_total_counts"", ""log1p_n_genes_by_counts""). adata.obs.hvplot.hist(""log1p_total_counts""). # Faceting. adata.obs.hvplot.hist(""pct_counts_mito"", by=""batch"", subplots=True).cols(1). ```. Or, if you want to play with cool most-biggest-data toys:. ```python. adata.obs.hvplot.scatter(. ""log1p_total_counts"",. ""log1p_n_genes_by_counts"",. datashade=True,. dynspread=True. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:434,modifiability,variab,variable,434,"@biskra Just my two cents on (3), I mostly use histograms or hex bins for viewing qc metrics. I've been meaning to write this up as a tutorial for a while, but I think you can lean on whole pyviz ecosystem pretty heavily here. Something static and pretty:. ```python. # Joint distribution with marginal histograms:. sns.jointplot(. x=""log1p_total_counts"",. y=""log1p_n_genes_by_counts"",. data=adata.obs,. kind=""hex"". ). # For a single variable. sns.distplot(adata.obs[""log1p_total_counts""]). # To facet the distplot by some columns of obs, like ""batch"":. g = sns.FacetGrid(adata.obs, row=""batch"", height=1.7, aspect=3) . g.map(sns.distplot, ""pct_counts_mito"") # Sadly, this doesn't work for joint grids. # I do have a PR for a ridge plot based on this in the works. ```. If you'd like it to be interactive:. ```python. import hvplot.pandas. adata.obs.hvplot.hexbin(""log1p_total_counts"", ""log1p_n_genes_by_counts""). adata.obs.hvplot.hist(""log1p_total_counts""). # Faceting. adata.obs.hvplot.hist(""pct_counts_mito"", by=""batch"", subplots=True).cols(1). ```. Or, if you want to play with cool most-biggest-data toys:. ```python. adata.obs.hvplot.scatter(. ""log1p_total_counts"",. ""log1p_n_genes_by_counts"",. datashade=True,. dynspread=True. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:545,performance,batch,batch,545,"@biskra Just my two cents on (3), I mostly use histograms or hex bins for viewing qc metrics. I've been meaning to write this up as a tutorial for a while, but I think you can lean on whole pyviz ecosystem pretty heavily here. Something static and pretty:. ```python. # Joint distribution with marginal histograms:. sns.jointplot(. x=""log1p_total_counts"",. y=""log1p_n_genes_by_counts"",. data=adata.obs,. kind=""hex"". ). # For a single variable. sns.distplot(adata.obs[""log1p_total_counts""]). # To facet the distplot by some columns of obs, like ""batch"":. g = sns.FacetGrid(adata.obs, row=""batch"", height=1.7, aspect=3) . g.map(sns.distplot, ""pct_counts_mito"") # Sadly, this doesn't work for joint grids. # I do have a PR for a ridge plot based on this in the works. ```. If you'd like it to be interactive:. ```python. import hvplot.pandas. adata.obs.hvplot.hexbin(""log1p_total_counts"", ""log1p_n_genes_by_counts""). adata.obs.hvplot.hist(""log1p_total_counts""). # Faceting. adata.obs.hvplot.hist(""pct_counts_mito"", by=""batch"", subplots=True).cols(1). ```. Or, if you want to play with cool most-biggest-data toys:. ```python. adata.obs.hvplot.scatter(. ""log1p_total_counts"",. ""log1p_n_genes_by_counts"",. datashade=True,. dynspread=True. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:588,performance,batch,batch,588,"@biskra Just my two cents on (3), I mostly use histograms or hex bins for viewing qc metrics. I've been meaning to write this up as a tutorial for a while, but I think you can lean on whole pyviz ecosystem pretty heavily here. Something static and pretty:. ```python. # Joint distribution with marginal histograms:. sns.jointplot(. x=""log1p_total_counts"",. y=""log1p_n_genes_by_counts"",. data=adata.obs,. kind=""hex"". ). # For a single variable. sns.distplot(adata.obs[""log1p_total_counts""]). # To facet the distplot by some columns of obs, like ""batch"":. g = sns.FacetGrid(adata.obs, row=""batch"", height=1.7, aspect=3) . g.map(sns.distplot, ""pct_counts_mito"") # Sadly, this doesn't work for joint grids. # I do have a PR for a ridge plot based on this in the works. ```. If you'd like it to be interactive:. ```python. import hvplot.pandas. adata.obs.hvplot.hexbin(""log1p_total_counts"", ""log1p_n_genes_by_counts""). adata.obs.hvplot.hist(""log1p_total_counts""). # Faceting. adata.obs.hvplot.hist(""pct_counts_mito"", by=""batch"", subplots=True).cols(1). ```. Or, if you want to play with cool most-biggest-data toys:. ```python. adata.obs.hvplot.scatter(. ""log1p_total_counts"",. ""log1p_n_genes_by_counts"",. datashade=True,. dynspread=True. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:1016,performance,batch,batch,1016,"@biskra Just my two cents on (3), I mostly use histograms or hex bins for viewing qc metrics. I've been meaning to write this up as a tutorial for a while, but I think you can lean on whole pyviz ecosystem pretty heavily here. Something static and pretty:. ```python. # Joint distribution with marginal histograms:. sns.jointplot(. x=""log1p_total_counts"",. y=""log1p_n_genes_by_counts"",. data=adata.obs,. kind=""hex"". ). # For a single variable. sns.distplot(adata.obs[""log1p_total_counts""]). # To facet the distplot by some columns of obs, like ""batch"":. g = sns.FacetGrid(adata.obs, row=""batch"", height=1.7, aspect=3) . g.map(sns.distplot, ""pct_counts_mito"") # Sadly, this doesn't work for joint grids. # I do have a PR for a ridge plot based on this in the works. ```. If you'd like it to be interactive:. ```python. import hvplot.pandas. adata.obs.hvplot.hexbin(""log1p_total_counts"", ""log1p_n_genes_by_counts""). adata.obs.hvplot.hist(""log1p_total_counts""). # Faceting. adata.obs.hvplot.hist(""pct_counts_mito"", by=""batch"", subplots=True).cols(1). ```. Or, if you want to play with cool most-biggest-data toys:. ```python. adata.obs.hvplot.scatter(. ""log1p_total_counts"",. ""log1p_n_genes_by_counts"",. datashade=True,. dynspread=True. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:673,reliability,doe,doesn,673,"@biskra Just my two cents on (3), I mostly use histograms or hex bins for viewing qc metrics. I've been meaning to write this up as a tutorial for a while, but I think you can lean on whole pyviz ecosystem pretty heavily here. Something static and pretty:. ```python. # Joint distribution with marginal histograms:. sns.jointplot(. x=""log1p_total_counts"",. y=""log1p_n_genes_by_counts"",. data=adata.obs,. kind=""hex"". ). # For a single variable. sns.distplot(adata.obs[""log1p_total_counts""]). # To facet the distplot by some columns of obs, like ""batch"":. g = sns.FacetGrid(adata.obs, row=""batch"", height=1.7, aspect=3) . g.map(sns.distplot, ""pct_counts_mito"") # Sadly, this doesn't work for joint grids. # I do have a PR for a ridge plot based on this in the works. ```. If you'd like it to be interactive:. ```python. import hvplot.pandas. adata.obs.hvplot.hexbin(""log1p_total_counts"", ""log1p_n_genes_by_counts""). adata.obs.hvplot.hist(""log1p_total_counts""). # Faceting. adata.obs.hvplot.hist(""pct_counts_mito"", by=""batch"", subplots=True).cols(1). ```. Or, if you want to play with cool most-biggest-data toys:. ```python. adata.obs.hvplot.scatter(. ""log1p_total_counts"",. ""log1p_n_genes_by_counts"",. datashade=True,. dynspread=True. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:793,usability,interact,interactive,793,"@biskra Just my two cents on (3), I mostly use histograms or hex bins for viewing qc metrics. I've been meaning to write this up as a tutorial for a while, but I think you can lean on whole pyviz ecosystem pretty heavily here. Something static and pretty:. ```python. # Joint distribution with marginal histograms:. sns.jointplot(. x=""log1p_total_counts"",. y=""log1p_n_genes_by_counts"",. data=adata.obs,. kind=""hex"". ). # For a single variable. sns.distplot(adata.obs[""log1p_total_counts""]). # To facet the distplot by some columns of obs, like ""batch"":. g = sns.FacetGrid(adata.obs, row=""batch"", height=1.7, aspect=3) . g.map(sns.distplot, ""pct_counts_mito"") # Sadly, this doesn't work for joint grids. # I do have a PR for a ridge plot based on this in the works. ```. If you'd like it to be interactive:. ```python. import hvplot.pandas. adata.obs.hvplot.hexbin(""log1p_total_counts"", ""log1p_n_genes_by_counts""). adata.obs.hvplot.hist(""log1p_total_counts""). # Faceting. adata.obs.hvplot.hist(""pct_counts_mito"", by=""batch"", subplots=True).cols(1). ```. Or, if you want to play with cool most-biggest-data toys:. ```python. adata.obs.hvplot.scatter(. ""log1p_total_counts"",. ""log1p_n_genes_by_counts"",. datashade=True,. dynspread=True. ). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:99,availability,cluster,cluster,99,"Thanks a lot for the useful comments & I am a great admirer of scanpy, @falexwolf . I am trying to cluster cells based on specific gene sets (same as @biskra). I am working with loom files & after the data preprocessing and finding out highly variable genes, I have subgrouped the HVG(s) into five different categories by functional annotation/pathway enrichment analysis. Then I tried to subset 'adata' to the gene group I am interested in to carry out the embedding & clustering:. adata = adata[:, adata.var['highly_variable']]. #From the highly variable genes, let's say I want to use Gene1, Gene2,... Gene500 for the Louvain clustering instead of the PCA. Then, I tried to do what you suggested before:. #I have nothing stored under adata.obsm. adata.var['highly_variable'] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. I am getting this error despite the fact that these genes are in the HVG list: . #KeyError: ""None of [Index(['Map7d1', 'Ndufa2', 'Klc2', 'Slc35b2'], dtype='object')] are in the [index]"". If this works, then the community graph can be computed:. sc.pp.neighbors(adata, use_rep='highly_variable'). I shall be grateful if you can help. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:470,availability,cluster,clustering,470,"Thanks a lot for the useful comments & I am a great admirer of scanpy, @falexwolf . I am trying to cluster cells based on specific gene sets (same as @biskra). I am working with loom files & after the data preprocessing and finding out highly variable genes, I have subgrouped the HVG(s) into five different categories by functional annotation/pathway enrichment analysis. Then I tried to subset 'adata' to the gene group I am interested in to carry out the embedding & clustering:. adata = adata[:, adata.var['highly_variable']]. #From the highly variable genes, let's say I want to use Gene1, Gene2,... Gene500 for the Louvain clustering instead of the PCA. Then, I tried to do what you suggested before:. #I have nothing stored under adata.obsm. adata.var['highly_variable'] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. I am getting this error despite the fact that these genes are in the HVG list: . #KeyError: ""None of [Index(['Map7d1', 'Ndufa2', 'Klc2', 'Slc35b2'], dtype='object')] are in the [index]"". If this works, then the community graph can be computed:. sc.pp.neighbors(adata, use_rep='highly_variable'). I shall be grateful if you can help. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:629,availability,cluster,clustering,629,"Thanks a lot for the useful comments & I am a great admirer of scanpy, @falexwolf . I am trying to cluster cells based on specific gene sets (same as @biskra). I am working with loom files & after the data preprocessing and finding out highly variable genes, I have subgrouped the HVG(s) into five different categories by functional annotation/pathway enrichment analysis. Then I tried to subset 'adata' to the gene group I am interested in to carry out the embedding & clustering:. adata = adata[:, adata.var['highly_variable']]. #From the highly variable genes, let's say I want to use Gene1, Gene2,... Gene500 for the Louvain clustering instead of the PCA. Then, I tried to do what you suggested before:. #I have nothing stored under adata.obsm. adata.var['highly_variable'] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. I am getting this error despite the fact that these genes are in the HVG list: . #KeyError: ""None of [Index(['Map7d1', 'Ndufa2', 'Klc2', 'Slc35b2'], dtype='object')] are in the [index]"". If this works, then the community graph can be computed:. sc.pp.neighbors(adata, use_rep='highly_variable'). I shall be grateful if you can help. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:845,availability,error,error,845,"Thanks a lot for the useful comments & I am a great admirer of scanpy, @falexwolf . I am trying to cluster cells based on specific gene sets (same as @biskra). I am working with loom files & after the data preprocessing and finding out highly variable genes, I have subgrouped the HVG(s) into five different categories by functional annotation/pathway enrichment analysis. Then I tried to subset 'adata' to the gene group I am interested in to carry out the embedding & clustering:. adata = adata[:, adata.var['highly_variable']]. #From the highly variable genes, let's say I want to use Gene1, Gene2,... Gene500 for the Louvain clustering instead of the PCA. Then, I tried to do what you suggested before:. #I have nothing stored under adata.obsm. adata.var['highly_variable'] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. I am getting this error despite the fact that these genes are in the HVG list: . #KeyError: ""None of [Index(['Map7d1', 'Ndufa2', 'Klc2', 'Slc35b2'], dtype='object')] are in the [index]"". If this works, then the community graph can be computed:. sc.pp.neighbors(adata, use_rep='highly_variable'). I shall be grateful if you can help. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:99,deployability,cluster,cluster,99,"Thanks a lot for the useful comments & I am a great admirer of scanpy, @falexwolf . I am trying to cluster cells based on specific gene sets (same as @biskra). I am working with loom files & after the data preprocessing and finding out highly variable genes, I have subgrouped the HVG(s) into five different categories by functional annotation/pathway enrichment analysis. Then I tried to subset 'adata' to the gene group I am interested in to carry out the embedding & clustering:. adata = adata[:, adata.var['highly_variable']]. #From the highly variable genes, let's say I want to use Gene1, Gene2,... Gene500 for the Louvain clustering instead of the PCA. Then, I tried to do what you suggested before:. #I have nothing stored under adata.obsm. adata.var['highly_variable'] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. I am getting this error despite the fact that these genes are in the HVG list: . #KeyError: ""None of [Index(['Map7d1', 'Ndufa2', 'Klc2', 'Slc35b2'], dtype='object')] are in the [index]"". If this works, then the community graph can be computed:. sc.pp.neighbors(adata, use_rep='highly_variable'). I shall be grateful if you can help. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:470,deployability,cluster,clustering,470,"Thanks a lot for the useful comments & I am a great admirer of scanpy, @falexwolf . I am trying to cluster cells based on specific gene sets (same as @biskra). I am working with loom files & after the data preprocessing and finding out highly variable genes, I have subgrouped the HVG(s) into five different categories by functional annotation/pathway enrichment analysis. Then I tried to subset 'adata' to the gene group I am interested in to carry out the embedding & clustering:. adata = adata[:, adata.var['highly_variable']]. #From the highly variable genes, let's say I want to use Gene1, Gene2,... Gene500 for the Louvain clustering instead of the PCA. Then, I tried to do what you suggested before:. #I have nothing stored under adata.obsm. adata.var['highly_variable'] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. I am getting this error despite the fact that these genes are in the HVG list: . #KeyError: ""None of [Index(['Map7d1', 'Ndufa2', 'Klc2', 'Slc35b2'], dtype='object')] are in the [index]"". If this works, then the community graph can be computed:. sc.pp.neighbors(adata, use_rep='highly_variable'). I shall be grateful if you can help. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:629,deployability,cluster,clustering,629,"Thanks a lot for the useful comments & I am a great admirer of scanpy, @falexwolf . I am trying to cluster cells based on specific gene sets (same as @biskra). I am working with loom files & after the data preprocessing and finding out highly variable genes, I have subgrouped the HVG(s) into five different categories by functional annotation/pathway enrichment analysis. Then I tried to subset 'adata' to the gene group I am interested in to carry out the embedding & clustering:. adata = adata[:, adata.var['highly_variable']]. #From the highly variable genes, let's say I want to use Gene1, Gene2,... Gene500 for the Louvain clustering instead of the PCA. Then, I tried to do what you suggested before:. #I have nothing stored under adata.obsm. adata.var['highly_variable'] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. I am getting this error despite the fact that these genes are in the HVG list: . #KeyError: ""None of [Index(['Map7d1', 'Ndufa2', 'Klc2', 'Slc35b2'], dtype='object')] are in the [index]"". If this works, then the community graph can be computed:. sc.pp.neighbors(adata, use_rep='highly_variable'). I shall be grateful if you can help. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:266,integrability,sub,subgrouped,266,"Thanks a lot for the useful comments & I am a great admirer of scanpy, @falexwolf . I am trying to cluster cells based on specific gene sets (same as @biskra). I am working with loom files & after the data preprocessing and finding out highly variable genes, I have subgrouped the HVG(s) into five different categories by functional annotation/pathway enrichment analysis. Then I tried to subset 'adata' to the gene group I am interested in to carry out the embedding & clustering:. adata = adata[:, adata.var['highly_variable']]. #From the highly variable genes, let's say I want to use Gene1, Gene2,... Gene500 for the Louvain clustering instead of the PCA. Then, I tried to do what you suggested before:. #I have nothing stored under adata.obsm. adata.var['highly_variable'] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. I am getting this error despite the fact that these genes are in the HVG list: . #KeyError: ""None of [Index(['Map7d1', 'Ndufa2', 'Klc2', 'Slc35b2'], dtype='object')] are in the [index]"". If this works, then the community graph can be computed:. sc.pp.neighbors(adata, use_rep='highly_variable'). I shall be grateful if you can help. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:389,integrability,sub,subset,389,"Thanks a lot for the useful comments & I am a great admirer of scanpy, @falexwolf . I am trying to cluster cells based on specific gene sets (same as @biskra). I am working with loom files & after the data preprocessing and finding out highly variable genes, I have subgrouped the HVG(s) into five different categories by functional annotation/pathway enrichment analysis. Then I tried to subset 'adata' to the gene group I am interested in to carry out the embedding & clustering:. adata = adata[:, adata.var['highly_variable']]. #From the highly variable genes, let's say I want to use Gene1, Gene2,... Gene500 for the Louvain clustering instead of the PCA. Then, I tried to do what you suggested before:. #I have nothing stored under adata.obsm. adata.var['highly_variable'] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. I am getting this error despite the fact that these genes are in the HVG list: . #KeyError: ""None of [Index(['Map7d1', 'Ndufa2', 'Klc2', 'Slc35b2'], dtype='object')] are in the [index]"". If this works, then the community graph can be computed:. sc.pp.neighbors(adata, use_rep='highly_variable'). I shall be grateful if you can help. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:122,interoperability,specif,specific,122,"Thanks a lot for the useful comments & I am a great admirer of scanpy, @falexwolf . I am trying to cluster cells based on specific gene sets (same as @biskra). I am working with loom files & after the data preprocessing and finding out highly variable genes, I have subgrouped the HVG(s) into five different categories by functional annotation/pathway enrichment analysis. Then I tried to subset 'adata' to the gene group I am interested in to carry out the embedding & clustering:. adata = adata[:, adata.var['highly_variable']]. #From the highly variable genes, let's say I want to use Gene1, Gene2,... Gene500 for the Louvain clustering instead of the PCA. Then, I tried to do what you suggested before:. #I have nothing stored under adata.obsm. adata.var['highly_variable'] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. I am getting this error despite the fact that these genes are in the HVG list: . #KeyError: ""None of [Index(['Map7d1', 'Ndufa2', 'Klc2', 'Slc35b2'], dtype='object')] are in the [index]"". If this works, then the community graph can be computed:. sc.pp.neighbors(adata, use_rep='highly_variable'). I shall be grateful if you can help. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:243,modifiability,variab,variable,243,"Thanks a lot for the useful comments & I am a great admirer of scanpy, @falexwolf . I am trying to cluster cells based on specific gene sets (same as @biskra). I am working with loom files & after the data preprocessing and finding out highly variable genes, I have subgrouped the HVG(s) into five different categories by functional annotation/pathway enrichment analysis. Then I tried to subset 'adata' to the gene group I am interested in to carry out the embedding & clustering:. adata = adata[:, adata.var['highly_variable']]. #From the highly variable genes, let's say I want to use Gene1, Gene2,... Gene500 for the Louvain clustering instead of the PCA. Then, I tried to do what you suggested before:. #I have nothing stored under adata.obsm. adata.var['highly_variable'] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. I am getting this error despite the fact that these genes are in the HVG list: . #KeyError: ""None of [Index(['Map7d1', 'Ndufa2', 'Klc2', 'Slc35b2'], dtype='object')] are in the [index]"". If this works, then the community graph can be computed:. sc.pp.neighbors(adata, use_rep='highly_variable'). I shall be grateful if you can help. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:548,modifiability,variab,variable,548,"Thanks a lot for the useful comments & I am a great admirer of scanpy, @falexwolf . I am trying to cluster cells based on specific gene sets (same as @biskra). I am working with loom files & after the data preprocessing and finding out highly variable genes, I have subgrouped the HVG(s) into five different categories by functional annotation/pathway enrichment analysis. Then I tried to subset 'adata' to the gene group I am interested in to carry out the embedding & clustering:. adata = adata[:, adata.var['highly_variable']]. #From the highly variable genes, let's say I want to use Gene1, Gene2,... Gene500 for the Louvain clustering instead of the PCA. Then, I tried to do what you suggested before:. #I have nothing stored under adata.obsm. adata.var['highly_variable'] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. I am getting this error despite the fact that these genes are in the HVG list: . #KeyError: ""None of [Index(['Map7d1', 'Ndufa2', 'Klc2', 'Slc35b2'], dtype='object')] are in the [index]"". If this works, then the community graph can be computed:. sc.pp.neighbors(adata, use_rep='highly_variable'). I shall be grateful if you can help. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:845,performance,error,error,845,"Thanks a lot for the useful comments & I am a great admirer of scanpy, @falexwolf . I am trying to cluster cells based on specific gene sets (same as @biskra). I am working with loom files & after the data preprocessing and finding out highly variable genes, I have subgrouped the HVG(s) into five different categories by functional annotation/pathway enrichment analysis. Then I tried to subset 'adata' to the gene group I am interested in to carry out the embedding & clustering:. adata = adata[:, adata.var['highly_variable']]. #From the highly variable genes, let's say I want to use Gene1, Gene2,... Gene500 for the Louvain clustering instead of the PCA. Then, I tried to do what you suggested before:. #I have nothing stored under adata.obsm. adata.var['highly_variable'] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. I am getting this error despite the fact that these genes are in the HVG list: . #KeyError: ""None of [Index(['Map7d1', 'Ndufa2', 'Klc2', 'Slc35b2'], dtype='object')] are in the [index]"". If this works, then the community graph can be computed:. sc.pp.neighbors(adata, use_rep='highly_variable'). I shall be grateful if you can help. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:845,safety,error,error,845,"Thanks a lot for the useful comments & I am a great admirer of scanpy, @falexwolf . I am trying to cluster cells based on specific gene sets (same as @biskra). I am working with loom files & after the data preprocessing and finding out highly variable genes, I have subgrouped the HVG(s) into five different categories by functional annotation/pathway enrichment analysis. Then I tried to subset 'adata' to the gene group I am interested in to carry out the embedding & clustering:. adata = adata[:, adata.var['highly_variable']]. #From the highly variable genes, let's say I want to use Gene1, Gene2,... Gene500 for the Louvain clustering instead of the PCA. Then, I tried to do what you suggested before:. #I have nothing stored under adata.obsm. adata.var['highly_variable'] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. I am getting this error despite the fact that these genes are in the HVG list: . #KeyError: ""None of [Index(['Map7d1', 'Ndufa2', 'Klc2', 'Slc35b2'], dtype='object')] are in the [index]"". If this works, then the community graph can be computed:. sc.pp.neighbors(adata, use_rep='highly_variable'). I shall be grateful if you can help. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:845,usability,error,error,845,"Thanks a lot for the useful comments & I am a great admirer of scanpy, @falexwolf . I am trying to cluster cells based on specific gene sets (same as @biskra). I am working with loom files & after the data preprocessing and finding out highly variable genes, I have subgrouped the HVG(s) into five different categories by functional annotation/pathway enrichment analysis. Then I tried to subset 'adata' to the gene group I am interested in to carry out the embedding & clustering:. adata = adata[:, adata.var['highly_variable']]. #From the highly variable genes, let's say I want to use Gene1, Gene2,... Gene500 for the Louvain clustering instead of the PCA. Then, I tried to do what you suggested before:. #I have nothing stored under adata.obsm. adata.var['highly_variable'] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. I am getting this error despite the fact that these genes are in the HVG list: . #KeyError: ""None of [Index(['Map7d1', 'Ndufa2', 'Klc2', 'Slc35b2'], dtype='object')] are in the [index]"". If this works, then the community graph can be computed:. sc.pp.neighbors(adata, use_rep='highly_variable'). I shall be grateful if you can help. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:1154,usability,help,help,1154,"Thanks a lot for the useful comments & I am a great admirer of scanpy, @falexwolf . I am trying to cluster cells based on specific gene sets (same as @biskra). I am working with loom files & after the data preprocessing and finding out highly variable genes, I have subgrouped the HVG(s) into five different categories by functional annotation/pathway enrichment analysis. Then I tried to subset 'adata' to the gene group I am interested in to carry out the embedding & clustering:. adata = adata[:, adata.var['highly_variable']]. #From the highly variable genes, let's say I want to use Gene1, Gene2,... Gene500 for the Louvain clustering instead of the PCA. Then, I tried to do what you suggested before:. #I have nothing stored under adata.obsm. adata.var['highly_variable'] = adata[['gene1', 'gene2', 'gene3', 'gene4']].X. I am getting this error despite the fact that these genes are in the HVG list: . #KeyError: ""None of [Index(['Map7d1', 'Ndufa2', 'Klc2', 'Slc35b2'], dtype='object')] are in the [index]"". If this works, then the community graph can be computed:. sc.pp.neighbors(adata, use_rep='highly_variable'). I shall be grateful if you can help. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:436,availability,error,error,436,"Hi @Olivia117,. Let's see if I can help. I think there are a few misunderstandings here. It appears that you are mixing the `adata.var['highly_variable']` approach with the `adata.obsm['X_geneset1']` approach Alex suggested. Firstly, there is a typo in Alex' code above. It should read:. ```. adata.obsm['X_geneset1'] = adata[:,['gene1', 'gene2', 'gene3', 'gene4']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). ```. I believe. Your error is due to this typo. The command is interpreting `'Map7d1'` as a cell index rather than a gene index. However, there are also a few other things. 1. `adata.var['highly_variable']` takes a boolean list, so you should assign e.g., `[True, True, False, False]` if you are interested in only the first two genes out of a total of 4 genes in the dataset. This can be trivially extended to select your Gene1, Gene,... Gene500 that you are interested in. When using this approach you will need to run `sc.pp.pca(adata, svd_solver='arpack', use_highly_variable=True)` and `sc.pp.neighbors(adata)` before clustering with louvain or leiden. This approach subsets to your genes of interest, then performs PCA on this gene subset, and builds a KNN graph based on Euclidean distances in this PCA space, which is then used for clustering. 2. If you don't want to use the route via PCA, you need to assign to `adata.obsm` as Alex suggests (with my typo correction above). Even if you do not have anything in `adata.obsm`, it should still work. If you want to put something in `adata.obsm`, just run `sc.pp.pca(adata, svd_solver='arpack')` and you will see `adata.obsm['X_pca']` appear. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:1038,availability,cluster,clustering,1038,"Hi @Olivia117,. Let's see if I can help. I think there are a few misunderstandings here. It appears that you are mixing the `adata.var['highly_variable']` approach with the `adata.obsm['X_geneset1']` approach Alex suggested. Firstly, there is a typo in Alex' code above. It should read:. ```. adata.obsm['X_geneset1'] = adata[:,['gene1', 'gene2', 'gene3', 'gene4']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). ```. I believe. Your error is due to this typo. The command is interpreting `'Map7d1'` as a cell index rather than a gene index. However, there are also a few other things. 1. `adata.var['highly_variable']` takes a boolean list, so you should assign e.g., `[True, True, False, False]` if you are interested in only the first two genes out of a total of 4 genes in the dataset. This can be trivially extended to select your Gene1, Gene,... Gene500 that you are interested in. When using this approach you will need to run `sc.pp.pca(adata, svd_solver='arpack', use_highly_variable=True)` and `sc.pp.neighbors(adata)` before clustering with louvain or leiden. This approach subsets to your genes of interest, then performs PCA on this gene subset, and builds a KNN graph based on Euclidean distances in this PCA space, which is then used for clustering. 2. If you don't want to use the route via PCA, you need to assign to `adata.obsm` as Alex suggests (with my typo correction above). Even if you do not have anything in `adata.obsm`, it should still work. If you want to put something in `adata.obsm`, just run `sc.pp.pca(adata, svd_solver='arpack')` and you will see `adata.obsm['X_pca']` appear. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:1255,availability,cluster,clustering,1255,"Hi @Olivia117,. Let's see if I can help. I think there are a few misunderstandings here. It appears that you are mixing the `adata.var['highly_variable']` approach with the `adata.obsm['X_geneset1']` approach Alex suggested. Firstly, there is a typo in Alex' code above. It should read:. ```. adata.obsm['X_geneset1'] = adata[:,['gene1', 'gene2', 'gene3', 'gene4']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). ```. I believe. Your error is due to this typo. The command is interpreting `'Map7d1'` as a cell index rather than a gene index. However, there are also a few other things. 1. `adata.var['highly_variable']` takes a boolean list, so you should assign e.g., `[True, True, False, False]` if you are interested in only the first two genes out of a total of 4 genes in the dataset. This can be trivially extended to select your Gene1, Gene,... Gene500 that you are interested in. When using this approach you will need to run `sc.pp.pca(adata, svd_solver='arpack', use_highly_variable=True)` and `sc.pp.neighbors(adata)` before clustering with louvain or leiden. This approach subsets to your genes of interest, then performs PCA on this gene subset, and builds a KNN graph based on Euclidean distances in this PCA space, which is then used for clustering. 2. If you don't want to use the route via PCA, you need to assign to `adata.obsm` as Alex suggests (with my typo correction above). Even if you do not have anything in `adata.obsm`, it should still work. If you want to put something in `adata.obsm`, just run `sc.pp.pca(adata, svd_solver='arpack')` and you will see `adata.obsm['X_pca']` appear. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:1038,deployability,cluster,clustering,1038,"Hi @Olivia117,. Let's see if I can help. I think there are a few misunderstandings here. It appears that you are mixing the `adata.var['highly_variable']` approach with the `adata.obsm['X_geneset1']` approach Alex suggested. Firstly, there is a typo in Alex' code above. It should read:. ```. adata.obsm['X_geneset1'] = adata[:,['gene1', 'gene2', 'gene3', 'gene4']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). ```. I believe. Your error is due to this typo. The command is interpreting `'Map7d1'` as a cell index rather than a gene index. However, there are also a few other things. 1. `adata.var['highly_variable']` takes a boolean list, so you should assign e.g., `[True, True, False, False]` if you are interested in only the first two genes out of a total of 4 genes in the dataset. This can be trivially extended to select your Gene1, Gene,... Gene500 that you are interested in. When using this approach you will need to run `sc.pp.pca(adata, svd_solver='arpack', use_highly_variable=True)` and `sc.pp.neighbors(adata)` before clustering with louvain or leiden. This approach subsets to your genes of interest, then performs PCA on this gene subset, and builds a KNN graph based on Euclidean distances in this PCA space, which is then used for clustering. 2. If you don't want to use the route via PCA, you need to assign to `adata.obsm` as Alex suggests (with my typo correction above). Even if you do not have anything in `adata.obsm`, it should still work. If you want to put something in `adata.obsm`, just run `sc.pp.pca(adata, svd_solver='arpack')` and you will see `adata.obsm['X_pca']` appear. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:1165,deployability,build,builds,1165,"Hi @Olivia117,. Let's see if I can help. I think there are a few misunderstandings here. It appears that you are mixing the `adata.var['highly_variable']` approach with the `adata.obsm['X_geneset1']` approach Alex suggested. Firstly, there is a typo in Alex' code above. It should read:. ```. adata.obsm['X_geneset1'] = adata[:,['gene1', 'gene2', 'gene3', 'gene4']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). ```. I believe. Your error is due to this typo. The command is interpreting `'Map7d1'` as a cell index rather than a gene index. However, there are also a few other things. 1. `adata.var['highly_variable']` takes a boolean list, so you should assign e.g., `[True, True, False, False]` if you are interested in only the first two genes out of a total of 4 genes in the dataset. This can be trivially extended to select your Gene1, Gene,... Gene500 that you are interested in. When using this approach you will need to run `sc.pp.pca(adata, svd_solver='arpack', use_highly_variable=True)` and `sc.pp.neighbors(adata)` before clustering with louvain or leiden. This approach subsets to your genes of interest, then performs PCA on this gene subset, and builds a KNN graph based on Euclidean distances in this PCA space, which is then used for clustering. 2. If you don't want to use the route via PCA, you need to assign to `adata.obsm` as Alex suggests (with my typo correction above). Even if you do not have anything in `adata.obsm`, it should still work. If you want to put something in `adata.obsm`, just run `sc.pp.pca(adata, svd_solver='arpack')` and you will see `adata.obsm['X_pca']` appear. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:1255,deployability,cluster,clustering,1255,"Hi @Olivia117,. Let's see if I can help. I think there are a few misunderstandings here. It appears that you are mixing the `adata.var['highly_variable']` approach with the `adata.obsm['X_geneset1']` approach Alex suggested. Firstly, there is a typo in Alex' code above. It should read:. ```. adata.obsm['X_geneset1'] = adata[:,['gene1', 'gene2', 'gene3', 'gene4']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). ```. I believe. Your error is due to this typo. The command is interpreting `'Map7d1'` as a cell index rather than a gene index. However, there are also a few other things. 1. `adata.var['highly_variable']` takes a boolean list, so you should assign e.g., `[True, True, False, False]` if you are interested in only the first two genes out of a total of 4 genes in the dataset. This can be trivially extended to select your Gene1, Gene,... Gene500 that you are interested in. When using this approach you will need to run `sc.pp.pca(adata, svd_solver='arpack', use_highly_variable=True)` and `sc.pp.neighbors(adata)` before clustering with louvain or leiden. This approach subsets to your genes of interest, then performs PCA on this gene subset, and builds a KNN graph based on Euclidean distances in this PCA space, which is then used for clustering. 2. If you don't want to use the route via PCA, you need to assign to `adata.obsm` as Alex suggests (with my typo correction above). Even if you do not have anything in `adata.obsm`, it should still work. If you want to put something in `adata.obsm`, just run `sc.pp.pca(adata, svd_solver='arpack')` and you will see `adata.obsm['X_pca']` appear. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:1087,integrability,sub,subsets,1087,"Hi @Olivia117,. Let's see if I can help. I think there are a few misunderstandings here. It appears that you are mixing the `adata.var['highly_variable']` approach with the `adata.obsm['X_geneset1']` approach Alex suggested. Firstly, there is a typo in Alex' code above. It should read:. ```. adata.obsm['X_geneset1'] = adata[:,['gene1', 'gene2', 'gene3', 'gene4']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). ```. I believe. Your error is due to this typo. The command is interpreting `'Map7d1'` as a cell index rather than a gene index. However, there are also a few other things. 1. `adata.var['highly_variable']` takes a boolean list, so you should assign e.g., `[True, True, False, False]` if you are interested in only the first two genes out of a total of 4 genes in the dataset. This can be trivially extended to select your Gene1, Gene,... Gene500 that you are interested in. When using this approach you will need to run `sc.pp.pca(adata, svd_solver='arpack', use_highly_variable=True)` and `sc.pp.neighbors(adata)` before clustering with louvain or leiden. This approach subsets to your genes of interest, then performs PCA on this gene subset, and builds a KNN graph based on Euclidean distances in this PCA space, which is then used for clustering. 2. If you don't want to use the route via PCA, you need to assign to `adata.obsm` as Alex suggests (with my typo correction above). Even if you do not have anything in `adata.obsm`, it should still work. If you want to put something in `adata.obsm`, just run `sc.pp.pca(adata, svd_solver='arpack')` and you will see `adata.obsm['X_pca']` appear. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:1153,integrability,sub,subset,1153,"Hi @Olivia117,. Let's see if I can help. I think there are a few misunderstandings here. It appears that you are mixing the `adata.var['highly_variable']` approach with the `adata.obsm['X_geneset1']` approach Alex suggested. Firstly, there is a typo in Alex' code above. It should read:. ```. adata.obsm['X_geneset1'] = adata[:,['gene1', 'gene2', 'gene3', 'gene4']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). ```. I believe. Your error is due to this typo. The command is interpreting `'Map7d1'` as a cell index rather than a gene index. However, there are also a few other things. 1. `adata.var['highly_variable']` takes a boolean list, so you should assign e.g., `[True, True, False, False]` if you are interested in only the first two genes out of a total of 4 genes in the dataset. This can be trivially extended to select your Gene1, Gene,... Gene500 that you are interested in. When using this approach you will need to run `sc.pp.pca(adata, svd_solver='arpack', use_highly_variable=True)` and `sc.pp.neighbors(adata)` before clustering with louvain or leiden. This approach subsets to your genes of interest, then performs PCA on this gene subset, and builds a KNN graph based on Euclidean distances in this PCA space, which is then used for clustering. 2. If you don't want to use the route via PCA, you need to assign to `adata.obsm` as Alex suggests (with my typo correction above). Even if you do not have anything in `adata.obsm`, it should still work. If you want to put something in `adata.obsm`, just run `sc.pp.pca(adata, svd_solver='arpack')` and you will see `adata.obsm['X_pca']` appear. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:1299,integrability,rout,route,1299,"Hi @Olivia117,. Let's see if I can help. I think there are a few misunderstandings here. It appears that you are mixing the `adata.var['highly_variable']` approach with the `adata.obsm['X_geneset1']` approach Alex suggested. Firstly, there is a typo in Alex' code above. It should read:. ```. adata.obsm['X_geneset1'] = adata[:,['gene1', 'gene2', 'gene3', 'gene4']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). ```. I believe. Your error is due to this typo. The command is interpreting `'Map7d1'` as a cell index rather than a gene index. However, there are also a few other things. 1. `adata.var['highly_variable']` takes a boolean list, so you should assign e.g., `[True, True, False, False]` if you are interested in only the first two genes out of a total of 4 genes in the dataset. This can be trivially extended to select your Gene1, Gene,... Gene500 that you are interested in. When using this approach you will need to run `sc.pp.pca(adata, svd_solver='arpack', use_highly_variable=True)` and `sc.pp.neighbors(adata)` before clustering with louvain or leiden. This approach subsets to your genes of interest, then performs PCA on this gene subset, and builds a KNN graph based on Euclidean distances in this PCA space, which is then used for clustering. 2. If you don't want to use the route via PCA, you need to assign to `adata.obsm` as Alex suggests (with my typo correction above). Even if you do not have anything in `adata.obsm`, it should still work. If you want to put something in `adata.obsm`, just run `sc.pp.pca(adata, svd_solver='arpack')` and you will see `adata.obsm['X_pca']` appear. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:814,modifiability,exten,extended,814,"Hi @Olivia117,. Let's see if I can help. I think there are a few misunderstandings here. It appears that you are mixing the `adata.var['highly_variable']` approach with the `adata.obsm['X_geneset1']` approach Alex suggested. Firstly, there is a typo in Alex' code above. It should read:. ```. adata.obsm['X_geneset1'] = adata[:,['gene1', 'gene2', 'gene3', 'gene4']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). ```. I believe. Your error is due to this typo. The command is interpreting `'Map7d1'` as a cell index rather than a gene index. However, there are also a few other things. 1. `adata.var['highly_variable']` takes a boolean list, so you should assign e.g., `[True, True, False, False]` if you are interested in only the first two genes out of a total of 4 genes in the dataset. This can be trivially extended to select your Gene1, Gene,... Gene500 that you are interested in. When using this approach you will need to run `sc.pp.pca(adata, svd_solver='arpack', use_highly_variable=True)` and `sc.pp.neighbors(adata)` before clustering with louvain or leiden. This approach subsets to your genes of interest, then performs PCA on this gene subset, and builds a KNN graph based on Euclidean distances in this PCA space, which is then used for clustering. 2. If you don't want to use the route via PCA, you need to assign to `adata.obsm` as Alex suggests (with my typo correction above). Even if you do not have anything in `adata.obsm`, it should still work. If you want to put something in `adata.obsm`, just run `sc.pp.pca(adata, svd_solver='arpack')` and you will see `adata.obsm['X_pca']` appear. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:436,performance,error,error,436,"Hi @Olivia117,. Let's see if I can help. I think there are a few misunderstandings here. It appears that you are mixing the `adata.var['highly_variable']` approach with the `adata.obsm['X_geneset1']` approach Alex suggested. Firstly, there is a typo in Alex' code above. It should read:. ```. adata.obsm['X_geneset1'] = adata[:,['gene1', 'gene2', 'gene3', 'gene4']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). ```. I believe. Your error is due to this typo. The command is interpreting `'Map7d1'` as a cell index rather than a gene index. However, there are also a few other things. 1. `adata.var['highly_variable']` takes a boolean list, so you should assign e.g., `[True, True, False, False]` if you are interested in only the first two genes out of a total of 4 genes in the dataset. This can be trivially extended to select your Gene1, Gene,... Gene500 that you are interested in. When using this approach you will need to run `sc.pp.pca(adata, svd_solver='arpack', use_highly_variable=True)` and `sc.pp.neighbors(adata)` before clustering with louvain or leiden. This approach subsets to your genes of interest, then performs PCA on this gene subset, and builds a KNN graph based on Euclidean distances in this PCA space, which is then used for clustering. 2. If you don't want to use the route via PCA, you need to assign to `adata.obsm` as Alex suggests (with my typo correction above). Even if you do not have anything in `adata.obsm`, it should still work. If you want to put something in `adata.obsm`, just run `sc.pp.pca(adata, svd_solver='arpack')` and you will see `adata.obsm['X_pca']` appear. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:1127,performance,perform,performs,1127,"Hi @Olivia117,. Let's see if I can help. I think there are a few misunderstandings here. It appears that you are mixing the `adata.var['highly_variable']` approach with the `adata.obsm['X_geneset1']` approach Alex suggested. Firstly, there is a typo in Alex' code above. It should read:. ```. adata.obsm['X_geneset1'] = adata[:,['gene1', 'gene2', 'gene3', 'gene4']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). ```. I believe. Your error is due to this typo. The command is interpreting `'Map7d1'` as a cell index rather than a gene index. However, there are also a few other things. 1. `adata.var['highly_variable']` takes a boolean list, so you should assign e.g., `[True, True, False, False]` if you are interested in only the first two genes out of a total of 4 genes in the dataset. This can be trivially extended to select your Gene1, Gene,... Gene500 that you are interested in. When using this approach you will need to run `sc.pp.pca(adata, svd_solver='arpack', use_highly_variable=True)` and `sc.pp.neighbors(adata)` before clustering with louvain or leiden. This approach subsets to your genes of interest, then performs PCA on this gene subset, and builds a KNN graph based on Euclidean distances in this PCA space, which is then used for clustering. 2. If you don't want to use the route via PCA, you need to assign to `adata.obsm` as Alex suggests (with my typo correction above). Even if you do not have anything in `adata.obsm`, it should still work. If you want to put something in `adata.obsm`, just run `sc.pp.pca(adata, svd_solver='arpack')` and you will see `adata.obsm['X_pca']` appear. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:436,safety,error,error,436,"Hi @Olivia117,. Let's see if I can help. I think there are a few misunderstandings here. It appears that you are mixing the `adata.var['highly_variable']` approach with the `adata.obsm['X_geneset1']` approach Alex suggested. Firstly, there is a typo in Alex' code above. It should read:. ```. adata.obsm['X_geneset1'] = adata[:,['gene1', 'gene2', 'gene3', 'gene4']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). ```. I believe. Your error is due to this typo. The command is interpreting `'Map7d1'` as a cell index rather than a gene index. However, there are also a few other things. 1. `adata.var['highly_variable']` takes a boolean list, so you should assign e.g., `[True, True, False, False]` if you are interested in only the first two genes out of a total of 4 genes in the dataset. This can be trivially extended to select your Gene1, Gene,... Gene500 that you are interested in. When using this approach you will need to run `sc.pp.pca(adata, svd_solver='arpack', use_highly_variable=True)` and `sc.pp.neighbors(adata)` before clustering with louvain or leiden. This approach subsets to your genes of interest, then performs PCA on this gene subset, and builds a KNN graph based on Euclidean distances in this PCA space, which is then used for clustering. 2. If you don't want to use the route via PCA, you need to assign to `adata.obsm` as Alex suggests (with my typo correction above). Even if you do not have anything in `adata.obsm`, it should still work. If you want to put something in `adata.obsm`, just run `sc.pp.pca(adata, svd_solver='arpack')` and you will see `adata.obsm['X_pca']` appear. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:35,usability,help,help,35,"Hi @Olivia117,. Let's see if I can help. I think there are a few misunderstandings here. It appears that you are mixing the `adata.var['highly_variable']` approach with the `adata.obsm['X_geneset1']` approach Alex suggested. Firstly, there is a typo in Alex' code above. It should read:. ```. adata.obsm['X_geneset1'] = adata[:,['gene1', 'gene2', 'gene3', 'gene4']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). ```. I believe. Your error is due to this typo. The command is interpreting `'Map7d1'` as a cell index rather than a gene index. However, there are also a few other things. 1. `adata.var['highly_variable']` takes a boolean list, so you should assign e.g., `[True, True, False, False]` if you are interested in only the first two genes out of a total of 4 genes in the dataset. This can be trivially extended to select your Gene1, Gene,... Gene500 that you are interested in. When using this approach you will need to run `sc.pp.pca(adata, svd_solver='arpack', use_highly_variable=True)` and `sc.pp.neighbors(adata)` before clustering with louvain or leiden. This approach subsets to your genes of interest, then performs PCA on this gene subset, and builds a KNN graph based on Euclidean distances in this PCA space, which is then used for clustering. 2. If you don't want to use the route via PCA, you need to assign to `adata.obsm` as Alex suggests (with my typo correction above). Even if you do not have anything in `adata.obsm`, it should still work. If you want to put something in `adata.obsm`, just run `sc.pp.pca(adata, svd_solver='arpack')` and you will see `adata.obsm['X_pca']` appear. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:436,usability,error,error,436,"Hi @Olivia117,. Let's see if I can help. I think there are a few misunderstandings here. It appears that you are mixing the `adata.var['highly_variable']` approach with the `adata.obsm['X_geneset1']` approach Alex suggested. Firstly, there is a typo in Alex' code above. It should read:. ```. adata.obsm['X_geneset1'] = adata[:,['gene1', 'gene2', 'gene3', 'gene4']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). ```. I believe. Your error is due to this typo. The command is interpreting `'Map7d1'` as a cell index rather than a gene index. However, there are also a few other things. 1. `adata.var['highly_variable']` takes a boolean list, so you should assign e.g., `[True, True, False, False]` if you are interested in only the first two genes out of a total of 4 genes in the dataset. This can be trivially extended to select your Gene1, Gene,... Gene500 that you are interested in. When using this approach you will need to run `sc.pp.pca(adata, svd_solver='arpack', use_highly_variable=True)` and `sc.pp.neighbors(adata)` before clustering with louvain or leiden. This approach subsets to your genes of interest, then performs PCA on this gene subset, and builds a KNN graph based on Euclidean distances in this PCA space, which is then used for clustering. 2. If you don't want to use the route via PCA, you need to assign to `adata.obsm` as Alex suggests (with my typo correction above). Even if you do not have anything in `adata.obsm`, it should still work. If you want to put something in `adata.obsm`, just run `sc.pp.pca(adata, svd_solver='arpack')` and you will see `adata.obsm['X_pca']` appear. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:467,usability,command,command,467,"Hi @Olivia117,. Let's see if I can help. I think there are a few misunderstandings here. It appears that you are mixing the `adata.var['highly_variable']` approach with the `adata.obsm['X_geneset1']` approach Alex suggested. Firstly, there is a typo in Alex' code above. It should read:. ```. adata.obsm['X_geneset1'] = adata[:,['gene1', 'gene2', 'gene3', 'gene4']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). ```. I believe. Your error is due to this typo. The command is interpreting `'Map7d1'` as a cell index rather than a gene index. However, there are also a few other things. 1. `adata.var['highly_variable']` takes a boolean list, so you should assign e.g., `[True, True, False, False]` if you are interested in only the first two genes out of a total of 4 genes in the dataset. This can be trivially extended to select your Gene1, Gene,... Gene500 that you are interested in. When using this approach you will need to run `sc.pp.pca(adata, svd_solver='arpack', use_highly_variable=True)` and `sc.pp.neighbors(adata)` before clustering with louvain or leiden. This approach subsets to your genes of interest, then performs PCA on this gene subset, and builds a KNN graph based on Euclidean distances in this PCA space, which is then used for clustering. 2. If you don't want to use the route via PCA, you need to assign to `adata.obsm` as Alex suggests (with my typo correction above). Even if you do not have anything in `adata.obsm`, it should still work. If you want to put something in `adata.obsm`, just run `sc.pp.pca(adata, svd_solver='arpack')` and you will see `adata.obsm['X_pca']` appear. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:1127,usability,perform,performs,1127,"Hi @Olivia117,. Let's see if I can help. I think there are a few misunderstandings here. It appears that you are mixing the `adata.var['highly_variable']` approach with the `adata.obsm['X_geneset1']` approach Alex suggested. Firstly, there is a typo in Alex' code above. It should read:. ```. adata.obsm['X_geneset1'] = adata[:,['gene1', 'gene2', 'gene3', 'gene4']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). ```. I believe. Your error is due to this typo. The command is interpreting `'Map7d1'` as a cell index rather than a gene index. However, there are also a few other things. 1. `adata.var['highly_variable']` takes a boolean list, so you should assign e.g., `[True, True, False, False]` if you are interested in only the first two genes out of a total of 4 genes in the dataset. This can be trivially extended to select your Gene1, Gene,... Gene500 that you are interested in. When using this approach you will need to run `sc.pp.pca(adata, svd_solver='arpack', use_highly_variable=True)` and `sc.pp.neighbors(adata)` before clustering with louvain or leiden. This approach subsets to your genes of interest, then performs PCA on this gene subset, and builds a KNN graph based on Euclidean distances in this PCA space, which is then used for clustering. 2. If you don't want to use the route via PCA, you need to assign to `adata.obsm` as Alex suggests (with my typo correction above). Even if you do not have anything in `adata.obsm`, it should still work. If you want to put something in `adata.obsm`, just run `sc.pp.pca(adata, svd_solver='arpack')` and you will see `adata.obsm['X_pca']` appear. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:1623,usability,help,helps,1623,"Hi @Olivia117,. Let's see if I can help. I think there are a few misunderstandings here. It appears that you are mixing the `adata.var['highly_variable']` approach with the `adata.obsm['X_geneset1']` approach Alex suggested. Firstly, there is a typo in Alex' code above. It should read:. ```. adata.obsm['X_geneset1'] = adata[:,['gene1', 'gene2', 'gene3', 'gene4']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). ```. I believe. Your error is due to this typo. The command is interpreting `'Map7d1'` as a cell index rather than a gene index. However, there are also a few other things. 1. `adata.var['highly_variable']` takes a boolean list, so you should assign e.g., `[True, True, False, False]` if you are interested in only the first two genes out of a total of 4 genes in the dataset. This can be trivially extended to select your Gene1, Gene,... Gene500 that you are interested in. When using this approach you will need to run `sc.pp.pca(adata, svd_solver='arpack', use_highly_variable=True)` and `sc.pp.neighbors(adata)` before clustering with louvain or leiden. This approach subsets to your genes of interest, then performs PCA on this gene subset, and builds a KNN graph based on Euclidean distances in this PCA space, which is then used for clustering. 2. If you don't want to use the route via PCA, you need to assign to `adata.obsm` as Alex suggests (with my typo correction above). Even if you do not have anything in `adata.obsm`, it should still work. If you want to put something in `adata.obsm`, just run `sc.pp.pca(adata, svd_solver='arpack')` and you will see `adata.obsm['X_pca']` appear. Hope this helps.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:77,availability,cluster,clustering,77,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```. adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X. ```. It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ . Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:220,availability,cluster,clustering,220,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```. adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X. ```. It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ . Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:77,deployability,cluster,clustering,77,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```. adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X. ```. It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ . Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:220,deployability,cluster,clustering,220,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```. adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X. ```. It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ . Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:564,deployability,contain,contain,564,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```. adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X. ```. It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ . Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:580,deployability,observ,observation,580,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```. adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X. ```. It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ . Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:883,deployability,log,log-normalization,883,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```. adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X. ```. It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ . Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:992,deployability,depend,dependence,992,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```. adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X. ```. It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ . Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:301,energy efficiency,reduc,reduction,301,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```. adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X. ```. It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ . Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:51,integrability,rout,route,51,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```. adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X. ```. It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ . Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:807,integrability,sub,subject,807,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```. adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X. ```. It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ . Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:992,integrability,depend,dependence,992,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```. adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X. ```. It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ . Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:242,interoperability,specif,specific,242,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```. adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X. ```. It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ . Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:592,modifiability,variab,variables,592,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```. adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X. ```. It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ . Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:992,modifiability,depend,dependence,992,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```. adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X. ```. It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ . Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:883,safety,log,log-normalization,883,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```. adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X. ```. It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ . Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:992,safety,depend,dependence,992,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```. adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X. ```. It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ . Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:883,security,log,log-normalization,883,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```. adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X. ```. It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ . Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:580,testability,observ,observation,580,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```. adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X. ```. It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ . Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:883,testability,log,log-normalization,883,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```. adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X. ```. It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ . Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:964,testability,regress,regression,964,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```. adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X. ```. It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ . Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:992,testability,depend,dependence,992,"Hi @LuckyMD,. Many thanks for your comments. . The route via PCA followed by clustering & embedding (UMAP/tSNE) works perfectly fine for me. I have also got some interesting results from the analysis. Now, I want to try clustering cells with specific gene sets instead of the conventional dimensional reduction. Yes, I tried the following lines before:. ```. adata.obsm['X_geneset1`] = adata[:, ['gene1', 'gene2', 'gene3', 'gene4']].X. ```. It still says, KeyError: 'Indices ""[\'Ada\', \'Mustn1\', \'Mlc1\', \'Gfra\', \'Gm765\', \'Csrp2\', \'Socs2\', \'Dnajb9\']"" contain invalid observation/variables names/indices.'. All of these genes are present in my dataset. I am still trying to figure out why this is happening :/ . Maybe, I will paste the short code snippet later. . P.S: Sorry for getting off the subject. Is there an alternative normalization step included apart from the log-normalization method? For example, TMM in edgeR & SCnorm- that uses quantile regression to calculate the dependence of read counts on sequencing depth for each gene (when count-depth relationship varies among genes). .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:851,availability,avail,available,851,"Are you sure that the genes are in `adata.var_names` in the gene symbol format that you are using to subset the object? In other words, is `'Ada' in adata.var_names` `True`? I'd just like to check whether you don't have e.g., Ensembl IDs as your variable names by chance. Regarding normalization... there are other normalization methods. I believe a method was recently added to scanpy to use only a particular fraction of genes to calculate size factors (avoiding genes that make up >5% of the total counts). Otherwise, we have recently compiled a best practices pipeline in the group, which uses Scran's pooling strategy to normalize the data. This is implemented in R, but can easily be used in a python-based workflow via [`anndata2ri`](www.github.com/flying-sheep/anndata2ri). A case study using the best practices (with scran and anndata2ri) is available [here](www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:564,deployability,pipelin,pipeline,564,"Are you sure that the genes are in `adata.var_names` in the gene symbol format that you are using to subset the object? In other words, is `'Ada' in adata.var_names` `True`? I'd just like to check whether you don't have e.g., Ensembl IDs as your variable names by chance. Regarding normalization... there are other normalization methods. I believe a method was recently added to scanpy to use only a particular fraction of genes to calculate size factors (avoiding genes that make up >5% of the total counts). Otherwise, we have recently compiled a best practices pipeline in the group, which uses Scran's pooling strategy to normalize the data. This is implemented in R, but can easily be used in a python-based workflow via [`anndata2ri`](www.github.com/flying-sheep/anndata2ri). A case study using the best practices (with scran and anndata2ri) is available [here](www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:101,integrability,sub,subset,101,"Are you sure that the genes are in `adata.var_names` in the gene symbol format that you are using to subset the object? In other words, is `'Ada' in adata.var_names` `True`? I'd just like to check whether you don't have e.g., Ensembl IDs as your variable names by chance. Regarding normalization... there are other normalization methods. I believe a method was recently added to scanpy to use only a particular fraction of genes to calculate size factors (avoiding genes that make up >5% of the total counts). Otherwise, we have recently compiled a best practices pipeline in the group, which uses Scran's pooling strategy to normalize the data. This is implemented in R, but can easily be used in a python-based workflow via [`anndata2ri`](www.github.com/flying-sheep/anndata2ri). A case study using the best practices (with scran and anndata2ri) is available [here](www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:564,integrability,pipelin,pipeline,564,"Are you sure that the genes are in `adata.var_names` in the gene symbol format that you are using to subset the object? In other words, is `'Ada' in adata.var_names` `True`? I'd just like to check whether you don't have e.g., Ensembl IDs as your variable names by chance. Regarding normalization... there are other normalization methods. I believe a method was recently added to scanpy to use only a particular fraction of genes to calculate size factors (avoiding genes that make up >5% of the total counts). Otherwise, we have recently compiled a best practices pipeline in the group, which uses Scran's pooling strategy to normalize the data. This is implemented in R, but can easily be used in a python-based workflow via [`anndata2ri`](www.github.com/flying-sheep/anndata2ri). A case study using the best practices (with scran and anndata2ri) is available [here](www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:72,interoperability,format,format,72,"Are you sure that the genes are in `adata.var_names` in the gene symbol format that you are using to subset the object? In other words, is `'Ada' in adata.var_names` `True`? I'd just like to check whether you don't have e.g., Ensembl IDs as your variable names by chance. Regarding normalization... there are other normalization methods. I believe a method was recently added to scanpy to use only a particular fraction of genes to calculate size factors (avoiding genes that make up >5% of the total counts). Otherwise, we have recently compiled a best practices pipeline in the group, which uses Scran's pooling strategy to normalize the data. This is implemented in R, but can easily be used in a python-based workflow via [`anndata2ri`](www.github.com/flying-sheep/anndata2ri). A case study using the best practices (with scran and anndata2ri) is available [here](www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:246,modifiability,variab,variable,246,"Are you sure that the genes are in `adata.var_names` in the gene symbol format that you are using to subset the object? In other words, is `'Ada' in adata.var_names` `True`? I'd just like to check whether you don't have e.g., Ensembl IDs as your variable names by chance. Regarding normalization... there are other normalization methods. I believe a method was recently added to scanpy to use only a particular fraction of genes to calculate size factors (avoiding genes that make up >5% of the total counts). Otherwise, we have recently compiled a best practices pipeline in the group, which uses Scran's pooling strategy to normalize the data. This is implemented in R, but can easily be used in a python-based workflow via [`anndata2ri`](www.github.com/flying-sheep/anndata2ri). A case study using the best practices (with scran and anndata2ri) is available [here](www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:554,reliability,pra,practices,554,"Are you sure that the genes are in `adata.var_names` in the gene symbol format that you are using to subset the object? In other words, is `'Ada' in adata.var_names` `True`? I'd just like to check whether you don't have e.g., Ensembl IDs as your variable names by chance. Regarding normalization... there are other normalization methods. I believe a method was recently added to scanpy to use only a particular fraction of genes to calculate size factors (avoiding genes that make up >5% of the total counts). Otherwise, we have recently compiled a best practices pipeline in the group, which uses Scran's pooling strategy to normalize the data. This is implemented in R, but can easily be used in a python-based workflow via [`anndata2ri`](www.github.com/flying-sheep/anndata2ri). A case study using the best practices (with scran and anndata2ri) is available [here](www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:810,reliability,pra,practices,810,"Are you sure that the genes are in `adata.var_names` in the gene symbol format that you are using to subset the object? In other words, is `'Ada' in adata.var_names` `True`? I'd just like to check whether you don't have e.g., Ensembl IDs as your variable names by chance. Regarding normalization... there are other normalization methods. I believe a method was recently added to scanpy to use only a particular fraction of genes to calculate size factors (avoiding genes that make up >5% of the total counts). Otherwise, we have recently compiled a best practices pipeline in the group, which uses Scran's pooling strategy to normalize the data. This is implemented in R, but can easily be used in a python-based workflow via [`anndata2ri`](www.github.com/flying-sheep/anndata2ri). A case study using the best practices (with scran and anndata2ri) is available [here](www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:851,reliability,availab,available,851,"Are you sure that the genes are in `adata.var_names` in the gene symbol format that you are using to subset the object? In other words, is `'Ada' in adata.var_names` `True`? I'd just like to check whether you don't have e.g., Ensembl IDs as your variable names by chance. Regarding normalization... there are other normalization methods. I believe a method was recently added to scanpy to use only a particular fraction of genes to calculate size factors (avoiding genes that make up >5% of the total counts). Otherwise, we have recently compiled a best practices pipeline in the group, which uses Scran's pooling strategy to normalize the data. This is implemented in R, but can easily be used in a python-based workflow via [`anndata2ri`](www.github.com/flying-sheep/anndata2ri). A case study using the best practices (with scran and anndata2ri) is available [here](www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:456,safety,avoid,avoiding,456,"Are you sure that the genes are in `adata.var_names` in the gene symbol format that you are using to subset the object? In other words, is `'Ada' in adata.var_names` `True`? I'd just like to check whether you don't have e.g., Ensembl IDs as your variable names by chance. Regarding normalization... there are other normalization methods. I believe a method was recently added to scanpy to use only a particular fraction of genes to calculate size factors (avoiding genes that make up >5% of the total counts). Otherwise, we have recently compiled a best practices pipeline in the group, which uses Scran's pooling strategy to normalize the data. This is implemented in R, but can easily be used in a python-based workflow via [`anndata2ri`](www.github.com/flying-sheep/anndata2ri). A case study using the best practices (with scran and anndata2ri) is available [here](www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:851,safety,avail,available,851,"Are you sure that the genes are in `adata.var_names` in the gene symbol format that you are using to subset the object? In other words, is `'Ada' in adata.var_names` `True`? I'd just like to check whether you don't have e.g., Ensembl IDs as your variable names by chance. Regarding normalization... there are other normalization methods. I believe a method was recently added to scanpy to use only a particular fraction of genes to calculate size factors (avoiding genes that make up >5% of the total counts). Otherwise, we have recently compiled a best practices pipeline in the group, which uses Scran's pooling strategy to normalize the data. This is implemented in R, but can easily be used in a python-based workflow via [`anndata2ri`](www.github.com/flying-sheep/anndata2ri). A case study using the best practices (with scran and anndata2ri) is available [here](www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:851,security,availab,available,851,"Are you sure that the genes are in `adata.var_names` in the gene symbol format that you are using to subset the object? In other words, is `'Ada' in adata.var_names` `True`? I'd just like to check whether you don't have e.g., Ensembl IDs as your variable names by chance. Regarding normalization... there are other normalization methods. I believe a method was recently added to scanpy to use only a particular fraction of genes to calculate size factors (avoiding genes that make up >5% of the total counts). Otherwise, we have recently compiled a best practices pipeline in the group, which uses Scran's pooling strategy to normalize the data. This is implemented in R, but can easily be used in a python-based workflow via [`anndata2ri`](www.github.com/flying-sheep/anndata2ri). A case study using the best practices (with scran and anndata2ri) is available [here](www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:713,usability,workflow,workflow,713,"Are you sure that the genes are in `adata.var_names` in the gene symbol format that you are using to subset the object? In other words, is `'Ada' in adata.var_names` `True`? I'd just like to check whether you don't have e.g., Ensembl IDs as your variable names by chance. Regarding normalization... there are other normalization methods. I believe a method was recently added to scanpy to use only a particular fraction of genes to calculate size factors (avoiding genes that make up >5% of the total counts). Otherwise, we have recently compiled a best practices pipeline in the group, which uses Scran's pooling strategy to normalize the data. This is implemented in R, but can easily be used in a python-based workflow via [`anndata2ri`](www.github.com/flying-sheep/anndata2ri). A case study using the best practices (with scran and anndata2ri) is available [here](www.github.com/theislab/single-cell-tutorial).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:523,availability,cluster,clustering,523,"Hello @LuckyMD,. Yeah, the genes are all present in adata.var_names. ![HVG_300419](https://user-images.githubusercontent.com/44576210/56977241-07ef9c00-6b75-11e9-85af-8b098b3ba13f.png). `adata.var_names. Index(['Ada', 'Mustn1', 'Mlc1', 'Gfra1', 'Rspo1', 'Gda', 'Car8', 'Ly86',. 'Kcnmb1', 'Lgals3',. ... 'Fam155a', 'Rnd2', 'Snx29', 'Map7d1', 'Unc80', 'Ttc17', 'Sncb', 'Esrra',. 'Enpp5', 'Kctd1'],. dtype='object', length=1573). `. I copy-pasted the symbols individually & it works now! I am able to do the louvain community clustering & visualize with UMAP. . `adata.obsm['X_geneset1'] = adata[:,['Ada', 'Mustn1', 'Mlc1', 'Gfra1', 'Rspo1', 'Gda', 'Car8', 'Ly86', 'Fam155a', 'Rnd2', 'Snx29']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). sc.tl.umap(adata). sc.pl.umap(adata). sc.tl.louvain(adata). sc.pl.umap(adata, color= ['louvain']). `. Thanks for the suggestions regarding normalization with scran & anndata2ri. I shall check it out :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:523,deployability,cluster,clustering,523,"Hello @LuckyMD,. Yeah, the genes are all present in adata.var_names. ![HVG_300419](https://user-images.githubusercontent.com/44576210/56977241-07ef9c00-6b75-11e9-85af-8b098b3ba13f.png). `adata.var_names. Index(['Ada', 'Mustn1', 'Mlc1', 'Gfra1', 'Rspo1', 'Gda', 'Car8', 'Ly86',. 'Kcnmb1', 'Lgals3',. ... 'Fam155a', 'Rnd2', 'Snx29', 'Map7d1', 'Unc80', 'Ttc17', 'Sncb', 'Esrra',. 'Enpp5', 'Kctd1'],. dtype='object', length=1573). `. I copy-pasted the symbols individually & it works now! I am able to do the louvain community clustering & visualize with UMAP. . `adata.obsm['X_geneset1'] = adata[:,['Ada', 'Mustn1', 'Mlc1', 'Gfra1', 'Rspo1', 'Gda', 'Car8', 'Ly86', 'Fam155a', 'Rnd2', 'Snx29']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). sc.tl.umap(adata). sc.pl.umap(adata). sc.tl.louvain(adata). sc.pl.umap(adata, color= ['louvain']). `. Thanks for the suggestions regarding normalization with scran & anndata2ri. I shall check it out :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:91,usability,user,user-images,91,"Hello @LuckyMD,. Yeah, the genes are all present in adata.var_names. ![HVG_300419](https://user-images.githubusercontent.com/44576210/56977241-07ef9c00-6b75-11e9-85af-8b098b3ba13f.png). `adata.var_names. Index(['Ada', 'Mustn1', 'Mlc1', 'Gfra1', 'Rspo1', 'Gda', 'Car8', 'Ly86',. 'Kcnmb1', 'Lgals3',. ... 'Fam155a', 'Rnd2', 'Snx29', 'Map7d1', 'Unc80', 'Ttc17', 'Sncb', 'Esrra',. 'Enpp5', 'Kctd1'],. dtype='object', length=1573). `. I copy-pasted the symbols individually & it works now! I am able to do the louvain community clustering & visualize with UMAP. . `adata.obsm['X_geneset1'] = adata[:,['Ada', 'Mustn1', 'Mlc1', 'Gfra1', 'Rspo1', 'Gda', 'Car8', 'Ly86', 'Fam155a', 'Rnd2', 'Snx29']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). sc.tl.umap(adata). sc.pl.umap(adata). sc.tl.louvain(adata). sc.pl.umap(adata, color= ['louvain']). `. Thanks for the suggestions regarding normalization with scran & anndata2ri. I shall check it out :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:536,usability,visual,visualize,536,"Hello @LuckyMD,. Yeah, the genes are all present in adata.var_names. ![HVG_300419](https://user-images.githubusercontent.com/44576210/56977241-07ef9c00-6b75-11e9-85af-8b098b3ba13f.png). `adata.var_names. Index(['Ada', 'Mustn1', 'Mlc1', 'Gfra1', 'Rspo1', 'Gda', 'Car8', 'Ly86',. 'Kcnmb1', 'Lgals3',. ... 'Fam155a', 'Rnd2', 'Snx29', 'Map7d1', 'Unc80', 'Ttc17', 'Sncb', 'Esrra',. 'Enpp5', 'Kctd1'],. dtype='object', length=1573). `. I copy-pasted the symbols individually & it works now! I am able to do the louvain community clustering & visualize with UMAP. . `adata.obsm['X_geneset1'] = adata[:,['Ada', 'Mustn1', 'Mlc1', 'Gfra1', 'Rspo1', 'Gda', 'Car8', 'Ly86', 'Fam155a', 'Rnd2', 'Snx29']].X. sc.pp.neighbors(adata, use_rep='X_geneset1'). sc.tl.umap(adata). sc.pl.umap(adata). sc.tl.louvain(adata). sc.pl.umap(adata, color= ['louvain']). `. Thanks for the suggestions regarding normalization with scran & anndata2ri. I shall check it out :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:224,deployability,api,api,224,"> I believe a method was recently added to scanpy to use only a particular fraction of genes to calculate size factors (avoiding genes that make up >5% of the total counts). Yes, it's https://scanpy.readthedocs.io/en/latest/api/scanpy.pp.normalize_total.html with param `fraction=0.95`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:224,integrability,api,api,224,"> I believe a method was recently added to scanpy to use only a particular fraction of genes to calculate size factors (avoiding genes that make up >5% of the total counts). Yes, it's https://scanpy.readthedocs.io/en/latest/api/scanpy.pp.normalize_total.html with param `fraction=0.95`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:224,interoperability,api,api,224,"> I believe a method was recently added to scanpy to use only a particular fraction of genes to calculate size factors (avoiding genes that make up >5% of the total counts). Yes, it's https://scanpy.readthedocs.io/en/latest/api/scanpy.pp.normalize_total.html with param `fraction=0.95`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:120,safety,avoid,avoiding,120,"> I believe a method was recently added to scanpy to use only a particular fraction of genes to calculate size factors (avoiding genes that make up >5% of the total counts). Yes, it's https://scanpy.readthedocs.io/en/latest/api/scanpy.pp.normalize_total.html with param `fraction=0.95`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:70,availability,cluster,clustered,70,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). . ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:136,availability,cluster,clusters,136,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). . ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:760,availability,cluster,cluster,760,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). . ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:942,availability,cluster,cluster,942,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). . ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:1038,availability,cluster,cluster,1038,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). . ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:1175,availability,cluster,cluster,1175,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). . ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:1384,availability,cluster,cluster,1384,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). . ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:70,deployability,cluster,clustered,70,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). . ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:136,deployability,cluster,clusters,136,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). . ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:651,deployability,Log,Logistic,651,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). . ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:760,deployability,cluster,cluster,760,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). . ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:942,deployability,cluster,cluster,942,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). . ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:1038,deployability,cluster,cluster,1038,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). . ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:1175,deployability,cluster,cluster,1175,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). . ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:1384,deployability,cluster,cluster,1384,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). . ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:1416,performance,time,time,1416,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). . ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:651,safety,Log,Logistic,651,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). . ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:591,security,ident,identification,591,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). . ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:651,security,Log,Logistic,651,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). . ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:651,testability,Log,Logistic,651,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). . ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:660,testability,regress,regression,660,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). . ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:1150,testability,simpl,simply,1150,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). . ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:480,usability,user,user-images,480,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). . ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:815,usability,user,user-images,815,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). . ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:1150,usability,simpl,simply,1150,"Thanks a lot, @falexwolf. . I have one more question. Suppose, I have clustered cells with a restricted gene set & arrived at 8 Louvain clusters (considering one like the example above). . `adata.obsm['X_geneset1`] = adata[:, ['Tmem72', 'Adgrg2', 'Scn4b', 'Ust', 'Htr1d', 'Prnp', 'Rom1', 'Gpr158', 'Robo2', 'Cntn2', 'Rab11fip5', 'Lhfpl2', 'Emb', 'Gabrg2', 'Ptk7', 'Prkar1a', 'Ehd3', 'Kitl', 'Slc6a19', 'Spry4', 'Nceh1', 'Lin7a',....,'Lpin1']].X`. ![Input_subgroup_030519](https://user-images.githubusercontent.com/44576210/57128124-bae91100-6d92-11e9-96d8-6d3d322d5f12.png). Now, for marker identification, I have ranked genes in each community using Logistic regression & Wilcoxon. Naturally, there can be genes with a very high score (those were not used to cluster the cells). . ![Input_CMarkers_LogReg](https://user-images.githubusercontent.com/44576210/57132746-d5c28200-6da0-11e9-816b-e3b71ee01a0f.png). Now, if I find a few genes in a cluster that acts as contradictory markers (like, the markers for vascular cells in a dendritic cluster) will I be able to eliminate contaminating cells from the group that expresses those vascular genes? To simply put it, I want to cluster genes with ['gene1', 'gene2', 'gene3', 'gene4',..'gene400'] but I don't want to include cells that express ['gene10' AND 'gene35' AND 'gene100'..etc]. Will I be able to omit all such cells & rerun the cluster? I can do one gene at a time. . `ldata_modified = ldata[ldata[: , 'Rpl13'].X > 0.5, :] `.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:210,availability,cluster,cluster,210,"You can construct arbitrarily complicated conditions of excluding cells by doing, e.g., . `subset = np.logical_and(ldata[: , 'A'].X > a, ldata[: , 'A'].X > a)`. However, I would question to consider cells in a cluster that express just a couple of genes in an unexpected way as ""contaminating"". In the worst case, you're looking at a cluster of doublets, but then you probably need to throw away the whole cluster. In the best case, you found some interesting biology.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:334,availability,cluster,cluster,334,"You can construct arbitrarily complicated conditions of excluding cells by doing, e.g., . `subset = np.logical_and(ldata[: , 'A'].X > a, ldata[: , 'A'].X > a)`. However, I would question to consider cells in a cluster that express just a couple of genes in an unexpected way as ""contaminating"". In the worst case, you're looking at a cluster of doublets, but then you probably need to throw away the whole cluster. In the best case, you found some interesting biology.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:406,availability,cluster,cluster,406,"You can construct arbitrarily complicated conditions of excluding cells by doing, e.g., . `subset = np.logical_and(ldata[: , 'A'].X > a, ldata[: , 'A'].X > a)`. However, I would question to consider cells in a cluster that express just a couple of genes in an unexpected way as ""contaminating"". In the worst case, you're looking at a cluster of doublets, but then you probably need to throw away the whole cluster. In the best case, you found some interesting biology.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:210,deployability,cluster,cluster,210,"You can construct arbitrarily complicated conditions of excluding cells by doing, e.g., . `subset = np.logical_and(ldata[: , 'A'].X > a, ldata[: , 'A'].X > a)`. However, I would question to consider cells in a cluster that express just a couple of genes in an unexpected way as ""contaminating"". In the worst case, you're looking at a cluster of doublets, but then you probably need to throw away the whole cluster. In the best case, you found some interesting biology.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:334,deployability,cluster,cluster,334,"You can construct arbitrarily complicated conditions of excluding cells by doing, e.g., . `subset = np.logical_and(ldata[: , 'A'].X > a, ldata[: , 'A'].X > a)`. However, I would question to consider cells in a cluster that express just a couple of genes in an unexpected way as ""contaminating"". In the worst case, you're looking at a cluster of doublets, but then you probably need to throw away the whole cluster. In the best case, you found some interesting biology.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:406,deployability,cluster,cluster,406,"You can construct arbitrarily complicated conditions of excluding cells by doing, e.g., . `subset = np.logical_and(ldata[: , 'A'].X > a, ldata[: , 'A'].X > a)`. However, I would question to consider cells in a cluster that express just a couple of genes in an unexpected way as ""contaminating"". In the worst case, you're looking at a cluster of doublets, but then you probably need to throw away the whole cluster. In the best case, you found some interesting biology.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:91,integrability,sub,subset,91,"You can construct arbitrarily complicated conditions of excluding cells by doing, e.g., . `subset = np.logical_and(ldata[: , 'A'].X > a, ldata[: , 'A'].X > a)`. However, I would question to consider cells in a cluster that express just a couple of genes in an unexpected way as ""contaminating"". In the worst case, you're looking at a cluster of doublets, but then you probably need to throw away the whole cluster. In the best case, you found some interesting biology.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:238,integrability,coupl,couple,238,"You can construct arbitrarily complicated conditions of excluding cells by doing, e.g., . `subset = np.logical_and(ldata[: , 'A'].X > a, ldata[: , 'A'].X > a)`. However, I would question to consider cells in a cluster that express just a couple of genes in an unexpected way as ""contaminating"". In the worst case, you're looking at a cluster of doublets, but then you probably need to throw away the whole cluster. In the best case, you found some interesting biology.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:238,modifiability,coupl,couple,238,"You can construct arbitrarily complicated conditions of excluding cells by doing, e.g., . `subset = np.logical_and(ldata[: , 'A'].X > a, ldata[: , 'A'].X > a)`. However, I would question to consider cells in a cluster that express just a couple of genes in an unexpected way as ""contaminating"". In the worst case, you're looking at a cluster of doublets, but then you probably need to throw away the whole cluster. In the best case, you found some interesting biology.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:30,safety,compl,complicated,30,"You can construct arbitrarily complicated conditions of excluding cells by doing, e.g., . `subset = np.logical_and(ldata[: , 'A'].X > a, ldata[: , 'A'].X > a)`. However, I would question to consider cells in a cluster that express just a couple of genes in an unexpected way as ""contaminating"". In the worst case, you're looking at a cluster of doublets, but then you probably need to throw away the whole cluster. In the best case, you found some interesting biology.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:30,security,compl,complicated,30,"You can construct arbitrarily complicated conditions of excluding cells by doing, e.g., . `subset = np.logical_and(ldata[: , 'A'].X > a, ldata[: , 'A'].X > a)`. However, I would question to consider cells in a cluster that express just a couple of genes in an unexpected way as ""contaminating"". In the worst case, you're looking at a cluster of doublets, but then you probably need to throw away the whole cluster. In the best case, you found some interesting biology.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/510:238,testability,coupl,couple,238,"You can construct arbitrarily complicated conditions of excluding cells by doing, e.g., . `subset = np.logical_and(ldata[: , 'A'].X > a, ldata[: , 'A'].X > a)`. However, I would question to consider cells in a cluster that express just a couple of genes in an unexpected way as ""contaminating"". In the worst case, you're looking at a cluster of doublets, but then you probably need to throw away the whole cluster. In the best case, you found some interesting biology.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/510
https://github.com/scverse/scanpy/issues/511:44,deployability,resourc,resources,44,"It should definitely run through with these resources, and I and many other people ran it already. @Koncopd, could you check whether everything behaves still normally? I don't know how we can test this, but I also can't see who we might have broken it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:44,energy efficiency,resourc,resources,44,"It should definitely run through with these resources, and I and many other people ran it already. @Koncopd, could you check whether everything behaves still normally? I don't know how we can test this, but I also can't see who we might have broken it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:44,performance,resourc,resources,44,"It should definitely run through with these resources, and I and many other people ran it already. @Koncopd, could you check whether everything behaves still normally? I don't know how we can test this, but I also can't see who we might have broken it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:44,safety,resourc,resources,44,"It should definitely run through with these resources, and I and many other people ran it already. @Koncopd, could you check whether everything behaves still normally? I don't know how we can test this, but I also can't see who we might have broken it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:192,safety,test,test,192,"It should definitely run through with these resources, and I and many other people ran it already. @Koncopd, could you check whether everything behaves still normally? I don't know how we can test this, but I also can't see who we might have broken it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:44,testability,resourc,resources,44,"It should definitely run through with these resources, and I and many other people ran it already. @Koncopd, could you check whether everything behaves still normally? I don't know how we can test this, but I also can't see who we might have broken it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:192,testability,test,test,192,"It should definitely run through with these resources, and I and many other people ran it already. @Koncopd, could you check whether everything behaves still normally? I don't know how we can test this, but I also can't see who we might have broken it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:212,deployability,stage,stage,212,"hi Alex, I'm not sure how to test this either. I tried to run in a new clean conda environment but cant use more than 50% of the cells in pre-processing (otherwise the process is killed at even the normalization stage, ""pp.normalize_ per_cell"" and uses over 120GB RAM). The file from 10X i'm using is the link to ""1M_neurons aggr - Gene / cell matrix HDF5 (filtered)"" from https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.3.0/ . This is what i type into the terminal. $ python cluster_mouse_brain.py 1M_neurons_filtered_gene_bc_matrices_h5.h5. Variable names are not unique. To make them unique, call `.var_names_make_unique`. reading 1M_neurons_filtered_gene_bc_matrices_h5.h5 (0:01:19.78). running recipe zheng17. filtered out 3983 genes that are detected in less than 1 counts. Variable names are not unique. To make them unique, call `.var_names_make_unique`. Variable names are not unique. To make them unique, call `.var_names_make_unique`. Killed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:357,integrability,filter,filtered,357,"hi Alex, I'm not sure how to test this either. I tried to run in a new clean conda environment but cant use more than 50% of the cells in pre-processing (otherwise the process is killed at even the normalization stage, ""pp.normalize_ per_cell"" and uses over 120GB RAM). The file from 10X i'm using is the link to ""1M_neurons aggr - Gene / cell matrix HDF5 (filtered)"" from https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.3.0/ . This is what i type into the terminal. $ python cluster_mouse_brain.py 1M_neurons_filtered_gene_bc_matrices_h5.h5. Variable names are not unique. To make them unique, call `.var_names_make_unique`. reading 1M_neurons_filtered_gene_bc_matrices_h5.h5 (0:01:19.78). running recipe zheng17. filtered out 3983 genes that are detected in less than 1 counts. Variable names are not unique. To make them unique, call `.var_names_make_unique`. Variable names are not unique. To make them unique, call `.var_names_make_unique`. Killed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:738,integrability,filter,filtered,738,"hi Alex, I'm not sure how to test this either. I tried to run in a new clean conda environment but cant use more than 50% of the cells in pre-processing (otherwise the process is killed at even the normalization stage, ""pp.normalize_ per_cell"" and uses over 120GB RAM). The file from 10X i'm using is the link to ""1M_neurons aggr - Gene / cell matrix HDF5 (filtered)"" from https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.3.0/ . This is what i type into the terminal. $ python cluster_mouse_brain.py 1M_neurons_filtered_gene_bc_matrices_h5.h5. Variable names are not unique. To make them unique, call `.var_names_make_unique`. reading 1M_neurons_filtered_gene_bc_matrices_h5.h5 (0:01:19.78). running recipe zheng17. filtered out 3983 genes that are detected in less than 1 counts. Variable names are not unique. To make them unique, call `.var_names_make_unique`. Variable names are not unique. To make them unique, call `.var_names_make_unique`. Killed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:566,modifiability,Variab,Variable,566,"hi Alex, I'm not sure how to test this either. I tried to run in a new clean conda environment but cant use more than 50% of the cells in pre-processing (otherwise the process is killed at even the normalization stage, ""pp.normalize_ per_cell"" and uses over 120GB RAM). The file from 10X i'm using is the link to ""1M_neurons aggr - Gene / cell matrix HDF5 (filtered)"" from https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.3.0/ . This is what i type into the terminal. $ python cluster_mouse_brain.py 1M_neurons_filtered_gene_bc_matrices_h5.h5. Variable names are not unique. To make them unique, call `.var_names_make_unique`. reading 1M_neurons_filtered_gene_bc_matrices_h5.h5 (0:01:19.78). running recipe zheng17. filtered out 3983 genes that are detected in less than 1 counts. Variable names are not unique. To make them unique, call `.var_names_make_unique`. Variable names are not unique. To make them unique, call `.var_names_make_unique`. Killed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:803,modifiability,Variab,Variable,803,"hi Alex, I'm not sure how to test this either. I tried to run in a new clean conda environment but cant use more than 50% of the cells in pre-processing (otherwise the process is killed at even the normalization stage, ""pp.normalize_ per_cell"" and uses over 120GB RAM). The file from 10X i'm using is the link to ""1M_neurons aggr - Gene / cell matrix HDF5 (filtered)"" from https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.3.0/ . This is what i type into the terminal. $ python cluster_mouse_brain.py 1M_neurons_filtered_gene_bc_matrices_h5.h5. Variable names are not unique. To make them unique, call `.var_names_make_unique`. reading 1M_neurons_filtered_gene_bc_matrices_h5.h5 (0:01:19.78). running recipe zheng17. filtered out 3983 genes that are detected in less than 1 counts. Variable names are not unique. To make them unique, call `.var_names_make_unique`. Variable names are not unique. To make them unique, call `.var_names_make_unique`. Killed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:886,modifiability,Variab,Variable,886,"hi Alex, I'm not sure how to test this either. I tried to run in a new clean conda environment but cant use more than 50% of the cells in pre-processing (otherwise the process is killed at even the normalization stage, ""pp.normalize_ per_cell"" and uses over 120GB RAM). The file from 10X i'm using is the link to ""1M_neurons aggr - Gene / cell matrix HDF5 (filtered)"" from https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.3.0/ . This is what i type into the terminal. $ python cluster_mouse_brain.py 1M_neurons_filtered_gene_bc_matrices_h5.h5. Variable names are not unique. To make them unique, call `.var_names_make_unique`. reading 1M_neurons_filtered_gene_bc_matrices_h5.h5 (0:01:19.78). running recipe zheng17. filtered out 3983 genes that are detected in less than 1 counts. Variable names are not unique. To make them unique, call `.var_names_make_unique`. Variable names are not unique. To make them unique, call `.var_names_make_unique`. Killed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:29,safety,test,test,29,"hi Alex, I'm not sure how to test this either. I tried to run in a new clean conda environment but cant use more than 50% of the cells in pre-processing (otherwise the process is killed at even the normalization stage, ""pp.normalize_ per_cell"" and uses over 120GB RAM). The file from 10X i'm using is the link to ""1M_neurons aggr - Gene / cell matrix HDF5 (filtered)"" from https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.3.0/ . This is what i type into the terminal. $ python cluster_mouse_brain.py 1M_neurons_filtered_gene_bc_matrices_h5.h5. Variable names are not unique. To make them unique, call `.var_names_make_unique`. reading 1M_neurons_filtered_gene_bc_matrices_h5.h5 (0:01:19.78). running recipe zheng17. filtered out 3983 genes that are detected in less than 1 counts. Variable names are not unique. To make them unique, call `.var_names_make_unique`. Variable names are not unique. To make them unique, call `.var_names_make_unique`. Killed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:771,safety,detect,detected,771,"hi Alex, I'm not sure how to test this either. I tried to run in a new clean conda environment but cant use more than 50% of the cells in pre-processing (otherwise the process is killed at even the normalization stage, ""pp.normalize_ per_cell"" and uses over 120GB RAM). The file from 10X i'm using is the link to ""1M_neurons aggr - Gene / cell matrix HDF5 (filtered)"" from https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.3.0/ . This is what i type into the terminal. $ python cluster_mouse_brain.py 1M_neurons_filtered_gene_bc_matrices_h5.h5. Variable names are not unique. To make them unique, call `.var_names_make_unique`. reading 1M_neurons_filtered_gene_bc_matrices_h5.h5 (0:01:19.78). running recipe zheng17. filtered out 3983 genes that are detected in less than 1 counts. Variable names are not unique. To make them unique, call `.var_names_make_unique`. Variable names are not unique. To make them unique, call `.var_names_make_unique`. Killed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:771,security,detect,detected,771,"hi Alex, I'm not sure how to test this either. I tried to run in a new clean conda environment but cant use more than 50% of the cells in pre-processing (otherwise the process is killed at even the normalization stage, ""pp.normalize_ per_cell"" and uses over 120GB RAM). The file from 10X i'm using is the link to ""1M_neurons aggr - Gene / cell matrix HDF5 (filtered)"" from https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.3.0/ . This is what i type into the terminal. $ python cluster_mouse_brain.py 1M_neurons_filtered_gene_bc_matrices_h5.h5. Variable names are not unique. To make them unique, call `.var_names_make_unique`. reading 1M_neurons_filtered_gene_bc_matrices_h5.h5 (0:01:19.78). running recipe zheng17. filtered out 3983 genes that are detected in less than 1 counts. Variable names are not unique. To make them unique, call `.var_names_make_unique`. Variable names are not unique. To make them unique, call `.var_names_make_unique`. Killed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:29,testability,test,test,29,"hi Alex, I'm not sure how to test this either. I tried to run in a new clean conda environment but cant use more than 50% of the cells in pre-processing (otherwise the process is killed at even the normalization stage, ""pp.normalize_ per_cell"" and uses over 120GB RAM). The file from 10X i'm using is the link to ""1M_neurons aggr - Gene / cell matrix HDF5 (filtered)"" from https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.3.0/ . This is what i type into the terminal. $ python cluster_mouse_brain.py 1M_neurons_filtered_gene_bc_matrices_h5.h5. Variable names are not unique. To make them unique, call `.var_names_make_unique`. reading 1M_neurons_filtered_gene_bc_matrices_h5.h5 (0:01:19.78). running recipe zheng17. filtered out 3983 genes that are detected in less than 1 counts. Variable names are not unique. To make them unique, call `.var_names_make_unique`. Variable names are not unique. To make them unique, call `.var_names_make_unique`. Killed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:381,usability,support,support,381,"hi Alex, I'm not sure how to test this either. I tried to run in a new clean conda environment but cant use more than 50% of the cells in pre-processing (otherwise the process is killed at even the normalization stage, ""pp.normalize_ per_cell"" and uses over 120GB RAM). The file from 10X i'm using is the link to ""1M_neurons aggr - Gene / cell matrix HDF5 (filtered)"" from https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.3.0/ . This is what i type into the terminal. $ python cluster_mouse_brain.py 1M_neurons_filtered_gene_bc_matrices_h5.h5. Variable names are not unique. To make them unique, call `.var_names_make_unique`. reading 1M_neurons_filtered_gene_bc_matrices_h5.h5 (0:01:19.78). running recipe zheng17. filtered out 3983 genes that are detected in less than 1 counts. Variable names are not unique. To make them unique, call `.var_names_make_unique`. Variable names are not unique. To make them unique, call `.var_names_make_unique`. Killed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:54,performance,memor,memory,54,"@falexwolf . Yes, i will run through it and check the memory usage and so on.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:54,usability,memor,memory,54,"@falexwolf . Yes, i will run through it and check the memory usage and so on.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:214,availability,error,error,214,I also just tried to run on a Windows machine (to make sure it was not just something to do with the memory management in my Linux machine which has 128GB RAM) with 64GB RAM and 6 cores @3.6GHz and also get Memory error at the normalization step when trying to process the 1.3M neuron file.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:108,deployability,manag,management,108,I also just tried to run on a Windows machine (to make sure it was not just something to do with the memory management in my Linux machine which has 128GB RAM) with 64GB RAM and 6 cores @3.6GHz and also get Memory error at the normalization step when trying to process the 1.3M neuron file.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:108,energy efficiency,manag,management,108,I also just tried to run on a Windows machine (to make sure it was not just something to do with the memory management in my Linux machine which has 128GB RAM) with 64GB RAM and 6 cores @3.6GHz and also get Memory error at the normalization step when trying to process the 1.3M neuron file.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:180,energy efficiency,core,cores,180,I also just tried to run on a Windows machine (to make sure it was not just something to do with the memory management in my Linux machine which has 128GB RAM) with 64GB RAM and 6 cores @3.6GHz and also get Memory error at the normalization step when trying to process the 1.3M neuron file.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:101,performance,memor,memory,101,I also just tried to run on a Windows machine (to make sure it was not just something to do with the memory management in my Linux machine which has 128GB RAM) with 64GB RAM and 6 cores @3.6GHz and also get Memory error at the normalization step when trying to process the 1.3M neuron file.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:207,performance,Memor,Memory,207,I also just tried to run on a Windows machine (to make sure it was not just something to do with the memory management in my Linux machine which has 128GB RAM) with 64GB RAM and 6 cores @3.6GHz and also get Memory error at the normalization step when trying to process the 1.3M neuron file.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:214,performance,error,error,214,I also just tried to run on a Windows machine (to make sure it was not just something to do with the memory management in my Linux machine which has 128GB RAM) with 64GB RAM and 6 cores @3.6GHz and also get Memory error at the normalization step when trying to process the 1.3M neuron file.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:108,safety,manag,management,108,I also just tried to run on a Windows machine (to make sure it was not just something to do with the memory management in my Linux machine which has 128GB RAM) with 64GB RAM and 6 cores @3.6GHz and also get Memory error at the normalization step when trying to process the 1.3M neuron file.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:214,safety,error,error,214,I also just tried to run on a Windows machine (to make sure it was not just something to do with the memory management in my Linux machine which has 128GB RAM) with 64GB RAM and 6 cores @3.6GHz and also get Memory error at the normalization step when trying to process the 1.3M neuron file.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:101,usability,memor,memory,101,I also just tried to run on a Windows machine (to make sure it was not just something to do with the memory management in my Linux machine which has 128GB RAM) with 64GB RAM and 6 cores @3.6GHz and also get Memory error at the normalization step when trying to process the 1.3M neuron file.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:207,usability,Memor,Memory,207,I also just tried to run on a Windows machine (to make sure it was not just something to do with the memory management in my Linux machine which has 128GB RAM) with 64GB RAM and 6 cores @3.6GHz and also get Memory error at the normalization step when trying to process the 1.3M neuron file.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:214,usability,error,error,214,I also just tried to run on a Windows machine (to make sure it was not just something to do with the memory management in my Linux machine which has 128GB RAM) with 64GB RAM and 6 cores @3.6GHz and also get Memory error at the normalization step when trying to process the 1.3M neuron file.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:208,deployability,updat,update,208,"Sergei (@Koncopd) tested it out and will get back to you. He also found a peak memory usage of 121 GB. I have to admit that I never made checks with that degree of detail and I fear that for now, I'll simply update the documentation stating that peak memory usage can go up to ~120 GB. I'm still puzzled by that, and maybe some efficiency found it's way into the code which wasn't there (simple guess: is everything in `float32`?). But we'll need some time to work it out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:79,performance,memor,memory,79,"Sergei (@Koncopd) tested it out and will get back to you. He also found a peak memory usage of 121 GB. I have to admit that I never made checks with that degree of detail and I fear that for now, I'll simply update the documentation stating that peak memory usage can go up to ~120 GB. I'm still puzzled by that, and maybe some efficiency found it's way into the code which wasn't there (simple guess: is everything in `float32`?). But we'll need some time to work it out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:251,performance,memor,memory,251,"Sergei (@Koncopd) tested it out and will get back to you. He also found a peak memory usage of 121 GB. I have to admit that I never made checks with that degree of detail and I fear that for now, I'll simply update the documentation stating that peak memory usage can go up to ~120 GB. I'm still puzzled by that, and maybe some efficiency found it's way into the code which wasn't there (simple guess: is everything in `float32`?). But we'll need some time to work it out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:452,performance,time,time,452,"Sergei (@Koncopd) tested it out and will get back to you. He also found a peak memory usage of 121 GB. I have to admit that I never made checks with that degree of detail and I fear that for now, I'll simply update the documentation stating that peak memory usage can go up to ~120 GB. I'm still puzzled by that, and maybe some efficiency found it's way into the code which wasn't there (simple guess: is everything in `float32`?). But we'll need some time to work it out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:18,safety,test,tested,18,"Sergei (@Koncopd) tested it out and will get back to you. He also found a peak memory usage of 121 GB. I have to admit that I never made checks with that degree of detail and I fear that for now, I'll simply update the documentation stating that peak memory usage can go up to ~120 GB. I'm still puzzled by that, and maybe some efficiency found it's way into the code which wasn't there (simple guess: is everything in `float32`?). But we'll need some time to work it out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:208,safety,updat,update,208,"Sergei (@Koncopd) tested it out and will get back to you. He also found a peak memory usage of 121 GB. I have to admit that I never made checks with that degree of detail and I fear that for now, I'll simply update the documentation stating that peak memory usage can go up to ~120 GB. I'm still puzzled by that, and maybe some efficiency found it's way into the code which wasn't there (simple guess: is everything in `float32`?). But we'll need some time to work it out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:208,security,updat,update,208,"Sergei (@Koncopd) tested it out and will get back to you. He also found a peak memory usage of 121 GB. I have to admit that I never made checks with that degree of detail and I fear that for now, I'll simply update the documentation stating that peak memory usage can go up to ~120 GB. I'm still puzzled by that, and maybe some efficiency found it's way into the code which wasn't there (simple guess: is everything in `float32`?). But we'll need some time to work it out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:18,testability,test,tested,18,"Sergei (@Koncopd) tested it out and will get back to you. He also found a peak memory usage of 121 GB. I have to admit that I never made checks with that degree of detail and I fear that for now, I'll simply update the documentation stating that peak memory usage can go up to ~120 GB. I'm still puzzled by that, and maybe some efficiency found it's way into the code which wasn't there (simple guess: is everything in `float32`?). But we'll need some time to work it out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:201,testability,simpl,simply,201,"Sergei (@Koncopd) tested it out and will get back to you. He also found a peak memory usage of 121 GB. I have to admit that I never made checks with that degree of detail and I fear that for now, I'll simply update the documentation stating that peak memory usage can go up to ~120 GB. I'm still puzzled by that, and maybe some efficiency found it's way into the code which wasn't there (simple guess: is everything in `float32`?). But we'll need some time to work it out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:388,testability,simpl,simple,388,"Sergei (@Koncopd) tested it out and will get back to you. He also found a peak memory usage of 121 GB. I have to admit that I never made checks with that degree of detail and I fear that for now, I'll simply update the documentation stating that peak memory usage can go up to ~120 GB. I'm still puzzled by that, and maybe some efficiency found it's way into the code which wasn't there (simple guess: is everything in `float32`?). But we'll need some time to work it out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:79,usability,memor,memory,79,"Sergei (@Koncopd) tested it out and will get back to you. He also found a peak memory usage of 121 GB. I have to admit that I never made checks with that degree of detail and I fear that for now, I'll simply update the documentation stating that peak memory usage can go up to ~120 GB. I'm still puzzled by that, and maybe some efficiency found it's way into the code which wasn't there (simple guess: is everything in `float32`?). But we'll need some time to work it out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:201,usability,simpl,simply,201,"Sergei (@Koncopd) tested it out and will get back to you. He also found a peak memory usage of 121 GB. I have to admit that I never made checks with that degree of detail and I fear that for now, I'll simply update the documentation stating that peak memory usage can go up to ~120 GB. I'm still puzzled by that, and maybe some efficiency found it's way into the code which wasn't there (simple guess: is everything in `float32`?). But we'll need some time to work it out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:219,usability,document,documentation,219,"Sergei (@Koncopd) tested it out and will get back to you. He also found a peak memory usage of 121 GB. I have to admit that I never made checks with that degree of detail and I fear that for now, I'll simply update the documentation stating that peak memory usage can go up to ~120 GB. I'm still puzzled by that, and maybe some efficiency found it's way into the code which wasn't there (simple guess: is everything in `float32`?). But we'll need some time to work it out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:251,usability,memor,memory,251,"Sergei (@Koncopd) tested it out and will get back to you. He also found a peak memory usage of 121 GB. I have to admit that I never made checks with that degree of detail and I fear that for now, I'll simply update the documentation stating that peak memory usage can go up to ~120 GB. I'm still puzzled by that, and maybe some efficiency found it's way into the code which wasn't there (simple guess: is everything in `float32`?). But we'll need some time to work it out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:328,usability,efficien,efficiency,328,"Sergei (@Koncopd) tested it out and will get back to you. He also found a peak memory usage of 121 GB. I have to admit that I never made checks with that degree of detail and I fear that for now, I'll simply update the documentation stating that peak memory usage can go up to ~120 GB. I'm still puzzled by that, and maybe some efficiency found it's way into the code which wasn't there (simple guess: is everything in `float32`?). But we'll need some time to work it out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:388,usability,simpl,simple,388,"Sergei (@Koncopd) tested it out and will get back to you. He also found a peak memory usage of 121 GB. I have to admit that I never made checks with that degree of detail and I fear that for now, I'll simply update the documentation stating that peak memory usage can go up to ~120 GB. I'm still puzzled by that, and maybe some efficiency found it's way into the code which wasn't there (simple guess: is everything in `float32`?). But we'll need some time to work it out.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:5,deployability,updat,updated,5,Just updated the readme https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:5,safety,updat,updated,5,Just updated the readme https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:5,security,updat,updated,5,Just updated the readme https://github.com/theislab/scanpy_usage/blob/master/170522_visualizing_one_million_cells/.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:52,performance,memor,memory,52,"Hi, @ShobiStassen. As @falexwolf said, i tested the memory usage in the step where you have the problem. https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/cluster_1m_neurons.ipynb. The peak usage is around 121 GB, but it should still be possible to run with 126 GB RAM. Maybe another process took some serious amount of memory?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:335,performance,memor,memory,335,"Hi, @ShobiStassen. As @falexwolf said, i tested the memory usage in the step where you have the problem. https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/cluster_1m_neurons.ipynb. The peak usage is around 121 GB, but it should still be possible to run with 126 GB RAM. Maybe another process took some serious amount of memory?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:41,safety,test,tested,41,"Hi, @ShobiStassen. As @falexwolf said, i tested the memory usage in the step where you have the problem. https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/cluster_1m_neurons.ipynb. The peak usage is around 121 GB, but it should still be possible to run with 126 GB RAM. Maybe another process took some serious amount of memory?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:41,testability,test,tested,41,"Hi, @ShobiStassen. As @falexwolf said, i tested the memory usage in the step where you have the problem. https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/cluster_1m_neurons.ipynb. The peak usage is around 121 GB, but it should still be possible to run with 126 GB RAM. Maybe another process took some serious amount of memory?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:52,usability,memor,memory,52,"Hi, @ShobiStassen. As @falexwolf said, i tested the memory usage in the step where you have the problem. https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/cluster_1m_neurons.ipynb. The peak usage is around 121 GB, but it should still be possible to run with 126 GB RAM. Maybe another process took some serious amount of memory?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:335,usability,memor,memory,335,"Hi, @ShobiStassen. As @falexwolf said, i tested the memory usage in the step where you have the problem. https://github.com/Koncopd/anndata-scanpy-benchmarks/blob/master/cluster_1m_neurons.ipynb. The peak usage is around 121 GB, but it should still be possible to run with 126 GB RAM. Maybe another process took some serious amount of memory?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:125,integrability,filter,filtering,125,"hi Koncopd, ive tried running your exact lines of code and my memory increment is the same as yours for reading the file and filtering the genes by count. Once i hit the normalization function, my memory shoots above 120 and crashes. in your case, your peak memory usage during normalization is around 92GB and only during filter_genes_variable do you hit 121GB. I dont have any other processes that are being triggered so it's very puzzling why my usage is different from yours... hmmm",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:62,performance,memor,memory,62,"hi Koncopd, ive tried running your exact lines of code and my memory increment is the same as yours for reading the file and filtering the genes by count. Once i hit the normalization function, my memory shoots above 120 and crashes. in your case, your peak memory usage during normalization is around 92GB and only during filter_genes_variable do you hit 121GB. I dont have any other processes that are being triggered so it's very puzzling why my usage is different from yours... hmmm",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:197,performance,memor,memory,197,"hi Koncopd, ive tried running your exact lines of code and my memory increment is the same as yours for reading the file and filtering the genes by count. Once i hit the normalization function, my memory shoots above 120 and crashes. in your case, your peak memory usage during normalization is around 92GB and only during filter_genes_variable do you hit 121GB. I dont have any other processes that are being triggered so it's very puzzling why my usage is different from yours... hmmm",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:258,performance,memor,memory,258,"hi Koncopd, ive tried running your exact lines of code and my memory increment is the same as yours for reading the file and filtering the genes by count. Once i hit the normalization function, my memory shoots above 120 and crashes. in your case, your peak memory usage during normalization is around 92GB and only during filter_genes_variable do you hit 121GB. I dont have any other processes that are being triggered so it's very puzzling why my usage is different from yours... hmmm",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:62,usability,memor,memory,62,"hi Koncopd, ive tried running your exact lines of code and my memory increment is the same as yours for reading the file and filtering the genes by count. Once i hit the normalization function, my memory shoots above 120 and crashes. in your case, your peak memory usage during normalization is around 92GB and only during filter_genes_variable do you hit 121GB. I dont have any other processes that are being triggered so it's very puzzling why my usage is different from yours... hmmm",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:197,usability,memor,memory,197,"hi Koncopd, ive tried running your exact lines of code and my memory increment is the same as yours for reading the file and filtering the genes by count. Once i hit the normalization function, my memory shoots above 120 and crashes. in your case, your peak memory usage during normalization is around 92GB and only during filter_genes_variable do you hit 121GB. I dont have any other processes that are being triggered so it's very puzzling why my usage is different from yours... hmmm",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:258,usability,memor,memory,258,"hi Koncopd, ive tried running your exact lines of code and my memory increment is the same as yours for reading the file and filtering the genes by count. Once i hit the normalization function, my memory shoots above 120 and crashes. in your case, your peak memory usage during normalization is around 92GB and only during filter_genes_variable do you hit 121GB. I dont have any other processes that are being triggered so it's very puzzling why my usage is different from yours... hmmm",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:166,performance,memor,memory,166,"Ok, so the first problem is normalization for some reason. @falexwolf , it seems we should just use new normalize_total when the pull request is accepted, it is more memory efficient. ![image](https://user-images.githubusercontent.com/3065736/54003760-9afeed80-4153-11e9-9187-8e474a2fa03e.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:166,usability,memor,memory,166,"Ok, so the first problem is normalization for some reason. @falexwolf , it seems we should just use new normalize_total when the pull request is accepted, it is more memory efficient. ![image](https://user-images.githubusercontent.com/3065736/54003760-9afeed80-4153-11e9-9187-8e474a2fa03e.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:173,usability,efficien,efficient,173,"Ok, so the first problem is normalization for some reason. @falexwolf , it seems we should just use new normalize_total when the pull request is accepted, it is more memory efficient. ![image](https://user-images.githubusercontent.com/3065736/54003760-9afeed80-4153-11e9-9187-8e474a2fa03e.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:201,usability,user,user-images,201,"Ok, so the first problem is normalization for some reason. @falexwolf , it seems we should just use new normalize_total when the pull request is accepted, it is more memory efficient. ![image](https://user-images.githubusercontent.com/3065736/54003760-9afeed80-4153-11e9-9187-8e474a2fa03e.png)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:0,energy efficiency,Cool,Cool,0,"Cool, @Koncopd! I'll rewrite a recipe for this with the new functions, which should be a lot more memory effective.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:98,performance,memor,memory,98,"Cool, @Koncopd! I'll rewrite a recipe for this with the new functions, which should be a lot more memory effective.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:98,usability,memor,memory,98,"Cool, @Koncopd! I'll rewrite a recipe for this with the new functions, which should be a lot more memory effective.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/issues/511:105,usability,effectiv,effective,105,"Cool, @Koncopd! I'll rewrite a recipe for this with the new functions, which should be a lot more memory effective.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/511
https://github.com/scverse/scanpy/pull/512:59,safety,test,test,59,This is very useful! Thanks a lot. Would you mind adding a test in `scanpy/tests/test_plotting.py`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:75,safety,test,tests,75,This is very useful! Thanks a lot. Would you mind adding a test in `scanpy/tests/test_plotting.py`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:59,testability,test,test,59,This is very useful! Thanks a lot. Would you mind adding a test in `scanpy/tests/test_plotting.py`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:75,testability,test,tests,75,This is very useful! Thanks a lot. Would you mind adding a test in `scanpy/tests/test_plotting.py`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:611,availability,state,state,611,"I was looking at the tests, and something made me think. If `use_raw=False` is given, we use a diverging colormap on purpose, right? Like this:. ![image](https://user-images.githubusercontent.com/1140359/53746250-cb523d80-3e6e-11e9-8952-5c5e93afaf13.png). Now with the new standardization option, values are squashed between 0 and 1 but the color scale is still diverging:. ![image](https://user-images.githubusercontent.com/1140359/53746542-65b28100-3e6f-11e9-9297-e4352c8befc0.png). @fidelram Do you think that's ok, or should we switch back to viridis when `standard_scale` is given, regardless of `use_raw` state?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:347,deployability,scale,scale,347,"I was looking at the tests, and something made me think. If `use_raw=False` is given, we use a diverging colormap on purpose, right? Like this:. ![image](https://user-images.githubusercontent.com/1140359/53746250-cb523d80-3e6e-11e9-8952-5c5e93afaf13.png). Now with the new standardization option, values are squashed between 0 and 1 but the color scale is still diverging:. ![image](https://user-images.githubusercontent.com/1140359/53746542-65b28100-3e6f-11e9-9297-e4352c8befc0.png). @fidelram Do you think that's ok, or should we switch back to viridis when `standard_scale` is given, regardless of `use_raw` state?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:347,energy efficiency,scale,scale,347,"I was looking at the tests, and something made me think. If `use_raw=False` is given, we use a diverging colormap on purpose, right? Like this:. ![image](https://user-images.githubusercontent.com/1140359/53746250-cb523d80-3e6e-11e9-8952-5c5e93afaf13.png). Now with the new standardization option, values are squashed between 0 and 1 but the color scale is still diverging:. ![image](https://user-images.githubusercontent.com/1140359/53746542-65b28100-3e6f-11e9-9297-e4352c8befc0.png). @fidelram Do you think that's ok, or should we switch back to viridis when `standard_scale` is given, regardless of `use_raw` state?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:273,integrability,standardiz,standardization,273,"I was looking at the tests, and something made me think. If `use_raw=False` is given, we use a diverging colormap on purpose, right? Like this:. ![image](https://user-images.githubusercontent.com/1140359/53746250-cb523d80-3e6e-11e9-8952-5c5e93afaf13.png). Now with the new standardization option, values are squashed between 0 and 1 but the color scale is still diverging:. ![image](https://user-images.githubusercontent.com/1140359/53746542-65b28100-3e6f-11e9-9297-e4352c8befc0.png). @fidelram Do you think that's ok, or should we switch back to viridis when `standard_scale` is given, regardless of `use_raw` state?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:611,integrability,state,state,611,"I was looking at the tests, and something made me think. If `use_raw=False` is given, we use a diverging colormap on purpose, right? Like this:. ![image](https://user-images.githubusercontent.com/1140359/53746250-cb523d80-3e6e-11e9-8952-5c5e93afaf13.png). Now with the new standardization option, values are squashed between 0 and 1 but the color scale is still diverging:. ![image](https://user-images.githubusercontent.com/1140359/53746542-65b28100-3e6f-11e9-9297-e4352c8befc0.png). @fidelram Do you think that's ok, or should we switch back to viridis when `standard_scale` is given, regardless of `use_raw` state?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:273,interoperability,standard,standardization,273,"I was looking at the tests, and something made me think. If `use_raw=False` is given, we use a diverging colormap on purpose, right? Like this:. ![image](https://user-images.githubusercontent.com/1140359/53746250-cb523d80-3e6e-11e9-8952-5c5e93afaf13.png). Now with the new standardization option, values are squashed between 0 and 1 but the color scale is still diverging:. ![image](https://user-images.githubusercontent.com/1140359/53746542-65b28100-3e6f-11e9-9297-e4352c8befc0.png). @fidelram Do you think that's ok, or should we switch back to viridis when `standard_scale` is given, regardless of `use_raw` state?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:347,modifiability,scal,scale,347,"I was looking at the tests, and something made me think. If `use_raw=False` is given, we use a diverging colormap on purpose, right? Like this:. ![image](https://user-images.githubusercontent.com/1140359/53746250-cb523d80-3e6e-11e9-8952-5c5e93afaf13.png). Now with the new standardization option, values are squashed between 0 and 1 but the color scale is still diverging:. ![image](https://user-images.githubusercontent.com/1140359/53746542-65b28100-3e6f-11e9-9297-e4352c8befc0.png). @fidelram Do you think that's ok, or should we switch back to viridis when `standard_scale` is given, regardless of `use_raw` state?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:347,performance,scale,scale,347,"I was looking at the tests, and something made me think. If `use_raw=False` is given, we use a diverging colormap on purpose, right? Like this:. ![image](https://user-images.githubusercontent.com/1140359/53746250-cb523d80-3e6e-11e9-8952-5c5e93afaf13.png). Now with the new standardization option, values are squashed between 0 and 1 but the color scale is still diverging:. ![image](https://user-images.githubusercontent.com/1140359/53746542-65b28100-3e6f-11e9-9297-e4352c8befc0.png). @fidelram Do you think that's ok, or should we switch back to viridis when `standard_scale` is given, regardless of `use_raw` state?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:21,safety,test,tests,21,"I was looking at the tests, and something made me think. If `use_raw=False` is given, we use a diverging colormap on purpose, right? Like this:. ![image](https://user-images.githubusercontent.com/1140359/53746250-cb523d80-3e6e-11e9-8952-5c5e93afaf13.png). Now with the new standardization option, values are squashed between 0 and 1 but the color scale is still diverging:. ![image](https://user-images.githubusercontent.com/1140359/53746542-65b28100-3e6f-11e9-9297-e4352c8befc0.png). @fidelram Do you think that's ok, or should we switch back to viridis when `standard_scale` is given, regardless of `use_raw` state?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:21,testability,test,tests,21,"I was looking at the tests, and something made me think. If `use_raw=False` is given, we use a diverging colormap on purpose, right? Like this:. ![image](https://user-images.githubusercontent.com/1140359/53746250-cb523d80-3e6e-11e9-8952-5c5e93afaf13.png). Now with the new standardization option, values are squashed between 0 and 1 but the color scale is still diverging:. ![image](https://user-images.githubusercontent.com/1140359/53746542-65b28100-3e6f-11e9-9297-e4352c8befc0.png). @fidelram Do you think that's ok, or should we switch back to viridis when `standard_scale` is given, regardless of `use_raw` state?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:162,usability,user,user-images,162,"I was looking at the tests, and something made me think. If `use_raw=False` is given, we use a diverging colormap on purpose, right? Like this:. ![image](https://user-images.githubusercontent.com/1140359/53746250-cb523d80-3e6e-11e9-8952-5c5e93afaf13.png). Now with the new standardization option, values are squashed between 0 and 1 but the color scale is still diverging:. ![image](https://user-images.githubusercontent.com/1140359/53746542-65b28100-3e6f-11e9-9297-e4352c8befc0.png). @fidelram Do you think that's ok, or should we switch back to viridis when `standard_scale` is given, regardless of `use_raw` state?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:391,usability,user,user-images,391,"I was looking at the tests, and something made me think. If `use_raw=False` is given, we use a diverging colormap on purpose, right? Like this:. ![image](https://user-images.githubusercontent.com/1140359/53746250-cb523d80-3e6e-11e9-8952-5c5e93afaf13.png). Now with the new standardization option, values are squashed between 0 and 1 but the color scale is still diverging:. ![image](https://user-images.githubusercontent.com/1140359/53746542-65b28100-3e6f-11e9-9297-e4352c8befc0.png). @fidelram Do you think that's ok, or should we switch back to viridis when `standard_scale` is given, regardless of `use_raw` state?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:25,deployability,fail,fail,25,"Added tests, too. (Tests fail in my setup, though. RMS is usually around 50-60, rather than 15.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:25,reliability,fail,fail,25,"Added tests, too. (Tests fail in my setup, though. RMS is usually around 50-60, rather than 15.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:6,safety,test,tests,6,"Added tests, too. (Tests fail in my setup, though. RMS is usually around 50-60, rather than 15.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:19,safety,Test,Tests,19,"Added tests, too. (Tests fail in my setup, though. RMS is usually around 50-60, rather than 15.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:6,testability,test,tests,6,"Added tests, too. (Tests fail in my setup, though. RMS is usually around 50-60, rather than 15.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:19,testability,Test,Tests,19,"Added tests, too. (Tests fail in my setup, though. RMS is usually around 50-60, rather than 15.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:159,deployability,scale,scaled,159,"@gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:218,deployability,scale,scale,218,"@gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:159,energy efficiency,scale,scaled,159,"@gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:218,energy efficiency,scale,scale,218,"@gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:159,modifiability,scal,scaled,159,"@gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:218,modifiability,scal,scale,218,"@gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:238,modifiability,paramet,parameters,238,"@gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:159,performance,scale,scaled,159,"@gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:218,performance,scale,scale,218,"@gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:15,safety,Test,Tests,15,"@gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:15,testability,Test,Tests,15,"@gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:161,deployability,scale,scaled,161,"> @gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion? Default values of vmin/vmax looks ok for most datasets, but when we squash everything between 0 and 1, the negative scale doesn't make sense any more. Furthermore, even for max values (i.e. 1.0) colors will look dimmer than the color representing the max value. For example:. ```python. sc.pl.rank_genes_groups_matrixplot(adata, n_genes=1, standard_scale='var', use_raw=False). ```. generates. ![image](https://user-images.githubusercontent.com/1140359/53822163-32d6be80-3f3d-11e9-8c34-d7885ca5d131.png). Color scale might be a bit confusing for some, IMHO. I think it makes more sense to switch back to default sequential colormap if `standard_scale in ('var', 'group')`, but it's totally up to you :) . We can merge this and play around with different datasets etc, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:220,deployability,scale,scale,220,"> @gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion? Default values of vmin/vmax looks ok for most datasets, but when we squash everything between 0 and 1, the negative scale doesn't make sense any more. Furthermore, even for max values (i.e. 1.0) colors will look dimmer than the color representing the max value. For example:. ```python. sc.pl.rank_genes_groups_matrixplot(adata, n_genes=1, standard_scale='var', use_raw=False). ```. generates. ![image](https://user-images.githubusercontent.com/1140359/53822163-32d6be80-3f3d-11e9-8c34-d7885ca5d131.png). Color scale might be a bit confusing for some, IMHO. I think it makes more sense to switch back to default sequential colormap if `standard_scale in ('var', 'group')`, but it's totally up to you :) . We can merge this and play around with different datasets etc, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:517,deployability,scale,scale,517,"> @gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion? Default values of vmin/vmax looks ok for most datasets, but when we squash everything between 0 and 1, the negative scale doesn't make sense any more. Furthermore, even for max values (i.e. 1.0) colors will look dimmer than the color representing the max value. For example:. ```python. sc.pl.rank_genes_groups_matrixplot(adata, n_genes=1, standard_scale='var', use_raw=False). ```. generates. ![image](https://user-images.githubusercontent.com/1140359/53822163-32d6be80-3f3d-11e9-8c34-d7885ca5d131.png). Color scale might be a bit confusing for some, IMHO. I think it makes more sense to switch back to default sequential colormap if `standard_scale in ('var', 'group')`, but it's totally up to you :) . We can merge this and play around with different datasets etc, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:912,deployability,scale,scale,912,"> @gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion? Default values of vmin/vmax looks ok for most datasets, but when we squash everything between 0 and 1, the negative scale doesn't make sense any more. Furthermore, even for max values (i.e. 1.0) colors will look dimmer than the color representing the max value. For example:. ```python. sc.pl.rank_genes_groups_matrixplot(adata, n_genes=1, standard_scale='var', use_raw=False). ```. generates. ![image](https://user-images.githubusercontent.com/1140359/53822163-32d6be80-3f3d-11e9-8c34-d7885ca5d131.png). Color scale might be a bit confusing for some, IMHO. I think it makes more sense to switch back to default sequential colormap if `standard_scale in ('var', 'group')`, but it's totally up to you :) . We can merge this and play around with different datasets etc, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:161,energy efficiency,scale,scaled,161,"> @gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion? Default values of vmin/vmax looks ok for most datasets, but when we squash everything between 0 and 1, the negative scale doesn't make sense any more. Furthermore, even for max values (i.e. 1.0) colors will look dimmer than the color representing the max value. For example:. ```python. sc.pl.rank_genes_groups_matrixplot(adata, n_genes=1, standard_scale='var', use_raw=False). ```. generates. ![image](https://user-images.githubusercontent.com/1140359/53822163-32d6be80-3f3d-11e9-8c34-d7885ca5d131.png). Color scale might be a bit confusing for some, IMHO. I think it makes more sense to switch back to default sequential colormap if `standard_scale in ('var', 'group')`, but it's totally up to you :) . We can merge this and play around with different datasets etc, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:220,energy efficiency,scale,scale,220,"> @gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion? Default values of vmin/vmax looks ok for most datasets, but when we squash everything between 0 and 1, the negative scale doesn't make sense any more. Furthermore, even for max values (i.e. 1.0) colors will look dimmer than the color representing the max value. For example:. ```python. sc.pl.rank_genes_groups_matrixplot(adata, n_genes=1, standard_scale='var', use_raw=False). ```. generates. ![image](https://user-images.githubusercontent.com/1140359/53822163-32d6be80-3f3d-11e9-8c34-d7885ca5d131.png). Color scale might be a bit confusing for some, IMHO. I think it makes more sense to switch back to default sequential colormap if `standard_scale in ('var', 'group')`, but it's totally up to you :) . We can merge this and play around with different datasets etc, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:517,energy efficiency,scale,scale,517,"> @gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion? Default values of vmin/vmax looks ok for most datasets, but when we squash everything between 0 and 1, the negative scale doesn't make sense any more. Furthermore, even for max values (i.e. 1.0) colors will look dimmer than the color representing the max value. For example:. ```python. sc.pl.rank_genes_groups_matrixplot(adata, n_genes=1, standard_scale='var', use_raw=False). ```. generates. ![image](https://user-images.githubusercontent.com/1140359/53822163-32d6be80-3f3d-11e9-8c34-d7885ca5d131.png). Color scale might be a bit confusing for some, IMHO. I think it makes more sense to switch back to default sequential colormap if `standard_scale in ('var', 'group')`, but it's totally up to you :) . We can merge this and play around with different datasets etc, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:912,energy efficiency,scale,scale,912,"> @gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion? Default values of vmin/vmax looks ok for most datasets, but when we squash everything between 0 and 1, the negative scale doesn't make sense any more. Furthermore, even for max values (i.e. 1.0) colors will look dimmer than the color representing the max value. For example:. ```python. sc.pl.rank_genes_groups_matrixplot(adata, n_genes=1, standard_scale='var', use_raw=False). ```. generates. ![image](https://user-images.githubusercontent.com/1140359/53822163-32d6be80-3f3d-11e9-8c34-d7885ca5d131.png). Color scale might be a bit confusing for some, IMHO. I think it makes more sense to switch back to default sequential colormap if `standard_scale in ('var', 'group')`, but it's totally up to you :) . We can merge this and play around with different datasets etc, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:161,modifiability,scal,scaled,161,"> @gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion? Default values of vmin/vmax looks ok for most datasets, but when we squash everything between 0 and 1, the negative scale doesn't make sense any more. Furthermore, even for max values (i.e. 1.0) colors will look dimmer than the color representing the max value. For example:. ```python. sc.pl.rank_genes_groups_matrixplot(adata, n_genes=1, standard_scale='var', use_raw=False). ```. generates. ![image](https://user-images.githubusercontent.com/1140359/53822163-32d6be80-3f3d-11e9-8c34-d7885ca5d131.png). Color scale might be a bit confusing for some, IMHO. I think it makes more sense to switch back to default sequential colormap if `standard_scale in ('var', 'group')`, but it's totally up to you :) . We can merge this and play around with different datasets etc, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:220,modifiability,scal,scale,220,"> @gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion? Default values of vmin/vmax looks ok for most datasets, but when we squash everything between 0 and 1, the negative scale doesn't make sense any more. Furthermore, even for max values (i.e. 1.0) colors will look dimmer than the color representing the max value. For example:. ```python. sc.pl.rank_genes_groups_matrixplot(adata, n_genes=1, standard_scale='var', use_raw=False). ```. generates. ![image](https://user-images.githubusercontent.com/1140359/53822163-32d6be80-3f3d-11e9-8c34-d7885ca5d131.png). Color scale might be a bit confusing for some, IMHO. I think it makes more sense to switch back to default sequential colormap if `standard_scale in ('var', 'group')`, but it's totally up to you :) . We can merge this and play around with different datasets etc, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:240,modifiability,paramet,parameters,240,"> @gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion? Default values of vmin/vmax looks ok for most datasets, but when we squash everything between 0 and 1, the negative scale doesn't make sense any more. Furthermore, even for max values (i.e. 1.0) colors will look dimmer than the color representing the max value. For example:. ```python. sc.pl.rank_genes_groups_matrixplot(adata, n_genes=1, standard_scale='var', use_raw=False). ```. generates. ![image](https://user-images.githubusercontent.com/1140359/53822163-32d6be80-3f3d-11e9-8c34-d7885ca5d131.png). Color scale might be a bit confusing for some, IMHO. I think it makes more sense to switch back to default sequential colormap if `standard_scale in ('var', 'group')`, but it's totally up to you :) . We can merge this and play around with different datasets etc, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:517,modifiability,scal,scale,517,"> @gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion? Default values of vmin/vmax looks ok for most datasets, but when we squash everything between 0 and 1, the negative scale doesn't make sense any more. Furthermore, even for max values (i.e. 1.0) colors will look dimmer than the color representing the max value. For example:. ```python. sc.pl.rank_genes_groups_matrixplot(adata, n_genes=1, standard_scale='var', use_raw=False). ```. generates. ![image](https://user-images.githubusercontent.com/1140359/53822163-32d6be80-3f3d-11e9-8c34-d7885ca5d131.png). Color scale might be a bit confusing for some, IMHO. I think it makes more sense to switch back to default sequential colormap if `standard_scale in ('var', 'group')`, but it's totally up to you :) . We can merge this and play around with different datasets etc, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:912,modifiability,scal,scale,912,"> @gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion? Default values of vmin/vmax looks ok for most datasets, but when we squash everything between 0 and 1, the negative scale doesn't make sense any more. Furthermore, even for max values (i.e. 1.0) colors will look dimmer than the color representing the max value. For example:. ```python. sc.pl.rank_genes_groups_matrixplot(adata, n_genes=1, standard_scale='var', use_raw=False). ```. generates. ![image](https://user-images.githubusercontent.com/1140359/53822163-32d6be80-3f3d-11e9-8c34-d7885ca5d131.png). Color scale might be a bit confusing for some, IMHO. I think it makes more sense to switch back to default sequential colormap if `standard_scale in ('var', 'group')`, but it's totally up to you :) . We can merge this and play around with different datasets etc, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:161,performance,scale,scaled,161,"> @gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion? Default values of vmin/vmax looks ok for most datasets, but when we squash everything between 0 and 1, the negative scale doesn't make sense any more. Furthermore, even for max values (i.e. 1.0) colors will look dimmer than the color representing the max value. For example:. ```python. sc.pl.rank_genes_groups_matrixplot(adata, n_genes=1, standard_scale='var', use_raw=False). ```. generates. ![image](https://user-images.githubusercontent.com/1140359/53822163-32d6be80-3f3d-11e9-8c34-d7885ca5d131.png). Color scale might be a bit confusing for some, IMHO. I think it makes more sense to switch back to default sequential colormap if `standard_scale in ('var', 'group')`, but it's totally up to you :) . We can merge this and play around with different datasets etc, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:220,performance,scale,scale,220,"> @gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion? Default values of vmin/vmax looks ok for most datasets, but when we squash everything between 0 and 1, the negative scale doesn't make sense any more. Furthermore, even for max values (i.e. 1.0) colors will look dimmer than the color representing the max value. For example:. ```python. sc.pl.rank_genes_groups_matrixplot(adata, n_genes=1, standard_scale='var', use_raw=False). ```. generates. ![image](https://user-images.githubusercontent.com/1140359/53822163-32d6be80-3f3d-11e9-8c34-d7885ca5d131.png). Color scale might be a bit confusing for some, IMHO. I think it makes more sense to switch back to default sequential colormap if `standard_scale in ('var', 'group')`, but it's totally up to you :) . We can merge this and play around with different datasets etc, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:517,performance,scale,scale,517,"> @gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion? Default values of vmin/vmax looks ok for most datasets, but when we squash everything between 0 and 1, the negative scale doesn't make sense any more. Furthermore, even for max values (i.e. 1.0) colors will look dimmer than the color representing the max value. For example:. ```python. sc.pl.rank_genes_groups_matrixplot(adata, n_genes=1, standard_scale='var', use_raw=False). ```. generates. ![image](https://user-images.githubusercontent.com/1140359/53822163-32d6be80-3f3d-11e9-8c34-d7885ca5d131.png). Color scale might be a bit confusing for some, IMHO. I think it makes more sense to switch back to default sequential colormap if `standard_scale in ('var', 'group')`, but it's totally up to you :) . We can merge this and play around with different datasets etc, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:912,performance,scale,scale,912,"> @gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion? Default values of vmin/vmax looks ok for most datasets, but when we squash everything between 0 and 1, the negative scale doesn't make sense any more. Furthermore, even for max values (i.e. 1.0) colors will look dimmer than the color representing the max value. For example:. ```python. sc.pl.rank_genes_groups_matrixplot(adata, n_genes=1, standard_scale='var', use_raw=False). ```. generates. ![image](https://user-images.githubusercontent.com/1140359/53822163-32d6be80-3f3d-11e9-8c34-d7885ca5d131.png). Color scale might be a bit confusing for some, IMHO. I think it makes more sense to switch back to default sequential colormap if `standard_scale in ('var', 'group')`, but it's totally up to you :) . We can merge this and play around with different datasets etc, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:523,reliability,doe,doesn,523,"> @gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion? Default values of vmin/vmax looks ok for most datasets, but when we squash everything between 0 and 1, the negative scale doesn't make sense any more. Furthermore, even for max values (i.e. 1.0) colors will look dimmer than the color representing the max value. For example:. ```python. sc.pl.rank_genes_groups_matrixplot(adata, n_genes=1, standard_scale='var', use_raw=False). ```. generates. ![image](https://user-images.githubusercontent.com/1140359/53822163-32d6be80-3f3d-11e9-8c34-d7885ca5d131.png). Color scale might be a bit confusing for some, IMHO. I think it makes more sense to switch back to default sequential colormap if `standard_scale in ('var', 'group')`, but it's totally up to you :) . We can merge this and play around with different datasets etc, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:17,safety,Test,Tests,17,"> @gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion? Default values of vmin/vmax looks ok for most datasets, but when we squash everything between 0 and 1, the negative scale doesn't make sense any more. Furthermore, even for max values (i.e. 1.0) colors will look dimmer than the color representing the max value. For example:. ```python. sc.pl.rank_genes_groups_matrixplot(adata, n_genes=1, standard_scale='var', use_raw=False). ```. generates. ![image](https://user-images.githubusercontent.com/1140359/53822163-32d6be80-3f3d-11e9-8c34-d7885ca5d131.png). Color scale might be a bit confusing for some, IMHO. I think it makes more sense to switch back to default sequential colormap if `standard_scale in ('var', 'group')`, but it's totally up to you :) . We can merge this and play around with different datasets etc, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:17,testability,Test,Tests,17,"> @gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion? Default values of vmin/vmax looks ok for most datasets, but when we squash everything between 0 and 1, the negative scale doesn't make sense any more. Furthermore, even for max values (i.e. 1.0) colors will look dimmer than the color representing the max value. For example:. ```python. sc.pl.rank_genes_groups_matrixplot(adata, n_genes=1, standard_scale='var', use_raw=False). ```. generates. ![image](https://user-images.githubusercontent.com/1140359/53822163-32d6be80-3f3d-11e9-8c34-d7885ca5d131.png). Color scale might be a bit confusing for some, IMHO. I think it makes more sense to switch back to default sequential colormap if `standard_scale in ('var', 'group')`, but it's totally up to you :) . We can merge this and play around with different datasets etc, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:812,usability,user,user-images,812,"> @gokceneraslan Tests with images are always problematic. I will take a look later. With respect to `use_raw=False`, what happens is that usually, `adata.X` is scaled and centered around zero. Thus, a default diverging scale was used with parameters `vmin=-3, vmax=3, cmap='bwr'`. This has been useful to me, but if data is being processed differently, this could be confusing. What is your opinion? Default values of vmin/vmax looks ok for most datasets, but when we squash everything between 0 and 1, the negative scale doesn't make sense any more. Furthermore, even for max values (i.e. 1.0) colors will look dimmer than the color representing the max value. For example:. ```python. sc.pl.rank_genes_groups_matrixplot(adata, n_genes=1, standard_scale='var', use_raw=False). ```. generates. ![image](https://user-images.githubusercontent.com/1140359/53822163-32d6be80-3f3d-11e9-8c34-d7885ca5d131.png). Color scale might be a bit confusing for some, IMHO. I think it makes more sense to switch back to default sequential colormap if `standard_scale in ('var', 'group')`, but it's totally up to you :) . We can merge this and play around with different datasets etc, too.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:78,testability,simpl,simpler,78,I think we should remove the that uses the divergent colormap and keep things simpler.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/pull/512:78,usability,simpl,simpler,78,I think we should remove the that uses the divergent colormap and keep things simpler.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/512
https://github.com/scverse/scanpy/issues/513:62,availability,cluster,cluster,62,"Hi @aditisk,. You can always make a dummy `.obs` variable for cluster membership. Something like this:. `adata.obs['cluster_dummy'] = adata.obs['louvain'] == adata.obs['louvain'].cat.categories[0]`. By iterating over the last index (currently at 0), you can create dummy variables to visualize via `sc.pl.umap(adata, 'cluster_dummy')`. Hope that helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/513
https://github.com/scverse/scanpy/issues/513:62,deployability,cluster,cluster,62,"Hi @aditisk,. You can always make a dummy `.obs` variable for cluster membership. Something like this:. `adata.obs['cluster_dummy'] = adata.obs['louvain'] == adata.obs['louvain'].cat.categories[0]`. By iterating over the last index (currently at 0), you can create dummy variables to visualize via `sc.pl.umap(adata, 'cluster_dummy')`. Hope that helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/513
https://github.com/scverse/scanpy/issues/513:233,energy efficiency,current,currently,233,"Hi @aditisk,. You can always make a dummy `.obs` variable for cluster membership. Something like this:. `adata.obs['cluster_dummy'] = adata.obs['louvain'] == adata.obs['louvain'].cat.categories[0]`. By iterating over the last index (currently at 0), you can create dummy variables to visualize via `sc.pl.umap(adata, 'cluster_dummy')`. Hope that helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/513
https://github.com/scverse/scanpy/issues/513:49,modifiability,variab,variable,49,"Hi @aditisk,. You can always make a dummy `.obs` variable for cluster membership. Something like this:. `adata.obs['cluster_dummy'] = adata.obs['louvain'] == adata.obs['louvain'].cat.categories[0]`. By iterating over the last index (currently at 0), you can create dummy variables to visualize via `sc.pl.umap(adata, 'cluster_dummy')`. Hope that helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/513
https://github.com/scverse/scanpy/issues/513:271,modifiability,variab,variables,271,"Hi @aditisk,. You can always make a dummy `.obs` variable for cluster membership. Something like this:. `adata.obs['cluster_dummy'] = adata.obs['louvain'] == adata.obs['louvain'].cat.categories[0]`. By iterating over the last index (currently at 0), you can create dummy variables to visualize via `sc.pl.umap(adata, 'cluster_dummy')`. Hope that helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/513
https://github.com/scverse/scanpy/issues/513:284,usability,visual,visualize,284,"Hi @aditisk,. You can always make a dummy `.obs` variable for cluster membership. Something like this:. `adata.obs['cluster_dummy'] = adata.obs['louvain'] == adata.obs['louvain'].cat.categories[0]`. By iterating over the last index (currently at 0), you can create dummy variables to visualize via `sc.pl.umap(adata, 'cluster_dummy')`. Hope that helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/513
https://github.com/scverse/scanpy/issues/513:346,usability,help,helps,346,"Hi @aditisk,. You can always make a dummy `.obs` variable for cluster membership. Something like this:. `adata.obs['cluster_dummy'] = adata.obs['louvain'] == adata.obs['louvain'].cat.categories[0]`. By iterating over the last index (currently at 0), you can create dummy variables to visualize via `sc.pl.umap(adata, 'cluster_dummy')`. Hope that helps!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/513
https://github.com/scverse/scanpy/issues/513:46,modifiability,paramet,parameter,46,"Thanks, @LuckyMD! In some cases, the `groups` parameter of the scatter plot might also do the job for you... But it's more limited than what Malte suggests.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/513
https://github.com/scverse/scanpy/issues/514:25,deployability,api,api,25,"try this:. import scanpy.api as sc. sc.pp.bbknn(adata,batch_key='batch', n_pcs=15). or:. import bbknn. bbknn.bbknn(adata,batch_key='batch')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/514
https://github.com/scverse/scanpy/issues/514:25,integrability,api,api,25,"try this:. import scanpy.api as sc. sc.pp.bbknn(adata,batch_key='batch', n_pcs=15). or:. import bbknn. bbknn.bbknn(adata,batch_key='batch')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/514
https://github.com/scverse/scanpy/issues/514:65,integrability,batch,batch,65,"try this:. import scanpy.api as sc. sc.pp.bbknn(adata,batch_key='batch', n_pcs=15). or:. import bbknn. bbknn.bbknn(adata,batch_key='batch')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/514
https://github.com/scverse/scanpy/issues/514:132,integrability,batch,batch,132,"try this:. import scanpy.api as sc. sc.pp.bbknn(adata,batch_key='batch', n_pcs=15). or:. import bbknn. bbknn.bbknn(adata,batch_key='batch')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/514
https://github.com/scverse/scanpy/issues/514:25,interoperability,api,api,25,"try this:. import scanpy.api as sc. sc.pp.bbknn(adata,batch_key='batch', n_pcs=15). or:. import bbknn. bbknn.bbknn(adata,batch_key='batch')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/514
https://github.com/scverse/scanpy/issues/514:65,performance,batch,batch,65,"try this:. import scanpy.api as sc. sc.pp.bbknn(adata,batch_key='batch', n_pcs=15). or:. import bbknn. bbknn.bbknn(adata,batch_key='batch')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/514
https://github.com/scverse/scanpy/issues/514:132,performance,batch,batch,132,"try this:. import scanpy.api as sc. sc.pp.bbknn(adata,batch_key='batch', n_pcs=15). or:. import bbknn. bbknn.bbknn(adata,batch_key='batch')",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/514
https://github.com/scverse/scanpy/issues/514:58,reliability,doe,does,58,"I tried the second one and it worked, while the first one does not anyway.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/514
https://github.com/scverse/scanpy/issues/514:195,security,auth,authored,195,"thanks for the help and the fix to both. Cheers. Den man. 18. mar. 2019 kl. 14.01 skrev Philipp A. <notifications@github.com. >:. > Thank you, fixed! >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/514#issuecomment-473900261>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AIXvUX_v3VYX5G3DBv5Zp9G--tAtEqyuks5vX44mgaJpZM4bb-PW>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/514
https://github.com/scverse/scanpy/issues/514:412,security,auth,auth,412,"thanks for the help and the fix to both. Cheers. Den man. 18. mar. 2019 kl. 14.01 skrev Philipp A. <notifications@github.com. >:. > Thank you, fixed! >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/514#issuecomment-473900261>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AIXvUX_v3VYX5G3DBv5Zp9G--tAtEqyuks5vX44mgaJpZM4bb-PW>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/514
https://github.com/scverse/scanpy/issues/514:15,usability,help,help,15,"thanks for the help and the fix to both. Cheers. Den man. 18. mar. 2019 kl. 14.01 skrev Philipp A. <notifications@github.com. >:. > Thank you, fixed! >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/514#issuecomment-473900261>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AIXvUX_v3VYX5G3DBv5Zp9G--tAtEqyuks5vX44mgaJpZM4bb-PW>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/514
https://github.com/scverse/scanpy/issues/515:20,availability,error,error,20,I just had the same error occur when trying to save my objects,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515
https://github.com/scverse/scanpy/issues/515:20,performance,error,error,20,I just had the same error occur when trying to save my objects,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515
https://github.com/scverse/scanpy/issues/515:20,safety,error,error,20,I just had the same error occur when trying to save my objects,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515
https://github.com/scverse/scanpy/issues/515:20,usability,error,error,20,I just had the same error occur when trying to save my objects,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515
https://github.com/scverse/scanpy/issues/515:19,deployability,instal,install,19,@macros29 try `pip install anndata --force-reinstall` then import your packages again and try saving.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515
https://github.com/scverse/scanpy/issues/515:71,modifiability,pac,packages,71,@macros29 try `pip install anndata --force-reinstall` then import your packages again and try saving.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515
https://github.com/scverse/scanpy/issues/515:21,deployability,instal,install,21,"> @macros29 try `pip install anndata --force-reinstall` then import your packages again and try saving. That indeed solved it! Thanks alot, @shayanhoss ! Although I still don't know what caused the issue in the first place exactly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515
https://github.com/scverse/scanpy/issues/515:73,modifiability,pac,packages,73,"> @macros29 try `pip install anndata --force-reinstall` then import your packages again and try saving. That indeed solved it! Thanks alot, @shayanhoss ! Although I still don't know what caused the issue in the first place exactly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515
https://github.com/scverse/scanpy/issues/515:13,deployability,updat,update,13,There was an update in how `pandas` treats categoricals a couple of weeks ago (I think 0.24); we had to update `anndata` in order to incorporate the changes; that's why a newer version of `anndata` was necessary. I'm sure you unconsciously updated `pandas` before. :). Thanks for fielding this one @shayanhoss!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515
https://github.com/scverse/scanpy/issues/515:104,deployability,updat,update,104,There was an update in how `pandas` treats categoricals a couple of weeks ago (I think 0.24); we had to update `anndata` in order to incorporate the changes; that's why a newer version of `anndata` was necessary. I'm sure you unconsciously updated `pandas` before. :). Thanks for fielding this one @shayanhoss!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515
https://github.com/scverse/scanpy/issues/515:177,deployability,version,version,177,There was an update in how `pandas` treats categoricals a couple of weeks ago (I think 0.24); we had to update `anndata` in order to incorporate the changes; that's why a newer version of `anndata` was necessary. I'm sure you unconsciously updated `pandas` before. :). Thanks for fielding this one @shayanhoss!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515
https://github.com/scverse/scanpy/issues/515:240,deployability,updat,updated,240,There was an update in how `pandas` treats categoricals a couple of weeks ago (I think 0.24); we had to update `anndata` in order to incorporate the changes; that's why a newer version of `anndata` was necessary. I'm sure you unconsciously updated `pandas` before. :). Thanks for fielding this one @shayanhoss!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515
https://github.com/scverse/scanpy/issues/515:58,integrability,coupl,couple,58,There was an update in how `pandas` treats categoricals a couple of weeks ago (I think 0.24); we had to update `anndata` in order to incorporate the changes; that's why a newer version of `anndata` was necessary. I'm sure you unconsciously updated `pandas` before. :). Thanks for fielding this one @shayanhoss!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515
https://github.com/scverse/scanpy/issues/515:177,integrability,version,version,177,There was an update in how `pandas` treats categoricals a couple of weeks ago (I think 0.24); we had to update `anndata` in order to incorporate the changes; that's why a newer version of `anndata` was necessary. I'm sure you unconsciously updated `pandas` before. :). Thanks for fielding this one @shayanhoss!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515
https://github.com/scverse/scanpy/issues/515:58,modifiability,coupl,couple,58,There was an update in how `pandas` treats categoricals a couple of weeks ago (I think 0.24); we had to update `anndata` in order to incorporate the changes; that's why a newer version of `anndata` was necessary. I'm sure you unconsciously updated `pandas` before. :). Thanks for fielding this one @shayanhoss!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515
https://github.com/scverse/scanpy/issues/515:177,modifiability,version,version,177,There was an update in how `pandas` treats categoricals a couple of weeks ago (I think 0.24); we had to update `anndata` in order to incorporate the changes; that's why a newer version of `anndata` was necessary. I'm sure you unconsciously updated `pandas` before. :). Thanks for fielding this one @shayanhoss!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515
https://github.com/scverse/scanpy/issues/515:13,safety,updat,update,13,There was an update in how `pandas` treats categoricals a couple of weeks ago (I think 0.24); we had to update `anndata` in order to incorporate the changes; that's why a newer version of `anndata` was necessary. I'm sure you unconsciously updated `pandas` before. :). Thanks for fielding this one @shayanhoss!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515
https://github.com/scverse/scanpy/issues/515:104,safety,updat,update,104,There was an update in how `pandas` treats categoricals a couple of weeks ago (I think 0.24); we had to update `anndata` in order to incorporate the changes; that's why a newer version of `anndata` was necessary. I'm sure you unconsciously updated `pandas` before. :). Thanks for fielding this one @shayanhoss!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515
https://github.com/scverse/scanpy/issues/515:240,safety,updat,updated,240,There was an update in how `pandas` treats categoricals a couple of weeks ago (I think 0.24); we had to update `anndata` in order to incorporate the changes; that's why a newer version of `anndata` was necessary. I'm sure you unconsciously updated `pandas` before. :). Thanks for fielding this one @shayanhoss!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515
https://github.com/scverse/scanpy/issues/515:13,security,updat,update,13,There was an update in how `pandas` treats categoricals a couple of weeks ago (I think 0.24); we had to update `anndata` in order to incorporate the changes; that's why a newer version of `anndata` was necessary. I'm sure you unconsciously updated `pandas` before. :). Thanks for fielding this one @shayanhoss!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515
https://github.com/scverse/scanpy/issues/515:104,security,updat,update,104,There was an update in how `pandas` treats categoricals a couple of weeks ago (I think 0.24); we had to update `anndata` in order to incorporate the changes; that's why a newer version of `anndata` was necessary. I'm sure you unconsciously updated `pandas` before. :). Thanks for fielding this one @shayanhoss!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515
https://github.com/scverse/scanpy/issues/515:240,security,updat,updated,240,There was an update in how `pandas` treats categoricals a couple of weeks ago (I think 0.24); we had to update `anndata` in order to incorporate the changes; that's why a newer version of `anndata` was necessary. I'm sure you unconsciously updated `pandas` before. :). Thanks for fielding this one @shayanhoss!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515
https://github.com/scverse/scanpy/issues/515:58,testability,coupl,couple,58,There was an update in how `pandas` treats categoricals a couple of weeks ago (I think 0.24); we had to update `anndata` in order to incorporate the changes; that's why a newer version of `anndata` was necessary. I'm sure you unconsciously updated `pandas` before. :). Thanks for fielding this one @shayanhoss!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/515
https://github.com/scverse/scanpy/issues/517:30,deployability,log,logs,30,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:105,deployability,log,log-scale,105,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:123,deployability,log,log-fold,123,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:302,deployability,log,log-normalized,302,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:109,energy efficiency,scale,scale,109,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:209,energy efficiency,model,model,209,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:109,modifiability,scal,scale,109,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:109,performance,scale,scale,109,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:228,reliability,Poisson,Poisson,228,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:30,safety,log,logs,30,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:105,safety,log,log-scale,105,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:123,safety,log,log-fold,123,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:244,safety,test,test,244,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:302,safety,log,log-normalized,302,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:30,security,log,logs,30,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:105,security,log,log-scale,105,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:123,security,log,log-fold,123,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:209,security,model,model,209,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:302,security,log,log-normalized,302,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:30,testability,log,logs,30,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:105,testability,log,log-scale,105,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:123,testability,log,log-fold,123,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:244,testability,test,test,244,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:302,testability,log,log-normalized,302,"I second the notion of double logs not making sense. You could use differences in mean expression on the log-scale to give log-fold changes though I think. If you use count data, you should probably use an NB model (or at least Poisson). The t-test assumes normality, which is at least approximated by log-normalized data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:934,availability,consist,consistent,934,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:78,deployability,log,log-scale,78,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:667,deployability,log,log,667,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:750,deployability,log,loge,750,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:825,deployability,scale,scale,825,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:918,deployability,log,loge,918,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:997,deployability,log,log-mean,997,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1014,deployability,log,log,1014,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1025,deployability,log,log,1025,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1050,deployability,log,log,1050,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1110,deployability,log,log,1110,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:82,energy efficiency,scale,scale,82,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:825,energy efficiency,scale,scale,825,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:236,integrability,transform,transformation,236,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:236,interoperability,transform,transformation,236,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:82,modifiability,scal,scale,82,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:305,modifiability,pac,packages,305,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:825,modifiability,scal,scale,825,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:82,performance,scale,scale,82,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:825,performance,scale,scale,825,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:78,safety,log,log-scale,78,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:377,safety,test,testing,377,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:395,safety,compl,completely,395,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:462,safety,test,tests,462,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:526,safety,test,test,526,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:667,safety,log,log,667,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:750,safety,log,loge,750,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:886,safety,test,tests,886,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:918,safety,log,loge,918,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:997,safety,log,log-mean,997,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1014,safety,log,log,1014,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1025,safety,log,log,1025,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1050,safety,log,log,1050,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1069,safety,test,tests,1069,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1110,safety,log,log,1110,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:78,security,log,log-scale,78,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:395,security,compl,completely,395,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:667,security,log,log,667,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:750,security,log,loge,750,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:918,security,log,loge,918,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:997,security,log,log-mean,997,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1014,security,log,log,1014,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1025,security,log,log,1025,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1050,security,log,log,1050,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1110,security,log,log,1110,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:78,testability,log,log-scale,78,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:377,testability,test,testing,377,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:462,testability,test,tests,462,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:526,testability,test,test,526,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:667,testability,log,log,667,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:750,testability,log,loge,750,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:798,testability,simpl,simplicity,798,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:886,testability,test,tests,886,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:918,testability,log,loge,918,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:997,testability,log,log-mean,997,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1014,testability,log,log,1014,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1025,testability,log,log,1025,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1050,testability,log,log,1050,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1069,testability,test,tests,1069,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1110,testability,log,log,1110,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:144,usability,intuit,intuitive,144,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:713,usability,prefer,preference,713,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:798,usability,simpl,simplicity,798,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:934,usability,consist,consistent,934,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1214,usability,prefer,preferred,1214,"@LuckyMD Yeah, we can definitely do the differences in mean expression on the log-scale as a quick fix. However, I think it's a little bit more intuitive to express fold-changes with a base of 2, as opposed to a base of e, which is the transformation used for the data matrix. This also mimics what other packages usually report, but I'm happy either way! For the differential testing itself, I completely agree with you about the assumption of normality with t-tests, so we definitely shouldn't change that. For the wilcoxon test, however, normality isn't assumed, so do you think it would be ok to run on raw counts? Either way, we should definitely fix the double-log for the fold-change reporting. Is there a preference on whether to keep it was loge(base e) difference or log2 difference? For simplicity, this change in scale would only affect the fold-change reporting, all other tests I think we should keep in loge to keep it consistent. One final thought I wanted to ask your opinion on: log-mean vs mean-log. (e.g. log(mean(count)) vs mean(log(count)). For t-tests I think it makes sense to use mean-log, however, when calculating fold-change differences in mean expression, I'm not entirely sure what's preferred (particularly for methods like wilcoxon that don't use the mean expression to calculate scores). Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:40,deployability,log,logs,40,"I agree and had also noticed it. Double logs make no sense. It should be the log2 basis. @a-munoz-rojas, as you implemented this, would you make PR to fix it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:40,safety,log,logs,40,"I agree and had also noticed it. Double logs make no sense. It should be the log2 basis. @a-munoz-rojas, as you implemented this, would you make PR to fix it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:40,security,log,logs,40,"I agree and had also noticed it. Double logs make no sense. It should be the log2 basis. @a-munoz-rojas, as you implemented this, would you make PR to fix it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:40,testability,log,logs,40,"I agree and had also noticed it. Double logs make no sense. It should be the log2 basis. @a-munoz-rojas, as you implemented this, would you make PR to fix it?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:108,deployability,log,log-transformed,108,"Sure thing, I'll make a PR now. I'll add a parameter and leave the default assuming that the data passed is log-transformed. Sorry for missing this earlier! I also added a fix for an indexing bug that was left-over from the original chunking done during the wilcoxon test. I'll add the details to the PR. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:112,integrability,transform,transformed,112,"Sure thing, I'll make a PR now. I'll add a parameter and leave the default assuming that the data passed is log-transformed. Sorry for missing this earlier! I also added a fix for an indexing bug that was left-over from the original chunking done during the wilcoxon test. I'll add the details to the PR. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:112,interoperability,transform,transformed,112,"Sure thing, I'll make a PR now. I'll add a parameter and leave the default assuming that the data passed is log-transformed. Sorry for missing this earlier! I also added a fix for an indexing bug that was left-over from the original chunking done during the wilcoxon test. I'll add the details to the PR. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:43,modifiability,paramet,parameter,43,"Sure thing, I'll make a PR now. I'll add a parameter and leave the default assuming that the data passed is log-transformed. Sorry for missing this earlier! I also added a fix for an indexing bug that was left-over from the original chunking done during the wilcoxon test. I'll add the details to the PR. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:108,safety,log,log-transformed,108,"Sure thing, I'll make a PR now. I'll add a parameter and leave the default assuming that the data passed is log-transformed. Sorry for missing this earlier! I also added a fix for an indexing bug that was left-over from the original chunking done during the wilcoxon test. I'll add the details to the PR. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:267,safety,test,test,267,"Sure thing, I'll make a PR now. I'll add a parameter and leave the default assuming that the data passed is log-transformed. Sorry for missing this earlier! I also added a fix for an indexing bug that was left-over from the original chunking done during the wilcoxon test. I'll add the details to the PR. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:108,security,log,log-transformed,108,"Sure thing, I'll make a PR now. I'll add a parameter and leave the default assuming that the data passed is log-transformed. Sorry for missing this earlier! I also added a fix for an indexing bug that was left-over from the original chunking done during the wilcoxon test. I'll add the details to the PR. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:108,testability,log,log-transformed,108,"Sure thing, I'll make a PR now. I'll add a parameter and leave the default assuming that the data passed is log-transformed. Sorry for missing this earlier! I also added a fix for an indexing bug that was left-over from the original chunking done during the wilcoxon test. I'll add the details to the PR. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:267,testability,test,test,267,"Sure thing, I'll make a PR now. I'll add a parameter and leave the default assuming that the data passed is log-transformed. Sorry for missing this earlier! I also added a fix for an indexing bug that was left-over from the original chunking done during the wilcoxon test. I'll add the details to the PR. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:468,deployability,log,log,468,I guess you could just divide by `ln(2)` to get log2 values before subtracting? That way you should have everything a bit quicker. I haven't tried Wilcoxon on raw counts yet... the only thing I would be wary of is that we shouldn't really assume equal variances especially in marker gene calculations... for the t-test we use Welch's correction at least. I recently read an interesting [preprint](https://www.biorxiv.org/content/10.1101/404962v1) about the issue with log mean vs mean log. I think log mean is the original interpretation of log fold change.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:485,deployability,log,log,485,I guess you could just divide by `ln(2)` to get log2 values before subtracting? That way you should have everything a bit quicker. I haven't tried Wilcoxon on raw counts yet... the only thing I would be wary of is that we shouldn't really assume equal variances especially in marker gene calculations... for the t-test we use Welch's correction at least. I recently read an interesting [preprint](https://www.biorxiv.org/content/10.1101/404962v1) about the issue with log mean vs mean log. I think log mean is the original interpretation of log fold change.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:498,deployability,log,log,498,I guess you could just divide by `ln(2)` to get log2 values before subtracting? That way you should have everything a bit quicker. I haven't tried Wilcoxon on raw counts yet... the only thing I would be wary of is that we shouldn't really assume equal variances especially in marker gene calculations... for the t-test we use Welch's correction at least. I recently read an interesting [preprint](https://www.biorxiv.org/content/10.1101/404962v1) about the issue with log mean vs mean log. I think log mean is the original interpretation of log fold change.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:541,deployability,log,log,541,I guess you could just divide by `ln(2)` to get log2 values before subtracting? That way you should have everything a bit quicker. I haven't tried Wilcoxon on raw counts yet... the only thing I would be wary of is that we shouldn't really assume equal variances especially in marker gene calculations... for the t-test we use Welch's correction at least. I recently read an interesting [preprint](https://www.biorxiv.org/content/10.1101/404962v1) about the issue with log mean vs mean log. I think log mean is the original interpretation of log fold change.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:67,integrability,sub,subtracting,67,I guess you could just divide by `ln(2)` to get log2 values before subtracting? That way you should have everything a bit quicker. I haven't tried Wilcoxon on raw counts yet... the only thing I would be wary of is that we shouldn't really assume equal variances especially in marker gene calculations... for the t-test we use Welch's correction at least. I recently read an interesting [preprint](https://www.biorxiv.org/content/10.1101/404962v1) about the issue with log mean vs mean log. I think log mean is the original interpretation of log fold change.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:421,performance,content,content,421,I guess you could just divide by `ln(2)` to get log2 values before subtracting? That way you should have everything a bit quicker. I haven't tried Wilcoxon on raw counts yet... the only thing I would be wary of is that we shouldn't really assume equal variances especially in marker gene calculations... for the t-test we use Welch's correction at least. I recently read an interesting [preprint](https://www.biorxiv.org/content/10.1101/404962v1) about the issue with log mean vs mean log. I think log mean is the original interpretation of log fold change.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:314,safety,test,test,314,I guess you could just divide by `ln(2)` to get log2 values before subtracting? That way you should have everything a bit quicker. I haven't tried Wilcoxon on raw counts yet... the only thing I would be wary of is that we shouldn't really assume equal variances especially in marker gene calculations... for the t-test we use Welch's correction at least. I recently read an interesting [preprint](https://www.biorxiv.org/content/10.1101/404962v1) about the issue with log mean vs mean log. I think log mean is the original interpretation of log fold change.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:468,safety,log,log,468,I guess you could just divide by `ln(2)` to get log2 values before subtracting? That way you should have everything a bit quicker. I haven't tried Wilcoxon on raw counts yet... the only thing I would be wary of is that we shouldn't really assume equal variances especially in marker gene calculations... for the t-test we use Welch's correction at least. I recently read an interesting [preprint](https://www.biorxiv.org/content/10.1101/404962v1) about the issue with log mean vs mean log. I think log mean is the original interpretation of log fold change.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:485,safety,log,log,485,I guess you could just divide by `ln(2)` to get log2 values before subtracting? That way you should have everything a bit quicker. I haven't tried Wilcoxon on raw counts yet... the only thing I would be wary of is that we shouldn't really assume equal variances especially in marker gene calculations... for the t-test we use Welch's correction at least. I recently read an interesting [preprint](https://www.biorxiv.org/content/10.1101/404962v1) about the issue with log mean vs mean log. I think log mean is the original interpretation of log fold change.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:498,safety,log,log,498,I guess you could just divide by `ln(2)` to get log2 values before subtracting? That way you should have everything a bit quicker. I haven't tried Wilcoxon on raw counts yet... the only thing I would be wary of is that we shouldn't really assume equal variances especially in marker gene calculations... for the t-test we use Welch's correction at least. I recently read an interesting [preprint](https://www.biorxiv.org/content/10.1101/404962v1) about the issue with log mean vs mean log. I think log mean is the original interpretation of log fold change.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:541,safety,log,log,541,I guess you could just divide by `ln(2)` to get log2 values before subtracting? That way you should have everything a bit quicker. I haven't tried Wilcoxon on raw counts yet... the only thing I would be wary of is that we shouldn't really assume equal variances especially in marker gene calculations... for the t-test we use Welch's correction at least. I recently read an interesting [preprint](https://www.biorxiv.org/content/10.1101/404962v1) about the issue with log mean vs mean log. I think log mean is the original interpretation of log fold change.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:468,security,log,log,468,I guess you could just divide by `ln(2)` to get log2 values before subtracting? That way you should have everything a bit quicker. I haven't tried Wilcoxon on raw counts yet... the only thing I would be wary of is that we shouldn't really assume equal variances especially in marker gene calculations... for the t-test we use Welch's correction at least. I recently read an interesting [preprint](https://www.biorxiv.org/content/10.1101/404962v1) about the issue with log mean vs mean log. I think log mean is the original interpretation of log fold change.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:485,security,log,log,485,I guess you could just divide by `ln(2)` to get log2 values before subtracting? That way you should have everything a bit quicker. I haven't tried Wilcoxon on raw counts yet... the only thing I would be wary of is that we shouldn't really assume equal variances especially in marker gene calculations... for the t-test we use Welch's correction at least. I recently read an interesting [preprint](https://www.biorxiv.org/content/10.1101/404962v1) about the issue with log mean vs mean log. I think log mean is the original interpretation of log fold change.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:498,security,log,log,498,I guess you could just divide by `ln(2)` to get log2 values before subtracting? That way you should have everything a bit quicker. I haven't tried Wilcoxon on raw counts yet... the only thing I would be wary of is that we shouldn't really assume equal variances especially in marker gene calculations... for the t-test we use Welch's correction at least. I recently read an interesting [preprint](https://www.biorxiv.org/content/10.1101/404962v1) about the issue with log mean vs mean log. I think log mean is the original interpretation of log fold change.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:541,security,log,log,541,I guess you could just divide by `ln(2)` to get log2 values before subtracting? That way you should have everything a bit quicker. I haven't tried Wilcoxon on raw counts yet... the only thing I would be wary of is that we shouldn't really assume equal variances especially in marker gene calculations... for the t-test we use Welch's correction at least. I recently read an interesting [preprint](https://www.biorxiv.org/content/10.1101/404962v1) about the issue with log mean vs mean log. I think log mean is the original interpretation of log fold change.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:314,testability,test,test,314,I guess you could just divide by `ln(2)` to get log2 values before subtracting? That way you should have everything a bit quicker. I haven't tried Wilcoxon on raw counts yet... the only thing I would be wary of is that we shouldn't really assume equal variances especially in marker gene calculations... for the t-test we use Welch's correction at least. I recently read an interesting [preprint](https://www.biorxiv.org/content/10.1101/404962v1) about the issue with log mean vs mean log. I think log mean is the original interpretation of log fold change.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:468,testability,log,log,468,I guess you could just divide by `ln(2)` to get log2 values before subtracting? That way you should have everything a bit quicker. I haven't tried Wilcoxon on raw counts yet... the only thing I would be wary of is that we shouldn't really assume equal variances especially in marker gene calculations... for the t-test we use Welch's correction at least. I recently read an interesting [preprint](https://www.biorxiv.org/content/10.1101/404962v1) about the issue with log mean vs mean log. I think log mean is the original interpretation of log fold change.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:485,testability,log,log,485,I guess you could just divide by `ln(2)` to get log2 values before subtracting? That way you should have everything a bit quicker. I haven't tried Wilcoxon on raw counts yet... the only thing I would be wary of is that we shouldn't really assume equal variances especially in marker gene calculations... for the t-test we use Welch's correction at least. I recently read an interesting [preprint](https://www.biorxiv.org/content/10.1101/404962v1) about the issue with log mean vs mean log. I think log mean is the original interpretation of log fold change.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:498,testability,log,log,498,I guess you could just divide by `ln(2)` to get log2 values before subtracting? That way you should have everything a bit quicker. I haven't tried Wilcoxon on raw counts yet... the only thing I would be wary of is that we shouldn't really assume equal variances especially in marker gene calculations... for the t-test we use Welch's correction at least. I recently read an interesting [preprint](https://www.biorxiv.org/content/10.1101/404962v1) about the issue with log mean vs mean log. I think log mean is the original interpretation of log fold change.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:541,testability,log,log,541,I guess you could just divide by `ln(2)` to get log2 values before subtracting? That way you should have everything a bit quicker. I haven't tried Wilcoxon on raw counts yet... the only thing I would be wary of is that we shouldn't really assume equal variances especially in marker gene calculations... for the t-test we use Welch's correction at least. I recently read an interesting [preprint](https://www.biorxiv.org/content/10.1101/404962v1) about the issue with log mean vs mean log. I think log mean is the original interpretation of log fold change.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:148,deployability,pipelin,pipelines,148,"That's a great point, I'll definitely implement that to speed things up. I also read that same paper, which made me realize that we (and most other pipelines as far as I know) use mean log. I agree that the original interpretation is log mean. Any thoughts on switching to log mean (for everything except t-tests)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:185,deployability,log,log,185,"That's a great point, I'll definitely implement that to speed things up. I also read that same paper, which made me realize that we (and most other pipelines as far as I know) use mean log. I agree that the original interpretation is log mean. Any thoughts on switching to log mean (for everything except t-tests)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:234,deployability,log,log,234,"That's a great point, I'll definitely implement that to speed things up. I also read that same paper, which made me realize that we (and most other pipelines as far as I know) use mean log. I agree that the original interpretation is log mean. Any thoughts on switching to log mean (for everything except t-tests)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:273,deployability,log,log,273,"That's a great point, I'll definitely implement that to speed things up. I also read that same paper, which made me realize that we (and most other pipelines as far as I know) use mean log. I agree that the original interpretation is log mean. Any thoughts on switching to log mean (for everything except t-tests)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:148,integrability,pipelin,pipelines,148,"That's a great point, I'll definitely implement that to speed things up. I also read that same paper, which made me realize that we (and most other pipelines as far as I know) use mean log. I agree that the original interpretation is log mean. Any thoughts on switching to log mean (for everything except t-tests)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:185,safety,log,log,185,"That's a great point, I'll definitely implement that to speed things up. I also read that same paper, which made me realize that we (and most other pipelines as far as I know) use mean log. I agree that the original interpretation is log mean. Any thoughts on switching to log mean (for everything except t-tests)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:234,safety,log,log,234,"That's a great point, I'll definitely implement that to speed things up. I also read that same paper, which made me realize that we (and most other pipelines as far as I know) use mean log. I agree that the original interpretation is log mean. Any thoughts on switching to log mean (for everything except t-tests)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:273,safety,log,log,273,"That's a great point, I'll definitely implement that to speed things up. I also read that same paper, which made me realize that we (and most other pipelines as far as I know) use mean log. I agree that the original interpretation is log mean. Any thoughts on switching to log mean (for everything except t-tests)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:298,safety,except,except,298,"That's a great point, I'll definitely implement that to speed things up. I also read that same paper, which made me realize that we (and most other pipelines as far as I know) use mean log. I agree that the original interpretation is log mean. Any thoughts on switching to log mean (for everything except t-tests)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:307,safety,test,tests,307,"That's a great point, I'll definitely implement that to speed things up. I also read that same paper, which made me realize that we (and most other pipelines as far as I know) use mean log. I agree that the original interpretation is log mean. Any thoughts on switching to log mean (for everything except t-tests)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:185,security,log,log,185,"That's a great point, I'll definitely implement that to speed things up. I also read that same paper, which made me realize that we (and most other pipelines as far as I know) use mean log. I agree that the original interpretation is log mean. Any thoughts on switching to log mean (for everything except t-tests)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:234,security,log,log,234,"That's a great point, I'll definitely implement that to speed things up. I also read that same paper, which made me realize that we (and most other pipelines as far as I know) use mean log. I agree that the original interpretation is log mean. Any thoughts on switching to log mean (for everything except t-tests)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:273,security,log,log,273,"That's a great point, I'll definitely implement that to speed things up. I also read that same paper, which made me realize that we (and most other pipelines as far as I know) use mean log. I agree that the original interpretation is log mean. Any thoughts on switching to log mean (for everything except t-tests)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:185,testability,log,log,185,"That's a great point, I'll definitely implement that to speed things up. I also read that same paper, which made me realize that we (and most other pipelines as far as I know) use mean log. I agree that the original interpretation is log mean. Any thoughts on switching to log mean (for everything except t-tests)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:234,testability,log,log,234,"That's a great point, I'll definitely implement that to speed things up. I also read that same paper, which made me realize that we (and most other pipelines as far as I know) use mean log. I agree that the original interpretation is log mean. Any thoughts on switching to log mean (for everything except t-tests)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:273,testability,log,log,273,"That's a great point, I'll definitely implement that to speed things up. I also read that same paper, which made me realize that we (and most other pipelines as far as I know) use mean log. I agree that the original interpretation is log mean. Any thoughts on switching to log mean (for everything except t-tests)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:307,testability,test,tests,307,"That's a great point, I'll definitely implement that to speed things up. I also read that same paper, which made me realize that we (and most other pipelines as far as I know) use mean log. I agree that the original interpretation is log mean. Any thoughts on switching to log mean (for everything except t-tests)?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:327,availability,down,downstream,327,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:101,deployability,log,log,101,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:150,deployability,Log,Log-transforming,150,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:433,deployability,log,log,433,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:752,deployability,log,log-mean,752,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:769,deployability,log,log,769,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:826,deployability,log,log,826,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1005,deployability,log,log-mean,1005,"journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it is very r",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1022,deployability,log,log,1022,"out this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it is very relevant in situ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1464,deployability,log,log-transformation,1464,"ations. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it is very relevant in situations where you have samples from 2 conditions sequenced to different depths. I'd love to hear your thoughts on this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:218,energy efficiency,reduc,reduces,218,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:460,energy efficiency,model,modeling,460,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:731,energy efficiency,estimat,estimate,731,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:154,integrability,transform,transforming,154,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:437,integrability,transform,transformation,437,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:830,integrability,transform,transforming,830,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1468,integrability,transform,transformation,1468,"ations. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it is very relevant in situations where you have samples from 2 conditions sequenced to different depths. I'd love to hear your thoughts on this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:154,interoperability,transform,transforming,154,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:290,interoperability,distribut,distribution,290,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:437,interoperability,transform,transformation,437,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:632,interoperability,distribut,distributions,632,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:687,interoperability,distribut,distributions,687,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:830,interoperability,transform,transforming,830,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1468,interoperability,transform,transformation,1468,"ations. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it is very relevant in situations where you have samples from 2 conditions sequenced to different depths. I'd love to hear your thoughts on this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1593,interoperability,distribut,distributions,1593,"ations. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it is very relevant in situations where you have samples from 2 conditions sequenced to different depths. I'd love to hear your thoughts on this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:708,performance,perform,performing,708,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:192,reliability,stabil,stabilizing,192,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1496,reliability,pra,practice,1496,"ations. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it is very relevant in situations where you have samples from 2 conditions sequenced to different depths. I'd love to hear your thoughts on this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:101,safety,log,log,101,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:150,safety,Log,Log-transforming,150,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:433,safety,log,log,433,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:589,safety,test,tests,589,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:723,safety,test,test,723,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:752,safety,log,log-mean,752,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:769,safety,log,log,769,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:800,safety,test,test,800,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:826,safety,log,log,826,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:867,safety,test,test,867,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:921,safety,test,test,921,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1005,safety,log,log-mean,1005,"journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it is very r",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1022,safety,log,log,1022,"out this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it is very relevant in situ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1464,safety,log,log-transformation,1464,"ations. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it is very relevant in situations where you have samples from 2 conditions sequenced to different depths. I'd love to hear your thoughts on this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1942,safety,compl,complicated,1942,"ations. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it is very relevant in situations where you have samples from 2 conditions sequenced to different depths. I'd love to hear your thoughts on this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:101,security,log,log,101,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:150,security,Log,Log-transforming,150,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:433,security,log,log,433,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:460,security,model,modeling,460,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:752,security,log,log-mean,752,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:769,security,log,log,769,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:826,security,log,log,826,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1005,security,log,log-mean,1005,"journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it is very r",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1022,security,log,log,1022,"out this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it is very relevant in situ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1464,security,log,log-transformation,1464,"ations. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it is very relevant in situations where you have samples from 2 conditions sequenced to different depths. I'd love to hear your thoughts on this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1942,security,compl,complicated,1942,"ations. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it is very relevant in situations where you have samples from 2 conditions sequenced to different depths. I'd love to hear your thoughts on this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:101,testability,log,log,101,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:150,testability,Log,Log-transforming,150,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:433,testability,log,log,433,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:589,testability,test,tests,589,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:723,testability,test,test,723,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:752,testability,log,log-mean,752,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:769,testability,log,log,769,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:800,testability,test,test,800,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:826,testability,log,log,826,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:867,testability,test,test,867,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:921,testability,test,test,921,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1005,testability,log,log-mean,1005,"journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it is very r",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1022,testability,log,log,1022,"out this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it is very relevant in situ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1464,testability,log,log-transformation,1464,"ations. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it is very relevant in situations where you have samples from 2 conditions sequenced to different depths. I'd love to hear your thoughts on this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:708,usability,perform,performing,708,"We had a journal club about this recently and couldn't really come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1054,usability,experien,experience,1054,"ly come up with a good solution tbh. Mean-log is so much easier for a lot of applications. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it is very relevant in situations where you have samples from ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1571,usability,visual,visualize,1571,"ations. Log-transforming data also has a variance-stabilizing effect and it reduces skewness so that the data at least better approximates a normal distribution than before, which many downstream methods assume (although data is often still far from normal). So I don't see how we can forgo log transformation without modeling count data for everything directly. The effect outlined in the paper is the most pronounced for differential expression tests between groups for which size factor distributions differ... So you could check size factor distributions before performing the test to estimate whether the log-mean vs mean-log difference will affect the test. If yes, try without log transforming the data and see if the test can deal with the outliers. Especially for the t-test, the poorer approximation of normality may not have as strong an effect as the log-mean vs mean-log difference. However, in our experience size factors tend to have a range of ~100-fold difference, and not 1,000-10,000 fold as was shown in the paper. We weren't so taken with the suggestion in the paper of increasing the pseudocount as that essentially removes fold-change effects... and also removes zeros (making all matrices dense). As for embeddings... you could remove size factor outliers for the PCA calculation and do it without log-transformation. Although in practice we found it gives very similar results. Thus, our solution was to visualize size factor distributions on embeddings to see whether there is an effect. Usually you do see a count depth effect in the embedding though... and that's not that surprising for CPM normalization, as you assume that all cells are of similar molecule count, which is incorrect. With other normalization methods it shouldn't be as bad. But yeah... overall, it's a complicated problem without a good solution. I imagine it is very relevant in situations where you have samples from 2 conditions sequenced to different depths. I'd love to hear your thoughts on this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:819,availability,down,downstream,819,"Thanks for your thorough response! And I apologize for the late reply, I've been away at a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1639,availability,down,downstream,1639," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1542,deployability,log,log-mean,1542," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1559,deployability,log,log,1559," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1573,deployability,manag,manageable,1573," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1661,deployability,depend,depends,1661," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1753,deployability,log,log-transformation,1753," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:2037,deployability,log,log,2037," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:2092,deployability,stage,stage,2092," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:613,energy efficiency,reduc,reduces,613,"Thanks for your thorough response! And I apologize for the late reply, I've been away at a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:621,energy efficiency,power,power,621,"Thanks for your thorough response! And I apologize for the late reply, I've been away at a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1573,energy efficiency,manag,manageable,1573," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1661,integrability,depend,depends,1661," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1757,integrability,transform,transformation,1757," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:2016,integrability,sub,subpopulations,2016," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:2110,integrability,transform,transformation,2110," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:2169,integrability,sub,subpopulations,2169," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:685,interoperability,distribut,distributions,685,"Thanks for your thorough response! And I apologize for the late reply, I've been away at a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:914,interoperability,distribut,distribution,914,"Thanks for your thorough response! And I apologize for the late reply, I've been away at a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1027,interoperability,architectur,architecture,1027,"! And I apologize for the late reply, I've been away at a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, m",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1696,interoperability,distribut,distributions,1696," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1757,interoperability,transform,transformation,1757," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:2110,interoperability,transform,transformation,2110," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:380,modifiability,scenario,scenario,380,"Thanks for your thorough response! And I apologize for the late reply, I've been away at a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:762,modifiability,pac,package,762,"Thanks for your thorough response! And I apologize for the late reply, I've been away at a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1661,modifiability,depend,depends,1661," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:303,performance,content,content,303,"Thanks for your thorough response! And I apologize for the late reply, I've been away at a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:426,safety,test,testing,426,"Thanks for your thorough response! And I apologize for the late reply, I've been away at a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:534,safety,test,testing,534,"Thanks for your thorough response! And I apologize for the late reply, I've been away at a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1084,safety,test,tested,1084,"t a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1126,safety,test,testing,1126,"oned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is id",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1542,safety,log,log-mean,1542," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1559,safety,log,log,1559," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1573,safety,manag,manageable,1573," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1661,safety,depend,depends,1661," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1753,safety,log,log-transformation,1753," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:2037,safety,log,log,2037," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:2102,safety,test,test,2102," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:2152,safety,valid,validating,2152," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:966,security,auth,authors,966,"Thanks for your thorough response! And I apologize for the late reply, I've been away at a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1542,security,log,log-mean,1542," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1559,security,log,log,1559," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1753,security,log,log-transformation,1753," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:2037,security,log,log,2037," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:2152,security,validat,validating,2152," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:426,testability,test,testing,426,"Thanks for your thorough response! And I apologize for the late reply, I've been away at a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:534,testability,test,testing,534,"Thanks for your thorough response! And I apologize for the late reply, I've been away at a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:830,testability,verif,verification,830,"Thanks for your thorough response! And I apologize for the late reply, I've been away at a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1084,testability,test,tested,1084,"t a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1126,testability,test,testing,1126,"oned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is id",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1542,testability,log,log-mean,1542," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1559,testability,log,log,1559," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1661,testability,depend,depends,1661," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1753,testability,log,log-transformation,1753," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:2037,testability,log,log,2037," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:2102,testability,test,test,2102," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:143,usability,experien,experience,143,"Thanks for your thorough response! And I apologize for the late reply, I've been away at a conference. I agree with what you mentioned - in my experience I also don't see a 1,000-10,000 fold change in size factors, even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:1916,usability,minim,minimally,1916," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:2000,usability,close,closely-related,2000," even when you're comparing drastically different cells with dramatic differences in RNA content (e.g. regulatory T-cells with large cells like macrophages). In this scenario, however, any sensitive differential testing should be done within similar cell types to account for these massive differences. For differential testing, I agree with you that their suggestion of increasing the pseudo-count reduces power and is not ideal. Your suggestion of checking size-factor distributions is definitely an interesting idea, but beyond the scope of the package I think. However, I do like the idea for further downstream verification of differentially regulated genes, particularly those with non-obvious distribution changes. In general, it seems that the authors of the paper are particularly worried about spurious architecture in the embeddings, but some of these can be tested and discarded with diff expression testing. Of note, I usually also see a count depth effect in embedding as well, even with normalization methods other than CPM normalization. I've never been satisfied with attributing all count-number variation as technical noise, which like you said is definitely incorrect, particularly when comparing conditions that could include drastic changes in transcription. All of this is to say, it seems that effect of log-mean vs mean-log should be manageable for embeddings, and like you mentioned, so much of the downstream processing depends on approximation of normal distributions that it seems impossible to get rid of the log-transformation. Overall, I haven't been able to find a satisfying solution either. In general, I tend to say that any obvious expression differences should be minimally affected by this problem, however, when you're trying to distinguish more closely-related subpopulations, mean-log might have an undesirable effect. However, at this stage, no test or transformation is ideal, and we should be validating these subpopulations using several methods anyways.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:78,availability,avail,available,78,"By default, scanpy took the expression data saved at adata.raw if that is not available it took the data from adata.X. If you are loading the expression data from csv or txt file, try to save adata.raw = data, before slicing for HVGs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:217,availability,sli,slicing,217,"By default, scanpy took the expression data saved at adata.raw if that is not available it took the data from adata.X. If you are loading the expression data from csv or txt file, try to save adata.raw = data, before slicing for HVGs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:130,energy efficiency,load,loading,130,"By default, scanpy took the expression data saved at adata.raw if that is not available it took the data from adata.X. If you are loading the expression data from csv or txt file, try to save adata.raw = data, before slicing for HVGs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:130,performance,load,loading,130,"By default, scanpy took the expression data saved at adata.raw if that is not available it took the data from adata.X. If you are loading the expression data from csv or txt file, try to save adata.raw = data, before slicing for HVGs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:78,reliability,availab,available,78,"By default, scanpy took the expression data saved at adata.raw if that is not available it took the data from adata.X. If you are loading the expression data from csv or txt file, try to save adata.raw = data, before slicing for HVGs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:217,reliability,sli,slicing,217,"By default, scanpy took the expression data saved at adata.raw if that is not available it took the data from adata.X. If you are loading the expression data from csv or txt file, try to save adata.raw = data, before slicing for HVGs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:78,safety,avail,available,78,"By default, scanpy took the expression data saved at adata.raw if that is not available it took the data from adata.X. If you are loading the expression data from csv or txt file, try to save adata.raw = data, before slicing for HVGs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/517:78,security,availab,available,78,"By default, scanpy took the expression data saved at adata.raw if that is not available it took the data from adata.X. If you are loading the expression data from csv or txt file, try to save adata.raw = data, before slicing for HVGs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/517
https://github.com/scverse/scanpy/issues/518:34,deployability,instal,install,34,"They should if you call. ```. pip install scanpy[louvain] -U. ```. anndata will also update if you call. ```. pip install scanpy -U. ```. The fact that we have `[igraph]` and `[louvain]` not in the default install is that they take quite a while. If the docs are unclear about it, happy to have you point us to it: https://scanpy.readthedocs.io/en/latest/installation.html :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/518
https://github.com/scverse/scanpy/issues/518:85,deployability,updat,update,85,"They should if you call. ```. pip install scanpy[louvain] -U. ```. anndata will also update if you call. ```. pip install scanpy -U. ```. The fact that we have `[igraph]` and `[louvain]` not in the default install is that they take quite a while. If the docs are unclear about it, happy to have you point us to it: https://scanpy.readthedocs.io/en/latest/installation.html :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/518
https://github.com/scverse/scanpy/issues/518:114,deployability,instal,install,114,"They should if you call. ```. pip install scanpy[louvain] -U. ```. anndata will also update if you call. ```. pip install scanpy -U. ```. The fact that we have `[igraph]` and `[louvain]` not in the default install is that they take quite a while. If the docs are unclear about it, happy to have you point us to it: https://scanpy.readthedocs.io/en/latest/installation.html :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/518
https://github.com/scverse/scanpy/issues/518:206,deployability,instal,install,206,"They should if you call. ```. pip install scanpy[louvain] -U. ```. anndata will also update if you call. ```. pip install scanpy -U. ```. The fact that we have `[igraph]` and `[louvain]` not in the default install is that they take quite a while. If the docs are unclear about it, happy to have you point us to it: https://scanpy.readthedocs.io/en/latest/installation.html :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/518
https://github.com/scverse/scanpy/issues/518:355,deployability,instal,installation,355,"They should if you call. ```. pip install scanpy[louvain] -U. ```. anndata will also update if you call. ```. pip install scanpy -U. ```. The fact that we have `[igraph]` and `[louvain]` not in the default install is that they take quite a while. If the docs are unclear about it, happy to have you point us to it: https://scanpy.readthedocs.io/en/latest/installation.html :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/518
https://github.com/scverse/scanpy/issues/518:85,safety,updat,update,85,"They should if you call. ```. pip install scanpy[louvain] -U. ```. anndata will also update if you call. ```. pip install scanpy -U. ```. The fact that we have `[igraph]` and `[louvain]` not in the default install is that they take quite a while. If the docs are unclear about it, happy to have you point us to it: https://scanpy.readthedocs.io/en/latest/installation.html :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/518
https://github.com/scverse/scanpy/issues/518:85,security,updat,update,85,"They should if you call. ```. pip install scanpy[louvain] -U. ```. anndata will also update if you call. ```. pip install scanpy -U. ```. The fact that we have `[igraph]` and `[louvain]` not in the default install is that they take quite a while. If the docs are unclear about it, happy to have you point us to it: https://scanpy.readthedocs.io/en/latest/installation.html :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/518
https://github.com/scverse/scanpy/pull/519:711,availability,down,down-weighted,711,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:1244,availability,robust,robust,1244,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:191,deployability,log,log,191,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:210,deployability,log,log,210,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:351,deployability,log,log,351,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:367,deployability,log,log,367,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:384,deployability,log,log,384,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:1122,energy efficiency,estimat,estimator,1122,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:1244,reliability,robust,robust,1244,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:191,safety,log,log,191,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:210,safety,log,log,210,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:351,safety,log,log,351,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:367,safety,log,log,367,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:384,safety,log,log,384,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:466,safety,test,tests,466,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:1244,safety,robust,robust,1244,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:191,security,log,log,191,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:210,security,log,log,210,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:351,security,log,log,351,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:367,security,log,log,367,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:384,security,log,log,384,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:191,testability,log,log,191,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:210,testability,log,log,210,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:351,testability,log,log,351,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:367,testability,log,log,367,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:384,testability,log,log,384,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:466,testability,test,tests,466,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:124,usability,prefer,prefer,124,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:1091,usability,cancel,cancel,1091,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:1268,usability,prefer,prefer,1268,"Hey @a-munoz-rojas and @LuckyMD! Thank you for this! However, I think this adds a lot of code and computational burden. I'd prefer to make an approximation, which is similar to interchanging log mean with mean log. `x1` and `x2` are two arrays storing count values. ```. log2FC(x1, x2) = log2(mean(x1) / mean(x2)) = log2(mean(x1)) - log2(mean(x2)) = (log(mean(x1)) - log(mean(x1))) / log(2). ```. In Scanpy, we typically store `log1p(x)` in the data matrix. For the tests, we have already computed `mean(log1p(x))`. Hence, the following expression is a one-line edit. . ```. log2FCapprox = log2((expm1(mean(log1p(x1))) / expm1(mean(log1p(x2)))). ```. Obviously, this is an approximation; high values in `x` are down-weighted by virtue of computing a mean that's weighted with a `log1p`. The resulting `mean(log1p(x))` is therefore rigorously smaller than `log1p(mean(x))`; if you don't have a lot of outliers, then there will be little difference. If there is a lot of variance, there will be a difference. As one has the same effect both in the numerator and denominator, some of this will cancel out. Hence, one gets an estimator for ""effect strength"" (after all, this is what we are interested in, that is very similar to `log2FC`, but more robust to outliers. I'd prefer this, I have to admit, together with a note in the docs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:262,availability,error,error,262,"I reckon that's a fair consideration. In the end we don't use `sc.tl.rank_genes_groups()` for complex DE tests that require this amount of detail, but instead for marker gene calculations where it's mainly about ranking genes. It would be interesting to see the error of the approximation though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:262,performance,error,error,262,"I reckon that's a fair consideration. In the end we don't use `sc.tl.rank_genes_groups()` for complex DE tests that require this amount of detail, but instead for marker gene calculations where it's mainly about ranking genes. It would be interesting to see the error of the approximation though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:94,safety,compl,complex,94,"I reckon that's a fair consideration. In the end we don't use `sc.tl.rank_genes_groups()` for complex DE tests that require this amount of detail, but instead for marker gene calculations where it's mainly about ranking genes. It would be interesting to see the error of the approximation though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:105,safety,test,tests,105,"I reckon that's a fair consideration. In the end we don't use `sc.tl.rank_genes_groups()` for complex DE tests that require this amount of detail, but instead for marker gene calculations where it's mainly about ranking genes. It would be interesting to see the error of the approximation though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:262,safety,error,error,262,"I reckon that's a fair consideration. In the end we don't use `sc.tl.rank_genes_groups()` for complex DE tests that require this amount of detail, but instead for marker gene calculations where it's mainly about ranking genes. It would be interesting to see the error of the approximation though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:94,security,compl,complex,94,"I reckon that's a fair consideration. In the end we don't use `sc.tl.rank_genes_groups()` for complex DE tests that require this amount of detail, but instead for marker gene calculations where it's mainly about ranking genes. It would be interesting to see the error of the approximation though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:105,testability,test,tests,105,"I reckon that's a fair consideration. In the end we don't use `sc.tl.rank_genes_groups()` for complex DE tests that require this amount of detail, but instead for marker gene calculations where it's mainly about ranking genes. It would be interesting to see the error of the approximation though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:262,usability,error,error,262,"I reckon that's a fair consideration. In the end we don't use `sc.tl.rank_genes_groups()` for complex DE tests that require this amount of detail, but instead for marker gene calculations where it's mainly about ranking genes. It would be interesting to see the error of the approximation though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:203,availability,robust,robust,203,"Hey @falexwolf, thanks for your note. I apologize for the late reply - I was away at a conference and had little time to work on this. . I agree that this is a cleaner way of doing this and will be more robust to outliers, even if it's at the expense of the approximation. Like @LuckyMD mentioned, this function is generally used for more basic differential testing, so further exploration of differential expression can rely on more complicated downstream analysis. Out of curiosity, I'll also calculate what the error of the approximation is, just to have an idea. I'm a little limited in bandwidth at the moment, but this is an easy change that I should be able to implement this week. Sorry for the delay - I'll submit the changes soon!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:446,availability,down,downstream,446,"Hey @falexwolf, thanks for your note. I apologize for the late reply - I was away at a conference and had little time to work on this. . I agree that this is a cleaner way of doing this and will be more robust to outliers, even if it's at the expense of the approximation. Like @LuckyMD mentioned, this function is generally used for more basic differential testing, so further exploration of differential expression can rely on more complicated downstream analysis. Out of curiosity, I'll also calculate what the error of the approximation is, just to have an idea. I'm a little limited in bandwidth at the moment, but this is an easy change that I should be able to implement this week. Sorry for the delay - I'll submit the changes soon!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:514,availability,error,error,514,"Hey @falexwolf, thanks for your note. I apologize for the late reply - I was away at a conference and had little time to work on this. . I agree that this is a cleaner way of doing this and will be more robust to outliers, even if it's at the expense of the approximation. Like @LuckyMD mentioned, this function is generally used for more basic differential testing, so further exploration of differential expression can rely on more complicated downstream analysis. Out of curiosity, I'll also calculate what the error of the approximation is, just to have an idea. I'm a little limited in bandwidth at the moment, but this is an easy change that I should be able to implement this week. Sorry for the delay - I'll submit the changes soon!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:716,integrability,sub,submit,716,"Hey @falexwolf, thanks for your note. I apologize for the late reply - I was away at a conference and had little time to work on this. . I agree that this is a cleaner way of doing this and will be more robust to outliers, even if it's at the expense of the approximation. Like @LuckyMD mentioned, this function is generally used for more basic differential testing, so further exploration of differential expression can rely on more complicated downstream analysis. Out of curiosity, I'll also calculate what the error of the approximation is, just to have an idea. I'm a little limited in bandwidth at the moment, but this is an easy change that I should be able to implement this week. Sorry for the delay - I'll submit the changes soon!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:113,performance,time,time,113,"Hey @falexwolf, thanks for your note. I apologize for the late reply - I was away at a conference and had little time to work on this. . I agree that this is a cleaner way of doing this and will be more robust to outliers, even if it's at the expense of the approximation. Like @LuckyMD mentioned, this function is generally used for more basic differential testing, so further exploration of differential expression can rely on more complicated downstream analysis. Out of curiosity, I'll also calculate what the error of the approximation is, just to have an idea. I'm a little limited in bandwidth at the moment, but this is an easy change that I should be able to implement this week. Sorry for the delay - I'll submit the changes soon!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:514,performance,error,error,514,"Hey @falexwolf, thanks for your note. I apologize for the late reply - I was away at a conference and had little time to work on this. . I agree that this is a cleaner way of doing this and will be more robust to outliers, even if it's at the expense of the approximation. Like @LuckyMD mentioned, this function is generally used for more basic differential testing, so further exploration of differential expression can rely on more complicated downstream analysis. Out of curiosity, I'll also calculate what the error of the approximation is, just to have an idea. I'm a little limited in bandwidth at the moment, but this is an easy change that I should be able to implement this week. Sorry for the delay - I'll submit the changes soon!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:203,reliability,robust,robust,203,"Hey @falexwolf, thanks for your note. I apologize for the late reply - I was away at a conference and had little time to work on this. . I agree that this is a cleaner way of doing this and will be more robust to outliers, even if it's at the expense of the approximation. Like @LuckyMD mentioned, this function is generally used for more basic differential testing, so further exploration of differential expression can rely on more complicated downstream analysis. Out of curiosity, I'll also calculate what the error of the approximation is, just to have an idea. I'm a little limited in bandwidth at the moment, but this is an easy change that I should be able to implement this week. Sorry for the delay - I'll submit the changes soon!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:203,safety,robust,robust,203,"Hey @falexwolf, thanks for your note. I apologize for the late reply - I was away at a conference and had little time to work on this. . I agree that this is a cleaner way of doing this and will be more robust to outliers, even if it's at the expense of the approximation. Like @LuckyMD mentioned, this function is generally used for more basic differential testing, so further exploration of differential expression can rely on more complicated downstream analysis. Out of curiosity, I'll also calculate what the error of the approximation is, just to have an idea. I'm a little limited in bandwidth at the moment, but this is an easy change that I should be able to implement this week. Sorry for the delay - I'll submit the changes soon!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:358,safety,test,testing,358,"Hey @falexwolf, thanks for your note. I apologize for the late reply - I was away at a conference and had little time to work on this. . I agree that this is a cleaner way of doing this and will be more robust to outliers, even if it's at the expense of the approximation. Like @LuckyMD mentioned, this function is generally used for more basic differential testing, so further exploration of differential expression can rely on more complicated downstream analysis. Out of curiosity, I'll also calculate what the error of the approximation is, just to have an idea. I'm a little limited in bandwidth at the moment, but this is an easy change that I should be able to implement this week. Sorry for the delay - I'll submit the changes soon!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:434,safety,compl,complicated,434,"Hey @falexwolf, thanks for your note. I apologize for the late reply - I was away at a conference and had little time to work on this. . I agree that this is a cleaner way of doing this and will be more robust to outliers, even if it's at the expense of the approximation. Like @LuckyMD mentioned, this function is generally used for more basic differential testing, so further exploration of differential expression can rely on more complicated downstream analysis. Out of curiosity, I'll also calculate what the error of the approximation is, just to have an idea. I'm a little limited in bandwidth at the moment, but this is an easy change that I should be able to implement this week. Sorry for the delay - I'll submit the changes soon!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:514,safety,error,error,514,"Hey @falexwolf, thanks for your note. I apologize for the late reply - I was away at a conference and had little time to work on this. . I agree that this is a cleaner way of doing this and will be more robust to outliers, even if it's at the expense of the approximation. Like @LuckyMD mentioned, this function is generally used for more basic differential testing, so further exploration of differential expression can rely on more complicated downstream analysis. Out of curiosity, I'll also calculate what the error of the approximation is, just to have an idea. I'm a little limited in bandwidth at the moment, but this is an easy change that I should be able to implement this week. Sorry for the delay - I'll submit the changes soon!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:434,security,compl,complicated,434,"Hey @falexwolf, thanks for your note. I apologize for the late reply - I was away at a conference and had little time to work on this. . I agree that this is a cleaner way of doing this and will be more robust to outliers, even if it's at the expense of the approximation. Like @LuckyMD mentioned, this function is generally used for more basic differential testing, so further exploration of differential expression can rely on more complicated downstream analysis. Out of curiosity, I'll also calculate what the error of the approximation is, just to have an idea. I'm a little limited in bandwidth at the moment, but this is an easy change that I should be able to implement this week. Sorry for the delay - I'll submit the changes soon!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:358,testability,test,testing,358,"Hey @falexwolf, thanks for your note. I apologize for the late reply - I was away at a conference and had little time to work on this. . I agree that this is a cleaner way of doing this and will be more robust to outliers, even if it's at the expense of the approximation. Like @LuckyMD mentioned, this function is generally used for more basic differential testing, so further exploration of differential expression can rely on more complicated downstream analysis. Out of curiosity, I'll also calculate what the error of the approximation is, just to have an idea. I'm a little limited in bandwidth at the moment, but this is an easy change that I should be able to implement this week. Sorry for the delay - I'll submit the changes soon!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:514,usability,error,error,514,"Hey @falexwolf, thanks for your note. I apologize for the late reply - I was away at a conference and had little time to work on this. . I agree that this is a cleaner way of doing this and will be more robust to outliers, even if it's at the expense of the approximation. Like @LuckyMD mentioned, this function is generally used for more basic differential testing, so further exploration of differential expression can rely on more complicated downstream analysis. Out of curiosity, I'll also calculate what the error of the approximation is, just to have an idea. I'm a little limited in bandwidth at the moment, but this is an easy change that I should be able to implement this week. Sorry for the delay - I'll submit the changes soon!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:122,availability,error,error,122,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:385,availability,error,error,385,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:421,availability,error,error,421,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:520,availability,error,error,520,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:59,deployability,version,version,59,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:225,deployability,log,log,225,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:243,deployability,log,log-mean,243,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:209,energy efficiency,estimat,estimated,209,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:59,integrability,version,version,59,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:59,modifiability,version,version,59,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:122,performance,error,error,122,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:385,performance,error,error,385,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:421,performance,error,error,421,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:520,performance,error,error,520,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:122,safety,error,error,122,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:225,safety,log,log,225,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:243,safety,log,log-mean,243,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:385,safety,error,error,385,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:421,safety,error,error,421,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:520,safety,error,error,520,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:225,security,log,log,225,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:243,security,log,log-mean,243,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:225,testability,log,log,225,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:243,testability,log,log-mean,243,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:122,usability,error,error,122,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:154,usability,close,close,154,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:385,usability,error,error,385,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:421,usability,error,error,421,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:520,usability,error,error,520,"Hey, sorry for the delayed response. I just pushed the new version with the changes we discussed. I also checked what the error looked like - it's pretty close for most of the cases (I'm attaching a plot with estimated (mean-log) vs ""actual"" (log-mean) fold changes - as expected, only in the extremes do we start to get a little bit of an underestimation. In my dataset, I got a mean error of about 3%, with the largest error seen in genes with extreme outliers as we expected (the attached violin plot has the largest error, ~70% lower. . [test_meanlogerror.pdf](https://github.com/theislab/scanpy/files/3000658/test_meanlogerror.pdf). [violintest_outlier.pdf](https://github.com/theislab/scanpy/files/3000659/violintest_outlier.pdf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:62,usability,user,user,62,@a-munoz-rojas I'm getting the following warning:. ```. /home/user/Code/scanpy/scanpy/tools/_rank_genes_groups.py:203: RuntimeWarning: overflow encountered in expm1. foldchanges = (np.expm1(means[igroup]) + 1e-9) / (np.expm1(mean_rest) + 1e-9) #add small value to remove 0's. ```. Any ideas?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:86,usability,tool,tools,86,@a-munoz-rojas I'm getting the following warning:. ```. /home/user/Code/scanpy/scanpy/tools/_rank_genes_groups.py:203: RuntimeWarning: overflow encountered in expm1. foldchanges = (np.expm1(means[igroup]) + 1e-9) / (np.expm1(mean_rest) + 1e-9) #add small value to remove 0's. ```. Any ideas?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:33,usability,user,user,33,Here is another one:. ```. /home/user/Code/scanpy/scanpy/tools/_rank_genes_groups.py:203: RuntimeWarning: invalid value encountered in true_divide. foldchanges = (np.expm1(means[igroup]) + 1e-9) / (np.expm1(mean_rest) + 1e-9) #add small value to remove 0's. ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:57,usability,tool,tools,57,Here is another one:. ```. /home/user/Code/scanpy/scanpy/tools/_rank_genes_groups.py:203: RuntimeWarning: invalid value encountered in true_divide. foldchanges = (np.expm1(means[igroup]) + 1e-9) / (np.expm1(mean_rest) + 1e-9) #add small value to remove 0's. ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:28,modifiability,paramet,parameter,28,Also `log_transformed=True` parameter is not listed in the documentation.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:59,usability,document,documentation,59,Also `log_transformed=True` parameter is not listed in the documentation.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:148,deployability,Depend,Depending,148,"`log_transformed` disappeared in the last commit here... Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Also: If trying to call a t-test with non-logarithmized data, a warning should be written. The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:264,deployability,log,logarithmized,264,"`log_transformed` disappeared in the last commit here... Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Also: If trying to call a t-test with non-logarithmized data, a warning should be written. The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:364,deployability,log,logarithmized,364,"`log_transformed` disappeared in the last commit here... Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Also: If trying to call a t-test with non-logarithmized data, a warning should be written. The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:148,integrability,Depend,Depending,148,"`log_transformed` disappeared in the last commit here... Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Also: If trying to call a t-test with non-logarithmized data, a warning should be written. The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:148,modifiability,Depend,Depending,148,"`log_transformed` disappeared in the last commit here... Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Also: If trying to call a t-test with non-logarithmized data, a warning should be written. The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:148,safety,Depend,Depending,148,"`log_transformed` disappeared in the last commit here... Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Also: If trying to call a t-test with non-logarithmized data, a warning should be written. The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:250,safety,test,test,250,"`log_transformed` disappeared in the last commit here... Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Also: If trying to call a t-test with non-logarithmized data, a warning should be written. The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:264,safety,log,logarithmized,264,"`log_transformed` disappeared in the last commit here... Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Also: If trying to call a t-test with non-logarithmized data, a warning should be written. The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:364,safety,log,logarithmized,364,"`log_transformed` disappeared in the last commit here... Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Also: If trying to call a t-test with non-logarithmized data, a warning should be written. The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:264,security,log,logarithmized,264,"`log_transformed` disappeared in the last commit here... Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Also: If trying to call a t-test with non-logarithmized data, a warning should be written. The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:364,security,log,logarithmized,364,"`log_transformed` disappeared in the last commit here... Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Also: If trying to call a t-test with non-logarithmized data, a warning should be written. The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:117,testability,simpl,simply,117,"`log_transformed` disappeared in the last commit here... Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Also: If trying to call a t-test with non-logarithmized data, a warning should be written. The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:148,testability,Depend,Depending,148,"`log_transformed` disappeared in the last commit here... Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Also: If trying to call a t-test with non-logarithmized data, a warning should be written. The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:250,testability,test,test,250,"`log_transformed` disappeared in the last commit here... Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Also: If trying to call a t-test with non-logarithmized data, a warning should be written. The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:264,testability,log,logarithmized,264,"`log_transformed` disappeared in the last commit here... Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Also: If trying to call a t-test with non-logarithmized data, a warning should be written. The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:364,testability,log,logarithmized,364,"`log_transformed` disappeared in the last commit here... Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Also: If trying to call a t-test with non-logarithmized data, a warning should be written. The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:117,usability,simpl,simply,117,"`log_transformed` disappeared in the last commit here... Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Also: If trying to call a t-test with non-logarithmized data, a warning should be written. The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:93,deployability,Depend,Depending,93,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > . > Also: If trying to call a t-test with non-logarithmized data, a warning should be written. > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen? Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:228,deployability,log,logarithmized,228,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > . > Also: If trying to call a t-test with non-logarithmized data, a warning should be written. > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen? Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:346,deployability,log,logarithmized,346,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > . > Also: If trying to call a t-test with non-logarithmized data, a warning should be written. > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen? Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:393,deployability,log,log,393,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > . > Also: If trying to call a t-test with non-logarithmized data, a warning should be written. > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen? Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:93,integrability,Depend,Depending,93,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > . > Also: If trying to call a t-test with non-logarithmized data, a warning should be written. > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen? Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:397,integrability,transform,transformed,397,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > . > Also: If trying to call a t-test with non-logarithmized data, a warning should be written. > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen? Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:397,interoperability,transform,transformed,397,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > . > Also: If trying to call a t-test with non-logarithmized data, a warning should be written. > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen? Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:93,modifiability,Depend,Depending,93,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > . > Also: If trying to call a t-test with non-logarithmized data, a warning should be written. > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen? Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:93,safety,Depend,Depending,93,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > . > Also: If trying to call a t-test with non-logarithmized data, a warning should be written. > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen? Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:214,safety,test,test,214,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > . > Also: If trying to call a t-test with non-logarithmized data, a warning should be written. > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen? Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:228,safety,log,logarithmized,228,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > . > Also: If trying to call a t-test with non-logarithmized data, a warning should be written. > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen? Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:346,safety,log,logarithmized,346,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > . > Also: If trying to call a t-test with non-logarithmized data, a warning should be written. > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen? Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:393,safety,log,log,393,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > . > Also: If trying to call a t-test with non-logarithmized data, a warning should be written. > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen? Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:228,security,log,logarithmized,228,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > . > Also: If trying to call a t-test with non-logarithmized data, a warning should be written. > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen? Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:346,security,log,logarithmized,346,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > . > Also: If trying to call a t-test with non-logarithmized data, a warning should be written. > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen? Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:393,security,log,log,393,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > . > Also: If trying to call a t-test with non-logarithmized data, a warning should be written. > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen? Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:62,testability,simpl,simply,62,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > . > Also: If trying to call a t-test with non-logarithmized data, a warning should be written. > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen? Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:93,testability,Depend,Depending,93,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > . > Also: If trying to call a t-test with non-logarithmized data, a warning should be written. > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen? Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:214,testability,test,test,214,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > . > Also: If trying to call a t-test with non-logarithmized data, a warning should be written. > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen? Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:228,testability,log,logarithmized,228,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > . > Also: If trying to call a t-test with non-logarithmized data, a warning should be written. > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen? Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:346,testability,log,logarithmized,346,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > . > Also: If trying to call a t-test with non-logarithmized data, a warning should be written. > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen? Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:393,testability,log,log,393,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > . > Also: If trying to call a t-test with non-logarithmized data, a warning should be written. > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen? Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:62,usability,simpl,simply,62,"> Better: `pp.log1p` should write an attribute to `.uns`, say simply `.uns['log1p'] = True`. Depending on that attribute, log2fc is computed by rexponaniating or not. Fully agree. > . > Also: If trying to call a t-test with non-logarithmized data, a warning should be written. > . Also agree. > The overflow and 0 warnings: are you sure you used logarithmized data, Gökcen? Oh true, it wasn't log transformed, true.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:32,deployability,log,log-transformed,32,"Ok, good to read that it wasn't log-transformed! @Koncopd, could you quickly implement these simple changes? Before continuing to work on the UMAP? These simple changes are for 1.4.1, the UMAP will be for 1.5. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:116,deployability,continu,continuing,116,"Ok, good to read that it wasn't log-transformed! @Koncopd, could you quickly implement these simple changes? Before continuing to work on the UMAP? These simple changes are for 1.4.1, the UMAP will be for 1.5. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:36,integrability,transform,transformed,36,"Ok, good to read that it wasn't log-transformed! @Koncopd, could you quickly implement these simple changes? Before continuing to work on the UMAP? These simple changes are for 1.4.1, the UMAP will be for 1.5. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:36,interoperability,transform,transformed,36,"Ok, good to read that it wasn't log-transformed! @Koncopd, could you quickly implement these simple changes? Before continuing to work on the UMAP? These simple changes are for 1.4.1, the UMAP will be for 1.5. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:32,safety,log,log-transformed,32,"Ok, good to read that it wasn't log-transformed! @Koncopd, could you quickly implement these simple changes? Before continuing to work on the UMAP? These simple changes are for 1.4.1, the UMAP will be for 1.5. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:32,security,log,log-transformed,32,"Ok, good to read that it wasn't log-transformed! @Koncopd, could you quickly implement these simple changes? Before continuing to work on the UMAP? These simple changes are for 1.4.1, the UMAP will be for 1.5. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:32,testability,log,log-transformed,32,"Ok, good to read that it wasn't log-transformed! @Koncopd, could you quickly implement these simple changes? Before continuing to work on the UMAP? These simple changes are for 1.4.1, the UMAP will be for 1.5. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:93,testability,simpl,simple,93,"Ok, good to read that it wasn't log-transformed! @Koncopd, could you quickly implement these simple changes? Before continuing to work on the UMAP? These simple changes are for 1.4.1, the UMAP will be for 1.5. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:154,testability,simpl,simple,154,"Ok, good to read that it wasn't log-transformed! @Koncopd, could you quickly implement these simple changes? Before continuing to work on the UMAP? These simple changes are for 1.4.1, the UMAP will be for 1.5. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:93,usability,simpl,simple,93,"Ok, good to read that it wasn't log-transformed! @Koncopd, could you quickly implement these simple changes? Before continuing to work on the UMAP? These simple changes are for 1.4.1, the UMAP will be for 1.5. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/pull/519:154,usability,simpl,simple,154,"Ok, good to read that it wasn't log-transformed! @Koncopd, could you quickly implement these simple changes? Before continuing to work on the UMAP? These simple changes are for 1.4.1, the UMAP will be for 1.5. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/519
https://github.com/scverse/scanpy/issues/520:40,performance,time,time,40,"I can help with that, too. I spent some time with scvi recently.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/520
https://github.com/scverse/scanpy/issues/520:6,usability,help,help,6,"I can help with that, too. I spent some time with scvi recently.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/520
https://github.com/scverse/scanpy/issues/520:22,deployability,integr,integration,22,I'd love to have scVI integration! :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/520
https://github.com/scverse/scanpy/issues/520:22,integrability,integr,integration,22,I'd love to have scVI integration! :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/520
https://github.com/scverse/scanpy/issues/520:22,interoperability,integr,integration,22,I'd love to have scVI integration! :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/520
https://github.com/scverse/scanpy/issues/520:22,modifiability,integr,integration,22,I'd love to have scVI integration! :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/520
https://github.com/scverse/scanpy/issues/520:22,reliability,integr,integration,22,I'd love to have scVI integration! :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/520
https://github.com/scverse/scanpy/issues/520:22,security,integr,integration,22,I'd love to have scVI integration! :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/520
https://github.com/scverse/scanpy/issues/520:22,testability,integr,integration,22,I'd love to have scVI integration! :),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/520
https://github.com/scverse/scanpy/issues/520:49,deployability,integr,integration,49,We have SCVI working on anndata objects for data integration in our benchmarking study.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/520
https://github.com/scverse/scanpy/issues/520:49,integrability,integr,integration,49,We have SCVI working on anndata objects for data integration in our benchmarking study.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/520
https://github.com/scverse/scanpy/issues/520:49,interoperability,integr,integration,49,We have SCVI working on anndata objects for data integration in our benchmarking study.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/520
https://github.com/scverse/scanpy/issues/520:49,modifiability,integr,integration,49,We have SCVI working on anndata objects for data integration in our benchmarking study.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/520
https://github.com/scverse/scanpy/issues/520:49,reliability,integr,integration,49,We have SCVI working on anndata objects for data integration in our benchmarking study.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/520
https://github.com/scverse/scanpy/issues/520:49,security,integr,integration,49,We have SCVI working on anndata objects for data integration in our benchmarking study.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/520
https://github.com/scverse/scanpy/issues/520:49,testability,integr,integration,49,We have SCVI working on anndata objects for data integration in our benchmarking study.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/520
https://github.com/scverse/scanpy/issues/521:250,availability,cluster,clusters,250,In principle the scatter plot and the the heatmap use the same colors. See for example: https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html#Heatmaps . The colors on the left are the same colors stored for the scatter plot clusters.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/521
https://github.com/scverse/scanpy/issues/521:250,deployability,cluster,clusters,250,In principle the scatter plot and the the heatmap use the same colors. See for example: https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html#Heatmaps . The colors on the left are the same colors stored for the scatter plot clusters.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/521
https://github.com/scverse/scanpy/issues/521:42,energy efficiency,heat,heatmap,42,In principle the scatter plot and the the heatmap use the same colors. See for example: https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html#Heatmaps . The colors on the left are the same colors stored for the scatter plot clusters.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/521
https://github.com/scverse/scanpy/issues/521:168,energy efficiency,Heat,Heatmaps,168,In principle the scatter plot and the the heatmap use the same colors. See for example: https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html#Heatmaps . The colors on the left are the same colors stored for the scatter plot clusters.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/521
https://github.com/scverse/scanpy/issues/521:138,usability,visual,visualizing-marker-genes,138,In principle the scatter plot and the the heatmap use the same colors. See for example: https://scanpy-tutorials.readthedocs.io/en/latest/visualizing-marker-genes.html#Heatmaps . The colors on the left are the same colors stored for the scatter plot clusters.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/521
https://github.com/scverse/scanpy/issues/521:16,deployability,continu,continuous,16,"If the issue is continuous color maps, that can be specified with the `cmap` parameter.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/521
https://github.com/scverse/scanpy/issues/521:51,interoperability,specif,specified,51,"If the issue is continuous color maps, that can be specified with the `cmap` parameter.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/521
https://github.com/scverse/scanpy/issues/521:77,modifiability,paramet,parameter,77,"If the issue is continuous color maps, that can be specified with the `cmap` parameter.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/521
https://github.com/scverse/scanpy/issues/522:39,availability,avail,available,39,"There might be couple of things that's available in umap but not in pynndescent such as sparse matrix support https://github.com/lmcinnes/pynndescent/issues/6 Since we typically use PCs, it's mostly fine. But in cases where users do sc.pp.neighbors(., use_rep=""X"") with a sparse adata.X this can be a problem. My 2 cents 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:15,integrability,coupl,couple,15,"There might be couple of things that's available in umap but not in pynndescent such as sparse matrix support https://github.com/lmcinnes/pynndescent/issues/6 Since we typically use PCs, it's mostly fine. But in cases where users do sc.pp.neighbors(., use_rep=""X"") with a sparse adata.X this can be a problem. My 2 cents 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:15,modifiability,coupl,couple,15,"There might be couple of things that's available in umap but not in pynndescent such as sparse matrix support https://github.com/lmcinnes/pynndescent/issues/6 Since we typically use PCs, it's mostly fine. But in cases where users do sc.pp.neighbors(., use_rep=""X"") with a sparse adata.X this can be a problem. My 2 cents 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:39,reliability,availab,available,39,"There might be couple of things that's available in umap but not in pynndescent such as sparse matrix support https://github.com/lmcinnes/pynndescent/issues/6 Since we typically use PCs, it's mostly fine. But in cases where users do sc.pp.neighbors(., use_rep=""X"") with a sparse adata.X this can be a problem. My 2 cents 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:39,safety,avail,available,39,"There might be couple of things that's available in umap but not in pynndescent such as sparse matrix support https://github.com/lmcinnes/pynndescent/issues/6 Since we typically use PCs, it's mostly fine. But in cases where users do sc.pp.neighbors(., use_rep=""X"") with a sparse adata.X this can be a problem. My 2 cents 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:39,security,availab,available,39,"There might be couple of things that's available in umap but not in pynndescent such as sparse matrix support https://github.com/lmcinnes/pynndescent/issues/6 Since we typically use PCs, it's mostly fine. But in cases where users do sc.pp.neighbors(., use_rep=""X"") with a sparse adata.X this can be a problem. My 2 cents 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:15,testability,coupl,couple,15,"There might be couple of things that's available in umap but not in pynndescent such as sparse matrix support https://github.com/lmcinnes/pynndescent/issues/6 Since we typically use PCs, it's mostly fine. But in cases where users do sc.pp.neighbors(., use_rep=""X"") with a sparse adata.X this can be a problem. My 2 cents 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:102,usability,support,support,102,"There might be couple of things that's available in umap but not in pynndescent such as sparse matrix support https://github.com/lmcinnes/pynndescent/issues/6 Since we typically use PCs, it's mostly fine. But in cases where users do sc.pp.neighbors(., use_rep=""X"") with a sparse adata.X this can be a problem. My 2 cents 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:224,usability,user,users,224,"There might be couple of things that's available in umap but not in pynndescent such as sparse matrix support https://github.com/lmcinnes/pynndescent/issues/6 Since we typically use PCs, it's mostly fine. But in cases where users do sc.pp.neighbors(., use_rep=""X"") with a sparse adata.X this can be a problem. My 2 cents 😊",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:166,deployability,depend,depend,166,"Thanks for tackling this one @falexwolf. I didn't realise until recently that umap has a copy of pynndescent too. However, I think it would be possible for scanpy to depend on both umap and pynndescent packages, and use the latter for generating the knn graph directly. This would mean new features in pynndescent (like the threading support) could be used from scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:166,integrability,depend,depend,166,"Thanks for tackling this one @falexwolf. I didn't realise until recently that umap has a copy of pynndescent too. However, I think it would be possible for scanpy to depend on both umap and pynndescent packages, and use the latter for generating the knn graph directly. This would mean new features in pynndescent (like the threading support) could be used from scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:166,modifiability,depend,depend,166,"Thanks for tackling this one @falexwolf. I didn't realise until recently that umap has a copy of pynndescent too. However, I think it would be possible for scanpy to depend on both umap and pynndescent packages, and use the latter for generating the knn graph directly. This would mean new features in pynndescent (like the threading support) could be used from scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:202,modifiability,pac,packages,202,"Thanks for tackling this one @falexwolf. I didn't realise until recently that umap has a copy of pynndescent too. However, I think it would be possible for scanpy to depend on both umap and pynndescent packages, and use the latter for generating the knn graph directly. This would mean new features in pynndescent (like the threading support) could be used from scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:166,safety,depend,depend,166,"Thanks for tackling this one @falexwolf. I didn't realise until recently that umap has a copy of pynndescent too. However, I think it would be possible for scanpy to depend on both umap and pynndescent packages, and use the latter for generating the knn graph directly. This would mean new features in pynndescent (like the threading support) could be used from scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:166,testability,depend,depend,166,"Thanks for tackling this one @falexwolf. I didn't realise until recently that umap has a copy of pynndescent too. However, I think it would be possible for scanpy to depend on both umap and pynndescent packages, and use the latter for generating the knn graph directly. This would mean new features in pynndescent (like the threading support) could be used from scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:334,usability,support,support,334,"Thanks for tackling this one @falexwolf. I didn't realise until recently that umap has a copy of pynndescent too. However, I think it would be possible for scanpy to depend on both umap and pynndescent packages, and use the latter for generating the knn graph directly. This would mean new features in pynndescent (like the threading support) could be used from scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:106,deployability,updat,updates,106,"@Koncopd, could we have a meeting or VC on the progress here? Let's discuss via email. 🙂 . @tomwhite, any updates from @lmcinnes regarding integrating the distributed version of `pynndescent` into UMAP itself? I'm not 100% convinced to mingle with private functions within UMAP that might eventually break (another reason for why I copied over code from UMAP back in January/February 2018). It would be nice to have Leland's OK for adding distributed aspects to the package. Scanpy would then just make use of them... @tomwhite, by this, also many other single-cell packages (many of them use UMAP these days) would profit from the new distributed computing capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:139,deployability,integr,integrating,139,"@Koncopd, could we have a meeting or VC on the progress here? Let's discuss via email. 🙂 . @tomwhite, any updates from @lmcinnes regarding integrating the distributed version of `pynndescent` into UMAP itself? I'm not 100% convinced to mingle with private functions within UMAP that might eventually break (another reason for why I copied over code from UMAP back in January/February 2018). It would be nice to have Leland's OK for adding distributed aspects to the package. Scanpy would then just make use of them... @tomwhite, by this, also many other single-cell packages (many of them use UMAP these days) would profit from the new distributed computing capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:167,deployability,version,version,167,"@Koncopd, could we have a meeting or VC on the progress here? Let's discuss via email. 🙂 . @tomwhite, any updates from @lmcinnes regarding integrating the distributed version of `pynndescent` into UMAP itself? I'm not 100% convinced to mingle with private functions within UMAP that might eventually break (another reason for why I copied over code from UMAP back in January/February 2018). It would be nice to have Leland's OK for adding distributed aspects to the package. Scanpy would then just make use of them... @tomwhite, by this, also many other single-cell packages (many of them use UMAP these days) would profit from the new distributed computing capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:139,integrability,integr,integrating,139,"@Koncopd, could we have a meeting or VC on the progress here? Let's discuss via email. 🙂 . @tomwhite, any updates from @lmcinnes regarding integrating the distributed version of `pynndescent` into UMAP itself? I'm not 100% convinced to mingle with private functions within UMAP that might eventually break (another reason for why I copied over code from UMAP back in January/February 2018). It would be nice to have Leland's OK for adding distributed aspects to the package. Scanpy would then just make use of them... @tomwhite, by this, also many other single-cell packages (many of them use UMAP these days) would profit from the new distributed computing capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:167,integrability,version,version,167,"@Koncopd, could we have a meeting or VC on the progress here? Let's discuss via email. 🙂 . @tomwhite, any updates from @lmcinnes regarding integrating the distributed version of `pynndescent` into UMAP itself? I'm not 100% convinced to mingle with private functions within UMAP that might eventually break (another reason for why I copied over code from UMAP back in January/February 2018). It would be nice to have Leland's OK for adding distributed aspects to the package. Scanpy would then just make use of them... @tomwhite, by this, also many other single-cell packages (many of them use UMAP these days) would profit from the new distributed computing capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:289,integrability,event,eventually,289,"@Koncopd, could we have a meeting or VC on the progress here? Let's discuss via email. 🙂 . @tomwhite, any updates from @lmcinnes regarding integrating the distributed version of `pynndescent` into UMAP itself? I'm not 100% convinced to mingle with private functions within UMAP that might eventually break (another reason for why I copied over code from UMAP back in January/February 2018). It would be nice to have Leland's OK for adding distributed aspects to the package. Scanpy would then just make use of them... @tomwhite, by this, also many other single-cell packages (many of them use UMAP these days) would profit from the new distributed computing capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:139,interoperability,integr,integrating,139,"@Koncopd, could we have a meeting or VC on the progress here? Let's discuss via email. 🙂 . @tomwhite, any updates from @lmcinnes regarding integrating the distributed version of `pynndescent` into UMAP itself? I'm not 100% convinced to mingle with private functions within UMAP that might eventually break (another reason for why I copied over code from UMAP back in January/February 2018). It would be nice to have Leland's OK for adding distributed aspects to the package. Scanpy would then just make use of them... @tomwhite, by this, also many other single-cell packages (many of them use UMAP these days) would profit from the new distributed computing capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:155,interoperability,distribut,distributed,155,"@Koncopd, could we have a meeting or VC on the progress here? Let's discuss via email. 🙂 . @tomwhite, any updates from @lmcinnes regarding integrating the distributed version of `pynndescent` into UMAP itself? I'm not 100% convinced to mingle with private functions within UMAP that might eventually break (another reason for why I copied over code from UMAP back in January/February 2018). It would be nice to have Leland's OK for adding distributed aspects to the package. Scanpy would then just make use of them... @tomwhite, by this, also many other single-cell packages (many of them use UMAP these days) would profit from the new distributed computing capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:439,interoperability,distribut,distributed,439,"@Koncopd, could we have a meeting or VC on the progress here? Let's discuss via email. 🙂 . @tomwhite, any updates from @lmcinnes regarding integrating the distributed version of `pynndescent` into UMAP itself? I'm not 100% convinced to mingle with private functions within UMAP that might eventually break (another reason for why I copied over code from UMAP back in January/February 2018). It would be nice to have Leland's OK for adding distributed aspects to the package. Scanpy would then just make use of them... @tomwhite, by this, also many other single-cell packages (many of them use UMAP these days) would profit from the new distributed computing capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:636,interoperability,distribut,distributed,636,"@Koncopd, could we have a meeting or VC on the progress here? Let's discuss via email. 🙂 . @tomwhite, any updates from @lmcinnes regarding integrating the distributed version of `pynndescent` into UMAP itself? I'm not 100% convinced to mingle with private functions within UMAP that might eventually break (another reason for why I copied over code from UMAP back in January/February 2018). It would be nice to have Leland's OK for adding distributed aspects to the package. Scanpy would then just make use of them... @tomwhite, by this, also many other single-cell packages (many of them use UMAP these days) would profit from the new distributed computing capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:139,modifiability,integr,integrating,139,"@Koncopd, could we have a meeting or VC on the progress here? Let's discuss via email. 🙂 . @tomwhite, any updates from @lmcinnes regarding integrating the distributed version of `pynndescent` into UMAP itself? I'm not 100% convinced to mingle with private functions within UMAP that might eventually break (another reason for why I copied over code from UMAP back in January/February 2018). It would be nice to have Leland's OK for adding distributed aspects to the package. Scanpy would then just make use of them... @tomwhite, by this, also many other single-cell packages (many of them use UMAP these days) would profit from the new distributed computing capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:167,modifiability,version,version,167,"@Koncopd, could we have a meeting or VC on the progress here? Let's discuss via email. 🙂 . @tomwhite, any updates from @lmcinnes regarding integrating the distributed version of `pynndescent` into UMAP itself? I'm not 100% convinced to mingle with private functions within UMAP that might eventually break (another reason for why I copied over code from UMAP back in January/February 2018). It would be nice to have Leland's OK for adding distributed aspects to the package. Scanpy would then just make use of them... @tomwhite, by this, also many other single-cell packages (many of them use UMAP these days) would profit from the new distributed computing capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:466,modifiability,pac,package,466,"@Koncopd, could we have a meeting or VC on the progress here? Let's discuss via email. 🙂 . @tomwhite, any updates from @lmcinnes regarding integrating the distributed version of `pynndescent` into UMAP itself? I'm not 100% convinced to mingle with private functions within UMAP that might eventually break (another reason for why I copied over code from UMAP back in January/February 2018). It would be nice to have Leland's OK for adding distributed aspects to the package. Scanpy would then just make use of them... @tomwhite, by this, also many other single-cell packages (many of them use UMAP these days) would profit from the new distributed computing capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:566,modifiability,pac,packages,566,"@Koncopd, could we have a meeting or VC on the progress here? Let's discuss via email. 🙂 . @tomwhite, any updates from @lmcinnes regarding integrating the distributed version of `pynndescent` into UMAP itself? I'm not 100% convinced to mingle with private functions within UMAP that might eventually break (another reason for why I copied over code from UMAP back in January/February 2018). It would be nice to have Leland's OK for adding distributed aspects to the package. Scanpy would then just make use of them... @tomwhite, by this, also many other single-cell packages (many of them use UMAP these days) would profit from the new distributed computing capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:139,reliability,integr,integrating,139,"@Koncopd, could we have a meeting or VC on the progress here? Let's discuss via email. 🙂 . @tomwhite, any updates from @lmcinnes regarding integrating the distributed version of `pynndescent` into UMAP itself? I'm not 100% convinced to mingle with private functions within UMAP that might eventually break (another reason for why I copied over code from UMAP back in January/February 2018). It would be nice to have Leland's OK for adding distributed aspects to the package. Scanpy would then just make use of them... @tomwhite, by this, also many other single-cell packages (many of them use UMAP these days) would profit from the new distributed computing capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:106,safety,updat,updates,106,"@Koncopd, could we have a meeting or VC on the progress here? Let's discuss via email. 🙂 . @tomwhite, any updates from @lmcinnes regarding integrating the distributed version of `pynndescent` into UMAP itself? I'm not 100% convinced to mingle with private functions within UMAP that might eventually break (another reason for why I copied over code from UMAP back in January/February 2018). It would be nice to have Leland's OK for adding distributed aspects to the package. Scanpy would then just make use of them... @tomwhite, by this, also many other single-cell packages (many of them use UMAP these days) would profit from the new distributed computing capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:106,security,updat,updates,106,"@Koncopd, could we have a meeting or VC on the progress here? Let's discuss via email. 🙂 . @tomwhite, any updates from @lmcinnes regarding integrating the distributed version of `pynndescent` into UMAP itself? I'm not 100% convinced to mingle with private functions within UMAP that might eventually break (another reason for why I copied over code from UMAP back in January/February 2018). It would be nice to have Leland's OK for adding distributed aspects to the package. Scanpy would then just make use of them... @tomwhite, by this, also many other single-cell packages (many of them use UMAP these days) would profit from the new distributed computing capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:139,security,integr,integrating,139,"@Koncopd, could we have a meeting or VC on the progress here? Let's discuss via email. 🙂 . @tomwhite, any updates from @lmcinnes regarding integrating the distributed version of `pynndescent` into UMAP itself? I'm not 100% convinced to mingle with private functions within UMAP that might eventually break (another reason for why I copied over code from UMAP back in January/February 2018). It would be nice to have Leland's OK for adding distributed aspects to the package. Scanpy would then just make use of them... @tomwhite, by this, also many other single-cell packages (many of them use UMAP these days) would profit from the new distributed computing capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:139,testability,integr,integrating,139,"@Koncopd, could we have a meeting or VC on the progress here? Let's discuss via email. 🙂 . @tomwhite, any updates from @lmcinnes regarding integrating the distributed version of `pynndescent` into UMAP itself? I'm not 100% convinced to mingle with private functions within UMAP that might eventually break (another reason for why I copied over code from UMAP back in January/February 2018). It would be nice to have Leland's OK for adding distributed aspects to the package. Scanpy would then just make use of them... @tomwhite, by this, also many other single-cell packages (many of them use UMAP these days) would profit from the new distributed computing capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:47,usability,progress,progress,47,"@Koncopd, could we have a meeting or VC on the progress here? Let's discuss via email. 🙂 . @tomwhite, any updates from @lmcinnes regarding integrating the distributed version of `pynndescent` into UMAP itself? I'm not 100% convinced to mingle with private functions within UMAP that might eventually break (another reason for why I copied over code from UMAP back in January/February 2018). It would be nice to have Leland's OK for adding distributed aspects to the package. Scanpy would then just make use of them... @tomwhite, by this, also many other single-cell packages (many of them use UMAP these days) would profit from the new distributed computing capabilities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:1181,deployability,log,logic,1181,"@falexwolf . Hi, Alex. What i figured out for now. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L105. This can be replaced by importing this. https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L148. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L258. This is basicly this. https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L329. But this `fuzzy_simplicial_set` doesn't calculate `distances`, only `connectivities`. What is the right approach to solve this? Writing PR to umap that adds `distances` as a return value for `fuzzy_simplicial_set`? https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/tools/_umap.py#L107. This line can be directly imported from umap of course, but now their `simplicial_set_embedding` requres also `adata.X` as an input, because the case with the number of connected components > 1 is treated differently. It should not be a problem as we have this in adata. I comment it just because this changes the logic a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:1046,integrability,compon,components,1046,"@falexwolf . Hi, Alex. What i figured out for now. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L105. This can be replaced by importing this. https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L148. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L258. This is basicly this. https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L329. But this `fuzzy_simplicial_set` doesn't calculate `distances`, only `connectivities`. What is the right approach to solve this? Writing PR to umap that adds `distances` as a return value for `fuzzy_simplicial_set`? https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/tools/_umap.py#L107. This line can be directly imported from umap of course, but now their `simplicial_set_embedding` requres also `adata.X` as an input, because the case with the number of connected components > 1 is treated differently. It should not be a problem as we have this in adata. I comment it just because this changes the logic a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:1046,interoperability,compon,components,1046,"@falexwolf . Hi, Alex. What i figured out for now. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L105. This can be replaced by importing this. https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L148. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L258. This is basicly this. https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L329. But this `fuzzy_simplicial_set` doesn't calculate `distances`, only `connectivities`. What is the right approach to solve this? Writing PR to umap that adds `distances` as a return value for `fuzzy_simplicial_set`? https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/tools/_umap.py#L107. This line can be directly imported from umap of course, but now their `simplicial_set_embedding` requres also `adata.X` as an input, because the case with the number of connected components > 1 is treated differently. It should not be a problem as we have this in adata. I comment it just because this changes the logic a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:1046,modifiability,compon,components,1046,"@falexwolf . Hi, Alex. What i figured out for now. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L105. This can be replaced by importing this. https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L148. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L258. This is basicly this. https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L329. But this `fuzzy_simplicial_set` doesn't calculate `distances`, only `connectivities`. What is the right approach to solve this? Writing PR to umap that adds `distances` as a return value for `fuzzy_simplicial_set`? https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/tools/_umap.py#L107. This line can be directly imported from umap of course, but now their `simplicial_set_embedding` requres also `adata.X` as an input, because the case with the number of connected components > 1 is treated differently. It should not be a problem as we have this in adata. I comment it just because this changes the logic a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:575,reliability,doe,doesn,575,"@falexwolf . Hi, Alex. What i figured out for now. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L105. This can be replaced by importing this. https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L148. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L258. This is basicly this. https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L329. But this `fuzzy_simplicial_set` doesn't calculate `distances`, only `connectivities`. What is the right approach to solve this? Writing PR to umap that adds `distances` as a return value for `fuzzy_simplicial_set`? https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/tools/_umap.py#L107. This line can be directly imported from umap of course, but now their `simplicial_set_embedding` requres also `adata.X` as an input, because the case with the number of connected components > 1 is treated differently. It should not be a problem as we have this in adata. I comment it just because this changes the logic a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:993,safety,input,input,993,"@falexwolf . Hi, Alex. What i figured out for now. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L105. This can be replaced by importing this. https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L148. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L258. This is basicly this. https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L329. But this `fuzzy_simplicial_set` doesn't calculate `distances`, only `connectivities`. What is the right approach to solve this? Writing PR to umap that adds `distances` as a return value for `fuzzy_simplicial_set`? https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/tools/_umap.py#L107. This line can be directly imported from umap of course, but now their `simplicial_set_embedding` requres also `adata.X` as an input, because the case with the number of connected components > 1 is treated differently. It should not be a problem as we have this in adata. I comment it just because this changes the logic a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:1181,safety,log,logic,1181,"@falexwolf . Hi, Alex. What i figured out for now. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L105. This can be replaced by importing this. https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L148. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L258. This is basicly this. https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L329. But this `fuzzy_simplicial_set` doesn't calculate `distances`, only `connectivities`. What is the right approach to solve this? Writing PR to umap that adds `distances` as a return value for `fuzzy_simplicial_set`? https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/tools/_umap.py#L107. This line can be directly imported from umap of course, but now their `simplicial_set_embedding` requres also `adata.X` as an input, because the case with the number of connected components > 1 is treated differently. It should not be a problem as we have this in adata. I comment it just because this changes the logic a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:1181,security,log,logic,1181,"@falexwolf . Hi, Alex. What i figured out for now. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L105. This can be replaced by importing this. https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L148. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L258. This is basicly this. https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L329. But this `fuzzy_simplicial_set` doesn't calculate `distances`, only `connectivities`. What is the right approach to solve this? Writing PR to umap that adds `distances` as a return value for `fuzzy_simplicial_set`? https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/tools/_umap.py#L107. This line can be directly imported from umap of course, but now their `simplicial_set_embedding` requres also `adata.X` as an input, because the case with the number of connected components > 1 is treated differently. It should not be a problem as we have this in adata. I comment it just because this changes the logic a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:1181,testability,log,logic,1181,"@falexwolf . Hi, Alex. What i figured out for now. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L105. This can be replaced by importing this. https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L148. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L258. This is basicly this. https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L329. But this `fuzzy_simplicial_set` doesn't calculate `distances`, only `connectivities`. What is the right approach to solve this? Writing PR to umap that adds `distances` as a return value for `fuzzy_simplicial_set`? https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/tools/_umap.py#L107. This line can be directly imported from umap of course, but now their `simplicial_set_embedding` requres also `adata.X` as an input, because the case with the number of connected components > 1 is treated differently. It should not be a problem as we have this in adata. I comment it just because this changes the logic a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:846,usability,tool,tools,846,"@falexwolf . Hi, Alex. What i figured out for now. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L105. This can be replaced by importing this. https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L148. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L258. This is basicly this. https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L329. But this `fuzzy_simplicial_set` doesn't calculate `distances`, only `connectivities`. What is the right approach to solve this? Writing PR to umap that adds `distances` as a return value for `fuzzy_simplicial_set`? https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/tools/_umap.py#L107. This line can be directly imported from umap of course, but now their `simplicial_set_embedding` requres also `adata.X` as an input, because the case with the number of connected components > 1 is treated differently. It should not be a problem as we have this in adata. I comment it just because this changes the logic a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:993,usability,input,input,993,"@falexwolf . Hi, Alex. What i figured out for now. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L105. This can be replaced by importing this. https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L148. https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L258. This is basicly this. https://github.com/lmcinnes/umap/blob/a858c6322a3e682d8daf9c17e13ac023f3e18cfa/umap/umap_.py#L329. But this `fuzzy_simplicial_set` doesn't calculate `distances`, only `connectivities`. What is the right approach to solve this? Writing PR to umap that adds `distances` as a return value for `fuzzy_simplicial_set`? https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/tools/_umap.py#L107. This line can be directly imported from umap of course, but now their `simplicial_set_embedding` requres also `adata.X` as an input, because the case with the number of connected components > 1 is treated differently. It should not be a problem as we have this in adata. I comment it just because this changes the logic a bit.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:263,deployability,depend,depending,263,"@Koncopd this looks correct to me. For `compute_connectivities_umap`, it could be left in `scanpy/scanpy/neighbors/__init__.py` until UMAP's `fuzzy_simplicial_set` returns distances too. (In other words, the change to `fuzzy_simplicial_set` doesn't have to block depending on UMAP.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:263,integrability,depend,depending,263,"@Koncopd this looks correct to me. For `compute_connectivities_umap`, it could be left in `scanpy/scanpy/neighbors/__init__.py` until UMAP's `fuzzy_simplicial_set` returns distances too. (In other words, the change to `fuzzy_simplicial_set` doesn't have to block depending on UMAP.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:263,modifiability,depend,depending,263,"@Koncopd this looks correct to me. For `compute_connectivities_umap`, it could be left in `scanpy/scanpy/neighbors/__init__.py` until UMAP's `fuzzy_simplicial_set` returns distances too. (In other words, the change to `fuzzy_simplicial_set` doesn't have to block depending on UMAP.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:241,reliability,doe,doesn,241,"@Koncopd this looks correct to me. For `compute_connectivities_umap`, it could be left in `scanpy/scanpy/neighbors/__init__.py` until UMAP's `fuzzy_simplicial_set` returns distances too. (In other words, the change to `fuzzy_simplicial_set` doesn't have to block depending on UMAP.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:263,safety,depend,depending,263,"@Koncopd this looks correct to me. For `compute_connectivities_umap`, it could be left in `scanpy/scanpy/neighbors/__init__.py` until UMAP's `fuzzy_simplicial_set` returns distances too. (In other words, the change to `fuzzy_simplicial_set` doesn't have to block depending on UMAP.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:263,testability,depend,depending,263,"@Koncopd this looks correct to me. For `compute_connectivities_umap`, it could be left in `scanpy/scanpy/neighbors/__init__.py` until UMAP's `fuzzy_simplicial_set` returns distances too. (In other words, the change to `fuzzy_simplicial_set` doesn't have to block depending on UMAP.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:223,deployability,API,API,223,"Cool, @Koncopd! Looks good! @tomwhite, thank you for your comments! @lmcinnes: are the functions like `nearest_neighbors` and `fuzzy_simplicial_set` stable enough to be used externally? They are not re-exported to the user API; a year ago, I was afraid that code that depended on them might break if changes were made, even if it's just renaming parameters etc. Do you announce chances that might break backwards compat for these functions? @Koncopd . > But this fuzzy_simplicial_set doesn't calculate distances, only connectivities. What is the right approach to solve this? Writing PR to umap that adds distances as a return value for fuzzy_simplicial_set? I'd guess that @lmcinnes wouldn't want to blow this up with another return value. Why can't we just use the return value for `nearest_neighbors` and construct the distance graph as it's done right now in Scanpy? In any case, it doesn't block depending on UMAP...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:268,deployability,depend,depended,268,"Cool, @Koncopd! Looks good! @tomwhite, thank you for your comments! @lmcinnes: are the functions like `nearest_neighbors` and `fuzzy_simplicial_set` stable enough to be used externally? They are not re-exported to the user API; a year ago, I was afraid that code that depended on them might break if changes were made, even if it's just renaming parameters etc. Do you announce chances that might break backwards compat for these functions? @Koncopd . > But this fuzzy_simplicial_set doesn't calculate distances, only connectivities. What is the right approach to solve this? Writing PR to umap that adds distances as a return value for fuzzy_simplicial_set? I'd guess that @lmcinnes wouldn't want to blow this up with another return value. Why can't we just use the return value for `nearest_neighbors` and construct the distance graph as it's done right now in Scanpy? In any case, it doesn't block depending on UMAP...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:901,deployability,depend,depending,901,"Cool, @Koncopd! Looks good! @tomwhite, thank you for your comments! @lmcinnes: are the functions like `nearest_neighbors` and `fuzzy_simplicial_set` stable enough to be used externally? They are not re-exported to the user API; a year ago, I was afraid that code that depended on them might break if changes were made, even if it's just renaming parameters etc. Do you announce chances that might break backwards compat for these functions? @Koncopd . > But this fuzzy_simplicial_set doesn't calculate distances, only connectivities. What is the right approach to solve this? Writing PR to umap that adds distances as a return value for fuzzy_simplicial_set? I'd guess that @lmcinnes wouldn't want to blow this up with another return value. Why can't we just use the return value for `nearest_neighbors` and construct the distance graph as it's done right now in Scanpy? In any case, it doesn't block depending on UMAP...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:0,energy efficiency,Cool,Cool,0,"Cool, @Koncopd! Looks good! @tomwhite, thank you for your comments! @lmcinnes: are the functions like `nearest_neighbors` and `fuzzy_simplicial_set` stable enough to be used externally? They are not re-exported to the user API; a year ago, I was afraid that code that depended on them might break if changes were made, even if it's just renaming parameters etc. Do you announce chances that might break backwards compat for these functions? @Koncopd . > But this fuzzy_simplicial_set doesn't calculate distances, only connectivities. What is the right approach to solve this? Writing PR to umap that adds distances as a return value for fuzzy_simplicial_set? I'd guess that @lmcinnes wouldn't want to blow this up with another return value. Why can't we just use the return value for `nearest_neighbors` and construct the distance graph as it's done right now in Scanpy? In any case, it doesn't block depending on UMAP...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:223,integrability,API,API,223,"Cool, @Koncopd! Looks good! @tomwhite, thank you for your comments! @lmcinnes: are the functions like `nearest_neighbors` and `fuzzy_simplicial_set` stable enough to be used externally? They are not re-exported to the user API; a year ago, I was afraid that code that depended on them might break if changes were made, even if it's just renaming parameters etc. Do you announce chances that might break backwards compat for these functions? @Koncopd . > But this fuzzy_simplicial_set doesn't calculate distances, only connectivities. What is the right approach to solve this? Writing PR to umap that adds distances as a return value for fuzzy_simplicial_set? I'd guess that @lmcinnes wouldn't want to blow this up with another return value. Why can't we just use the return value for `nearest_neighbors` and construct the distance graph as it's done right now in Scanpy? In any case, it doesn't block depending on UMAP...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:268,integrability,depend,depended,268,"Cool, @Koncopd! Looks good! @tomwhite, thank you for your comments! @lmcinnes: are the functions like `nearest_neighbors` and `fuzzy_simplicial_set` stable enough to be used externally? They are not re-exported to the user API; a year ago, I was afraid that code that depended on them might break if changes were made, even if it's just renaming parameters etc. Do you announce chances that might break backwards compat for these functions? @Koncopd . > But this fuzzy_simplicial_set doesn't calculate distances, only connectivities. What is the right approach to solve this? Writing PR to umap that adds distances as a return value for fuzzy_simplicial_set? I'd guess that @lmcinnes wouldn't want to blow this up with another return value. Why can't we just use the return value for `nearest_neighbors` and construct the distance graph as it's done right now in Scanpy? In any case, it doesn't block depending on UMAP...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:901,integrability,depend,depending,901,"Cool, @Koncopd! Looks good! @tomwhite, thank you for your comments! @lmcinnes: are the functions like `nearest_neighbors` and `fuzzy_simplicial_set` stable enough to be used externally? They are not re-exported to the user API; a year ago, I was afraid that code that depended on them might break if changes were made, even if it's just renaming parameters etc. Do you announce chances that might break backwards compat for these functions? @Koncopd . > But this fuzzy_simplicial_set doesn't calculate distances, only connectivities. What is the right approach to solve this? Writing PR to umap that adds distances as a return value for fuzzy_simplicial_set? I'd guess that @lmcinnes wouldn't want to blow this up with another return value. Why can't we just use the return value for `nearest_neighbors` and construct the distance graph as it's done right now in Scanpy? In any case, it doesn't block depending on UMAP...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:223,interoperability,API,API,223,"Cool, @Koncopd! Looks good! @tomwhite, thank you for your comments! @lmcinnes: are the functions like `nearest_neighbors` and `fuzzy_simplicial_set` stable enough to be used externally? They are not re-exported to the user API; a year ago, I was afraid that code that depended on them might break if changes were made, even if it's just renaming parameters etc. Do you announce chances that might break backwards compat for these functions? @Koncopd . > But this fuzzy_simplicial_set doesn't calculate distances, only connectivities. What is the right approach to solve this? Writing PR to umap that adds distances as a return value for fuzzy_simplicial_set? I'd guess that @lmcinnes wouldn't want to blow this up with another return value. Why can't we just use the return value for `nearest_neighbors` and construct the distance graph as it's done right now in Scanpy? In any case, it doesn't block depending on UMAP...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:268,modifiability,depend,depended,268,"Cool, @Koncopd! Looks good! @tomwhite, thank you for your comments! @lmcinnes: are the functions like `nearest_neighbors` and `fuzzy_simplicial_set` stable enough to be used externally? They are not re-exported to the user API; a year ago, I was afraid that code that depended on them might break if changes were made, even if it's just renaming parameters etc. Do you announce chances that might break backwards compat for these functions? @Koncopd . > But this fuzzy_simplicial_set doesn't calculate distances, only connectivities. What is the right approach to solve this? Writing PR to umap that adds distances as a return value for fuzzy_simplicial_set? I'd guess that @lmcinnes wouldn't want to blow this up with another return value. Why can't we just use the return value for `nearest_neighbors` and construct the distance graph as it's done right now in Scanpy? In any case, it doesn't block depending on UMAP...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:346,modifiability,paramet,parameters,346,"Cool, @Koncopd! Looks good! @tomwhite, thank you for your comments! @lmcinnes: are the functions like `nearest_neighbors` and `fuzzy_simplicial_set` stable enough to be used externally? They are not re-exported to the user API; a year ago, I was afraid that code that depended on them might break if changes were made, even if it's just renaming parameters etc. Do you announce chances that might break backwards compat for these functions? @Koncopd . > But this fuzzy_simplicial_set doesn't calculate distances, only connectivities. What is the right approach to solve this? Writing PR to umap that adds distances as a return value for fuzzy_simplicial_set? I'd guess that @lmcinnes wouldn't want to blow this up with another return value. Why can't we just use the return value for `nearest_neighbors` and construct the distance graph as it's done right now in Scanpy? In any case, it doesn't block depending on UMAP...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:901,modifiability,depend,depending,901,"Cool, @Koncopd! Looks good! @tomwhite, thank you for your comments! @lmcinnes: are the functions like `nearest_neighbors` and `fuzzy_simplicial_set` stable enough to be used externally? They are not re-exported to the user API; a year ago, I was afraid that code that depended on them might break if changes were made, even if it's just renaming parameters etc. Do you announce chances that might break backwards compat for these functions? @Koncopd . > But this fuzzy_simplicial_set doesn't calculate distances, only connectivities. What is the right approach to solve this? Writing PR to umap that adds distances as a return value for fuzzy_simplicial_set? I'd guess that @lmcinnes wouldn't want to blow this up with another return value. Why can't we just use the return value for `nearest_neighbors` and construct the distance graph as it's done right now in Scanpy? In any case, it doesn't block depending on UMAP...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:484,reliability,doe,doesn,484,"Cool, @Koncopd! Looks good! @tomwhite, thank you for your comments! @lmcinnes: are the functions like `nearest_neighbors` and `fuzzy_simplicial_set` stable enough to be used externally? They are not re-exported to the user API; a year ago, I was afraid that code that depended on them might break if changes were made, even if it's just renaming parameters etc. Do you announce chances that might break backwards compat for these functions? @Koncopd . > But this fuzzy_simplicial_set doesn't calculate distances, only connectivities. What is the right approach to solve this? Writing PR to umap that adds distances as a return value for fuzzy_simplicial_set? I'd guess that @lmcinnes wouldn't want to blow this up with another return value. Why can't we just use the return value for `nearest_neighbors` and construct the distance graph as it's done right now in Scanpy? In any case, it doesn't block depending on UMAP...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:887,reliability,doe,doesn,887,"Cool, @Koncopd! Looks good! @tomwhite, thank you for your comments! @lmcinnes: are the functions like `nearest_neighbors` and `fuzzy_simplicial_set` stable enough to be used externally? They are not re-exported to the user API; a year ago, I was afraid that code that depended on them might break if changes were made, even if it's just renaming parameters etc. Do you announce chances that might break backwards compat for these functions? @Koncopd . > But this fuzzy_simplicial_set doesn't calculate distances, only connectivities. What is the right approach to solve this? Writing PR to umap that adds distances as a return value for fuzzy_simplicial_set? I'd guess that @lmcinnes wouldn't want to blow this up with another return value. Why can't we just use the return value for `nearest_neighbors` and construct the distance graph as it's done right now in Scanpy? In any case, it doesn't block depending on UMAP...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:268,safety,depend,depended,268,"Cool, @Koncopd! Looks good! @tomwhite, thank you for your comments! @lmcinnes: are the functions like `nearest_neighbors` and `fuzzy_simplicial_set` stable enough to be used externally? They are not re-exported to the user API; a year ago, I was afraid that code that depended on them might break if changes were made, even if it's just renaming parameters etc. Do you announce chances that might break backwards compat for these functions? @Koncopd . > But this fuzzy_simplicial_set doesn't calculate distances, only connectivities. What is the right approach to solve this? Writing PR to umap that adds distances as a return value for fuzzy_simplicial_set? I'd guess that @lmcinnes wouldn't want to blow this up with another return value. Why can't we just use the return value for `nearest_neighbors` and construct the distance graph as it's done right now in Scanpy? In any case, it doesn't block depending on UMAP...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:901,safety,depend,depending,901,"Cool, @Koncopd! Looks good! @tomwhite, thank you for your comments! @lmcinnes: are the functions like `nearest_neighbors` and `fuzzy_simplicial_set` stable enough to be used externally? They are not re-exported to the user API; a year ago, I was afraid that code that depended on them might break if changes were made, even if it's just renaming parameters etc. Do you announce chances that might break backwards compat for these functions? @Koncopd . > But this fuzzy_simplicial_set doesn't calculate distances, only connectivities. What is the right approach to solve this? Writing PR to umap that adds distances as a return value for fuzzy_simplicial_set? I'd guess that @lmcinnes wouldn't want to blow this up with another return value. Why can't we just use the return value for `nearest_neighbors` and construct the distance graph as it's done right now in Scanpy? In any case, it doesn't block depending on UMAP...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:268,testability,depend,depended,268,"Cool, @Koncopd! Looks good! @tomwhite, thank you for your comments! @lmcinnes: are the functions like `nearest_neighbors` and `fuzzy_simplicial_set` stable enough to be used externally? They are not re-exported to the user API; a year ago, I was afraid that code that depended on them might break if changes were made, even if it's just renaming parameters etc. Do you announce chances that might break backwards compat for these functions? @Koncopd . > But this fuzzy_simplicial_set doesn't calculate distances, only connectivities. What is the right approach to solve this? Writing PR to umap that adds distances as a return value for fuzzy_simplicial_set? I'd guess that @lmcinnes wouldn't want to blow this up with another return value. Why can't we just use the return value for `nearest_neighbors` and construct the distance graph as it's done right now in Scanpy? In any case, it doesn't block depending on UMAP...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:901,testability,depend,depending,901,"Cool, @Koncopd! Looks good! @tomwhite, thank you for your comments! @lmcinnes: are the functions like `nearest_neighbors` and `fuzzy_simplicial_set` stable enough to be used externally? They are not re-exported to the user API; a year ago, I was afraid that code that depended on them might break if changes were made, even if it's just renaming parameters etc. Do you announce chances that might break backwards compat for these functions? @Koncopd . > But this fuzzy_simplicial_set doesn't calculate distances, only connectivities. What is the right approach to solve this? Writing PR to umap that adds distances as a return value for fuzzy_simplicial_set? I'd guess that @lmcinnes wouldn't want to blow this up with another return value. Why can't we just use the return value for `nearest_neighbors` and construct the distance graph as it's done right now in Scanpy? In any case, it doesn't block depending on UMAP...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:218,usability,user,user,218,"Cool, @Koncopd! Looks good! @tomwhite, thank you for your comments! @lmcinnes: are the functions like `nearest_neighbors` and `fuzzy_simplicial_set` stable enough to be used externally? They are not re-exported to the user API; a year ago, I was afraid that code that depended on them might break if changes were made, even if it's just renaming parameters etc. Do you announce chances that might break backwards compat for these functions? @Koncopd . > But this fuzzy_simplicial_set doesn't calculate distances, only connectivities. What is the right approach to solve this? Writing PR to umap that adds distances as a return value for fuzzy_simplicial_set? I'd guess that @lmcinnes wouldn't want to blow this up with another return value. Why can't we just use the return value for `nearest_neighbors` and construct the distance graph as it's done right now in Scanpy? In any case, it doesn't block depending on UMAP...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/issues/522:396,usability,custom,custom,396,"@falexwolf . Maybe just an additional optional argument which allows to return distances is fine? But, yes, you are right, we can just repeat [this loop](https://github.com/theislab/scanpy/blob/07606455c524b38c4efec475a0d7ba87251754bb/scanpy/neighbors/__init__.py#L280) to get the distances matrix for the graph. So we have 2 loops (one in umap's `fuzzy_simplicial_set` and one additional in our custom function) instead of one, but maybe it is better than cluttering basicly the internal function of umap.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/522
https://github.com/scverse/scanpy/pull/524:151,deployability,API,API,151,"@fidelram, are you happy with this? If you agree, I would also just make you a maintainer of Scanpy, so that you can merge PRs related to the plotting API yourself. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/524
https://github.com/scverse/scanpy/pull/524:151,integrability,API,API,151,"@fidelram, are you happy with this? If you agree, I would also just make you a maintainer of Scanpy, so that you can merge PRs related to the plotting API yourself. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/524
https://github.com/scverse/scanpy/pull/524:151,interoperability,API,API,151,"@fidelram, are you happy with this? If you agree, I would also just make you a maintainer of Scanpy, so that you can merge PRs related to the plotting API yourself. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/524
https://github.com/scverse/scanpy/pull/524:79,modifiability,maintain,maintainer,79,"@fidelram, are you happy with this? If you agree, I would also just make you a maintainer of Scanpy, so that you can merge PRs related to the plotting API yourself. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/524
https://github.com/scverse/scanpy/pull/524:79,safety,maintain,maintainer,79,"@fidelram, are you happy with this? If you agree, I would also just make you a maintainer of Scanpy, so that you can merge PRs related to the plotting API yourself. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/524
https://github.com/scverse/scanpy/pull/524:57,deployability,integr,integrate,57,Thanks for this PR @sjfleming . If you don't mind I will integrate this functionality into a new PR that also covers #512 and #525,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/524
https://github.com/scverse/scanpy/pull/524:57,integrability,integr,integrate,57,Thanks for this PR @sjfleming . If you don't mind I will integrate this functionality into a new PR that also covers #512 and #525,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/524
https://github.com/scverse/scanpy/pull/524:57,interoperability,integr,integrate,57,Thanks for this PR @sjfleming . If you don't mind I will integrate this functionality into a new PR that also covers #512 and #525,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/524
https://github.com/scverse/scanpy/pull/524:57,modifiability,integr,integrate,57,Thanks for this PR @sjfleming . If you don't mind I will integrate this functionality into a new PR that also covers #512 and #525,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/524
https://github.com/scverse/scanpy/pull/524:57,reliability,integr,integrate,57,Thanks for this PR @sjfleming . If you don't mind I will integrate this functionality into a new PR that also covers #512 and #525,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/524
https://github.com/scverse/scanpy/pull/524:57,security,integr,integrate,57,Thanks for this PR @sjfleming . If you don't mind I will integrate this functionality into a new PR that also covers #512 and #525,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/524
https://github.com/scverse/scanpy/pull/524:57,testability,integr,integrate,57,Thanks for this PR @sjfleming . If you don't mind I will integrate this functionality into a new PR that also covers #512 and #525,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/524
https://github.com/scverse/scanpy/pull/524:77,interoperability,specif,specify,77,Does this feature work with the latest scanpy? I don't see any change when I specify different values for the smallest_dot option.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/524
https://github.com/scverse/scanpy/pull/524:0,reliability,Doe,Does,0,Does this feature work with the latest scanpy? I don't see any change when I specify different values for the smallest_dot option.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/524
https://github.com/scverse/scanpy/pull/525:49,safety,test,tests,49,"Thank you for this! Unfortunately, it breaks the tests. It's such a small change, but I guess @fidelram had something in mind when setting it the way he did...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:49,testability,test,tests,49,"Thank you for this! Unfortunately, it breaks the tests. It's such a small change, but I guess @fidelram had something in mind when setting it the way he did...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:31,reliability,doe,doesn,31,I’ll have another look. But it doesn’t work the way it is now either,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:52,deployability,integr,integrate,52,@outlace I will check the problem with the test and integrate your changes in a new PR that addresses #512 and #524 if this is OK with you.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:52,integrability,integr,integrate,52,@outlace I will check the problem with the test and integrate your changes in a new PR that addresses #512 and #524 if this is OK with you.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:52,interoperability,integr,integrate,52,@outlace I will check the problem with the test and integrate your changes in a new PR that addresses #512 and #524 if this is OK with you.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:52,modifiability,integr,integrate,52,@outlace I will check the problem with the test and integrate your changes in a new PR that addresses #512 and #524 if this is OK with you.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:52,reliability,integr,integrate,52,@outlace I will check the problem with the test and integrate your changes in a new PR that addresses #512 and #524 if this is OK with you.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:43,safety,test,test,43,@outlace I will check the problem with the test and integrate your changes in a new PR that addresses #512 and #524 if this is OK with you.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:52,security,integr,integrate,52,@outlace I will check the problem with the test and integrate your changes in a new PR that addresses #512 and #524 if this is OK with you.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:43,testability,test,test,43,@outlace I will check the problem with the test and integrate your changes in a new PR that addresses #512 and #524 if this is OK with you.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:52,testability,integr,integrate,52,@outlace I will check the problem with the test and integrate your changes in a new PR that addresses #512 and #524 if this is OK with you.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:42,availability,error,error,42,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:394,availability,error,error,394,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:186,deployability,integr,integrated,186,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:186,integrability,integr,integrated,186,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:186,interoperability,integr,integrated,186,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:186,modifiability,integr,integrated,186,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:42,performance,error,error,42,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:394,performance,error,error,394,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:186,reliability,integr,integrated,186,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:42,safety,error,error,42,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:83,safety,test,tests,83,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:120,safety,reme,remember,120,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:394,safety,error,error,394,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:186,security,integr,integrated,186,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:83,testability,test,tests,83,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:186,testability,integr,integrated,186,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:42,usability,error,error,42,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:394,usability,error,error,394,"@outlace Curiously, your change causes an error. Without your change I can run the tests correctly without a problem. I remember that I fixed a bug similar to this one that was recently integrated into master (see https://github.com/theislab/scanpy/pull/425/files#diff-b5175ed1415cdbf853646e523cbe8ae0L902). Could it be that you didn't have the latest pull from scanpy and that was causing the error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/pull/525:28,usability,close,close,28,@outlace do you think I can close this PR?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/525
https://github.com/scverse/scanpy/issues/526:386,deployability,depend,depends,386,"Great, thank you for summarizing this so neatly. We could even link from the PBMC3k tutorial to this. Quick answer: yes, there are many situations in which `pp.regress_out` can do more harm than good. In most cases, I personally don't correct for mitochondrial gene expression, for instance. Quite a few people will agree with that. Whether a certain processing step makes sense or not depends on the data. You should choose with subject knowledge. Because, of that, I found it hard to come up with a best practice tutorial; what came into life as Benchmark with Seurat, remained Seurat's way of defining best practice. Many papers stick to this. But I'm sure that also many Seurat users won't always regress out mitochondrial genes and number of counts per cell. I'm sure @LuckyMD has a lot to say on this. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:386,integrability,depend,depends,386,"Great, thank you for summarizing this so neatly. We could even link from the PBMC3k tutorial to this. Quick answer: yes, there are many situations in which `pp.regress_out` can do more harm than good. In most cases, I personally don't correct for mitochondrial gene expression, for instance. Quite a few people will agree with that. Whether a certain processing step makes sense or not depends on the data. You should choose with subject knowledge. Because, of that, I found it hard to come up with a best practice tutorial; what came into life as Benchmark with Seurat, remained Seurat's way of defining best practice. Many papers stick to this. But I'm sure that also many Seurat users won't always regress out mitochondrial genes and number of counts per cell. I'm sure @LuckyMD has a lot to say on this. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:430,integrability,sub,subject,430,"Great, thank you for summarizing this so neatly. We could even link from the PBMC3k tutorial to this. Quick answer: yes, there are many situations in which `pp.regress_out` can do more harm than good. In most cases, I personally don't correct for mitochondrial gene expression, for instance. Quite a few people will agree with that. Whether a certain processing step makes sense or not depends on the data. You should choose with subject knowledge. Because, of that, I found it hard to come up with a best practice tutorial; what came into life as Benchmark with Seurat, remained Seurat's way of defining best practice. Many papers stick to this. But I'm sure that also many Seurat users won't always regress out mitochondrial genes and number of counts per cell. I'm sure @LuckyMD has a lot to say on this. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:386,modifiability,depend,depends,386,"Great, thank you for summarizing this so neatly. We could even link from the PBMC3k tutorial to this. Quick answer: yes, there are many situations in which `pp.regress_out` can do more harm than good. In most cases, I personally don't correct for mitochondrial gene expression, for instance. Quite a few people will agree with that. Whether a certain processing step makes sense or not depends on the data. You should choose with subject knowledge. Because, of that, I found it hard to come up with a best practice tutorial; what came into life as Benchmark with Seurat, remained Seurat's way of defining best practice. Many papers stick to this. But I'm sure that also many Seurat users won't always regress out mitochondrial genes and number of counts per cell. I'm sure @LuckyMD has a lot to say on this. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:506,reliability,pra,practice,506,"Great, thank you for summarizing this so neatly. We could even link from the PBMC3k tutorial to this. Quick answer: yes, there are many situations in which `pp.regress_out` can do more harm than good. In most cases, I personally don't correct for mitochondrial gene expression, for instance. Quite a few people will agree with that. Whether a certain processing step makes sense or not depends on the data. You should choose with subject knowledge. Because, of that, I found it hard to come up with a best practice tutorial; what came into life as Benchmark with Seurat, remained Seurat's way of defining best practice. Many papers stick to this. But I'm sure that also many Seurat users won't always regress out mitochondrial genes and number of counts per cell. I'm sure @LuckyMD has a lot to say on this. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:610,reliability,pra,practice,610,"Great, thank you for summarizing this so neatly. We could even link from the PBMC3k tutorial to this. Quick answer: yes, there are many situations in which `pp.regress_out` can do more harm than good. In most cases, I personally don't correct for mitochondrial gene expression, for instance. Quite a few people will agree with that. Whether a certain processing step makes sense or not depends on the data. You should choose with subject knowledge. Because, of that, I found it hard to come up with a best practice tutorial; what came into life as Benchmark with Seurat, remained Seurat's way of defining best practice. Many papers stick to this. But I'm sure that also many Seurat users won't always regress out mitochondrial genes and number of counts per cell. I'm sure @LuckyMD has a lot to say on this. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:386,safety,depend,depends,386,"Great, thank you for summarizing this so neatly. We could even link from the PBMC3k tutorial to this. Quick answer: yes, there are many situations in which `pp.regress_out` can do more harm than good. In most cases, I personally don't correct for mitochondrial gene expression, for instance. Quite a few people will agree with that. Whether a certain processing step makes sense or not depends on the data. You should choose with subject knowledge. Because, of that, I found it hard to come up with a best practice tutorial; what came into life as Benchmark with Seurat, remained Seurat's way of defining best practice. Many papers stick to this. But I'm sure that also many Seurat users won't always regress out mitochondrial genes and number of counts per cell. I'm sure @LuckyMD has a lot to say on this. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:386,testability,depend,depends,386,"Great, thank you for summarizing this so neatly. We could even link from the PBMC3k tutorial to this. Quick answer: yes, there are many situations in which `pp.regress_out` can do more harm than good. In most cases, I personally don't correct for mitochondrial gene expression, for instance. Quite a few people will agree with that. Whether a certain processing step makes sense or not depends on the data. You should choose with subject knowledge. Because, of that, I found it hard to come up with a best practice tutorial; what came into life as Benchmark with Seurat, remained Seurat's way of defining best practice. Many papers stick to this. But I'm sure that also many Seurat users won't always regress out mitochondrial genes and number of counts per cell. I'm sure @LuckyMD has a lot to say on this. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:701,testability,regress,regress,701,"Great, thank you for summarizing this so neatly. We could even link from the PBMC3k tutorial to this. Quick answer: yes, there are many situations in which `pp.regress_out` can do more harm than good. In most cases, I personally don't correct for mitochondrial gene expression, for instance. Quite a few people will agree with that. Whether a certain processing step makes sense or not depends on the data. You should choose with subject knowledge. Because, of that, I found it hard to come up with a best practice tutorial; what came into life as Benchmark with Seurat, remained Seurat's way of defining best practice. Many papers stick to this. But I'm sure that also many Seurat users won't always regress out mitochondrial genes and number of counts per cell. I'm sure @LuckyMD has a lot to say on this. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:218,usability,person,personally,218,"Great, thank you for summarizing this so neatly. We could even link from the PBMC3k tutorial to this. Quick answer: yes, there are many situations in which `pp.regress_out` can do more harm than good. In most cases, I personally don't correct for mitochondrial gene expression, for instance. Quite a few people will agree with that. Whether a certain processing step makes sense or not depends on the data. You should choose with subject knowledge. Because, of that, I found it hard to come up with a best practice tutorial; what came into life as Benchmark with Seurat, remained Seurat's way of defining best practice. Many papers stick to this. But I'm sure that also many Seurat users won't always regress out mitochondrial genes and number of counts per cell. I'm sure @LuckyMD has a lot to say on this. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:682,usability,user,users,682,"Great, thank you for summarizing this so neatly. We could even link from the PBMC3k tutorial to this. Quick answer: yes, there are many situations in which `pp.regress_out` can do more harm than good. In most cases, I personally don't correct for mitochondrial gene expression, for instance. Quite a few people will agree with that. Whether a certain processing step makes sense or not depends on the data. You should choose with subject knowledge. Because, of that, I found it hard to come up with a best practice tutorial; what came into life as Benchmark with Seurat, remained Seurat's way of defining best practice. Many papers stick to this. But I'm sure that also many Seurat users won't always regress out mitochondrial genes and number of counts per cell. I'm sure @LuckyMD has a lot to say on this. :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:599,availability,down,downstream,599,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:1043,availability,cluster,clustering,1043,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:1670,availability,down,downstream,1670,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:152,deployability,integr,integrates,152,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:560,deployability,depend,dependent,560,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:582,deployability,depend,dependent,582,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:1043,deployability,cluster,clustering,1043,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:1079,deployability,stage,stage,1079,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:152,integrability,integr,integrates,152,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:334,integrability,sub,submitted,334,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:560,integrability,depend,dependent,560,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:582,integrability,depend,dependent,582,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:152,interoperability,integr,integrates,152,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:152,modifiability,integr,integrates,152,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:560,modifiability,depend,dependent,560,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:582,modifiability,depend,dependent,582,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:40,reliability,pra,practices,40,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:152,reliability,integr,integrates,152,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:560,safety,depend,dependent,560,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:582,safety,depend,dependent,582,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:823,safety,isol,isolate,823,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:152,security,integr,integrates,152,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:823,security,iso,isolate,823,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:152,testability,integr,integrates,152,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:474,testability,regress,regressing,474,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:560,testability,depend,dependent,560,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:582,testability,depend,dependent,582,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:765,testability,Regress,Regressing,765,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:823,testability,isol,isolate,823,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:1509,testability,regress,regressing,1509,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:1602,testability,regress,regressing,1602,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:50,usability,workflow,workflow,50,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:163,usability,tool,tools,163,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:234,usability,workflow,workflow,234,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:943,usability,help,helpful,943,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:1345,usability,indicat,indicator,1345,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:1412,usability,indicat,indicate,1412,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/issues/526:1768,usability,help,helps,1768,"Hi @grst,. We've been working on a best-practices workflow/tutorial for scRNA-sesq data for the past year. The tutorial is based on scanpy, but it also integrates tools from R. You can take a look at a case study which implements the workflow [here](https://github.com/theislab/single-cell-tutorial). The revised manuscript should be submitted this week as well, so I hope it will be out soon. If you like, I can send it to you, if you pass me your email address. Regarding regressing out covariates. @falexwolf has already mentioned that this is very dataset dependent. It is also dependent on the downstream analysis. This is especially true for the covariates you suggest. MT gene expression and cell cycle are both biological, rather than technical covariates. Regressing out biological covariates is generally done to isolate particular processes in the data that you are interested in, while losing global structure in the data. This is helpful especially for trajectory inference, but maybe less so for global exploratory analysis with clustering. For example, cell cycle stage can be a major determinant in the difference between two cell types (e.g. stem cells and proliferating cells like transit amplifying cells). Removing this effect, hides the distinction. MT gene expression is also a biological covariate (as well as a technical indicator of cell stress). Higher levels of MT gene expression can indicate increased respiration in e.g., asthmatic conditions. . An additional unwanted effect to regressing out biological covariates is that biological processes are not independent. Thus, regressing out one process, will partially remove effects of other, downstream processes as well. If you're interested, we can discuss this in more detail. Hope this helps a bit,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/526
https://github.com/scverse/scanpy/pull/528:13,deployability,updat,updated,13,@falexwolf I updated the visualizations example notebook to reflect the changes: https://github.com/theislab/scanpy_usage/pull/11,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/528
https://github.com/scverse/scanpy/pull/528:13,safety,updat,updated,13,@falexwolf I updated the visualizations example notebook to reflect the changes: https://github.com/theislab/scanpy_usage/pull/11,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/528
https://github.com/scverse/scanpy/pull/528:13,security,updat,updated,13,@falexwolf I updated the visualizations example notebook to reflect the changes: https://github.com/theislab/scanpy_usage/pull/11,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/528
https://github.com/scverse/scanpy/pull/528:25,usability,visual,visualizations,25,@falexwolf I updated the visualizations example notebook to reflect the changes: https://github.com/theislab/scanpy_usage/pull/11,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/528
https://github.com/scverse/scanpy/pull/528:20,usability,close,close,20,"Thank you! Shall we close @gokceneraslan PR then? Or do we need to merge it first and then merge this? Thanks for clarifying! Regarding the examples: it's a bit unfortunate, but we migrated to https://github.com/theislab/scanpy-tutorials, and `scanpy_usage` is actually no longer used. I mentioned it before, but it might have got forgotten... Could you make a PR to `scanpy-tutorials` instead?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/528
https://github.com/scverse/scanpy/pull/528:82,usability,close,close,82,I think this PR has all the commits from two other PRs. Tricky to set up 😛 We can close mine.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/528
https://github.com/scverse/scanpy/pull/528:0,energy efficiency,Cool,Cool,0,Cool! I'll merge this then. Thanks everybody!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/528
https://github.com/scverse/scanpy/issues/530:62,safety,compl,complete,62,"This certainly looks strange. Would you mind making a minimal complete example? If you need, [here's a useful guide](http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) to making one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:62,security,compl,complete,62,"This certainly looks strange. Would you mind making a minimal complete example? If you need, [here's a useful guide](http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) to making one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:54,usability,minim,minimal,54,"This certainly looks strange. Would you mind making a minimal complete example? If you need, [here's a useful guide](http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) to making one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:110,usability,guid,guide,110,"This certainly looks strange. Would you mind making a minimal complete example? If you need, [here's a useful guide](http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) to making one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:164,usability,minim,minimal-bug-reports,164,"This certainly looks strange. Would you mind making a minimal complete example? If you need, [here's a useful guide](http://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports) to making one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:238,deployability,log,logarithmization,238,"Sorry, there is a small bug in the wilcoxon method, that might hit sometimes. @a-munoz-rojas, it should be resolved after merging your fix, don't you think so? I'd be happy to move forward as soon as the code-overhead issue around double logarithmization is fixed. Should be very simple. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:209,performance,overhead,overhead,209,"Sorry, there is a small bug in the wilcoxon method, that might hit sometimes. @a-munoz-rojas, it should be resolved after merging your fix, don't you think so? I'd be happy to move forward as soon as the code-overhead issue around double logarithmization is fixed. Should be very simple. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:238,safety,log,logarithmization,238,"Sorry, there is a small bug in the wilcoxon method, that might hit sometimes. @a-munoz-rojas, it should be resolved after merging your fix, don't you think so? I'd be happy to move forward as soon as the code-overhead issue around double logarithmization is fixed. Should be very simple. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:238,security,log,logarithmization,238,"Sorry, there is a small bug in the wilcoxon method, that might hit sometimes. @a-munoz-rojas, it should be resolved after merging your fix, don't you think so? I'd be happy to move forward as soon as the code-overhead issue around double logarithmization is fixed. Should be very simple. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:238,testability,log,logarithmization,238,"Sorry, there is a small bug in the wilcoxon method, that might hit sometimes. @a-munoz-rojas, it should be resolved after merging your fix, don't you think so? I'd be happy to move forward as soon as the code-overhead issue around double logarithmization is fixed. Should be very simple. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:280,testability,simpl,simple,280,"Sorry, there is a small bug in the wilcoxon method, that might hit sometimes. @a-munoz-rojas, it should be resolved after merging your fix, don't you think so? I'd be happy to move forward as soon as the code-overhead issue around double logarithmization is fixed. Should be very simple. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:280,usability,simpl,simple,280,"Sorry, there is a small bug in the wilcoxon method, that might hit sometimes. @a-munoz-rojas, it should be resolved after merging your fix, don't you think so? I'd be happy to move forward as soon as the code-overhead issue around double logarithmization is fixed. Should be very simple. Thank you!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:130,performance,overhead,overhead,130,"Hi @falexwolf - I think it be resolved with the bug fix, but I'm not entirely sure. I just pushed the changes addressing the code-overhead issue, we can give it a try to see if it fixes it. Otherwise we'd have to take a closer look.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:220,usability,close,closer,220,"Hi @falexwolf - I think it be resolved with the bug fix, but I'm not entirely sure. I just pushed the changes addressing the code-overhead issue, we can give it a try to see if it fixes it. Otherwise we'd have to take a closer look.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:53,usability,close,close,53,"@ivirshup I haven't tried it yet, sorry. But you can close the issue. if I still have trouble when I get back to the analysis I can re-open it",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:69,availability,error,error,69,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:385,availability,cluster,clusters,385,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:427,availability,replic,replicating,427,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:777,availability,error,error,777,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:1155,availability,error,error,1155,"with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:2063,availability,error,error,2063,"with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:120,deployability,releas,release,120,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:227,deployability,log,logreg,227,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:385,deployability,cluster,clusters,385,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:587,deployability,releas,release,587,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:1251,deployability,modul,module,1251,"with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:1109,interoperability,share,sharey,1109," latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:1547,interoperability,share,sharey,1547,"with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:1991,interoperability,distribut,distributions,1991,"with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:1251,modifiability,modul,module,1251,"with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:1583,modifiability,pac,packages,1583,"with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:69,performance,error,error,69,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:777,performance,error,error,777,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:1155,performance,error,error,1155,"with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:2063,performance,error,error,2063,"with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:69,safety,error,error,69,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:219,safety,test,test,219,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:227,safety,log,logreg,227,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:777,safety,error,error,777,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:1155,safety,error,error,1155,"with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:1223,safety,input,input-,1223,"with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:1251,safety,modul,module,1251,"with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:2063,safety,error,error,2063,"with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:227,security,log,logreg,227,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:219,testability,test,test,219,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:227,testability,log,logreg,227,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:1179,testability,Trace,Traceback,1179,"with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:69,usability,error,error,69,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:378,usability,custom,custom,378,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:452,usability,workflow,workflow,452,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:492,usability,experien,experience,492,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:739,usability,help,help,739,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:777,usability,error,error,777,"Hi guys,. Sorry to re-open the thread but I am also getting the same error as described by the OP above with the latest release of Scanpy (v1.4.3). . As with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distribut",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:1155,usability,error,error,1155,"with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:1223,usability,input,input-,1223,"with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:1599,usability,tool,tools,1599,"with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/530:2063,usability,error,error,2063,"with #566 I have no trouble running the rank_genes_groups using t-test or logreg, the problem only arises when using method='wilcoxon'. For the example provided below `adata` is using one of our real data sets and I am using custom clusters but I have the same problem when replicating the tutorial workflow. My colleague has had the same experience when trying to work through the tutorial on his system, again using the most recent release of Scanpy. I've made sure 'log_transformed' was being applied to include the #519 fix provided by **a-munoz-rojas** in the hope that this might help but no such luck, I get the same error either way. Any ideas? Here is what I ran:. ```. sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ```. And here is the resulting error:. ```. ValueError Traceback (most recent call last). <ipython-input-117-a5ba74ea872c> in <module>. ----> 1 sc.tl.rank_genes_groups(adata, groupby='Custom_clusters_Leiden', groups=['NKT1','NKT2','NKT17','IL2+ aNKT1','aNKT2 & aNKT17','TNF- aNKT1'], reference='rest', method='wilcoxon', corr_method='benjamini-hochberg', log_transformed=True). 2 sc.pl.rank_genes_groups(adata, n_genes=25, sharey=False). ~\Anaconda3\lib\site-packages\scanpy\tools\_rank_genes_groups.py in rank_genes_groups(adata, groupby, use_raw, groups, reference, n_genes, rankby_abs, key_added, copy, method, corr_method, log_transformed, **kwds). 367 . 368 scores[imask, :] = (scores[imask, :] - (ns[imask] * (n_cells + 1) / 2)) / sqrt(. --> 369 (ns[imask] * (n_cells - ns[imask]) * (n_cells + 1) / 12)). 370 scores[np.isnan(scores)] = 0. 371 pvals = 2 * stats.distributions.norm.sf(np.abs(scores[imask,:])). ValueError: math domain error. ```. P.S I just want to say thank you for all the work on Scanpy, loving it so far!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/530
https://github.com/scverse/scanpy/issues/531:138,energy efficiency,current,currently,138,We're very happy to consider PRs around engineering representations around NB or multinomial methods. But we have to admit that we're not currently working on this.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/531
https://github.com/scverse/scanpy/issues/532:902,interoperability,format,format,902,"Hi @ParisaMa,. So you want a single umap visualization with the the sum of several marker genes (or some related score) plotted on top of this? I'm a bit sceptical regarding how that would be helpful (you may want to know which cells have 0 values for a particular marker), but there is a way to do this. . You can use `sc.tl.score_genes(adata, gene_list, score_name='my_score')` to calculate a gene score for all the genes you wish to plot at the same time, and then visualize that score on a umap via: `sc.pl.umap(adata, color='my_score')`. That wouldn't give you the sum of the gene expression values, but the average expression minus an average expression of a random gene set. If you just want to add the gene expression values, you can of course also create your own score via something like this:. `adata.obs['my_score'] = adata.X[:,my_genes].sum(1)` . and plot that. You may have to check what format is expected for `my_genes` though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:453,performance,time,time,453,"Hi @ParisaMa,. So you want a single umap visualization with the the sum of several marker genes (or some related score) plotted on top of this? I'm a bit sceptical regarding how that would be helpful (you may want to know which cells have 0 values for a particular marker), but there is a way to do this. . You can use `sc.tl.score_genes(adata, gene_list, score_name='my_score')` to calculate a gene score for all the genes you wish to plot at the same time, and then visualize that score on a umap via: `sc.pl.umap(adata, color='my_score')`. That wouldn't give you the sum of the gene expression values, but the average expression minus an average expression of a random gene set. If you just want to add the gene expression values, you can of course also create your own score via something like this:. `adata.obs['my_score'] = adata.X[:,my_genes].sum(1)` . and plot that. You may have to check what format is expected for `my_genes` though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:41,usability,visual,visualization,41,"Hi @ParisaMa,. So you want a single umap visualization with the the sum of several marker genes (or some related score) plotted on top of this? I'm a bit sceptical regarding how that would be helpful (you may want to know which cells have 0 values for a particular marker), but there is a way to do this. . You can use `sc.tl.score_genes(adata, gene_list, score_name='my_score')` to calculate a gene score for all the genes you wish to plot at the same time, and then visualize that score on a umap via: `sc.pl.umap(adata, color='my_score')`. That wouldn't give you the sum of the gene expression values, but the average expression minus an average expression of a random gene set. If you just want to add the gene expression values, you can of course also create your own score via something like this:. `adata.obs['my_score'] = adata.X[:,my_genes].sum(1)` . and plot that. You may have to check what format is expected for `my_genes` though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:192,usability,help,helpful,192,"Hi @ParisaMa,. So you want a single umap visualization with the the sum of several marker genes (or some related score) plotted on top of this? I'm a bit sceptical regarding how that would be helpful (you may want to know which cells have 0 values for a particular marker), but there is a way to do this. . You can use `sc.tl.score_genes(adata, gene_list, score_name='my_score')` to calculate a gene score for all the genes you wish to plot at the same time, and then visualize that score on a umap via: `sc.pl.umap(adata, color='my_score')`. That wouldn't give you the sum of the gene expression values, but the average expression minus an average expression of a random gene set. If you just want to add the gene expression values, you can of course also create your own score via something like this:. `adata.obs['my_score'] = adata.X[:,my_genes].sum(1)` . and plot that. You may have to check what format is expected for `my_genes` though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:468,usability,visual,visualize,468,"Hi @ParisaMa,. So you want a single umap visualization with the the sum of several marker genes (or some related score) plotted on top of this? I'm a bit sceptical regarding how that would be helpful (you may want to know which cells have 0 values for a particular marker), but there is a way to do this. . You can use `sc.tl.score_genes(adata, gene_list, score_name='my_score')` to calculate a gene score for all the genes you wish to plot at the same time, and then visualize that score on a umap via: `sc.pl.umap(adata, color='my_score')`. That wouldn't give you the sum of the gene expression values, but the average expression minus an average expression of a random gene set. If you just want to add the gene expression values, you can of course also create your own score via something like this:. `adata.obs['my_score'] = adata.X[:,my_genes].sum(1)` . and plot that. You may have to check what format is expected for `my_genes` though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:275,availability,cluster,clusters,275,"Hi @LuckyMD . Thanks for your reply! I'm actually interested in the distribution of a bunch of markers instead of just looking at one. I have a set of markers for a specific population (extracted from a study) and would like to know how how their expressions look like on my clusters (to see if I actually have that population). However, because of the differences in the scales, it can be tricky and kind of different than just adding them up, what I want is more like scaling them altogether. Is this what that score_genes functions that you suggested does?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:275,deployability,cluster,clusters,275,"Hi @LuckyMD . Thanks for your reply! I'm actually interested in the distribution of a bunch of markers instead of just looking at one. I have a set of markers for a specific population (extracted from a study) and would like to know how how their expressions look like on my clusters (to see if I actually have that population). However, because of the differences in the scales, it can be tricky and kind of different than just adding them up, what I want is more like scaling them altogether. Is this what that score_genes functions that you suggested does?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:372,deployability,scale,scales,372,"Hi @LuckyMD . Thanks for your reply! I'm actually interested in the distribution of a bunch of markers instead of just looking at one. I have a set of markers for a specific population (extracted from a study) and would like to know how how their expressions look like on my clusters (to see if I actually have that population). However, because of the differences in the scales, it can be tricky and kind of different than just adding them up, what I want is more like scaling them altogether. Is this what that score_genes functions that you suggested does?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:372,energy efficiency,scale,scales,372,"Hi @LuckyMD . Thanks for your reply! I'm actually interested in the distribution of a bunch of markers instead of just looking at one. I have a set of markers for a specific population (extracted from a study) and would like to know how how their expressions look like on my clusters (to see if I actually have that population). However, because of the differences in the scales, it can be tricky and kind of different than just adding them up, what I want is more like scaling them altogether. Is this what that score_genes functions that you suggested does?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:68,interoperability,distribut,distribution,68,"Hi @LuckyMD . Thanks for your reply! I'm actually interested in the distribution of a bunch of markers instead of just looking at one. I have a set of markers for a specific population (extracted from a study) and would like to know how how their expressions look like on my clusters (to see if I actually have that population). However, because of the differences in the scales, it can be tricky and kind of different than just adding them up, what I want is more like scaling them altogether. Is this what that score_genes functions that you suggested does?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:165,interoperability,specif,specific,165,"Hi @LuckyMD . Thanks for your reply! I'm actually interested in the distribution of a bunch of markers instead of just looking at one. I have a set of markers for a specific population (extracted from a study) and would like to know how how their expressions look like on my clusters (to see if I actually have that population). However, because of the differences in the scales, it can be tricky and kind of different than just adding them up, what I want is more like scaling them altogether. Is this what that score_genes functions that you suggested does?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:372,modifiability,scal,scales,372,"Hi @LuckyMD . Thanks for your reply! I'm actually interested in the distribution of a bunch of markers instead of just looking at one. I have a set of markers for a specific population (extracted from a study) and would like to know how how their expressions look like on my clusters (to see if I actually have that population). However, because of the differences in the scales, it can be tricky and kind of different than just adding them up, what I want is more like scaling them altogether. Is this what that score_genes functions that you suggested does?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:470,modifiability,scal,scaling,470,"Hi @LuckyMD . Thanks for your reply! I'm actually interested in the distribution of a bunch of markers instead of just looking at one. I have a set of markers for a specific population (extracted from a study) and would like to know how how their expressions look like on my clusters (to see if I actually have that population). However, because of the differences in the scales, it can be tricky and kind of different than just adding them up, what I want is more like scaling them altogether. Is this what that score_genes functions that you suggested does?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:372,performance,scale,scales,372,"Hi @LuckyMD . Thanks for your reply! I'm actually interested in the distribution of a bunch of markers instead of just looking at one. I have a set of markers for a specific population (extracted from a study) and would like to know how how their expressions look like on my clusters (to see if I actually have that population). However, because of the differences in the scales, it can be tricky and kind of different than just adding them up, what I want is more like scaling them altogether. Is this what that score_genes functions that you suggested does?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:554,reliability,doe,does,554,"Hi @LuckyMD . Thanks for your reply! I'm actually interested in the distribution of a bunch of markers instead of just looking at one. I have a set of markers for a specific population (extracted from a study) and would like to know how how their expressions look like on my clusters (to see if I actually have that population). However, because of the differences in the scales, it can be tricky and kind of different than just adding them up, what I want is more like scaling them altogether. Is this what that score_genes functions that you suggested does?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:61,deployability,scale,scale,61,"Hi @ParisaMa,. I think then you'd be better off using `sc.pp.scale()` to create z-scores and then just using the second method I suggested, but using `.mean(1)` instead of the sum. That way you take the average z-scres of the marker gene expression values. I think it would probably be better to look at this in a violin plot though, if you really want to see the marker gene expression distributions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:61,energy efficiency,scale,scale,61,"Hi @ParisaMa,. I think then you'd be better off using `sc.pp.scale()` to create z-scores and then just using the second method I suggested, but using `.mean(1)` instead of the sum. That way you take the average z-scres of the marker gene expression values. I think it would probably be better to look at this in a violin plot though, if you really want to see the marker gene expression distributions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:387,interoperability,distribut,distributions,387,"Hi @ParisaMa,. I think then you'd be better off using `sc.pp.scale()` to create z-scores and then just using the second method I suggested, but using `.mean(1)` instead of the sum. That way you take the average z-scres of the marker gene expression values. I think it would probably be better to look at this in a violin plot though, if you really want to see the marker gene expression distributions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:61,modifiability,scal,scale,61,"Hi @ParisaMa,. I think then you'd be better off using `sc.pp.scale()` to create z-scores and then just using the second method I suggested, but using `.mean(1)` instead of the sum. That way you take the average z-scres of the marker gene expression values. I think it would probably be better to look at this in a violin plot though, if you really want to see the marker gene expression distributions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:61,performance,scale,scale,61,"Hi @ParisaMa,. I think then you'd be better off using `sc.pp.scale()` to create z-scores and then just using the second method I suggested, but using `.mean(1)` instead of the sum. That way you take the average z-scres of the marker gene expression values. I think it would probably be better to look at this in a violin plot though, if you really want to see the marker gene expression distributions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:203,reliability,doe,does,203,"Hi Parisa and @LuckyMD. I hope you are doing well. . I have the same question as Parisa. I am wondering if the code that you suggested should be implemented in Seurat or Python? If it's not from Seurat, does Seurat have a code for that? Parisa, did you figure it out? Thank you so much",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:107,reliability,doe,does,107,"Hi,. We don't have a simple function for this atm. But you could check out the dotplot, maybe that already does what you'd like. I'm not sure about Seurat, as I predominantly use scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:21,testability,simpl,simple,21,"Hi,. We don't have a simple function for this atm. But you could check out the dotplot, maybe that already does what you'd like. I'm not sure about Seurat, as I predominantly use scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:21,usability,simpl,simple,21,"Hi,. We don't have a simple function for this atm. But you could check out the dotplot, maybe that already does what you'd like. I'm not sure about Seurat, as I predominantly use scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:400,deployability,continu,continuous,400,"Just to follow-up because I also had a similar question to the OP. Here's one way to plot several marker genes in different colors on the same UMAP plot. The trick is to make different colormaps that have an alpha gradient so that cells with NA expression appear transparent. Then just use matplot axes to merge the images. The only issue is that Scanpy doesn't yet allow you to remove colorbars for continuous variables, so the multiple colorbars can throw off the scaling, which you can work around by changing the figure parameters. ```. #make red colormap. colors2 = plt.cm.Reds(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap = mymap(np.arange(mymap.N)). my_cmap[:,-1] = np.linspace(0, 1, mymap.N). my_cmap = colors.ListedColormap(my_cmap). sc.pl.umap(adata, color=['AIF1'], use_raw=True, color_map=my_cmap, show=False, frameon=False). ```. ![image](https://user-images.githubusercontent.com/56206488/126086651-df0d46c9-5f1d-4b64-8109-f82cd1feb9cb.png). ```. #make blue colormap. colors2 = plt.cm.Blues(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap2 = mymap(np.arange(mymap.N)). my_cmap2[:,-1] = np.linspace(0, 1, mymap.N). my_cmap2 = colors.ListedColormap(my_cmap2). sc.pl.umap(adata, color=['CD3E'], use_raw=True, color_map=my_cmap2, show=False, frameon=False, vmax=3). ```. ![image](https://user-images.githubusercontent.com/56206488/126086666-a0828d86-d943-47b8-8207-eb42aeb32e4b.png). ```. #make green colormap. colors2 = plt.cm.Greens(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap3 = mymap(np.arange(mymap.N)). my_cmap3[:,-1] = np.linspace(0, 1, mymap.N). my_cmap3 = colors.ListedColormap(my_cmap3). sc.pl.umap(adata, color=['CD79A'], use_raw=True, color_map=my_cmap3, show=False, frameon=False",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:1602,energy efficiency,green,green,1602,"). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap = mymap(np.arange(mymap.N)). my_cmap[:,-1] = np.linspace(0, 1, mymap.N). my_cmap = colors.ListedColormap(my_cmap). sc.pl.umap(adata, color=['AIF1'], use_raw=True, color_map=my_cmap, show=False, frameon=False). ```. ![image](https://user-images.githubusercontent.com/56206488/126086651-df0d46c9-5f1d-4b64-8109-f82cd1feb9cb.png). ```. #make blue colormap. colors2 = plt.cm.Blues(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap2 = mymap(np.arange(mymap.N)). my_cmap2[:,-1] = np.linspace(0, 1, mymap.N). my_cmap2 = colors.ListedColormap(my_cmap2). sc.pl.umap(adata, color=['CD3E'], use_raw=True, color_map=my_cmap2, show=False, frameon=False, vmax=3). ```. ![image](https://user-images.githubusercontent.com/56206488/126086666-a0828d86-d943-47b8-8207-eb42aeb32e4b.png). ```. #make green colormap. colors2 = plt.cm.Greens(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap3 = mymap(np.arange(mymap.N)). my_cmap3[:,-1] = np.linspace(0, 1, mymap.N). my_cmap3 = colors.ListedColormap(my_cmap3). sc.pl.umap(adata, color=['CD79A'], use_raw=True, color_map=my_cmap3, show=False, frameon=False). ```. ![image](https://user-images.githubusercontent.com/56206488/126086688-66a3af40-ecc1-4b2e-a3e4-8038f7f207b0.png). ```. #make purple colormap. colors2 = plt.cm.Purples(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap4 = mymap(np.arange(mymap.N)). my_cmap4[:,-1] = np.linspace(0, 1, mymap.N). my_cmap4 = colors.ListedColormap(my_cmap4). sc.pl.umap(adata, color=['VWF'], use_raw=True, color_map=my_cmap4, show=False, frameon=False, vmax=5). ```. ![image](https://user-images.githubusercontent.com/56206488",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:1635,energy efficiency,Green,Greens,1635,"2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap = mymap(np.arange(mymap.N)). my_cmap[:,-1] = np.linspace(0, 1, mymap.N). my_cmap = colors.ListedColormap(my_cmap). sc.pl.umap(adata, color=['AIF1'], use_raw=True, color_map=my_cmap, show=False, frameon=False). ```. ![image](https://user-images.githubusercontent.com/56206488/126086651-df0d46c9-5f1d-4b64-8109-f82cd1feb9cb.png). ```. #make blue colormap. colors2 = plt.cm.Blues(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap2 = mymap(np.arange(mymap.N)). my_cmap2[:,-1] = np.linspace(0, 1, mymap.N). my_cmap2 = colors.ListedColormap(my_cmap2). sc.pl.umap(adata, color=['CD3E'], use_raw=True, color_map=my_cmap2, show=False, frameon=False, vmax=3). ```. ![image](https://user-images.githubusercontent.com/56206488/126086666-a0828d86-d943-47b8-8207-eb42aeb32e4b.png). ```. #make green colormap. colors2 = plt.cm.Greens(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap3 = mymap(np.arange(mymap.N)). my_cmap3[:,-1] = np.linspace(0, 1, mymap.N). my_cmap3 = colors.ListedColormap(my_cmap3). sc.pl.umap(adata, color=['CD79A'], use_raw=True, color_map=my_cmap3, show=False, frameon=False). ```. ![image](https://user-images.githubusercontent.com/56206488/126086688-66a3af40-ecc1-4b2e-a3e4-8038f7f207b0.png). ```. #make purple colormap. colors2 = plt.cm.Purples(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap4 = mymap(np.arange(mymap.N)). my_cmap4[:,-1] = np.linspace(0, 1, mymap.N). my_cmap4 = colors.ListedColormap(my_cmap4). sc.pl.umap(adata, color=['VWF'], use_raw=True, color_map=my_cmap4, show=False, frameon=False, vmax=5). ```. ![image](https://user-images.githubusercontent.com/56206488/126086713-d8b24873-f3ea-4067-857",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:411,modifiability,variab,variables,411,"Just to follow-up because I also had a similar question to the OP. Here's one way to plot several marker genes in different colors on the same UMAP plot. The trick is to make different colormaps that have an alpha gradient so that cells with NA expression appear transparent. Then just use matplot axes to merge the images. The only issue is that Scanpy doesn't yet allow you to remove colorbars for continuous variables, so the multiple colorbars can throw off the scaling, which you can work around by changing the figure parameters. ```. #make red colormap. colors2 = plt.cm.Reds(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap = mymap(np.arange(mymap.N)). my_cmap[:,-1] = np.linspace(0, 1, mymap.N). my_cmap = colors.ListedColormap(my_cmap). sc.pl.umap(adata, color=['AIF1'], use_raw=True, color_map=my_cmap, show=False, frameon=False). ```. ![image](https://user-images.githubusercontent.com/56206488/126086651-df0d46c9-5f1d-4b64-8109-f82cd1feb9cb.png). ```. #make blue colormap. colors2 = plt.cm.Blues(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap2 = mymap(np.arange(mymap.N)). my_cmap2[:,-1] = np.linspace(0, 1, mymap.N). my_cmap2 = colors.ListedColormap(my_cmap2). sc.pl.umap(adata, color=['CD3E'], use_raw=True, color_map=my_cmap2, show=False, frameon=False, vmax=3). ```. ![image](https://user-images.githubusercontent.com/56206488/126086666-a0828d86-d943-47b8-8207-eb42aeb32e4b.png). ```. #make green colormap. colors2 = plt.cm.Greens(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap3 = mymap(np.arange(mymap.N)). my_cmap3[:,-1] = np.linspace(0, 1, mymap.N). my_cmap3 = colors.ListedColormap(my_cmap3). sc.pl.umap(adata, color=['CD79A'], use_raw=True, color_map=my_cmap3, show=False, frameon=False",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:466,modifiability,scal,scaling,466,"Just to follow-up because I also had a similar question to the OP. Here's one way to plot several marker genes in different colors on the same UMAP plot. The trick is to make different colormaps that have an alpha gradient so that cells with NA expression appear transparent. Then just use matplot axes to merge the images. The only issue is that Scanpy doesn't yet allow you to remove colorbars for continuous variables, so the multiple colorbars can throw off the scaling, which you can work around by changing the figure parameters. ```. #make red colormap. colors2 = plt.cm.Reds(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap = mymap(np.arange(mymap.N)). my_cmap[:,-1] = np.linspace(0, 1, mymap.N). my_cmap = colors.ListedColormap(my_cmap). sc.pl.umap(adata, color=['AIF1'], use_raw=True, color_map=my_cmap, show=False, frameon=False). ```. ![image](https://user-images.githubusercontent.com/56206488/126086651-df0d46c9-5f1d-4b64-8109-f82cd1feb9cb.png). ```. #make blue colormap. colors2 = plt.cm.Blues(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap2 = mymap(np.arange(mymap.N)). my_cmap2[:,-1] = np.linspace(0, 1, mymap.N). my_cmap2 = colors.ListedColormap(my_cmap2). sc.pl.umap(adata, color=['CD3E'], use_raw=True, color_map=my_cmap2, show=False, frameon=False, vmax=3). ```. ![image](https://user-images.githubusercontent.com/56206488/126086666-a0828d86-d943-47b8-8207-eb42aeb32e4b.png). ```. #make green colormap. colors2 = plt.cm.Greens(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap3 = mymap(np.arange(mymap.N)). my_cmap3[:,-1] = np.linspace(0, 1, mymap.N). my_cmap3 = colors.ListedColormap(my_cmap3). sc.pl.umap(adata, color=['CD79A'], use_raw=True, color_map=my_cmap3, show=False, frameon=False",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:524,modifiability,paramet,parameters,524,"Just to follow-up because I also had a similar question to the OP. Here's one way to plot several marker genes in different colors on the same UMAP plot. The trick is to make different colormaps that have an alpha gradient so that cells with NA expression appear transparent. Then just use matplot axes to merge the images. The only issue is that Scanpy doesn't yet allow you to remove colorbars for continuous variables, so the multiple colorbars can throw off the scaling, which you can work around by changing the figure parameters. ```. #make red colormap. colors2 = plt.cm.Reds(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap = mymap(np.arange(mymap.N)). my_cmap[:,-1] = np.linspace(0, 1, mymap.N). my_cmap = colors.ListedColormap(my_cmap). sc.pl.umap(adata, color=['AIF1'], use_raw=True, color_map=my_cmap, show=False, frameon=False). ```. ![image](https://user-images.githubusercontent.com/56206488/126086651-df0d46c9-5f1d-4b64-8109-f82cd1feb9cb.png). ```. #make blue colormap. colors2 = plt.cm.Blues(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap2 = mymap(np.arange(mymap.N)). my_cmap2[:,-1] = np.linspace(0, 1, mymap.N). my_cmap2 = colors.ListedColormap(my_cmap2). sc.pl.umap(adata, color=['CD3E'], use_raw=True, color_map=my_cmap2, show=False, frameon=False, vmax=3). ```. ![image](https://user-images.githubusercontent.com/56206488/126086666-a0828d86-d943-47b8-8207-eb42aeb32e4b.png). ```. #make green colormap. colors2 = plt.cm.Greens(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap3 = mymap(np.arange(mymap.N)). my_cmap3[:,-1] = np.linspace(0, 1, mymap.N). my_cmap3 = colors.ListedColormap(my_cmap3). sc.pl.umap(adata, color=['CD79A'], use_raw=True, color_map=my_cmap3, show=False, frameon=False",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:354,reliability,doe,doesn,354,"Just to follow-up because I also had a similar question to the OP. Here's one way to plot several marker genes in different colors on the same UMAP plot. The trick is to make different colormaps that have an alpha gradient so that cells with NA expression appear transparent. Then just use matplot axes to merge the images. The only issue is that Scanpy doesn't yet allow you to remove colorbars for continuous variables, so the multiple colorbars can throw off the scaling, which you can work around by changing the figure parameters. ```. #make red colormap. colors2 = plt.cm.Reds(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap = mymap(np.arange(mymap.N)). my_cmap[:,-1] = np.linspace(0, 1, mymap.N). my_cmap = colors.ListedColormap(my_cmap). sc.pl.umap(adata, color=['AIF1'], use_raw=True, color_map=my_cmap, show=False, frameon=False). ```. ![image](https://user-images.githubusercontent.com/56206488/126086651-df0d46c9-5f1d-4b64-8109-f82cd1feb9cb.png). ```. #make blue colormap. colors2 = plt.cm.Blues(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap2 = mymap(np.arange(mymap.N)). my_cmap2[:,-1] = np.linspace(0, 1, mymap.N). my_cmap2 = colors.ListedColormap(my_cmap2). sc.pl.umap(adata, color=['CD3E'], use_raw=True, color_map=my_cmap2, show=False, frameon=False, vmax=3). ```. ![image](https://user-images.githubusercontent.com/56206488/126086666-a0828d86-d943-47b8-8207-eb42aeb32e4b.png). ```. #make green colormap. colors2 = plt.cm.Greens(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap3 = mymap(np.arange(mymap.N)). my_cmap3[:,-1] = np.linspace(0, 1, mymap.N). my_cmap3 = colors.ListedColormap(my_cmap3). sc.pl.umap(adata, color=['CD79A'], use_raw=True, color_map=my_cmap3, show=False, frameon=False",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:960,usability,user,user-images,960,"Just to follow-up because I also had a similar question to the OP. Here's one way to plot several marker genes in different colors on the same UMAP plot. The trick is to make different colormaps that have an alpha gradient so that cells with NA expression appear transparent. Then just use matplot axes to merge the images. The only issue is that Scanpy doesn't yet allow you to remove colorbars for continuous variables, so the multiple colorbars can throw off the scaling, which you can work around by changing the figure parameters. ```. #make red colormap. colors2 = plt.cm.Reds(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap = mymap(np.arange(mymap.N)). my_cmap[:,-1] = np.linspace(0, 1, mymap.N). my_cmap = colors.ListedColormap(my_cmap). sc.pl.umap(adata, color=['AIF1'], use_raw=True, color_map=my_cmap, show=False, frameon=False). ```. ![image](https://user-images.githubusercontent.com/56206488/126086651-df0d46c9-5f1d-4b64-8109-f82cd1feb9cb.png). ```. #make blue colormap. colors2 = plt.cm.Blues(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap2 = mymap(np.arange(mymap.N)). my_cmap2[:,-1] = np.linspace(0, 1, mymap.N). my_cmap2 = colors.ListedColormap(my_cmap2). sc.pl.umap(adata, color=['CD3E'], use_raw=True, color_map=my_cmap2, show=False, frameon=False, vmax=3). ```. ![image](https://user-images.githubusercontent.com/56206488/126086666-a0828d86-d943-47b8-8207-eb42aeb32e4b.png). ```. #make green colormap. colors2 = plt.cm.Greens(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap3 = mymap(np.arange(mymap.N)). my_cmap3[:,-1] = np.linspace(0, 1, mymap.N). my_cmap3 = colors.ListedColormap(my_cmap3). sc.pl.umap(adata, color=['CD79A'], use_raw=True, color_map=my_cmap3, show=False, frameon=False",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:1495,usability,user,user-images,1495,"by changing the figure parameters. ```. #make red colormap. colors2 = plt.cm.Reds(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap = mymap(np.arange(mymap.N)). my_cmap[:,-1] = np.linspace(0, 1, mymap.N). my_cmap = colors.ListedColormap(my_cmap). sc.pl.umap(adata, color=['AIF1'], use_raw=True, color_map=my_cmap, show=False, frameon=False). ```. ![image](https://user-images.githubusercontent.com/56206488/126086651-df0d46c9-5f1d-4b64-8109-f82cd1feb9cb.png). ```. #make blue colormap. colors2 = plt.cm.Blues(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap2 = mymap(np.arange(mymap.N)). my_cmap2[:,-1] = np.linspace(0, 1, mymap.N). my_cmap2 = colors.ListedColormap(my_cmap2). sc.pl.umap(adata, color=['CD3E'], use_raw=True, color_map=my_cmap2, show=False, frameon=False, vmax=3). ```. ![image](https://user-images.githubusercontent.com/56206488/126086666-a0828d86-d943-47b8-8207-eb42aeb32e4b.png). ```. #make green colormap. colors2 = plt.cm.Greens(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap3 = mymap(np.arange(mymap.N)). my_cmap3[:,-1] = np.linspace(0, 1, mymap.N). my_cmap3 = colors.ListedColormap(my_cmap3). sc.pl.umap(adata, color=['CD79A'], use_raw=True, color_map=my_cmap3, show=False, frameon=False). ```. ![image](https://user-images.githubusercontent.com/56206488/126086688-66a3af40-ecc1-4b2e-a3e4-8038f7f207b0.png). ```. #make purple colormap. colors2 = plt.cm.Purples(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap4 = mymap(np.arange(mymap.N)). my_cmap4[:,-1] = np.linspace(0, 1, mymap.N). my_cmap4 = colors.ListedColormap(my_cmap4). sc.pl.umap(adata, color=['VWF'], use_raw=True, color_map=my_cma",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:2025,usability,user,user-images,2025,"-8109-f82cd1feb9cb.png). ```. #make blue colormap. colors2 = plt.cm.Blues(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap2 = mymap(np.arange(mymap.N)). my_cmap2[:,-1] = np.linspace(0, 1, mymap.N). my_cmap2 = colors.ListedColormap(my_cmap2). sc.pl.umap(adata, color=['CD3E'], use_raw=True, color_map=my_cmap2, show=False, frameon=False, vmax=3). ```. ![image](https://user-images.githubusercontent.com/56206488/126086666-a0828d86-d943-47b8-8207-eb42aeb32e4b.png). ```. #make green colormap. colors2 = plt.cm.Greens(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap3 = mymap(np.arange(mymap.N)). my_cmap3[:,-1] = np.linspace(0, 1, mymap.N). my_cmap3 = colors.ListedColormap(my_cmap3). sc.pl.umap(adata, color=['CD79A'], use_raw=True, color_map=my_cmap3, show=False, frameon=False). ```. ![image](https://user-images.githubusercontent.com/56206488/126086688-66a3af40-ecc1-4b2e-a3e4-8038f7f207b0.png). ```. #make purple colormap. colors2 = plt.cm.Purples(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap4 = mymap(np.arange(mymap.N)). my_cmap4[:,-1] = np.linspace(0, 1, mymap.N). my_cmap4 = colors.ListedColormap(my_cmap4). sc.pl.umap(adata, color=['VWF'], use_raw=True, color_map=my_cmap4, show=False, frameon=False, vmax=5). ```. ![image](https://user-images.githubusercontent.com/56206488/126086713-d8b24873-f3ea-4067-8573-99241db1c9b2.png). ```. #combine images to one UMAP. plt.rcParams['figure.figsize']=(6,4). ax = sc.pl.umap(adata, color=['AIF1'], use_raw=True, color_map=my_cmap, show=False, vmax=5, frameon=False). ax = sc.pl.umap(adata, color=['CD3E'], use_raw=True, color_map=my_cmap2, show=False, vmax=3, frameon=False, ax=ax). ax = sc.pl.umap(adata, color=['CD79A'], use_raw=True, color_map=my_cmap3, sh",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:2563,usability,user,user-images,2563,".N). my_cmap2 = colors.ListedColormap(my_cmap2). sc.pl.umap(adata, color=['CD3E'], use_raw=True, color_map=my_cmap2, show=False, frameon=False, vmax=3). ```. ![image](https://user-images.githubusercontent.com/56206488/126086666-a0828d86-d943-47b8-8207-eb42aeb32e4b.png). ```. #make green colormap. colors2 = plt.cm.Greens(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap3 = mymap(np.arange(mymap.N)). my_cmap3[:,-1] = np.linspace(0, 1, mymap.N). my_cmap3 = colors.ListedColormap(my_cmap3). sc.pl.umap(adata, color=['CD79A'], use_raw=True, color_map=my_cmap3, show=False, frameon=False). ```. ![image](https://user-images.githubusercontent.com/56206488/126086688-66a3af40-ecc1-4b2e-a3e4-8038f7f207b0.png). ```. #make purple colormap. colors2 = plt.cm.Purples(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap4 = mymap(np.arange(mymap.N)). my_cmap4[:,-1] = np.linspace(0, 1, mymap.N). my_cmap4 = colors.ListedColormap(my_cmap4). sc.pl.umap(adata, color=['VWF'], use_raw=True, color_map=my_cmap4, show=False, frameon=False, vmax=5). ```. ![image](https://user-images.githubusercontent.com/56206488/126086713-d8b24873-f3ea-4067-8573-99241db1c9b2.png). ```. #combine images to one UMAP. plt.rcParams['figure.figsize']=(6,4). ax = sc.pl.umap(adata, color=['AIF1'], use_raw=True, color_map=my_cmap, show=False, vmax=5, frameon=False). ax = sc.pl.umap(adata, color=['CD3E'], use_raw=True, color_map=my_cmap2, show=False, vmax=3, frameon=False, ax=ax). ax = sc.pl.umap(adata, color=['CD79A'], use_raw=True, color_map=my_cmap3, show=False, frameon=False, ax=ax). ax = sc.pl.umap(adata, color=['VWF'], use_raw=True, color_map=my_cmap4, show=True, frameon=False, ax=ax, vmax=5). ```. ![image](https://user-images.githubusercontent.com/56206488/126086774-4c92352c-83b2-4c58-9874-6ff61660e22d.png). Hope this helps someone!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:3200,usability,user,user-images,3200,".N). my_cmap2 = colors.ListedColormap(my_cmap2). sc.pl.umap(adata, color=['CD3E'], use_raw=True, color_map=my_cmap2, show=False, frameon=False, vmax=3). ```. ![image](https://user-images.githubusercontent.com/56206488/126086666-a0828d86-d943-47b8-8207-eb42aeb32e4b.png). ```. #make green colormap. colors2 = plt.cm.Greens(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap3 = mymap(np.arange(mymap.N)). my_cmap3[:,-1] = np.linspace(0, 1, mymap.N). my_cmap3 = colors.ListedColormap(my_cmap3). sc.pl.umap(adata, color=['CD79A'], use_raw=True, color_map=my_cmap3, show=False, frameon=False). ```. ![image](https://user-images.githubusercontent.com/56206488/126086688-66a3af40-ecc1-4b2e-a3e4-8038f7f207b0.png). ```. #make purple colormap. colors2 = plt.cm.Purples(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap4 = mymap(np.arange(mymap.N)). my_cmap4[:,-1] = np.linspace(0, 1, mymap.N). my_cmap4 = colors.ListedColormap(my_cmap4). sc.pl.umap(adata, color=['VWF'], use_raw=True, color_map=my_cmap4, show=False, frameon=False, vmax=5). ```. ![image](https://user-images.githubusercontent.com/56206488/126086713-d8b24873-f3ea-4067-8573-99241db1c9b2.png). ```. #combine images to one UMAP. plt.rcParams['figure.figsize']=(6,4). ax = sc.pl.umap(adata, color=['AIF1'], use_raw=True, color_map=my_cmap, show=False, vmax=5, frameon=False). ax = sc.pl.umap(adata, color=['CD3E'], use_raw=True, color_map=my_cmap2, show=False, vmax=3, frameon=False, ax=ax). ax = sc.pl.umap(adata, color=['CD79A'], use_raw=True, color_map=my_cmap3, show=False, frameon=False, ax=ax). ax = sc.pl.umap(adata, color=['VWF'], use_raw=True, color_map=my_cmap4, show=True, frameon=False, ax=ax, vmax=5). ```. ![image](https://user-images.githubusercontent.com/56206488/126086774-4c92352c-83b2-4c58-9874-6ff61660e22d.png). Hope this helps someone!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/532:3306,usability,help,helps,3306,".N). my_cmap2 = colors.ListedColormap(my_cmap2). sc.pl.umap(adata, color=['CD3E'], use_raw=True, color_map=my_cmap2, show=False, frameon=False, vmax=3). ```. ![image](https://user-images.githubusercontent.com/56206488/126086666-a0828d86-d943-47b8-8207-eb42aeb32e4b.png). ```. #make green colormap. colors2 = plt.cm.Greens(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap3 = mymap(np.arange(mymap.N)). my_cmap3[:,-1] = np.linspace(0, 1, mymap.N). my_cmap3 = colors.ListedColormap(my_cmap3). sc.pl.umap(adata, color=['CD79A'], use_raw=True, color_map=my_cmap3, show=False, frameon=False). ```. ![image](https://user-images.githubusercontent.com/56206488/126086688-66a3af40-ecc1-4b2e-a3e4-8038f7f207b0.png). ```. #make purple colormap. colors2 = plt.cm.Purples(np.linspace(0, 1, 128)). colorsComb = np.vstack([colors2]). mymap = colors.LinearSegmentedColormap.from_list('my_colormap', colorsComb). my_cmap4 = mymap(np.arange(mymap.N)). my_cmap4[:,-1] = np.linspace(0, 1, mymap.N). my_cmap4 = colors.ListedColormap(my_cmap4). sc.pl.umap(adata, color=['VWF'], use_raw=True, color_map=my_cmap4, show=False, frameon=False, vmax=5). ```. ![image](https://user-images.githubusercontent.com/56206488/126086713-d8b24873-f3ea-4067-8573-99241db1c9b2.png). ```. #combine images to one UMAP. plt.rcParams['figure.figsize']=(6,4). ax = sc.pl.umap(adata, color=['AIF1'], use_raw=True, color_map=my_cmap, show=False, vmax=5, frameon=False). ax = sc.pl.umap(adata, color=['CD3E'], use_raw=True, color_map=my_cmap2, show=False, vmax=3, frameon=False, ax=ax). ax = sc.pl.umap(adata, color=['CD79A'], use_raw=True, color_map=my_cmap3, show=False, frameon=False, ax=ax). ax = sc.pl.umap(adata, color=['VWF'], use_raw=True, color_map=my_cmap4, show=True, frameon=False, ax=ax, vmax=5). ```. ![image](https://user-images.githubusercontent.com/56206488/126086774-4c92352c-83b2-4c58-9874-6ff61660e22d.png). Hope this helps someone!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/532
https://github.com/scverse/scanpy/issues/535:485,deployability,fail,fail,485,"I think to preserve the signature like that we could easily do a subset of what `update_wrapper` (and therefore `wraps`) does:. ```py. def wraps_plot_scatter(wrapper):. wrapper.__annotations__ = {. k: v for k, v in plot_scatter.__annotations__.items(). if k != 'basis'. }. wrapper.__wrapped__ = plot_scatter. return wrapper. @wraps_plot_scatter. def umap(adata, **kwargs):. """"""..."""""". return plot_scatter(adata, basis='umap', **kwargs). ```. but first: what did you try and why did it fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:65,integrability,sub,subset,65,"I think to preserve the signature like that we could easily do a subset of what `update_wrapper` (and therefore `wraps`) does:. ```py. def wraps_plot_scatter(wrapper):. wrapper.__annotations__ = {. k: v for k, v in plot_scatter.__annotations__.items(). if k != 'basis'. }. wrapper.__wrapped__ = plot_scatter. return wrapper. @wraps_plot_scatter. def umap(adata, **kwargs):. """"""..."""""". return plot_scatter(adata, basis='umap', **kwargs). ```. but first: what did you try and why did it fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:113,integrability,wrap,wraps,113,"I think to preserve the signature like that we could easily do a subset of what `update_wrapper` (and therefore `wraps`) does:. ```py. def wraps_plot_scatter(wrapper):. wrapper.__annotations__ = {. k: v for k, v in plot_scatter.__annotations__.items(). if k != 'basis'. }. wrapper.__wrapped__ = plot_scatter. return wrapper. @wraps_plot_scatter. def umap(adata, **kwargs):. """"""..."""""". return plot_scatter(adata, basis='umap', **kwargs). ```. but first: what did you try and why did it fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:158,integrability,wrap,wrapper,158,"I think to preserve the signature like that we could easily do a subset of what `update_wrapper` (and therefore `wraps`) does:. ```py. def wraps_plot_scatter(wrapper):. wrapper.__annotations__ = {. k: v for k, v in plot_scatter.__annotations__.items(). if k != 'basis'. }. wrapper.__wrapped__ = plot_scatter. return wrapper. @wraps_plot_scatter. def umap(adata, **kwargs):. """"""..."""""". return plot_scatter(adata, basis='umap', **kwargs). ```. but first: what did you try and why did it fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:169,integrability,wrap,wrapper,169,"I think to preserve the signature like that we could easily do a subset of what `update_wrapper` (and therefore `wraps`) does:. ```py. def wraps_plot_scatter(wrapper):. wrapper.__annotations__ = {. k: v for k, v in plot_scatter.__annotations__.items(). if k != 'basis'. }. wrapper.__wrapped__ = plot_scatter. return wrapper. @wraps_plot_scatter. def umap(adata, **kwargs):. """"""..."""""". return plot_scatter(adata, basis='umap', **kwargs). ```. but first: what did you try and why did it fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:273,integrability,wrap,wrapper,273,"I think to preserve the signature like that we could easily do a subset of what `update_wrapper` (and therefore `wraps`) does:. ```py. def wraps_plot_scatter(wrapper):. wrapper.__annotations__ = {. k: v for k, v in plot_scatter.__annotations__.items(). if k != 'basis'. }. wrapper.__wrapped__ = plot_scatter. return wrapper. @wraps_plot_scatter. def umap(adata, **kwargs):. """"""..."""""". return plot_scatter(adata, basis='umap', **kwargs). ```. but first: what did you try and why did it fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:316,integrability,wrap,wrapper,316,"I think to preserve the signature like that we could easily do a subset of what `update_wrapper` (and therefore `wraps`) does:. ```py. def wraps_plot_scatter(wrapper):. wrapper.__annotations__ = {. k: v for k, v in plot_scatter.__annotations__.items(). if k != 'basis'. }. wrapper.__wrapped__ = plot_scatter. return wrapper. @wraps_plot_scatter. def umap(adata, **kwargs):. """"""..."""""". return plot_scatter(adata, basis='umap', **kwargs). ```. but first: what did you try and why did it fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:158,interoperability,wrapper,wrapper,158,"I think to preserve the signature like that we could easily do a subset of what `update_wrapper` (and therefore `wraps`) does:. ```py. def wraps_plot_scatter(wrapper):. wrapper.__annotations__ = {. k: v for k, v in plot_scatter.__annotations__.items(). if k != 'basis'. }. wrapper.__wrapped__ = plot_scatter. return wrapper. @wraps_plot_scatter. def umap(adata, **kwargs):. """"""..."""""". return plot_scatter(adata, basis='umap', **kwargs). ```. but first: what did you try and why did it fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:169,interoperability,wrapper,wrapper,169,"I think to preserve the signature like that we could easily do a subset of what `update_wrapper` (and therefore `wraps`) does:. ```py. def wraps_plot_scatter(wrapper):. wrapper.__annotations__ = {. k: v for k, v in plot_scatter.__annotations__.items(). if k != 'basis'. }. wrapper.__wrapped__ = plot_scatter. return wrapper. @wraps_plot_scatter. def umap(adata, **kwargs):. """"""..."""""". return plot_scatter(adata, basis='umap', **kwargs). ```. but first: what did you try and why did it fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:273,interoperability,wrapper,wrapper,273,"I think to preserve the signature like that we could easily do a subset of what `update_wrapper` (and therefore `wraps`) does:. ```py. def wraps_plot_scatter(wrapper):. wrapper.__annotations__ = {. k: v for k, v in plot_scatter.__annotations__.items(). if k != 'basis'. }. wrapper.__wrapped__ = plot_scatter. return wrapper. @wraps_plot_scatter. def umap(adata, **kwargs):. """"""..."""""". return plot_scatter(adata, basis='umap', **kwargs). ```. but first: what did you try and why did it fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:316,interoperability,wrapper,wrapper,316,"I think to preserve the signature like that we could easily do a subset of what `update_wrapper` (and therefore `wraps`) does:. ```py. def wraps_plot_scatter(wrapper):. wrapper.__annotations__ = {. k: v for k, v in plot_scatter.__annotations__.items(). if k != 'basis'. }. wrapper.__wrapped__ = plot_scatter. return wrapper. @wraps_plot_scatter. def umap(adata, **kwargs):. """"""..."""""". return plot_scatter(adata, basis='umap', **kwargs). ```. but first: what did you try and why did it fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:121,reliability,doe,does,121,"I think to preserve the signature like that we could easily do a subset of what `update_wrapper` (and therefore `wraps`) does:. ```py. def wraps_plot_scatter(wrapper):. wrapper.__annotations__ = {. k: v for k, v in plot_scatter.__annotations__.items(). if k != 'basis'. }. wrapper.__wrapped__ = plot_scatter. return wrapper. @wraps_plot_scatter. def umap(adata, **kwargs):. """"""..."""""". return plot_scatter(adata, basis='umap', **kwargs). ```. but first: what did you try and why did it fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:485,reliability,fail,fail,485,"I think to preserve the signature like that we could easily do a subset of what `update_wrapper` (and therefore `wraps`) does:. ```py. def wraps_plot_scatter(wrapper):. wrapper.__annotations__ = {. k: v for k, v in plot_scatter.__annotations__.items(). if k != 'basis'. }. wrapper.__wrapped__ = plot_scatter. return wrapper. @wraps_plot_scatter. def umap(adata, **kwargs):. """"""..."""""". return plot_scatter(adata, basis='umap', **kwargs). ```. but first: what did you try and why did it fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:24,security,sign,signature,24,"I think to preserve the signature like that we could easily do a subset of what `update_wrapper` (and therefore `wraps`) does:. ```py. def wraps_plot_scatter(wrapper):. wrapper.__annotations__ = {. k: v for k, v in plot_scatter.__annotations__.items(). if k != 'basis'. }. wrapper.__wrapped__ = plot_scatter. return wrapper. @wraps_plot_scatter. def umap(adata, **kwargs):. """"""..."""""". return plot_scatter(adata, basis='umap', **kwargs). ```. but first: what did you try and why did it fail?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:91,integrability,wrap,wraps,91,"Here's pretty much what I've tried:. ```python. import scanpy as sc. from functools import wraps, partial. pca = wraps(sc.pl.scatter)(partial(sc.pl.scatter, basis=""pca"")). pca( #tried tab completion here. ```. Tab completion shows:. <img width=""597"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/54574990-8e796f80-4a46-11e9-8ad4-ae5aeead9604.png"">. As opposed to:. <img width=""598"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/54580161-fdf95a00-4a5a-11e9-9b51-8eeec17babfc.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:113,integrability,wrap,wraps,113,"Here's pretty much what I've tried:. ```python. import scanpy as sc. from functools import wraps, partial. pca = wraps(sc.pl.scatter)(partial(sc.pl.scatter, basis=""pca"")). pca( #tried tab completion here. ```. Tab completion shows:. <img width=""597"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/54574990-8e796f80-4a46-11e9-8ad4-ae5aeead9604.png"">. As opposed to:. <img width=""598"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/54580161-fdf95a00-4a5a-11e9-9b51-8eeec17babfc.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:188,safety,compl,completion,188,"Here's pretty much what I've tried:. ```python. import scanpy as sc. from functools import wraps, partial. pca = wraps(sc.pl.scatter)(partial(sc.pl.scatter, basis=""pca"")). pca( #tried tab completion here. ```. Tab completion shows:. <img width=""597"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/54574990-8e796f80-4a46-11e9-8ad4-ae5aeead9604.png"">. As opposed to:. <img width=""598"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/54580161-fdf95a00-4a5a-11e9-9b51-8eeec17babfc.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:214,safety,compl,completion,214,"Here's pretty much what I've tried:. ```python. import scanpy as sc. from functools import wraps, partial. pca = wraps(sc.pl.scatter)(partial(sc.pl.scatter, basis=""pca"")). pca( #tried tab completion here. ```. Tab completion shows:. <img width=""597"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/54574990-8e796f80-4a46-11e9-8ad4-ae5aeead9604.png"">. As opposed to:. <img width=""598"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/54580161-fdf95a00-4a5a-11e9-9b51-8eeec17babfc.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:188,security,compl,completion,188,"Here's pretty much what I've tried:. ```python. import scanpy as sc. from functools import wraps, partial. pca = wraps(sc.pl.scatter)(partial(sc.pl.scatter, basis=""pca"")). pca( #tried tab completion here. ```. Tab completion shows:. <img width=""597"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/54574990-8e796f80-4a46-11e9-8ad4-ae5aeead9604.png"">. As opposed to:. <img width=""598"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/54580161-fdf95a00-4a5a-11e9-9b51-8eeec17babfc.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:214,security,compl,completion,214,"Here's pretty much what I've tried:. ```python. import scanpy as sc. from functools import wraps, partial. pca = wraps(sc.pl.scatter)(partial(sc.pl.scatter, basis=""pca"")). pca( #tried tab completion here. ```. Tab completion shows:. <img width=""597"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/54574990-8e796f80-4a46-11e9-8ad4-ae5aeead9604.png"">. As opposed to:. <img width=""598"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/54580161-fdf95a00-4a5a-11e9-9b51-8eeec17babfc.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:275,usability,user,user-images,275,"Here's pretty much what I've tried:. ```python. import scanpy as sc. from functools import wraps, partial. pca = wraps(sc.pl.scatter)(partial(sc.pl.scatter, basis=""pca"")). pca( #tried tab completion here. ```. Tab completion shows:. <img width=""597"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/54574990-8e796f80-4a46-11e9-8ad4-ae5aeead9604.png"">. As opposed to:. <img width=""598"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/54580161-fdf95a00-4a5a-11e9-9b51-8eeec17babfc.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:428,usability,user,user-images,428,"Here's pretty much what I've tried:. ```python. import scanpy as sc. from functools import wraps, partial. pca = wraps(sc.pl.scatter)(partial(sc.pl.scatter, basis=""pca"")). pca( #tried tab completion here. ```. Tab completion shows:. <img width=""597"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/54574990-8e796f80-4a46-11e9-8ad4-ae5aeead9604.png"">. As opposed to:. <img width=""598"" alt=""image"" src=""https://user-images.githubusercontent.com/8238804/54580161-fdf95a00-4a5a-11e9-9b51-8eeec17babfc.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:156,integrability,wrap,wraps,156,"Hmm, doesn’t seem to work with `functools.partial`. It works if I do almost the same, but with a lambda:. ```py. import scanpy as sc. from functools import wraps, partial. pca = wraps(sc.pl.scatter)(lambda *args, **kw: sc.pl.scatter(*args, basis=""pca"", **kw)). ```. But I think the custom solution above is better anyway! `wraps` is if you really want to pose as the wrapped function, while we only want to inherit its signature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:178,integrability,wrap,wraps,178,"Hmm, doesn’t seem to work with `functools.partial`. It works if I do almost the same, but with a lambda:. ```py. import scanpy as sc. from functools import wraps, partial. pca = wraps(sc.pl.scatter)(lambda *args, **kw: sc.pl.scatter(*args, basis=""pca"", **kw)). ```. But I think the custom solution above is better anyway! `wraps` is if you really want to pose as the wrapped function, while we only want to inherit its signature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:323,integrability,wrap,wraps,323,"Hmm, doesn’t seem to work with `functools.partial`. It works if I do almost the same, but with a lambda:. ```py. import scanpy as sc. from functools import wraps, partial. pca = wraps(sc.pl.scatter)(lambda *args, **kw: sc.pl.scatter(*args, basis=""pca"", **kw)). ```. But I think the custom solution above is better anyway! `wraps` is if you really want to pose as the wrapped function, while we only want to inherit its signature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:367,integrability,wrap,wrapped,367,"Hmm, doesn’t seem to work with `functools.partial`. It works if I do almost the same, but with a lambda:. ```py. import scanpy as sc. from functools import wraps, partial. pca = wraps(sc.pl.scatter)(lambda *args, **kw: sc.pl.scatter(*args, basis=""pca"", **kw)). ```. But I think the custom solution above is better anyway! `wraps` is if you really want to pose as the wrapped function, while we only want to inherit its signature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:407,modifiability,inherit,inherit,407,"Hmm, doesn’t seem to work with `functools.partial`. It works if I do almost the same, but with a lambda:. ```py. import scanpy as sc. from functools import wraps, partial. pca = wraps(sc.pl.scatter)(lambda *args, **kw: sc.pl.scatter(*args, basis=""pca"", **kw)). ```. But I think the custom solution above is better anyway! `wraps` is if you really want to pose as the wrapped function, while we only want to inherit its signature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:5,reliability,doe,doesn,5,"Hmm, doesn’t seem to work with `functools.partial`. It works if I do almost the same, but with a lambda:. ```py. import scanpy as sc. from functools import wraps, partial. pca = wraps(sc.pl.scatter)(lambda *args, **kw: sc.pl.scatter(*args, basis=""pca"", **kw)). ```. But I think the custom solution above is better anyway! `wraps` is if you really want to pose as the wrapped function, while we only want to inherit its signature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:419,security,sign,signature,419,"Hmm, doesn’t seem to work with `functools.partial`. It works if I do almost the same, but with a lambda:. ```py. import scanpy as sc. from functools import wraps, partial. pca = wraps(sc.pl.scatter)(lambda *args, **kw: sc.pl.scatter(*args, basis=""pca"", **kw)). ```. But I think the custom solution above is better anyway! `wraps` is if you really want to pose as the wrapped function, while we only want to inherit its signature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:282,usability,custom,custom,282,"Hmm, doesn’t seem to work with `functools.partial`. It works if I do almost the same, but with a lambda:. ```py. import scanpy as sc. from functools import wraps, partial. pca = wraps(sc.pl.scatter)(lambda *args, **kw: sc.pl.scatter(*args, basis=""pca"", **kw)). ```. But I think the custom solution above is better anyway! `wraps` is if you really want to pose as the wrapped function, while we only want to inherit its signature.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:94,deployability,API,API,94,"Just wanted to mention that this would add much convenience. Since Fidel rewrote the plotting API, I saw that it was the right thing to do to reduce all the code in the almost-identical function headers, but I was missing the autocomplete, which had obviously disappeared.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:142,energy efficiency,reduc,reduce,142,"Just wanted to mention that this would add much convenience. Since Fidel rewrote the plotting API, I saw that it was the right thing to do to reduce all the code in the almost-identical function headers, but I was missing the autocomplete, which had obviously disappeared.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:94,integrability,API,API,94,"Just wanted to mention that this would add much convenience. Since Fidel rewrote the plotting API, I saw that it was the right thing to do to reduce all the code in the almost-identical function headers, but I was missing the autocomplete, which had obviously disappeared.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:94,interoperability,API,API,94,"Just wanted to mention that this would add much convenience. Since Fidel rewrote the plotting API, I saw that it was the right thing to do to reduce all the code in the almost-identical function headers, but I was missing the autocomplete, which had obviously disappeared.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/535:176,security,ident,identical,176,"Just wanted to mention that this would add much convenience. Since Fidel rewrote the plotting API, I saw that it was the right thing to do to reduce all the code in the almost-identical function headers, but I was missing the autocomplete, which had obviously disappeared.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/535
https://github.com/scverse/scanpy/issues/536:185,availability,avail,available,185,"That's very strange. I will take a look. On Mon, Mar 18, 2019 at 4:09 PM Fabian Rost <notifications@github.com>. wrote:. > I have a dataset for which I have an observation that is only available. > for some cells. When I make a scatter plot that I color code for this. > observation not all cells are plotted:. >. > import randomimport scanpy as sc. >. > adata = sc.datasets.blobs(). > adata.obs['property'] = 630 * [float(""nan"")] + 10 * [1]. >. > sc.tl.pca(adata). > sc.pl.pca(adata, color='property', size=50). >. > While this should plot 10 cells it only shows one cell:. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540172-caa1c700-4997-11e9-946e-01c1e04dd2d2.png>. > I can get the plot I want by filtering cells first:. >. > sc.pl.pca(adata[adata.obs['property'] == 1], color='property', size=50). >. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540221-e60cd200-4997-11e9-9b53-e9917bd01c59.png>. > Would you agree that scanpy should plot all cells that have a valid. > observation? >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/536>, or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1X3Le-1usPntk050roRY9vedXEHHks5vX6wMgaJpZM4b6BYA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:160,deployability,observ,observation,160,"That's very strange. I will take a look. On Mon, Mar 18, 2019 at 4:09 PM Fabian Rost <notifications@github.com>. wrote:. > I have a dataset for which I have an observation that is only available. > for some cells. When I make a scatter plot that I color code for this. > observation not all cells are plotted:. >. > import randomimport scanpy as sc. >. > adata = sc.datasets.blobs(). > adata.obs['property'] = 630 * [float(""nan"")] + 10 * [1]. >. > sc.tl.pca(adata). > sc.pl.pca(adata, color='property', size=50). >. > While this should plot 10 cells it only shows one cell:. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540172-caa1c700-4997-11e9-946e-01c1e04dd2d2.png>. > I can get the plot I want by filtering cells first:. >. > sc.pl.pca(adata[adata.obs['property'] == 1], color='property', size=50). >. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540221-e60cd200-4997-11e9-9b53-e9917bd01c59.png>. > Would you agree that scanpy should plot all cells that have a valid. > observation? >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/536>, or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1X3Le-1usPntk050roRY9vedXEHHks5vX6wMgaJpZM4b6BYA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:271,deployability,observ,observation,271,"That's very strange. I will take a look. On Mon, Mar 18, 2019 at 4:09 PM Fabian Rost <notifications@github.com>. wrote:. > I have a dataset for which I have an observation that is only available. > for some cells. When I make a scatter plot that I color code for this. > observation not all cells are plotted:. >. > import randomimport scanpy as sc. >. > adata = sc.datasets.blobs(). > adata.obs['property'] = 630 * [float(""nan"")] + 10 * [1]. >. > sc.tl.pca(adata). > sc.pl.pca(adata, color='property', size=50). >. > While this should plot 10 cells it only shows one cell:. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540172-caa1c700-4997-11e9-946e-01c1e04dd2d2.png>. > I can get the plot I want by filtering cells first:. >. > sc.pl.pca(adata[adata.obs['property'] == 1], color='property', size=50). >. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540221-e60cd200-4997-11e9-9b53-e9917bd01c59.png>. > Would you agree that scanpy should plot all cells that have a valid. > observation? >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/536>, or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1X3Le-1usPntk050roRY9vedXEHHks5vX6wMgaJpZM4b6BYA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:1030,deployability,observ,observation,1030,"That's very strange. I will take a look. On Mon, Mar 18, 2019 at 4:09 PM Fabian Rost <notifications@github.com>. wrote:. > I have a dataset for which I have an observation that is only available. > for some cells. When I make a scatter plot that I color code for this. > observation not all cells are plotted:. >. > import randomimport scanpy as sc. >. > adata = sc.datasets.blobs(). > adata.obs['property'] = 630 * [float(""nan"")] + 10 * [1]. >. > sc.tl.pca(adata). > sc.pl.pca(adata, color='property', size=50). >. > While this should plot 10 cells it only shows one cell:. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540172-caa1c700-4997-11e9-946e-01c1e04dd2d2.png>. > I can get the plot I want by filtering cells first:. >. > sc.pl.pca(adata[adata.obs['property'] == 1], color='property', size=50). >. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540221-e60cd200-4997-11e9-9b53-e9917bd01c59.png>. > Would you agree that scanpy should plot all cells that have a valid. > observation? >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/536>, or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1X3Le-1usPntk050roRY9vedXEHHks5vX6wMgaJpZM4b6BYA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:729,integrability,filter,filtering,729,"That's very strange. I will take a look. On Mon, Mar 18, 2019 at 4:09 PM Fabian Rost <notifications@github.com>. wrote:. > I have a dataset for which I have an observation that is only available. > for some cells. When I make a scatter plot that I color code for this. > observation not all cells are plotted:. >. > import randomimport scanpy as sc. >. > adata = sc.datasets.blobs(). > adata.obs['property'] = 630 * [float(""nan"")] + 10 * [1]. >. > sc.tl.pca(adata). > sc.pl.pca(adata, color='property', size=50). >. > While this should plot 10 cells it only shows one cell:. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540172-caa1c700-4997-11e9-946e-01c1e04dd2d2.png>. > I can get the plot I want by filtering cells first:. >. > sc.pl.pca(adata[adata.obs['property'] == 1], color='property', size=50). >. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540221-e60cd200-4997-11e9-9b53-e9917bd01c59.png>. > Would you agree that scanpy should plot all cells that have a valid. > observation? >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/536>, or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1X3Le-1usPntk050roRY9vedXEHHks5vX6wMgaJpZM4b6BYA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:1092,integrability,sub,subscribed,1092,"That's very strange. I will take a look. On Mon, Mar 18, 2019 at 4:09 PM Fabian Rost <notifications@github.com>. wrote:. > I have a dataset for which I have an observation that is only available. > for some cells. When I make a scatter plot that I color code for this. > observation not all cells are plotted:. >. > import randomimport scanpy as sc. >. > adata = sc.datasets.blobs(). > adata.obs['property'] = 630 * [float(""nan"")] + 10 * [1]. >. > sc.tl.pca(adata). > sc.pl.pca(adata, color='property', size=50). >. > While this should plot 10 cells it only shows one cell:. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540172-caa1c700-4997-11e9-946e-01c1e04dd2d2.png>. > I can get the plot I want by filtering cells first:. >. > sc.pl.pca(adata[adata.obs['property'] == 1], color='property', size=50). >. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540221-e60cd200-4997-11e9-9b53-e9917bd01c59.png>. > Would you agree that scanpy should plot all cells that have a valid. > observation? >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/536>, or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1X3Le-1usPntk050roRY9vedXEHHks5vX6wMgaJpZM4b6BYA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:185,reliability,availab,available,185,"That's very strange. I will take a look. On Mon, Mar 18, 2019 at 4:09 PM Fabian Rost <notifications@github.com>. wrote:. > I have a dataset for which I have an observation that is only available. > for some cells. When I make a scatter plot that I color code for this. > observation not all cells are plotted:. >. > import randomimport scanpy as sc. >. > adata = sc.datasets.blobs(). > adata.obs['property'] = 630 * [float(""nan"")] + 10 * [1]. >. > sc.tl.pca(adata). > sc.pl.pca(adata, color='property', size=50). >. > While this should plot 10 cells it only shows one cell:. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540172-caa1c700-4997-11e9-946e-01c1e04dd2d2.png>. > I can get the plot I want by filtering cells first:. >. > sc.pl.pca(adata[adata.obs['property'] == 1], color='property', size=50). >. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540221-e60cd200-4997-11e9-9b53-e9917bd01c59.png>. > Would you agree that scanpy should plot all cells that have a valid. > observation? >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/536>, or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1X3Le-1usPntk050roRY9vedXEHHks5vX6wMgaJpZM4b6BYA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:185,safety,avail,available,185,"That's very strange. I will take a look. On Mon, Mar 18, 2019 at 4:09 PM Fabian Rost <notifications@github.com>. wrote:. > I have a dataset for which I have an observation that is only available. > for some cells. When I make a scatter plot that I color code for this. > observation not all cells are plotted:. >. > import randomimport scanpy as sc. >. > adata = sc.datasets.blobs(). > adata.obs['property'] = 630 * [float(""nan"")] + 10 * [1]. >. > sc.tl.pca(adata). > sc.pl.pca(adata, color='property', size=50). >. > While this should plot 10 cells it only shows one cell:. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540172-caa1c700-4997-11e9-946e-01c1e04dd2d2.png>. > I can get the plot I want by filtering cells first:. >. > sc.pl.pca(adata[adata.obs['property'] == 1], color='property', size=50). >. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540221-e60cd200-4997-11e9-9b53-e9917bd01c59.png>. > Would you agree that scanpy should plot all cells that have a valid. > observation? >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/536>, or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1X3Le-1usPntk050roRY9vedXEHHks5vX6wMgaJpZM4b6BYA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:1021,safety,valid,valid,1021,"That's very strange. I will take a look. On Mon, Mar 18, 2019 at 4:09 PM Fabian Rost <notifications@github.com>. wrote:. > I have a dataset for which I have an observation that is only available. > for some cells. When I make a scatter plot that I color code for this. > observation not all cells are plotted:. >. > import randomimport scanpy as sc. >. > adata = sc.datasets.blobs(). > adata.obs['property'] = 630 * [float(""nan"")] + 10 * [1]. >. > sc.tl.pca(adata). > sc.pl.pca(adata, color='property', size=50). >. > While this should plot 10 cells it only shows one cell:. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540172-caa1c700-4997-11e9-946e-01c1e04dd2d2.png>. > I can get the plot I want by filtering cells first:. >. > sc.pl.pca(adata[adata.obs['property'] == 1], color='property', size=50). >. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540221-e60cd200-4997-11e9-9b53-e9917bd01c59.png>. > Would you agree that scanpy should plot all cells that have a valid. > observation? >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/536>, or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1X3Le-1usPntk050roRY9vedXEHHks5vX6wMgaJpZM4b6BYA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:185,security,availab,available,185,"That's very strange. I will take a look. On Mon, Mar 18, 2019 at 4:09 PM Fabian Rost <notifications@github.com>. wrote:. > I have a dataset for which I have an observation that is only available. > for some cells. When I make a scatter plot that I color code for this. > observation not all cells are plotted:. >. > import randomimport scanpy as sc. >. > adata = sc.datasets.blobs(). > adata.obs['property'] = 630 * [float(""nan"")] + 10 * [1]. >. > sc.tl.pca(adata). > sc.pl.pca(adata, color='property', size=50). >. > While this should plot 10 cells it only shows one cell:. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540172-caa1c700-4997-11e9-946e-01c1e04dd2d2.png>. > I can get the plot I want by filtering cells first:. >. > sc.pl.pca(adata[adata.obs['property'] == 1], color='property', size=50). >. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540221-e60cd200-4997-11e9-9b53-e9917bd01c59.png>. > Would you agree that scanpy should plot all cells that have a valid. > observation? >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/536>, or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1X3Le-1usPntk050roRY9vedXEHHks5vX6wMgaJpZM4b6BYA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:1289,security,auth,auth,1289,"That's very strange. I will take a look. On Mon, Mar 18, 2019 at 4:09 PM Fabian Rost <notifications@github.com>. wrote:. > I have a dataset for which I have an observation that is only available. > for some cells. When I make a scatter plot that I color code for this. > observation not all cells are plotted:. >. > import randomimport scanpy as sc. >. > adata = sc.datasets.blobs(). > adata.obs['property'] = 630 * [float(""nan"")] + 10 * [1]. >. > sc.tl.pca(adata). > sc.pl.pca(adata, color='property', size=50). >. > While this should plot 10 cells it only shows one cell:. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540172-caa1c700-4997-11e9-946e-01c1e04dd2d2.png>. > I can get the plot I want by filtering cells first:. >. > sc.pl.pca(adata[adata.obs['property'] == 1], color='property', size=50). >. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540221-e60cd200-4997-11e9-9b53-e9917bd01c59.png>. > Would you agree that scanpy should plot all cells that have a valid. > observation? >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/536>, or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1X3Le-1usPntk050roRY9vedXEHHks5vX6wMgaJpZM4b6BYA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:160,testability,observ,observation,160,"That's very strange. I will take a look. On Mon, Mar 18, 2019 at 4:09 PM Fabian Rost <notifications@github.com>. wrote:. > I have a dataset for which I have an observation that is only available. > for some cells. When I make a scatter plot that I color code for this. > observation not all cells are plotted:. >. > import randomimport scanpy as sc. >. > adata = sc.datasets.blobs(). > adata.obs['property'] = 630 * [float(""nan"")] + 10 * [1]. >. > sc.tl.pca(adata). > sc.pl.pca(adata, color='property', size=50). >. > While this should plot 10 cells it only shows one cell:. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540172-caa1c700-4997-11e9-946e-01c1e04dd2d2.png>. > I can get the plot I want by filtering cells first:. >. > sc.pl.pca(adata[adata.obs['property'] == 1], color='property', size=50). >. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540221-e60cd200-4997-11e9-9b53-e9917bd01c59.png>. > Would you agree that scanpy should plot all cells that have a valid. > observation? >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/536>, or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1X3Le-1usPntk050roRY9vedXEHHks5vX6wMgaJpZM4b6BYA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:271,testability,observ,observation,271,"That's very strange. I will take a look. On Mon, Mar 18, 2019 at 4:09 PM Fabian Rost <notifications@github.com>. wrote:. > I have a dataset for which I have an observation that is only available. > for some cells. When I make a scatter plot that I color code for this. > observation not all cells are plotted:. >. > import randomimport scanpy as sc. >. > adata = sc.datasets.blobs(). > adata.obs['property'] = 630 * [float(""nan"")] + 10 * [1]. >. > sc.tl.pca(adata). > sc.pl.pca(adata, color='property', size=50). >. > While this should plot 10 cells it only shows one cell:. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540172-caa1c700-4997-11e9-946e-01c1e04dd2d2.png>. > I can get the plot I want by filtering cells first:. >. > sc.pl.pca(adata[adata.obs['property'] == 1], color='property', size=50). >. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540221-e60cd200-4997-11e9-9b53-e9917bd01c59.png>. > Would you agree that scanpy should plot all cells that have a valid. > observation? >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/536>, or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1X3Le-1usPntk050roRY9vedXEHHks5vX6wMgaJpZM4b6BYA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:1030,testability,observ,observation,1030,"That's very strange. I will take a look. On Mon, Mar 18, 2019 at 4:09 PM Fabian Rost <notifications@github.com>. wrote:. > I have a dataset for which I have an observation that is only available. > for some cells. When I make a scatter plot that I color code for this. > observation not all cells are plotted:. >. > import randomimport scanpy as sc. >. > adata = sc.datasets.blobs(). > adata.obs['property'] = 630 * [float(""nan"")] + 10 * [1]. >. > sc.tl.pca(adata). > sc.pl.pca(adata, color='property', size=50). >. > While this should plot 10 cells it only shows one cell:. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540172-caa1c700-4997-11e9-946e-01c1e04dd2d2.png>. > I can get the plot I want by filtering cells first:. >. > sc.pl.pca(adata[adata.obs['property'] == 1], color='property', size=50). >. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540221-e60cd200-4997-11e9-9b53-e9917bd01c59.png>. > Would you agree that scanpy should plot all cells that have a valid. > observation? >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/536>, or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1X3Le-1usPntk050roRY9vedXEHHks5vX6wMgaJpZM4b6BYA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:604,usability,user,user-images,604,"That's very strange. I will take a look. On Mon, Mar 18, 2019 at 4:09 PM Fabian Rost <notifications@github.com>. wrote:. > I have a dataset for which I have an observation that is only available. > for some cells. When I make a scatter plot that I color code for this. > observation not all cells are plotted:. >. > import randomimport scanpy as sc. >. > adata = sc.datasets.blobs(). > adata.obs['property'] = 630 * [float(""nan"")] + 10 * [1]. >. > sc.tl.pca(adata). > sc.pl.pca(adata, color='property', size=50). >. > While this should plot 10 cells it only shows one cell:. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540172-caa1c700-4997-11e9-946e-01c1e04dd2d2.png>. > I can get the plot I want by filtering cells first:. >. > sc.pl.pca(adata[adata.obs['property'] == 1], color='property', size=50). >. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540221-e60cd200-4997-11e9-9b53-e9917bd01c59.png>. > Would you agree that scanpy should plot all cells that have a valid. > observation? >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/536>, or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1X3Le-1usPntk050roRY9vedXEHHks5vX6wMgaJpZM4b6BYA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:863,usability,user,user-images,863,"That's very strange. I will take a look. On Mon, Mar 18, 2019 at 4:09 PM Fabian Rost <notifications@github.com>. wrote:. > I have a dataset for which I have an observation that is only available. > for some cells. When I make a scatter plot that I color code for this. > observation not all cells are plotted:. >. > import randomimport scanpy as sc. >. > adata = sc.datasets.blobs(). > adata.obs['property'] = 630 * [float(""nan"")] + 10 * [1]. >. > sc.tl.pca(adata). > sc.pl.pca(adata, color='property', size=50). >. > While this should plot 10 cells it only shows one cell:. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540172-caa1c700-4997-11e9-946e-01c1e04dd2d2.png>. > I can get the plot I want by filtering cells first:. >. > sc.pl.pca(adata[adata.obs['property'] == 1], color='property', size=50). >. > [image: image]. > <https://user-images.githubusercontent.com/7300030/54540221-e60cd200-4997-11e9-9b53-e9917bd01c59.png>. > Would you agree that scanpy should plot all cells that have a valid. > observation? >. > —. > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/536>, or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1X3Le-1usPntk050roRY9vedXEHHks5vX6wMgaJpZM4b6BYA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:15,deployability,version,versions,15,I just add the versions I used:. ```python. sc.logging.print_versions(). scanpy==1.4 anndata==0.6.18 numpy==1.15.4 scipy==1.2.0 pandas==0.24.2 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:47,deployability,log,logging,47,I just add the versions I used:. ```python. sc.logging.print_versions(). scanpy==1.4 anndata==0.6.18 numpy==1.15.4 scipy==1.2.0 pandas==0.24.2 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:15,integrability,version,versions,15,I just add the versions I used:. ```python. sc.logging.print_versions(). scanpy==1.4 anndata==0.6.18 numpy==1.15.4 scipy==1.2.0 pandas==0.24.2 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:15,modifiability,version,versions,15,I just add the versions I used:. ```python. sc.logging.print_versions(). scanpy==1.4 anndata==0.6.18 numpy==1.15.4 scipy==1.2.0 pandas==0.24.2 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:47,safety,log,logging,47,I just add the versions I used:. ```python. sc.logging.print_versions(). scanpy==1.4 anndata==0.6.18 numpy==1.15.4 scipy==1.2.0 pandas==0.24.2 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:47,security,log,logging,47,I just add the versions I used:. ```python. sc.logging.print_versions(). scanpy==1.4 anndata==0.6.18 numpy==1.15.4 scipy==1.2.0 pandas==0.24.2 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:47,testability,log,logging,47,I just add the versions I used:. ```python. sc.logging.print_versions(). scanpy==1.4 anndata==0.6.18 numpy==1.15.4 scipy==1.2.0 pandas==0.24.2 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:150,usability,learn,learn,150,I just add the versions I used:. ```python. sc.logging.print_versions(). scanpy==1.4 anndata==0.6.18 numpy==1.15.4 scipy==1.2.0 pandas==0.24.2 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1 . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:345,deployability,version,versions,345,"the problem is that at some point the code calls np.argsort on a. pandas.Series and this returns -1 for NaN values. I will submit a PR to fix. this. Meanwhile, simpy plot as follows: sc.pl.pca(adata, color='property',. size=50, sort_order=False). On Tue, Mar 19, 2019 at 11:45 AM Fabian Rost <notifications@github.com>. wrote:. > I just add the versions I used:. >. > sc.logging.print_versions(). >. > scanpy==1.4 anndata==0.6.18 numpy==1.15.4 scipy==1.2.0 pandas==0.24.2 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. >. > —. > You are receiving this because you commented. >. >. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/536#issuecomment-474301705>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1b3l_xKITwuZQ-XpENUHSioDqLWLks5vYL_TgaJpZM4b6BYA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:371,deployability,log,logging,371,"the problem is that at some point the code calls np.argsort on a. pandas.Series and this returns -1 for NaN values. I will submit a PR to fix. this. Meanwhile, simpy plot as follows: sc.pl.pca(adata, color='property',. size=50, sort_order=False). On Tue, Mar 19, 2019 at 11:45 AM Fabian Rost <notifications@github.com>. wrote:. > I just add the versions I used:. >. > sc.logging.print_versions(). >. > scanpy==1.4 anndata==0.6.18 numpy==1.15.4 scipy==1.2.0 pandas==0.24.2 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. >. > —. > You are receiving this because you commented. >. >. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/536#issuecomment-474301705>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1b3l_xKITwuZQ-XpENUHSioDqLWLks5vYL_TgaJpZM4b6BYA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:123,integrability,sub,submit,123,"the problem is that at some point the code calls np.argsort on a. pandas.Series and this returns -1 for NaN values. I will submit a PR to fix. this. Meanwhile, simpy plot as follows: sc.pl.pca(adata, color='property',. size=50, sort_order=False). On Tue, Mar 19, 2019 at 11:45 AM Fabian Rost <notifications@github.com>. wrote:. > I just add the versions I used:. >. > sc.logging.print_versions(). >. > scanpy==1.4 anndata==0.6.18 numpy==1.15.4 scipy==1.2.0 pandas==0.24.2 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. >. > —. > You are receiving this because you commented. >. >. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/536#issuecomment-474301705>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1b3l_xKITwuZQ-XpENUHSioDqLWLks5vYL_TgaJpZM4b6BYA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:345,integrability,version,versions,345,"the problem is that at some point the code calls np.argsort on a. pandas.Series and this returns -1 for NaN values. I will submit a PR to fix. this. Meanwhile, simpy plot as follows: sc.pl.pca(adata, color='property',. size=50, sort_order=False). On Tue, Mar 19, 2019 at 11:45 AM Fabian Rost <notifications@github.com>. wrote:. > I just add the versions I used:. >. > sc.logging.print_versions(). >. > scanpy==1.4 anndata==0.6.18 numpy==1.15.4 scipy==1.2.0 pandas==0.24.2 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. >. > —. > You are receiving this because you commented. >. >. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/536#issuecomment-474301705>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1b3l_xKITwuZQ-XpENUHSioDqLWLks5vYL_TgaJpZM4b6BYA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:345,modifiability,version,versions,345,"the problem is that at some point the code calls np.argsort on a. pandas.Series and this returns -1 for NaN values. I will submit a PR to fix. this. Meanwhile, simpy plot as follows: sc.pl.pca(adata, color='property',. size=50, sort_order=False). On Tue, Mar 19, 2019 at 11:45 AM Fabian Rost <notifications@github.com>. wrote:. > I just add the versions I used:. >. > sc.logging.print_versions(). >. > scanpy==1.4 anndata==0.6.18 numpy==1.15.4 scipy==1.2.0 pandas==0.24.2 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. >. > —. > You are receiving this because you commented. >. >. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/536#issuecomment-474301705>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1b3l_xKITwuZQ-XpENUHSioDqLWLks5vYL_TgaJpZM4b6BYA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:371,safety,log,logging,371,"the problem is that at some point the code calls np.argsort on a. pandas.Series and this returns -1 for NaN values. I will submit a PR to fix. this. Meanwhile, simpy plot as follows: sc.pl.pca(adata, color='property',. size=50, sort_order=False). On Tue, Mar 19, 2019 at 11:45 AM Fabian Rost <notifications@github.com>. wrote:. > I just add the versions I used:. >. > sc.logging.print_versions(). >. > scanpy==1.4 anndata==0.6.18 numpy==1.15.4 scipy==1.2.0 pandas==0.24.2 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. >. > —. > You are receiving this because you commented. >. >. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/536#issuecomment-474301705>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1b3l_xKITwuZQ-XpENUHSioDqLWLks5vYL_TgaJpZM4b6BYA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:371,security,log,logging,371,"the problem is that at some point the code calls np.argsort on a. pandas.Series and this returns -1 for NaN values. I will submit a PR to fix. this. Meanwhile, simpy plot as follows: sc.pl.pca(adata, color='property',. size=50, sort_order=False). On Tue, Mar 19, 2019 at 11:45 AM Fabian Rost <notifications@github.com>. wrote:. > I just add the versions I used:. >. > sc.logging.print_versions(). >. > scanpy==1.4 anndata==0.6.18 numpy==1.15.4 scipy==1.2.0 pandas==0.24.2 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. >. > —. > You are receiving this because you commented. >. >. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/536#issuecomment-474301705>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1b3l_xKITwuZQ-XpENUHSioDqLWLks5vYL_TgaJpZM4b6BYA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:807,security,auth,auth,807,"the problem is that at some point the code calls np.argsort on a. pandas.Series and this returns -1 for NaN values. I will submit a PR to fix. this. Meanwhile, simpy plot as follows: sc.pl.pca(adata, color='property',. size=50, sort_order=False). On Tue, Mar 19, 2019 at 11:45 AM Fabian Rost <notifications@github.com>. wrote:. > I just add the versions I used:. >. > sc.logging.print_versions(). >. > scanpy==1.4 anndata==0.6.18 numpy==1.15.4 scipy==1.2.0 pandas==0.24.2 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. >. > —. > You are receiving this because you commented. >. >. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/536#issuecomment-474301705>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1b3l_xKITwuZQ-XpENUHSioDqLWLks5vYL_TgaJpZM4b6BYA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:371,testability,log,logging,371,"the problem is that at some point the code calls np.argsort on a. pandas.Series and this returns -1 for NaN values. I will submit a PR to fix. this. Meanwhile, simpy plot as follows: sc.pl.pca(adata, color='property',. size=50, sort_order=False). On Tue, Mar 19, 2019 at 11:45 AM Fabian Rost <notifications@github.com>. wrote:. > I just add the versions I used:. >. > sc.logging.print_versions(). >. > scanpy==1.4 anndata==0.6.18 numpy==1.15.4 scipy==1.2.0 pandas==0.24.2 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. >. > —. > You are receiving this because you commented. >. >. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/536#issuecomment-474301705>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1b3l_xKITwuZQ-XpENUHSioDqLWLks5vYL_TgaJpZM4b6BYA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/536:479,usability,learn,learn,479,"the problem is that at some point the code calls np.argsort on a. pandas.Series and this returns -1 for NaN values. I will submit a PR to fix. this. Meanwhile, simpy plot as follows: sc.pl.pca(adata, color='property',. size=50, sort_order=False). On Tue, Mar 19, 2019 at 11:45 AM Fabian Rost <notifications@github.com>. wrote:. > I just add the versions I used:. >. > sc.logging.print_versions(). >. > scanpy==1.4 anndata==0.6.18 numpy==1.15.4 scipy==1.2.0 pandas==0.24.2 scikit-learn==0.20.2 statsmodels==0.9.0 python-igraph==0.7.1 louvain==0.6.1. >. > —. > You are receiving this because you commented. >. >. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/536#issuecomment-474301705>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1b3l_xKITwuZQ-XpENUHSioDqLWLks5vYL_TgaJpZM4b6BYA>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/536
https://github.com/scverse/scanpy/issues/537:16,deployability,releas,release,16,"There is no new release with these changes, yet. You'd need to install from github if you want them. However, these updates aren't critical and you can continue using the old functions without any bad conscience. A new release is obviously pushed to GitHub, PyPI and BioConda, and announced on twitter (https://twitter.com/falexwolf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/537
https://github.com/scverse/scanpy/issues/537:63,deployability,instal,install,63,"There is no new release with these changes, yet. You'd need to install from github if you want them. However, these updates aren't critical and you can continue using the old functions without any bad conscience. A new release is obviously pushed to GitHub, PyPI and BioConda, and announced on twitter (https://twitter.com/falexwolf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/537
https://github.com/scverse/scanpy/issues/537:116,deployability,updat,updates,116,"There is no new release with these changes, yet. You'd need to install from github if you want them. However, these updates aren't critical and you can continue using the old functions without any bad conscience. A new release is obviously pushed to GitHub, PyPI and BioConda, and announced on twitter (https://twitter.com/falexwolf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/537
https://github.com/scverse/scanpy/issues/537:152,deployability,continu,continue,152,"There is no new release with these changes, yet. You'd need to install from github if you want them. However, these updates aren't critical and you can continue using the old functions without any bad conscience. A new release is obviously pushed to GitHub, PyPI and BioConda, and announced on twitter (https://twitter.com/falexwolf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/537
https://github.com/scverse/scanpy/issues/537:219,deployability,releas,release,219,"There is no new release with these changes, yet. You'd need to install from github if you want them. However, these updates aren't critical and you can continue using the old functions without any bad conscience. A new release is obviously pushed to GitHub, PyPI and BioConda, and announced on twitter (https://twitter.com/falexwolf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/537
https://github.com/scverse/scanpy/issues/537:116,safety,updat,updates,116,"There is no new release with these changes, yet. You'd need to install from github if you want them. However, these updates aren't critical and you can continue using the old functions without any bad conscience. A new release is obviously pushed to GitHub, PyPI and BioConda, and announced on twitter (https://twitter.com/falexwolf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/537
https://github.com/scverse/scanpy/issues/537:116,security,updat,updates,116,"There is no new release with these changes, yet. You'd need to install from github if you want them. However, these updates aren't critical and you can continue using the old functions without any bad conscience. A new release is obviously pushed to GitHub, PyPI and BioConda, and announced on twitter (https://twitter.com/falexwolf).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/537
https://github.com/scverse/scanpy/pull/538:108,deployability,API,API,108,"@fidelram; I gave you write access to the repo so that you can quickly merge PRs like this to your plotting API. It would still be great if bigger chunks of new functionality continued to come in PRs, which you could then merge yourself upon a brief check by any of us. Does that sound right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/538
https://github.com/scverse/scanpy/pull/538:175,deployability,continu,continued,175,"@fidelram; I gave you write access to the repo so that you can quickly merge PRs like this to your plotting API. It would still be great if bigger chunks of new functionality continued to come in PRs, which you could then merge yourself upon a brief check by any of us. Does that sound right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/538
https://github.com/scverse/scanpy/pull/538:108,integrability,API,API,108,"@fidelram; I gave you write access to the repo so that you can quickly merge PRs like this to your plotting API. It would still be great if bigger chunks of new functionality continued to come in PRs, which you could then merge yourself upon a brief check by any of us. Does that sound right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/538
https://github.com/scverse/scanpy/pull/538:108,interoperability,API,API,108,"@fidelram; I gave you write access to the repo so that you can quickly merge PRs like this to your plotting API. It would still be great if bigger chunks of new functionality continued to come in PRs, which you could then merge yourself upon a brief check by any of us. Does that sound right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/538
https://github.com/scverse/scanpy/pull/538:270,reliability,Doe,Does,270,"@fidelram; I gave you write access to the repo so that you can quickly merge PRs like this to your plotting API. It would still be great if bigger chunks of new functionality continued to come in PRs, which you could then merge yourself upon a brief check by any of us. Does that sound right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/538
https://github.com/scverse/scanpy/pull/538:28,security,access,access,28,"@fidelram; I gave you write access to the repo so that you can quickly merge PRs like this to your plotting API. It would still be great if bigger chunks of new functionality continued to come in PRs, which you could then merge yourself upon a brief check by any of us. Does that sound right?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/538
https://github.com/scverse/scanpy/pull/538:230,reliability,doe,does,230,"@gokceneraslan Thanks for the PR. I hesitated in the past to add such functionality as this makes the definition of expression very *ad hoc*. However, I also noticed the pitfalls when you have only normalized data and the dotplot does not makes sense. Are you planning any further changes? @falexwolf Thanks for giving me write access. I will use the new status responsible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/538
https://github.com/scverse/scanpy/pull/538:328,security,access,access,328,"@gokceneraslan Thanks for the PR. I hesitated in the past to add such functionality as this makes the definition of expression very *ad hoc*. However, I also noticed the pitfalls when you have only normalized data and the dotplot does not makes sense. Are you planning any further changes? @falexwolf Thanks for giving me write access. I will use the new status responsible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/538
https://github.com/scverse/scanpy/pull/538:260,testability,plan,planning,260,"@gokceneraslan Thanks for the PR. I hesitated in the past to add such functionality as this makes the definition of expression very *ad hoc*. However, I also noticed the pitfalls when you have only normalized data and the dotplot does not makes sense. Are you planning any further changes? @falexwolf Thanks for giving me write access. I will use the new status responsible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/538
https://github.com/scverse/scanpy/pull/538:355,usability,statu,status,355,"@gokceneraslan Thanks for the PR. I hesitated in the past to add such functionality as this makes the definition of expression very *ad hoc*. However, I also noticed the pitfalls when you have only normalized data and the dotplot does not makes sense. Are you planning any further changes? @falexwolf Thanks for giving me write access. I will use the new status responsible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/538
https://github.com/scverse/scanpy/pull/538:105,integrability,configur,configurable,105,"@fidelram Thanks, no further changes. I agree about the arbitrariness but I think it's good to provide a configurable implementation with reasonable defaults. This, I believe, is also what we do in other functions like pp.neighbors and pp.highly_variable_genes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/538
https://github.com/scverse/scanpy/pull/538:105,modifiability,configur,configurable,105,"@fidelram Thanks, no further changes. I agree about the arbitrariness but I think it's good to provide a configurable implementation with reasonable defaults. This, I believe, is also what we do in other functions like pp.neighbors and pp.highly_variable_genes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/538
https://github.com/scverse/scanpy/pull/538:105,security,configur,configurable,105,"@fidelram Thanks, no further changes. I agree about the arbitrariness but I think it's good to provide a configurable implementation with reasonable defaults. This, I believe, is also what we do in other functions like pp.neighbors and pp.highly_variable_genes.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/538
https://github.com/scverse/scanpy/pull/538:0,energy efficiency,Cool,Cool,0,"Cool! Great to have you with write access, @fidelram! :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/538
https://github.com/scverse/scanpy/pull/538:35,security,access,access,35,"Cool! Great to have you with write access, @fidelram! :smile:",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/538
https://github.com/scverse/scanpy/pull/539:32,safety,test,tests,32,Looks great! Let's wait for the tests to complete and merge!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:41,safety,compl,complete,41,Looks great! Let's wait for the tests to complete and merge!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:41,security,compl,complete,41,Looks great! Let's wait for the tests to complete and merge!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:32,testability,test,tests,32,Looks great! Let's wait for the tests to complete and merge!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:183,modifiability,paramet,parameters,183,"I think putting “basis” first and making it required is a valid change since `plot_scatter` should never be called directly, right? The only problem with the whole thing is that some parameters (e.g. the `arrows` family) isn’t valid for all functions, but will still autocomplete and be passed on to `plot_scatter`. Changing that is more work though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:58,safety,valid,valid,58,"I think putting “basis” first and making it required is a valid change since `plot_scatter` should never be called directly, right? The only problem with the whole thing is that some parameters (e.g. the `arrows` family) isn’t valid for all functions, but will still autocomplete and be passed on to `plot_scatter`. Changing that is more work though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:227,safety,valid,valid,227,"I think putting “basis” first and making it required is a valid change since `plot_scatter` should never be called directly, right? The only problem with the whole thing is that some parameters (e.g. the `arrows` family) isn’t valid for all functions, but will still autocomplete and be passed on to `plot_scatter`. Changing that is more work though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:259,availability,fault,fault,259,"Putting `basis` first is fine as `plot_scatter` is an internal function that doesn't appear in the API. The `arrows` should evtl appear in all embeddings; so that's fine. All of these scatter functions should have exactly the same arguments. So, it's not the fault of your PR but my fault, as I haven't pulled the change through. Due to `scvelo`, `arrows` might also disappear... So, let's not worry about it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:283,availability,fault,fault,283,"Putting `basis` first is fine as `plot_scatter` is an internal function that doesn't appear in the API. The `arrows` should evtl appear in all embeddings; so that's fine. All of these scatter functions should have exactly the same arguments. So, it's not the fault of your PR but my fault, as I haven't pulled the change through. Due to `scvelo`, `arrows` might also disappear... So, let's not worry about it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:99,deployability,API,API,99,"Putting `basis` first is fine as `plot_scatter` is an internal function that doesn't appear in the API. The `arrows` should evtl appear in all embeddings; so that's fine. All of these scatter functions should have exactly the same arguments. So, it's not the fault of your PR but my fault, as I haven't pulled the change through. Due to `scvelo`, `arrows` might also disappear... So, let's not worry about it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:259,energy efficiency,fault,fault,259,"Putting `basis` first is fine as `plot_scatter` is an internal function that doesn't appear in the API. The `arrows` should evtl appear in all embeddings; so that's fine. All of these scatter functions should have exactly the same arguments. So, it's not the fault of your PR but my fault, as I haven't pulled the change through. Due to `scvelo`, `arrows` might also disappear... So, let's not worry about it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:283,energy efficiency,fault,fault,283,"Putting `basis` first is fine as `plot_scatter` is an internal function that doesn't appear in the API. The `arrows` should evtl appear in all embeddings; so that's fine. All of these scatter functions should have exactly the same arguments. So, it's not the fault of your PR but my fault, as I haven't pulled the change through. Due to `scvelo`, `arrows` might also disappear... So, let's not worry about it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:99,integrability,API,API,99,"Putting `basis` first is fine as `plot_scatter` is an internal function that doesn't appear in the API. The `arrows` should evtl appear in all embeddings; so that's fine. All of these scatter functions should have exactly the same arguments. So, it's not the fault of your PR but my fault, as I haven't pulled the change through. Due to `scvelo`, `arrows` might also disappear... So, let's not worry about it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:99,interoperability,API,API,99,"Putting `basis` first is fine as `plot_scatter` is an internal function that doesn't appear in the API. The `arrows` should evtl appear in all embeddings; so that's fine. All of these scatter functions should have exactly the same arguments. So, it's not the fault of your PR but my fault, as I haven't pulled the change through. Due to `scvelo`, `arrows` might also disappear... So, let's not worry about it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:259,performance,fault,fault,259,"Putting `basis` first is fine as `plot_scatter` is an internal function that doesn't appear in the API. The `arrows` should evtl appear in all embeddings; so that's fine. All of these scatter functions should have exactly the same arguments. So, it's not the fault of your PR but my fault, as I haven't pulled the change through. Due to `scvelo`, `arrows` might also disappear... So, let's not worry about it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:283,performance,fault,fault,283,"Putting `basis` first is fine as `plot_scatter` is an internal function that doesn't appear in the API. The `arrows` should evtl appear in all embeddings; so that's fine. All of these scatter functions should have exactly the same arguments. So, it's not the fault of your PR but my fault, as I haven't pulled the change through. Due to `scvelo`, `arrows` might also disappear... So, let's not worry about it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:77,reliability,doe,doesn,77,"Putting `basis` first is fine as `plot_scatter` is an internal function that doesn't appear in the API. The `arrows` should evtl appear in all embeddings; so that's fine. All of these scatter functions should have exactly the same arguments. So, it's not the fault of your PR but my fault, as I haven't pulled the change through. Due to `scvelo`, `arrows` might also disappear... So, let's not worry about it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:259,reliability,fault,fault,259,"Putting `basis` first is fine as `plot_scatter` is an internal function that doesn't appear in the API. The `arrows` should evtl appear in all embeddings; so that's fine. All of these scatter functions should have exactly the same arguments. So, it's not the fault of your PR but my fault, as I haven't pulled the change through. Due to `scvelo`, `arrows` might also disappear... So, let's not worry about it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:283,reliability,fault,fault,283,"Putting `basis` first is fine as `plot_scatter` is an internal function that doesn't appear in the API. The `arrows` should evtl appear in all embeddings; so that's fine. All of these scatter functions should have exactly the same arguments. So, it's not the fault of your PR but my fault, as I haven't pulled the change through. Due to `scvelo`, `arrows` might also disappear... So, let's not worry about it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:259,safety,fault,fault,259,"Putting `basis` first is fine as `plot_scatter` is an internal function that doesn't appear in the API. The `arrows` should evtl appear in all embeddings; so that's fine. All of these scatter functions should have exactly the same arguments. So, it's not the fault of your PR but my fault, as I haven't pulled the change through. Due to `scvelo`, `arrows` might also disappear... So, let's not worry about it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:283,safety,fault,fault,283,"Putting `basis` first is fine as `plot_scatter` is an internal function that doesn't appear in the API. The `arrows` should evtl appear in all embeddings; so that's fine. All of these scatter functions should have exactly the same arguments. So, it's not the fault of your PR but my fault, as I haven't pulled the change through. Due to `scvelo`, `arrows` might also disappear... So, let's not worry about it.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:101,deployability,API,API,101,"@flying-sheep @falexwolf I ended up calling `plot_scatter` directly, and maybe should be part of the API as this is useful to plot data whose `basis` is none of the predefined ones. . Recently, I was storing different data in `.obsm` to reflect different parameters used for example for umap or drawgraph and then plotting with `plot_scatter`. Other solution would be to add parameters like `key_added` and for the `tool` functions like `pca`, `umap`, `tsne` etc. And a `key` parameter for the corresponding `plotting` functions. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:295,energy efficiency,draw,drawgraph,295,"@flying-sheep @falexwolf I ended up calling `plot_scatter` directly, and maybe should be part of the API as this is useful to plot data whose `basis` is none of the predefined ones. . Recently, I was storing different data in `.obsm` to reflect different parameters used for example for umap or drawgraph and then plotting with `plot_scatter`. Other solution would be to add parameters like `key_added` and for the `tool` functions like `pca`, `umap`, `tsne` etc. And a `key` parameter for the corresponding `plotting` functions. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:101,integrability,API,API,101,"@flying-sheep @falexwolf I ended up calling `plot_scatter` directly, and maybe should be part of the API as this is useful to plot data whose `basis` is none of the predefined ones. . Recently, I was storing different data in `.obsm` to reflect different parameters used for example for umap or drawgraph and then plotting with `plot_scatter`. Other solution would be to add parameters like `key_added` and for the `tool` functions like `pca`, `umap`, `tsne` etc. And a `key` parameter for the corresponding `plotting` functions. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:101,interoperability,API,API,101,"@flying-sheep @falexwolf I ended up calling `plot_scatter` directly, and maybe should be part of the API as this is useful to plot data whose `basis` is none of the predefined ones. . Recently, I was storing different data in `.obsm` to reflect different parameters used for example for umap or drawgraph and then plotting with `plot_scatter`. Other solution would be to add parameters like `key_added` and for the `tool` functions like `pca`, `umap`, `tsne` etc. And a `key` parameter for the corresponding `plotting` functions. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:255,modifiability,paramet,parameters,255,"@flying-sheep @falexwolf I ended up calling `plot_scatter` directly, and maybe should be part of the API as this is useful to plot data whose `basis` is none of the predefined ones. . Recently, I was storing different data in `.obsm` to reflect different parameters used for example for umap or drawgraph and then plotting with `plot_scatter`. Other solution would be to add parameters like `key_added` and for the `tool` functions like `pca`, `umap`, `tsne` etc. And a `key` parameter for the corresponding `plotting` functions. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:375,modifiability,paramet,parameters,375,"@flying-sheep @falexwolf I ended up calling `plot_scatter` directly, and maybe should be part of the API as this is useful to plot data whose `basis` is none of the predefined ones. . Recently, I was storing different data in `.obsm` to reflect different parameters used for example for umap or drawgraph and then plotting with `plot_scatter`. Other solution would be to add parameters like `key_added` and for the `tool` functions like `pca`, `umap`, `tsne` etc. And a `key` parameter for the corresponding `plotting` functions. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:476,modifiability,paramet,parameter,476,"@flying-sheep @falexwolf I ended up calling `plot_scatter` directly, and maybe should be part of the API as this is useful to plot data whose `basis` is none of the predefined ones. . Recently, I was storing different data in `.obsm` to reflect different parameters used for example for umap or drawgraph and then plotting with `plot_scatter`. Other solution would be to add parameters like `key_added` and for the `tool` functions like `pca`, `umap`, `tsne` etc. And a `key` parameter for the corresponding `plotting` functions. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:416,usability,tool,tool,416,"@flying-sheep @falexwolf I ended up calling `plot_scatter` directly, and maybe should be part of the API as this is useful to plot data whose `basis` is none of the predefined ones. . Recently, I was storing different data in `.obsm` to reflect different parameters used for example for umap or drawgraph and then plotting with `plot_scatter`. Other solution would be to add parameters like `key_added` and for the `tool` functions like `pca`, `umap`, `tsne` etc. And a `key` parameter for the corresponding `plotting` functions. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:243,deployability,API,API,243,"Thanks for the note, @fidelram. But, putting `basis` first will still allow you to call `plot_scatter` directly, right? We don't have problem, here. I see your use case and it's a valid one. Let's discuss about putting `plot_scatter` into the API in another PR, though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:243,integrability,API,API,243,"Thanks for the note, @fidelram. But, putting `basis` first will still allow you to call `plot_scatter` directly, right? We don't have problem, here. I see your use case and it's a valid one. Let's discuss about putting `plot_scatter` into the API in another PR, though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:243,interoperability,API,API,243,"Thanks for the note, @fidelram. But, putting `basis` first will still allow you to call `plot_scatter` directly, right? We don't have problem, here. I see your use case and it's a valid one. Let's discuss about putting `plot_scatter` into the API in another PR, though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/539:180,safety,valid,valid,180,"Thanks for the note, @fidelram. But, putting `basis` first will still allow you to call `plot_scatter` directly, right? We don't have problem, here. I see your use case and it's a valid one. Let's discuss about putting `plot_scatter` into the API in another PR, though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/539
https://github.com/scverse/scanpy/pull/540:4,deployability,fail,failing,4,"The failing test seems unrelated. I'm merging this. [@fidelram, you could have merged it yourself. :)]",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/540
https://github.com/scverse/scanpy/pull/540:4,reliability,fail,failing,4,"The failing test seems unrelated. I'm merging this. [@fidelram, you could have merged it yourself. :)]",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/540
https://github.com/scverse/scanpy/pull/540:12,safety,test,test,12,"The failing test seems unrelated. I'm merging this. [@fidelram, you could have merged it yourself. :)]",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/540
https://github.com/scverse/scanpy/pull/540:12,testability,test,test,12,"The failing test seems unrelated. I'm merging this. [@fidelram, you could have merged it yourself. :)]",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/540
https://github.com/scverse/scanpy/issues/542:73,reliability,doe,does,73,Agreed! :) I just haven't ever done that... ;) I'm happy if someone else does it but would otherwise look into it next week or so...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:230,usability,support,support,230,"I wanted to do it, but I couldn’t create gitter.im/scanpy. I noticed that https://github.com/scanpy exists which seems to be the problem. Seems to be a typo though, their name is Scana.py with a second “a”. I contacted the GitHub support, maybe they can rename it and give us https://github.com/scanpy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:254,energy efficiency,reduc,reduce,254,"As a possible alternate/ supplement, what about a discourse forum? I think threaded conversations are useful, especially when you can't expect everyone who has input to be online at the same time. It also looks like google indexes discourse, which could reduce repeated questions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:84,interoperability,convers,conversations,84,"As a possible alternate/ supplement, what about a discourse forum? I think threaded conversations are useful, especially when you can't expect everyone who has input to be online at the same time. It also looks like google indexes discourse, which could reduce repeated questions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:191,performance,time,time,191,"As a possible alternate/ supplement, what about a discourse forum? I think threaded conversations are useful, especially when you can't expect everyone who has input to be online at the same time. It also looks like google indexes discourse, which could reduce repeated questions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:160,safety,input,input,160,"As a possible alternate/ supplement, what about a discourse forum? I think threaded conversations are useful, especially when you can't expect everyone who has input to be online at the same time. It also looks like google indexes discourse, which could reduce repeated questions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:160,usability,input,input,160,"As a possible alternate/ supplement, what about a discourse forum? I think threaded conversations are useful, especially when you can't expect everyone who has input to be online at the same time. It also looks like google indexes discourse, which could reduce repeated questions.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:83,interoperability,share,share-link,83,I created gitter.im/scanpyhelp . https://gitter.im/scanpyhelp/community?utm_source=share-link&utm_medium=link&utm_campaign=share-link,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:123,interoperability,share,share-link,123,I created gitter.im/scanpyhelp . https://gitter.im/scanpyhelp/community?utm_source=share-link&utm_medium=link&utm_campaign=share-link,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:90,deployability,version,version,90,@ivirshup A discourse forum would be great but it looks like its quite pricy with no free version,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:90,integrability,version,version,90,@ivirshup A discourse forum would be great but it looks like its quite pricy with no free version,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:90,modifiability,version,version,90,@ivirshup A discourse forum would be great but it looks like its quite pricy with no free version,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:339,availability,sla,slack,339,"Expanding on this a bit, here's an example discourse forum I've found useful: [https://discourse.julialang.org](). Good, relevant threads show up all the time in google searches, while I've spent a lot of time trying to find help on various `pyviz` and `conda` gitters with a pretty low success rate. I think something like gitter/ single slack channel works for about 20 people, but after that it gets a bit rough. Having a single stream of messages means keeping track of a conversation over days becomes a huge task. Topics get dropped not based on the value of the discussion, but because of the conversation's overhead.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:442,integrability,messag,messages,442,"Expanding on this a bit, here's an example discourse forum I've found useful: [https://discourse.julialang.org](). Good, relevant threads show up all the time in google searches, while I've spent a lot of time trying to find help on various `pyviz` and `conda` gitters with a pretty low success rate. I think something like gitter/ single slack channel works for about 20 people, but after that it gets a bit rough. Having a single stream of messages means keeping track of a conversation over days becomes a huge task. Topics get dropped not based on the value of the discussion, but because of the conversation's overhead.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:520,integrability,Topic,Topics,520,"Expanding on this a bit, here's an example discourse forum I've found useful: [https://discourse.julialang.org](). Good, relevant threads show up all the time in google searches, while I've spent a lot of time trying to find help on various `pyviz` and `conda` gitters with a pretty low success rate. I think something like gitter/ single slack channel works for about 20 people, but after that it gets a bit rough. Having a single stream of messages means keeping track of a conversation over days becomes a huge task. Topics get dropped not based on the value of the discussion, but because of the conversation's overhead.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:442,interoperability,messag,messages,442,"Expanding on this a bit, here's an example discourse forum I've found useful: [https://discourse.julialang.org](). Good, relevant threads show up all the time in google searches, while I've spent a lot of time trying to find help on various `pyviz` and `conda` gitters with a pretty low success rate. I think something like gitter/ single slack channel works for about 20 people, but after that it gets a bit rough. Having a single stream of messages means keeping track of a conversation over days becomes a huge task. Topics get dropped not based on the value of the discussion, but because of the conversation's overhead.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:476,interoperability,convers,conversation,476,"Expanding on this a bit, here's an example discourse forum I've found useful: [https://discourse.julialang.org](). Good, relevant threads show up all the time in google searches, while I've spent a lot of time trying to find help on various `pyviz` and `conda` gitters with a pretty low success rate. I think something like gitter/ single slack channel works for about 20 people, but after that it gets a bit rough. Having a single stream of messages means keeping track of a conversation over days becomes a huge task. Topics get dropped not based on the value of the discussion, but because of the conversation's overhead.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:600,interoperability,convers,conversation,600,"Expanding on this a bit, here's an example discourse forum I've found useful: [https://discourse.julialang.org](). Good, relevant threads show up all the time in google searches, while I've spent a lot of time trying to find help on various `pyviz` and `conda` gitters with a pretty low success rate. I think something like gitter/ single slack channel works for about 20 people, but after that it gets a bit rough. Having a single stream of messages means keeping track of a conversation over days becomes a huge task. Topics get dropped not based on the value of the discussion, but because of the conversation's overhead.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:154,performance,time,time,154,"Expanding on this a bit, here's an example discourse forum I've found useful: [https://discourse.julialang.org](). Good, relevant threads show up all the time in google searches, while I've spent a lot of time trying to find help on various `pyviz` and `conda` gitters with a pretty low success rate. I think something like gitter/ single slack channel works for about 20 people, but after that it gets a bit rough. Having a single stream of messages means keeping track of a conversation over days becomes a huge task. Topics get dropped not based on the value of the discussion, but because of the conversation's overhead.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:205,performance,time,time,205,"Expanding on this a bit, here's an example discourse forum I've found useful: [https://discourse.julialang.org](). Good, relevant threads show up all the time in google searches, while I've spent a lot of time trying to find help on various `pyviz` and `conda` gitters with a pretty low success rate. I think something like gitter/ single slack channel works for about 20 people, but after that it gets a bit rough. Having a single stream of messages means keeping track of a conversation over days becomes a huge task. Topics get dropped not based on the value of the discussion, but because of the conversation's overhead.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:615,performance,overhead,overhead,615,"Expanding on this a bit, here's an example discourse forum I've found useful: [https://discourse.julialang.org](). Good, relevant threads show up all the time in google searches, while I've spent a lot of time trying to find help on various `pyviz` and `conda` gitters with a pretty low success rate. I think something like gitter/ single slack channel works for about 20 people, but after that it gets a bit rough. Having a single stream of messages means keeping track of a conversation over days becomes a huge task. Topics get dropped not based on the value of the discussion, but because of the conversation's overhead.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:339,reliability,sla,slack,339,"Expanding on this a bit, here's an example discourse forum I've found useful: [https://discourse.julialang.org](). Good, relevant threads show up all the time in google searches, while I've spent a lot of time trying to find help on various `pyviz` and `conda` gitters with a pretty low success rate. I think something like gitter/ single slack channel works for about 20 people, but after that it gets a bit rough. Having a single stream of messages means keeping track of a conversation over days becomes a huge task. Topics get dropped not based on the value of the discussion, but because of the conversation's overhead.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:225,usability,help,help,225,"Expanding on this a bit, here's an example discourse forum I've found useful: [https://discourse.julialang.org](). Good, relevant threads show up all the time in google searches, while I've spent a lot of time trying to find help on various `pyviz` and `conda` gitters with a pretty low success rate. I think something like gitter/ single slack channel works for about 20 people, but after that it gets a bit rough. Having a single stream of messages means keeping track of a conversation over days becomes a huge task. Topics get dropped not based on the value of the discussion, but because of the conversation's overhead.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:346,deployability,stack,stack,346,"@outlace, whoops, didn't see your message before I posted mine, chatroom model woulda stopped that. It looks to me like it's free to self host and theres (admittedly kinda high) educational price for discourse. I'll check out how easy it is to self host. An alternative for threaded conversations is a good old fashioned google group or a tag on stack overflow. (edit: we could probably even just use biostars). The main reason I'm pushing this, is because the more I think about it, the more how unhelpful most gitters have been for me. It might to do with being in a non-European or American timezone though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:73,energy efficiency,model,model,73,"@outlace, whoops, didn't see your message before I posted mine, chatroom model woulda stopped that. It looks to me like it's free to self host and theres (admittedly kinda high) educational price for discourse. I'll check out how easy it is to self host. An alternative for threaded conversations is a good old fashioned google group or a tag on stack overflow. (edit: we could probably even just use biostars). The main reason I'm pushing this, is because the more I think about it, the more how unhelpful most gitters have been for me. It might to do with being in a non-European or American timezone though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:34,integrability,messag,message,34,"@outlace, whoops, didn't see your message before I posted mine, chatroom model woulda stopped that. It looks to me like it's free to self host and theres (admittedly kinda high) educational price for discourse. I'll check out how easy it is to self host. An alternative for threaded conversations is a good old fashioned google group or a tag on stack overflow. (edit: we could probably even just use biostars). The main reason I'm pushing this, is because the more I think about it, the more how unhelpful most gitters have been for me. It might to do with being in a non-European or American timezone though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:34,interoperability,messag,message,34,"@outlace, whoops, didn't see your message before I posted mine, chatroom model woulda stopped that. It looks to me like it's free to self host and theres (admittedly kinda high) educational price for discourse. I'll check out how easy it is to self host. An alternative for threaded conversations is a good old fashioned google group or a tag on stack overflow. (edit: we could probably even just use biostars). The main reason I'm pushing this, is because the more I think about it, the more how unhelpful most gitters have been for me. It might to do with being in a non-European or American timezone though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:283,interoperability,convers,conversations,283,"@outlace, whoops, didn't see your message before I posted mine, chatroom model woulda stopped that. It looks to me like it's free to self host and theres (admittedly kinda high) educational price for discourse. I'll check out how easy it is to self host. An alternative for threaded conversations is a good old fashioned google group or a tag on stack overflow. (edit: we could probably even just use biostars). The main reason I'm pushing this, is because the more I think about it, the more how unhelpful most gitters have been for me. It might to do with being in a non-European or American timezone though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:594,performance,time,timezone,594,"@outlace, whoops, didn't see your message before I posted mine, chatroom model woulda stopped that. It looks to me like it's free to self host and theres (admittedly kinda high) educational price for discourse. I'll check out how easy it is to self host. An alternative for threaded conversations is a good old fashioned google group or a tag on stack overflow. (edit: we could probably even just use biostars). The main reason I'm pushing this, is because the more I think about it, the more how unhelpful most gitters have been for me. It might to do with being in a non-European or American timezone though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:73,security,model,model,73,"@outlace, whoops, didn't see your message before I posted mine, chatroom model woulda stopped that. It looks to me like it's free to self host and theres (admittedly kinda high) educational price for discourse. I'll check out how easy it is to self host. An alternative for threaded conversations is a good old fashioned google group or a tag on stack overflow. (edit: we could probably even just use biostars). The main reason I'm pushing this, is because the more I think about it, the more how unhelpful most gitters have been for me. It might to do with being in a non-European or American timezone though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:86,usability,stop,stopped,86,"@outlace, whoops, didn't see your message before I posted mine, chatroom model woulda stopped that. It looks to me like it's free to self host and theres (admittedly kinda high) educational price for discourse. I'll check out how easy it is to self host. An alternative for threaded conversations is a good old fashioned google group or a tag on stack overflow. (edit: we could probably even just use biostars). The main reason I'm pushing this, is because the more I think about it, the more how unhelpful most gitters have been for me. It might to do with being in a non-European or American timezone though.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:18,deployability,stack,stackoverflow,18,@ivirshup I guess stackoverflow tag would work for now until a dedicated discourse or the like is setup. The advantage of gitter is that if people are online questions can be answered rapidly which is helpful when youre in the middle of an analysis and run into a problem. It's no fun when you have to give up and wait until the next day to get some help. But I can see that timezone differences may prevent this if the users and collaborators are not timezone similar.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:375,performance,time,timezone,375,@ivirshup I guess stackoverflow tag would work for now until a dedicated discourse or the like is setup. The advantage of gitter is that if people are online questions can be answered rapidly which is helpful when youre in the middle of an analysis and run into a problem. It's no fun when you have to give up and wait until the next day to get some help. But I can see that timezone differences may prevent this if the users and collaborators are not timezone similar.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:452,performance,time,timezone,452,@ivirshup I guess stackoverflow tag would work for now until a dedicated discourse or the like is setup. The advantage of gitter is that if people are online questions can be answered rapidly which is helpful when youre in the middle of an analysis and run into a problem. It's no fun when you have to give up and wait until the next day to get some help. But I can see that timezone differences may prevent this if the users and collaborators are not timezone similar.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:400,safety,prevent,prevent,400,@ivirshup I guess stackoverflow tag would work for now until a dedicated discourse or the like is setup. The advantage of gitter is that if people are online questions can be answered rapidly which is helpful when youre in the middle of an analysis and run into a problem. It's no fun when you have to give up and wait until the next day to get some help. But I can see that timezone differences may prevent this if the users and collaborators are not timezone similar.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:400,security,preven,prevent,400,@ivirshup I guess stackoverflow tag would work for now until a dedicated discourse or the like is setup. The advantage of gitter is that if people are online questions can be answered rapidly which is helpful when youre in the middle of an analysis and run into a problem. It's no fun when you have to give up and wait until the next day to get some help. But I can see that timezone differences may prevent this if the users and collaborators are not timezone similar.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:201,usability,help,helpful,201,@ivirshup I guess stackoverflow tag would work for now until a dedicated discourse or the like is setup. The advantage of gitter is that if people are online questions can be answered rapidly which is helpful when youre in the middle of an analysis and run into a problem. It's no fun when you have to give up and wait until the next day to get some help. But I can see that timezone differences may prevent this if the users and collaborators are not timezone similar.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:350,usability,help,help,350,@ivirshup I guess stackoverflow tag would work for now until a dedicated discourse or the like is setup. The advantage of gitter is that if people are online questions can be answered rapidly which is helpful when youre in the middle of an analysis and run into a problem. It's no fun when you have to give up and wait until the next day to get some help. But I can see that timezone differences may prevent this if the users and collaborators are not timezone similar.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:420,usability,user,users,420,@ivirshup I guess stackoverflow tag would work for now until a dedicated discourse or the like is setup. The advantage of gitter is that if people are online questions can be answered rapidly which is helpful when youre in the middle of an analysis and run into a problem. It's no fun when you have to give up and wait until the next day to get some help. But I can see that timezone differences may prevent this if the users and collaborators are not timezone similar.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:25,integrability,messag,message,25,"not yet, but we sent the message to them only recently.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:25,interoperability,messag,message,25,"not yet, but we sent the message to them only recently.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:80,safety,except,except,80,It's been about 3 months and there's still no place for people to ask questions except to file issues. https://gitter.im/scanpyhelp/community is still there,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:41,performance,time,time,41,"I don't know how I missed this the first time, but discourse could just be free for us [https://free.discourse.group](). I can go ahead and set this up, but would also be fine with a google group.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:318,testability,simpl,simply,318,". I have to admit that I'm still not an expert in these forums. I'm happy if we go with https://gitter.im/scanpyhelp as a solution. I also know discourse is super popular among many people and I'm happy if we go with it if all three of you, @outlace, @ivirshup and @flying-sheep, think this could be a better place. I simply can't judge myself as I haven't used either of them. Most importantly, let's put what you guys choose on the top of the webpage and properly announce it; it would be terrible to have several of these chat rooms; one on gitter, one discourse, etc. with potentially even different names `scanpyhelp`, `scanpy` etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:318,usability,simpl,simply,318,". I have to admit that I'm still not an expert in these forums. I'm happy if we go with https://gitter.im/scanpyhelp as a solution. I also know discourse is super popular among many people and I'm happy if we go with it if all three of you, @outlace, @ivirshup and @flying-sheep, think this could be a better place. I simply can't judge myself as I haven't used either of them. Most importantly, let's put what you guys choose on the top of the webpage and properly announce it; it would be terrible to have several of these chat rooms; one on gitter, one discourse, etc. with potentially even different names `scanpyhelp`, `scanpy` etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:426,safety,avoid,avoid,426,"Great! @ivirshup set up this https://scanpy.discourse.group. We'll properly announce it and, I hope this becomes the persistent place for discussing issues around using Scanpy. Thank you for the initiative, Brandon! I'll close this for now; if we're unhappy with this solution, we can get back at some point. I'll also follow up on this with an email to you guys. PS: Brandon, could you delete scanpyhelp at gitter so that we avoid potentially confusing people? Thank you. . PPS: For reference: https://github.com/theislab/scanpy/commit/df80290a2c24403d4af4c8eb4091acaa49e39496.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/issues/542:221,usability,close,close,221,"Great! @ivirshup set up this https://scanpy.discourse.group. We'll properly announce it and, I hope this becomes the persistent place for discussing issues around using Scanpy. Thank you for the initiative, Brandon! I'll close this for now; if we're unhappy with this solution, we can get back at some point. I'll also follow up on this with an email to you guys. PS: Brandon, could you delete scanpyhelp at gitter so that we avoid potentially confusing people? Thank you. . PPS: For reference: https://github.com/theislab/scanpy/commit/df80290a2c24403d4af4c8eb4091acaa49e39496.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/542
https://github.com/scverse/scanpy/pull/543:181,safety,test,test,181,This looks good so far! Thank you! Can we call it `embedding_density` or something similar? `density` is a little generic; we might have other methods in the future... Some form of test would also be great! ;). Let me know when this should be merged.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:181,testability,test,test,181,This looks good so far! Thank you! Can we call it `embedding_density` or something similar? `density` is a little generic; we might have other methods in the future... Some form of test would also be great! ;). Let me know when this should be merged.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:404,integrability,wrap,wrapping,404,"@fidelram I guess you are the right person to ask for help with this... I'm struggling to work nicely with `plot_scatter()`. I am trying to generate a plot where density values for non-selected conditions are grey, while density values for the selected condition are on 'YlOrRd' or another color map. It seems this is not ideal with a single `plot_scatter()` call (which I was hoping to use as the facet wrapping is already done there). For the grey values I am using a color value of -1, while the others are between 0 and 1. However, when I define a color map that is symmetric around 0, positive values near 0 are mapped to grey instead of colours... any idea why?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:36,usability,person,person,36,"@fidelram I guess you are the right person to ask for help with this... I'm struggling to work nicely with `plot_scatter()`. I am trying to generate a plot where density values for non-selected conditions are grey, while density values for the selected condition are on 'YlOrRd' or another color map. It seems this is not ideal with a single `plot_scatter()` call (which I was hoping to use as the facet wrapping is already done there). For the grey values I am using a color value of -1, while the others are between 0 and 1. However, when I define a color map that is symmetric around 0, positive values near 0 are mapped to grey instead of colours... any idea why?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:54,usability,help,help,54,"@fidelram I guess you are the right person to ask for help with this... I'm struggling to work nicely with `plot_scatter()`. I am trying to generate a plot where density values for non-selected conditions are grey, while density values for the selected condition are on 'YlOrRd' or another color map. It seems this is not ideal with a single `plot_scatter()` call (which I was hoping to use as the facet wrapping is already done there). For the grey values I am using a color value of -1, while the others are between 0 and 1. However, when I define a color map that is symmetric around 0, positive values near 0 are mapped to grey instead of colours... any idea why?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:112,integrability,coupl,couple,112,Can't you use `vmin` and `vmax`? I remember there was a similar issue asking for greying out some data points a couple of weeks ago. And the person asking seemed to be happy with that answer...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:112,modifiability,coupl,couple,112,Can't you use `vmin` and `vmax`? I remember there was a similar issue asking for greying out some data points a couple of weeks ago. And the person asking seemed to be happy with that answer...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:35,safety,reme,remember,35,Can't you use `vmin` and `vmax`? I remember there was a similar issue asking for greying out some data points a couple of weeks ago. And the person asking seemed to be happy with that answer...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:112,testability,coupl,couple,112,Can't you use `vmin` and `vmax`? I remember there was a similar issue asking for greying out some data points a couple of weeks ago. And the person asking seemed to be happy with that answer...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:141,usability,person,person,141,Can't you use `vmin` and `vmax`? I remember there was a similar issue asking for greying out some data points a couple of weeks ago. And the person asking seemed to be happy with that answer...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:438,usability,user,user-images,438,"@LuckyMD You can do something like this:. ```PYTHON. import matplotlib.pyplot as plt. import matplotlib as mpl. adata = sc.datasets.blobs(). adata.obs['n_blob'] = np.array(adata.obs.blobs.apply(lambda x: int(x))). sc.tl.pca(adata). cmap = plt.get_cmap('YlOrRd'). norm = mpl.colors.Normalize(vmin=1, vmax=3). cmap.set_over('blue'). cmap.set_under('lightgray'). sc.pl.pca(adata, color='n_blob', cmap=cmap, norm=norm). ```. ![image](https://user-images.githubusercontent.com/4964309/54740631-42e8d200-4bbc-11e9-8534-11e68927da9e.png). In this case any value that is less than 1 get a `lightgray` color and any value greater than 2 gets a `blue` color. You can pass `cmap` and `norm` to any scatter plot function including `plot_scatter`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:74,modifiability,paramet,parameter,74,"@fidelram I think I found a bug in `plot_scatter`. While the `sort_order` parameter is reordering the data points to plot the highest obs covariate last, which is great... I don't think this is happening correctly with the dot sizes. Thus, with `sort_order=True` you cannot really use dot sizes. I don't have a minimal example for this yet, but I think this is what I see while calibrating defaults for dot sizes with this code. I will confirm later, but let me know if you think this is possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:311,usability,minim,minimal,311,"@fidelram I think I found a bug in `plot_scatter`. While the `sort_order` parameter is reordering the data points to plot the highest obs covariate last, which is great... I don't think this is happening correctly with the dot sizes. Thus, with `sort_order=True` you cannot really use dot sizes. I don't have a minimal example for this yet, but I think this is what I see while calibrating defaults for dot sizes with this code. I will confirm later, but let me know if you think this is possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:436,usability,confirm,confirm,436,"@fidelram I think I found a bug in `plot_scatter`. While the `sort_order` parameter is reordering the data points to plot the highest obs covariate last, which is great... I don't think this is happening correctly with the dot sizes. Thus, with `sort_order=True` you cannot really use dot sizes. I don't have a minimal example for this yet, but I think this is what I see while calibrating defaults for dot sizes with this code. I will confirm later, but let me know if you think this is possible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:50,integrability,sub,submit,50,@LuckyMD plot_scatter does not sort size.. Let me submit a PR for this quickly.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:22,reliability,doe,does,22,@LuckyMD plot_scatter does not sort size.. Let me submit a PR for this quickly.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:165,modifiability,variab,variable,165,"@fidelram Thanks a lot! I was getting confused why my dot sizes weren't working (only sometimes, strangely...). If the dot sizes are sorted according to the `color` variable it should hopefully work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:158,safety,test,test,158,"Let me check if dot sizes work now. Also, I still have another function I would like to add, which probably requires less work. Just some marker gene overlap test that takes a dictionary as input. Could you give til next week Wednesday for that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:190,safety,input,input,190,"Let me check if dot sizes work now. Also, I still have another function I would like to add, which probably requires less work. Just some marker gene overlap test that takes a dictionary as input. Could you give til next week Wednesday for that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:158,testability,test,test,158,"Let me check if dot sizes work now. Also, I still have another function I would like to add, which probably requires less work. Just some marker gene overlap test that takes a dictionary as input. Could you give til next week Wednesday for that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:190,usability,input,input,190,"Let me check if dot sizes work now. Also, I still have another function I would like to add, which probably requires less work. Just some marker gene overlap test that takes a dictionary as input. Could you give til next week Wednesday for that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:84,deployability,integr,integrated,84,"Dot sizes now work, this is ready to be merged... assuming you are happy with how I integrated it into the documentation (I added a separate ""density"" subsection for the plotting tools as I felt it shouldn't really be put in the same category as embeddings.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:84,integrability,integr,integrated,84,"Dot sizes now work, this is ready to be merged... assuming you are happy with how I integrated it into the documentation (I added a separate ""density"" subsection for the plotting tools as I felt it shouldn't really be put in the same category as embeddings.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:151,integrability,sub,subsection,151,"Dot sizes now work, this is ready to be merged... assuming you are happy with how I integrated it into the documentation (I added a separate ""density"" subsection for the plotting tools as I felt it shouldn't really be put in the same category as embeddings.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:84,interoperability,integr,integrated,84,"Dot sizes now work, this is ready to be merged... assuming you are happy with how I integrated it into the documentation (I added a separate ""density"" subsection for the plotting tools as I felt it shouldn't really be put in the same category as embeddings.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:84,modifiability,integr,integrated,84,"Dot sizes now work, this is ready to be merged... assuming you are happy with how I integrated it into the documentation (I added a separate ""density"" subsection for the plotting tools as I felt it shouldn't really be put in the same category as embeddings.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:84,reliability,integr,integrated,84,"Dot sizes now work, this is ready to be merged... assuming you are happy with how I integrated it into the documentation (I added a separate ""density"" subsection for the plotting tools as I felt it shouldn't really be put in the same category as embeddings.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:84,security,integr,integrated,84,"Dot sizes now work, this is ready to be merged... assuming you are happy with how I integrated it into the documentation (I added a separate ""density"" subsection for the plotting tools as I felt it shouldn't really be put in the same category as embeddings.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:84,testability,integr,integrated,84,"Dot sizes now work, this is ready to be merged... assuming you are happy with how I integrated it into the documentation (I added a separate ""density"" subsection for the plotting tools as I felt it shouldn't really be put in the same category as embeddings.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:107,usability,document,documentation,107,"Dot sizes now work, this is ready to be merged... assuming you are happy with how I integrated it into the documentation (I added a separate ""density"" subsection for the plotting tools as I felt it shouldn't really be put in the same category as embeddings.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:179,usability,tool,tools,179,"Dot sizes now work, this is ready to be merged... assuming you are happy with how I integrated it into the documentation (I added a separate ""density"" subsection for the plotting tools as I felt it shouldn't really be put in the same category as embeddings.)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:149,deployability,releas,release,149,"Great! :smile:. Sure, next Wednesday is fine. Also, we can always simply make 1.4.2. I just need to check one tiny thing before we actually make the release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:66,testability,simpl,simply,66,"Great! :smile:. Sure, next Wednesday is fine. Also, we can always simply make 1.4.2. I just need to check one tiny thing before we actually make the release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:66,usability,simpl,simply,66,"Great! :smile:. Sure, next Wednesday is fine. Also, we can always simply make 1.4.2. I just need to check one tiny thing before we actually make the release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:29,safety,test,test,29,@LuckyMD why don't you add a test to `scanpy/tests/test_plotting.py`. Thus we can guarantee that future changes do not break your code.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:45,safety,test,tests,45,@LuckyMD why don't you add a test to `scanpy/tests/test_plotting.py`. Thus we can guarantee that future changes do not break your code.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:29,testability,test,test,29,@LuckyMD why don't you add a test to `scanpy/tests/test_plotting.py`. Thus we can guarantee that future changes do not break your code.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:45,testability,test,tests,45,@LuckyMD why don't you add a test to `scanpy/tests/test_plotting.py`. Thus we can guarantee that future changes do not break your code.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:12,safety,test,tests,12,I added two tests in `scanpy/tests/test_embedding_density.py`... one of them just to test if the plotting functions run. Should this have been placed in a different file?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:29,safety,test,tests,29,I added two tests in `scanpy/tests/test_embedding_density.py`... one of them just to test if the plotting functions run. Should this have been placed in a different file?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:85,safety,test,test,85,I added two tests in `scanpy/tests/test_embedding_density.py`... one of them just to test if the plotting functions run. Should this have been placed in a different file?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:12,testability,test,tests,12,I added two tests in `scanpy/tests/test_embedding_density.py`... one of them just to test if the plotting functions run. Should this have been placed in a different file?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:29,testability,test,tests,29,I added two tests in `scanpy/tests/test_embedding_density.py`... one of them just to test if the plotting functions run. Should this have been placed in a different file?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/pull/543:85,testability,test,test,85,I added two tests in `scanpy/tests/test_embedding_density.py`... one of them just to test if the plotting functions run. Should this have been placed in a different file?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/543
https://github.com/scverse/scanpy/issues/544:61,deployability,version,version,61,"I think that correlation matrix is only in the latest master version. You can install it using:. ```. pip install git+https://github.com/theislab/scanpy.git. ```. Also, be sure to load scanpy as 'import scanpy as sc'. If you use the old method (`import scanpy.api as sc`) it will not work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:78,deployability,instal,install,78,"I think that correlation matrix is only in the latest master version. You can install it using:. ```. pip install git+https://github.com/theislab/scanpy.git. ```. Also, be sure to load scanpy as 'import scanpy as sc'. If you use the old method (`import scanpy.api as sc`) it will not work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:106,deployability,instal,install,106,"I think that correlation matrix is only in the latest master version. You can install it using:. ```. pip install git+https://github.com/theislab/scanpy.git. ```. Also, be sure to load scanpy as 'import scanpy as sc'. If you use the old method (`import scanpy.api as sc`) it will not work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:260,deployability,api,api,260,"I think that correlation matrix is only in the latest master version. You can install it using:. ```. pip install git+https://github.com/theislab/scanpy.git. ```. Also, be sure to load scanpy as 'import scanpy as sc'. If you use the old method (`import scanpy.api as sc`) it will not work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:180,energy efficiency,load,load,180,"I think that correlation matrix is only in the latest master version. You can install it using:. ```. pip install git+https://github.com/theislab/scanpy.git. ```. Also, be sure to load scanpy as 'import scanpy as sc'. If you use the old method (`import scanpy.api as sc`) it will not work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:61,integrability,version,version,61,"I think that correlation matrix is only in the latest master version. You can install it using:. ```. pip install git+https://github.com/theislab/scanpy.git. ```. Also, be sure to load scanpy as 'import scanpy as sc'. If you use the old method (`import scanpy.api as sc`) it will not work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:260,integrability,api,api,260,"I think that correlation matrix is only in the latest master version. You can install it using:. ```. pip install git+https://github.com/theislab/scanpy.git. ```. Also, be sure to load scanpy as 'import scanpy as sc'. If you use the old method (`import scanpy.api as sc`) it will not work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:260,interoperability,api,api,260,"I think that correlation matrix is only in the latest master version. You can install it using:. ```. pip install git+https://github.com/theislab/scanpy.git. ```. Also, be sure to load scanpy as 'import scanpy as sc'. If you use the old method (`import scanpy.api as sc`) it will not work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:61,modifiability,version,version,61,"I think that correlation matrix is only in the latest master version. You can install it using:. ```. pip install git+https://github.com/theislab/scanpy.git. ```. Also, be sure to load scanpy as 'import scanpy as sc'. If you use the old method (`import scanpy.api as sc`) it will not work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:180,performance,load,load,180,"I think that correlation matrix is only in the latest master version. You can install it using:. ```. pip install git+https://github.com/theislab/scanpy.git. ```. Also, be sure to load scanpy as 'import scanpy as sc'. If you use the old method (`import scanpy.api as sc`) it will not work.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:96,availability,error,error,96,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp. xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun. Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:382,availability,error,error,382,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp. xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun. Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:681,availability,error,error,681,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp. xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun. Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:137,deployability,instal,install,137,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp. xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun. Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:359,deployability,build,build-,359,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp. xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun. Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:653,deployability,build,build-,653,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp. xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun. Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:669,deployability,fail,failed,669,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp. xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun. Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:96,performance,error,error,96,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp. xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun. Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:382,performance,error,error,382,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp. xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun. Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:681,performance,error,error,681,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp. xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun. Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:669,reliability,fail,failed,669,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp. xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun. Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:96,safety,error,error,96,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp. xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun. Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:382,safety,error,error,382,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp. xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun. Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:681,safety,error,error,681,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp. xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun. Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:53,usability,command,command,53,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp. xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun. Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:96,usability,error,error,96,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp. xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun. Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:382,usability,error,error,382,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp. xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun. Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:439,usability,Command,CommandLineTools,439,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp. xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun. Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:495,usability,Command,CommandLineTools,495,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp. xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun. Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:527,usability,Command,Command,527,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp. xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun. Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:681,usability,error,error,681,"@fidelram thanks for letting me know. I am using the command you suggested and still getting an error:. CCBR-KULKAMILT:~ kulkarnia2$ pip install git+https://github.com/theislab/scanpy.git. Collecting git+https://github.com/theislab/scanpy.git. Cloning https://github.com/theislab/scanpy.git to /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp. xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun. Command ""git clone -q https://github.com/theislab/scanpy.git /private/var/folders/56/g1b462hs0d3816ktcj6twm8hmsw5ch/T/pip-req-build-o4lkd6tp"" failed with error code 1 in None",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:2,availability,down,downloaded,2,I downloaded the folder from GitHub and then installed Scanpy and it worked for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/544:45,deployability,instal,installed,45,I downloaded the folder from GitHub and then installed Scanpy and it worked for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/544
https://github.com/scverse/scanpy/issues/545:111,availability,avail,available,111,"Hi! Sorry, my bad. That parameter was undocumented, and I added it to the wrong docstring building block. It’s available in all scatterplots for dimension reductions, like `pca`, `tsne` and so on.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/545
https://github.com/scverse/scanpy/issues/545:90,deployability,build,building,90,"Hi! Sorry, my bad. That parameter was undocumented, and I added it to the wrong docstring building block. It’s available in all scatterplots for dimension reductions, like `pca`, `tsne` and so on.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/545
https://github.com/scverse/scanpy/issues/545:155,energy efficiency,reduc,reductions,155,"Hi! Sorry, my bad. That parameter was undocumented, and I added it to the wrong docstring building block. It’s available in all scatterplots for dimension reductions, like `pca`, `tsne` and so on.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/545
https://github.com/scverse/scanpy/issues/545:24,modifiability,paramet,parameter,24,"Hi! Sorry, my bad. That parameter was undocumented, and I added it to the wrong docstring building block. It’s available in all scatterplots for dimension reductions, like `pca`, `tsne` and so on.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/545
https://github.com/scverse/scanpy/issues/545:111,reliability,availab,available,111,"Hi! Sorry, my bad. That parameter was undocumented, and I added it to the wrong docstring building block. It’s available in all scatterplots for dimension reductions, like `pca`, `tsne` and so on.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/545
https://github.com/scverse/scanpy/issues/545:111,safety,avail,available,111,"Hi! Sorry, my bad. That parameter was undocumented, and I added it to the wrong docstring building block. It’s available in all scatterplots for dimension reductions, like `pca`, `tsne` and so on.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/545
https://github.com/scverse/scanpy/issues/545:111,security,availab,available,111,"Hi! Sorry, my bad. That parameter was undocumented, and I added it to the wrong docstring building block. It’s available in all scatterplots for dimension reductions, like `pca`, `tsne` and so on.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/545
https://github.com/scverse/scanpy/issues/545:38,usability,undo,undocumented,38,"Hi! Sorry, my bad. That parameter was undocumented, and I added it to the wrong docstring building block. It’s available in all scatterplots for dimension reductions, like `pca`, `tsne` and so on.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/545
https://github.com/scverse/scanpy/issues/545:13,energy efficiency,heat,heatmaps,13,To save your heatmaps use the `save` argument.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/545
https://github.com/scverse/scanpy/pull/546:25,testability,plan,planning,25,This is great... are you planning to merge this soon? Then I can check if it fixes my issue.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/546
https://github.com/scverse/scanpy/issues/547:192,reliability,doe,doesn,192,"Ah, sorry, that was introduced by a PR quite a while ago; fixed it via https://github.com/theislab/anndata/commit/90bea2c1721d5dbfad20975b14809c63cc126ae8. Added a test that will make sure it doesn't happen again in the future:. https://github.com/theislab/anndata/commit/8737bc2c3fe7946fdab0f6f63f36695e86a4b6a3",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/547
https://github.com/scverse/scanpy/issues/547:164,safety,test,test,164,"Ah, sorry, that was introduced by a PR quite a while ago; fixed it via https://github.com/theislab/anndata/commit/90bea2c1721d5dbfad20975b14809c63cc126ae8. Added a test that will make sure it doesn't happen again in the future:. https://github.com/theislab/anndata/commit/8737bc2c3fe7946fdab0f6f63f36695e86a4b6a3",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/547
https://github.com/scverse/scanpy/issues/547:164,testability,test,test,164,"Ah, sorry, that was introduced by a PR quite a while ago; fixed it via https://github.com/theislab/anndata/commit/90bea2c1721d5dbfad20975b14809c63cc126ae8. Added a test that will make sure it doesn't happen again in the future:. https://github.com/theislab/anndata/commit/8737bc2c3fe7946fdab0f6f63f36695e86a4b6a3",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/547
https://github.com/scverse/scanpy/issues/547:14,deployability,updat,updated,14,Has this been updated on the latest version of scanpy ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/547
https://github.com/scverse/scanpy/issues/547:36,deployability,version,version,36,Has this been updated on the latest version of scanpy ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/547
https://github.com/scverse/scanpy/issues/547:36,integrability,version,version,36,Has this been updated on the latest version of scanpy ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/547
https://github.com/scverse/scanpy/issues/547:36,modifiability,version,version,36,Has this been updated on the latest version of scanpy ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/547
https://github.com/scverse/scanpy/issues/547:14,safety,updat,updated,14,Has this been updated on the latest version of scanpy ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/547
https://github.com/scverse/scanpy/issues/547:14,security,updat,updated,14,Has this been updated on the latest version of scanpy ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/547
https://github.com/scverse/scanpy/issues/548:196,energy efficiency,heat,heatmap,196,"the problem is related to the palette being used. The color palette is taken from the scatter plots. A way to fix this is by running for example `sc.pl.umap(adata, palette='Blues')`. Then run the heatmap again.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548
https://github.com/scverse/scanpy/issues/548:0,energy efficiency,Cool,Cool,0,"Cool! It did solve my problems. Thank you! From: Fidel Ramirez. Sent: Friday, March 22, 2019 5:55 AM. To: theislab/scanpy. Cc: screamer; Author. Subject: Re: [theislab/scanpy] sc.pl.heatmap cannot show different colors formore than 20 cell types (#548). the problem is related to the palette being used. The color palette is taken from the scatter plots. A way to fix this is by running for example sc.pl.umap(adata, palette='Blues'). Then run the heatmap again. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548
https://github.com/scverse/scanpy/issues/548:182,energy efficiency,heat,heatmap,182,"Cool! It did solve my problems. Thank you! From: Fidel Ramirez. Sent: Friday, March 22, 2019 5:55 AM. To: theislab/scanpy. Cc: screamer; Author. Subject: Re: [theislab/scanpy] sc.pl.heatmap cannot show different colors formore than 20 cell types (#548). the problem is related to the palette being used. The color palette is taken from the scatter plots. A way to fix this is by running for example sc.pl.umap(adata, palette='Blues'). Then run the heatmap again. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548
https://github.com/scverse/scanpy/issues/548:448,energy efficiency,heat,heatmap,448,"Cool! It did solve my problems. Thank you! From: Fidel Ramirez. Sent: Friday, March 22, 2019 5:55 AM. To: theislab/scanpy. Cc: screamer; Author. Subject: Re: [theislab/scanpy] sc.pl.heatmap cannot show different colors formore than 20 cell types (#548). the problem is related to the palette being used. The color palette is taken from the scatter plots. A way to fix this is by running for example sc.pl.umap(adata, palette='Blues'). Then run the heatmap again. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548
https://github.com/scverse/scanpy/issues/548:145,integrability,Sub,Subject,145,"Cool! It did solve my problems. Thank you! From: Fidel Ramirez. Sent: Friday, March 22, 2019 5:55 AM. To: theislab/scanpy. Cc: screamer; Author. Subject: Re: [theislab/scanpy] sc.pl.heatmap cannot show different colors formore than 20 cell types (#548). the problem is related to the palette being used. The color palette is taken from the scatter plots. A way to fix this is by running for example sc.pl.umap(adata, palette='Blues'). Then run the heatmap again. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548
https://github.com/scverse/scanpy/issues/548:137,security,Auth,Author,137,"Cool! It did solve my problems. Thank you! From: Fidel Ramirez. Sent: Friday, March 22, 2019 5:55 AM. To: theislab/scanpy. Cc: screamer; Author. Subject: Re: [theislab/scanpy] sc.pl.heatmap cannot show different colors formore than 20 cell types (#548). the problem is related to the palette being used. The color palette is taken from the scatter plots. A way to fix this is by running for example sc.pl.umap(adata, palette='Blues'). Then run the heatmap again. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548
https://github.com/scverse/scanpy/issues/548:501,security,auth,authored,501,"Cool! It did solve my problems. Thank you! From: Fidel Ramirez. Sent: Friday, March 22, 2019 5:55 AM. To: theislab/scanpy. Cc: screamer; Author. Subject: Re: [theislab/scanpy] sc.pl.heatmap cannot show different colors formore than 20 cell types (#548). the problem is related to the palette being used. The color palette is taken from the scatter plots. A way to fix this is by running for example sc.pl.umap(adata, palette='Blues'). Then run the heatmap again. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548
https://github.com/scverse/scanpy/issues/548:27,modifiability,reu,reuse,27,"Actually, it'd be great to reuse category number-based dynamic color map selection code thingy we have for scatterplots here. What do you think @fidelram ?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548
https://github.com/scverse/scanpy/issues/548:89,energy efficiency,heat,heatmap,89,"@gokceneraslan If I follow you correctly, the idea would be to add a palette argument to heatmap. That indeed may solve the issue and should not be difficult to achieve. I will put it on my list of future enhancements.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548
https://github.com/scverse/scanpy/issues/548:327,availability,slo,slot,327,"> the problem is related to the palette being used. The color palette is taken from the scatter plots. A way to fix this is by running for example `sc.pl.umap(adata, palette='Blues')`. Then run the heatmap again. Does it work if I manually update the adata.uns['louvain_colors'] ? It feels weird to run umap just to create the slot for colormap althought it worked for me. Just want to double check.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548
https://github.com/scverse/scanpy/issues/548:240,deployability,updat,update,240,"> the problem is related to the palette being used. The color palette is taken from the scatter plots. A way to fix this is by running for example `sc.pl.umap(adata, palette='Blues')`. Then run the heatmap again. Does it work if I manually update the adata.uns['louvain_colors'] ? It feels weird to run umap just to create the slot for colormap althought it worked for me. Just want to double check.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548
https://github.com/scverse/scanpy/issues/548:198,energy efficiency,heat,heatmap,198,"> the problem is related to the palette being used. The color palette is taken from the scatter plots. A way to fix this is by running for example `sc.pl.umap(adata, palette='Blues')`. Then run the heatmap again. Does it work if I manually update the adata.uns['louvain_colors'] ? It feels weird to run umap just to create the slot for colormap althought it worked for me. Just want to double check.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548
https://github.com/scverse/scanpy/issues/548:213,reliability,Doe,Does,213,"> the problem is related to the palette being used. The color palette is taken from the scatter plots. A way to fix this is by running for example `sc.pl.umap(adata, palette='Blues')`. Then run the heatmap again. Does it work if I manually update the adata.uns['louvain_colors'] ? It feels weird to run umap just to create the slot for colormap althought it worked for me. Just want to double check.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548
https://github.com/scverse/scanpy/issues/548:327,reliability,slo,slot,327,"> the problem is related to the palette being used. The color palette is taken from the scatter plots. A way to fix this is by running for example `sc.pl.umap(adata, palette='Blues')`. Then run the heatmap again. Does it work if I manually update the adata.uns['louvain_colors'] ? It feels weird to run umap just to create the slot for colormap althought it worked for me. Just want to double check.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548
https://github.com/scverse/scanpy/issues/548:240,safety,updat,update,240,"> the problem is related to the palette being used. The color palette is taken from the scatter plots. A way to fix this is by running for example `sc.pl.umap(adata, palette='Blues')`. Then run the heatmap again. Does it work if I manually update the adata.uns['louvain_colors'] ? It feels weird to run umap just to create the slot for colormap althought it worked for me. Just want to double check.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548
https://github.com/scverse/scanpy/issues/548:240,security,updat,update,240,"> the problem is related to the palette being used. The color palette is taken from the scatter plots. A way to fix this is by running for example `sc.pl.umap(adata, palette='Blues')`. Then run the heatmap again. Does it work if I manually update the adata.uns['louvain_colors'] ? It feels weird to run umap just to create the slot for colormap althought it worked for me. Just want to double check.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548
https://github.com/scverse/scanpy/issues/548:50,deployability,updat,update,50,"@brianpenghe I believe it'll work if you manually update `adata.uns[""louvain_colors""]`, at least it does for the scatter plots. It is weird. We've talked a bit about having a better API for this here #596.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548
https://github.com/scverse/scanpy/issues/548:182,deployability,API,API,182,"@brianpenghe I believe it'll work if you manually update `adata.uns[""louvain_colors""]`, at least it does for the scatter plots. It is weird. We've talked a bit about having a better API for this here #596.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548
https://github.com/scverse/scanpy/issues/548:182,integrability,API,API,182,"@brianpenghe I believe it'll work if you manually update `adata.uns[""louvain_colors""]`, at least it does for the scatter plots. It is weird. We've talked a bit about having a better API for this here #596.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548
https://github.com/scverse/scanpy/issues/548:182,interoperability,API,API,182,"@brianpenghe I believe it'll work if you manually update `adata.uns[""louvain_colors""]`, at least it does for the scatter plots. It is weird. We've talked a bit about having a better API for this here #596.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548
https://github.com/scverse/scanpy/issues/548:100,reliability,doe,does,100,"@brianpenghe I believe it'll work if you manually update `adata.uns[""louvain_colors""]`, at least it does for the scatter plots. It is weird. We've talked a bit about having a better API for this here #596.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548
https://github.com/scverse/scanpy/issues/548:50,safety,updat,update,50,"@brianpenghe I believe it'll work if you manually update `adata.uns[""louvain_colors""]`, at least it does for the scatter plots. It is weird. We've talked a bit about having a better API for this here #596.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548
https://github.com/scverse/scanpy/issues/548:50,security,updat,update,50,"@brianpenghe I believe it'll work if you manually update `adata.uns[""louvain_colors""]`, at least it does for the scatter plots. It is weird. We've talked a bit about having a better API for this here #596.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/548
https://github.com/scverse/scanpy/pull/549:438,modifiability,paramet,parameter,438,"This looks very good already! Nice code! :) Thanks for also adding the things you're still planning to add. @flying-sheep might not like that you spell out the types in the docs in addition to the type annotations but I think it's good: the string selection values for `method` can't be represented as a type annotation, I think; and I still like browsing the type annotations with shift+tab at the same time when reading the rest of the parameter explanation. So, I'd say, just keep it as it is.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:404,performance,time,time,404,"This looks very good already! Nice code! :) Thanks for also adding the things you're still planning to add. @flying-sheep might not like that you spell out the types in the docs in addition to the type annotations but I think it's good: the string selection values for `method` can't be represented as a type annotation, I think; and I still like browsing the type annotations with shift+tab at the same time when reading the rest of the parameter explanation. So, I'd say, just keep it as it is.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:91,testability,plan,planning,91,"This looks very good already! Nice code! :) Thanks for also adding the things you're still planning to add. @flying-sheep might not like that you spell out the types in the docs in addition to the type annotations but I think it's good: the string selection values for `method` can't be represented as a type annotation, I think; and I still like browsing the type annotations with shift+tab at the same time when reading the rest of the parameter explanation. So, I'd say, just keep it as it is.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:309,availability,redund,redundant,309,"Could you please do `Dict[KeyType, ValueType]` instead of `dict` in the type annotations? @falexwolf you forgot that the types will be added to the shift-tab info too: https://github.com/theislab/scanpy/blob/10f8a3c8aa5cfa4431db2a10f1f3cc088072e788/scanpy/__init__.py#L42. So yes, @LuckyMD please remove all *redundant* type info in the docs. The info for `method` and `normalize` should stay, the rest can go with absolutely no loss of information anywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:309,deployability,redundan,redundant,309,"Could you please do `Dict[KeyType, ValueType]` instead of `dict` in the type annotations? @falexwolf you forgot that the types will be added to the shift-tab info too: https://github.com/theislab/scanpy/blob/10f8a3c8aa5cfa4431db2a10f1f3cc088072e788/scanpy/__init__.py#L42. So yes, @LuckyMD please remove all *redundant* type info in the docs. The info for `method` and `normalize` should stay, the rest can go with absolutely no loss of information anywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:309,reliability,redundan,redundant,309,"Could you please do `Dict[KeyType, ValueType]` instead of `dict` in the type annotations? @falexwolf you forgot that the types will be added to the shift-tab info too: https://github.com/theislab/scanpy/blob/10f8a3c8aa5cfa4431db2a10f1f3cc088072e788/scanpy/__init__.py#L42. So yes, @LuckyMD please remove all *redundant* type info in the docs. The info for `method` and `normalize` should stay, the rest can go with absolutely no loss of information anywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:309,safety,redund,redundant,309,"Could you please do `Dict[KeyType, ValueType]` instead of `dict` in the type annotations? @falexwolf you forgot that the types will be added to the shift-tab info too: https://github.com/theislab/scanpy/blob/10f8a3c8aa5cfa4431db2a10f1f3cc088072e788/scanpy/__init__.py#L42. So yes, @LuckyMD please remove all *redundant* type info in the docs. The info for `method` and `normalize` should stay, the rest can go with absolutely no loss of information anywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:429,security,loss,loss,429,"Could you please do `Dict[KeyType, ValueType]` instead of `dict` in the type annotations? @falexwolf you forgot that the types will be added to the shift-tab info too: https://github.com/theislab/scanpy/blob/10f8a3c8aa5cfa4431db2a10f1f3cc088072e788/scanpy/__init__.py#L42. So yes, @LuckyMD please remove all *redundant* type info in the docs. The info for `method` and `normalize` should stay, the rest can go with absolutely no loss of information anywhere.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:4,energy efficiency,cool,cool,4,"OK, cool; thanks @flying-sheep! The function looks otherwise good!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:204,availability,state,state,204,"> Could you please do `Dict[KeyType, ValueType]` instead of `dict` in the type annotations? @flying-sheep When I put in `key: dict[str, set]` it tells me type annotations are not subscriptable. How can I state the dict key-value types required?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:179,integrability,sub,subscriptable,179,"> Could you please do `Dict[KeyType, ValueType]` instead of `dict` in the type annotations? @flying-sheep When I put in `key: dict[str, set]` it tells me type annotations are not subscriptable. How can I state the dict key-value types required?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:204,integrability,state,state,204,"> Could you please do `Dict[KeyType, ValueType]` instead of `dict` in the type annotations? @flying-sheep When I put in `key: dict[str, set]` it tells me type annotations are not subscriptable. How can I state the dict key-value types required?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:54,usability,document,documentation,54,"Finished most of the features... just need to add the documentation... would appreciate if someone could take a look at the code @flying-sheep, @falexwolf...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:79,modifiability,exten,extending,79,"From my side it's ready to be merged. I have left a note in the comments about extending this to enrichment scores, and that this would be difficult. I though it might be good to leave that in there in case anyone wants to extend it later. Thoughts on that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:223,modifiability,exten,extend,223,"From my side it's ready to be merged. I have left a note in the comments about extending this to enrichment scores, and that this would be difficult. I though it might be good to leave that in there in case anyone wants to extend it later. Thoughts on that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:80,security,auth,author,80,"This looks great, Malte! Only thing see my comment above. You should get on the author list! :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:23,security,auth,author,23,"I'd love to get on the author list :). Will add the inplace option now with the `NotImplementedError` raised. The only thing remaining is what @flying-sheep suggested with the typing for the dictionary, which I can't seem to do.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:50,deployability,modul,module,50,"Found the `Dict[str, set]` option in the `typing` module. I've left the `dict` typing for the hidden functions though... I guess they're not user exposed anyway. I left the code in there for `inplace=True`... so when the pandas writing option is implemented, the `if inplace: raise NotImplementedError('...')` lines just need to be removed. Ready to be merged from my side now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:50,modifiability,modul,module,50,"Found the `Dict[str, set]` option in the `typing` module. I've left the `dict` typing for the hidden functions though... I guess they're not user exposed anyway. I left the code in there for `inplace=True`... so when the pandas writing option is implemented, the `if inplace: raise NotImplementedError('...')` lines just need to be removed. Ready to be merged from my side now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:50,safety,modul,module,50,"Found the `Dict[str, set]` option in the `typing` module. I've left the `dict` typing for the hidden functions though... I guess they're not user exposed anyway. I left the code in there for `inplace=True`... so when the pandas writing option is implemented, the `if inplace: raise NotImplementedError('...')` lines just need to be removed. Ready to be merged from my side now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:146,security,expos,exposed,146,"Found the `Dict[str, set]` option in the `typing` module. I've left the `dict` typing for the hidden functions though... I guess they're not user exposed anyway. I left the code in there for `inplace=True`... so when the pandas writing option is implemented, the `if inplace: raise NotImplementedError('...')` lines just need to be removed. Ready to be merged from my side now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:141,usability,user,user,141,"Found the `Dict[str, set]` option in the `typing` module. I've left the `dict` typing for the hidden functions though... I guess they're not user exposed anyway. I left the code in there for `inplace=True`... so when the pandas writing option is implemented, the `if inplace: raise NotImplementedError('...')` lines just need to be removed. Ready to be merged from my side now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:182,deployability,fail,fail,182,"Not sure what's up with Travis... the tests pass on my machine, and they were passing on Travis the whole time... my last commit hasn't really changed anything that would cause this fail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:106,performance,time,time,106,"Not sure what's up with Travis... the tests pass on my machine, and they were passing on Travis the whole time... my last commit hasn't really changed anything that would cause this fail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:182,reliability,fail,fail,182,"Not sure what's up with Travis... the tests pass on my machine, and they were passing on Travis the whole time... my last commit hasn't really changed anything that would cause this fail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:38,safety,test,tests,38,"Not sure what's up with Travis... the tests pass on my machine, and they were passing on Travis the whole time... my last commit hasn't really changed anything that would cause this fail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:38,testability,test,tests,38,"Not sure what's up with Travis... the tests pass on my machine, and they were passing on Travis the whole time... my last commit hasn't really changed anything that would cause this fail.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:33,deployability,build,build,33,Great! Travis looks like stalled build...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:164,safety,compl,completely,164,"Damn, there seems to be some Python 3.5 related thing going on: https://travis-ci.org/theislab/scanpy/jobs/513835981. @LuckyMD, any idea why this returns something completely different?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:164,security,compl,completely,164,"Damn, there seems to be some Python 3.5 related thing going on: https://travis-ci.org/theislab/scanpy/jobs/513835981. @LuckyMD, any idea why this returns something completely different?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:215,reliability,doe,does,215,"I have no idea... I was trying to understand how this would be different... the matrix I expect is `[[3,1],[1,3]]`... And that's what I get for python 3.6. I don't know what changed from 3.5. Maybe pandas `.iloc[]` does something else?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:34,testability,understand,understand,34,"I have no idea... I was trying to understand how this would be different... the matrix I expect is `[[3,1],[1,3]]`... And that's what I get for python 3.6. I don't know what changed from 3.5. Maybe pandas `.iloc[]` does something else?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:95,availability,state,statement,95,It started to go wrong with ff26149 and all I changed there was that I moved the `if inplace:` statement up to the user tests instead of down to where the outputs were written. Is python 3.5 somehow sensitive to whitespace after if statements? I found a whitespace after the `if inplace: `... maybe that's it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:137,availability,down,down,137,It started to go wrong with ff26149 and all I changed there was that I moved the `if inplace:` statement up to the user tests instead of down to where the outputs were written. Is python 3.5 somehow sensitive to whitespace after if statements? I found a whitespace after the `if inplace: `... maybe that's it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:232,availability,state,statements,232,It started to go wrong with ff26149 and all I changed there was that I moved the `if inplace:` statement up to the user tests instead of down to where the outputs were written. Is python 3.5 somehow sensitive to whitespace after if statements? I found a whitespace after the `if inplace: `... maybe that's it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:95,integrability,state,statement,95,It started to go wrong with ff26149 and all I changed there was that I moved the `if inplace:` statement up to the user tests instead of down to where the outputs were written. Is python 3.5 somehow sensitive to whitespace after if statements? I found a whitespace after the `if inplace: `... maybe that's it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:232,integrability,state,statements,232,It started to go wrong with ff26149 and all I changed there was that I moved the `if inplace:` statement up to the user tests instead of down to where the outputs were written. Is python 3.5 somehow sensitive to whitespace after if statements? I found a whitespace after the `if inplace: `... maybe that's it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:120,safety,test,tests,120,It started to go wrong with ff26149 and all I changed there was that I moved the `if inplace:` statement up to the user tests instead of down to where the outputs were written. Is python 3.5 somehow sensitive to whitespace after if statements? I found a whitespace after the `if inplace: `... maybe that's it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:120,testability,test,tests,120,It started to go wrong with ff26149 and all I changed there was that I moved the `if inplace:` statement up to the user tests instead of down to where the outputs were written. Is python 3.5 somehow sensitive to whitespace after if statements? I found a whitespace after the `if inplace: `... maybe that's it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:115,usability,user,user,115,It started to go wrong with ff26149 and all I changed there was that I moved the `if inplace:` statement up to the user tests instead of down to where the outputs were written. Is python 3.5 somehow sensitive to whitespace after if statements? I found a whitespace after the `if inplace: `... maybe that's it?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:130,availability,down,down,130,Does anyone have a nice instruction set on how I can reproduce the travis python 3.5 environment? @flying-sheep? Maybe I can hunt down the cause of the error then... although it's apparently only sporadic according to @ivirshup :/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:152,availability,error,error,152,Does anyone have a nice instruction set on how I can reproduce the travis python 3.5 environment? @flying-sheep? Maybe I can hunt down the cause of the error then... although it's apparently only sporadic according to @ivirshup :/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:152,performance,error,error,152,Does anyone have a nice instruction set on how I can reproduce the travis python 3.5 environment? @flying-sheep? Maybe I can hunt down the cause of the error then... although it's apparently only sporadic according to @ivirshup :/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:0,reliability,Doe,Does,0,Does anyone have a nice instruction set on how I can reproduce the travis python 3.5 environment? @flying-sheep? Maybe I can hunt down the cause of the error then... although it's apparently only sporadic according to @ivirshup :/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:152,safety,error,error,152,Does anyone have a nice instruction set on how I can reproduce the travis python 3.5 environment? @flying-sheep? Maybe I can hunt down the cause of the error then... although it's apparently only sporadic according to @ivirshup :/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:152,usability,error,error,152,Does anyone have a nice instruction set on how I can reproduce the travis python 3.5 environment? @flying-sheep? Maybe I can hunt down the cause of the error then... although it's apparently only sporadic according to @ivirshup :/,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:54,usability,close,close,54,"iirc, I think there is a docker image which is pretty close to what Travis runs. > On Apr 2, 2019, at 07:27, Philipp A. <notifications@github.com> wrote:. > . > I don’t think there’s an easy way to reproduce it exactly, sorry. > . > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub, or mute the thread.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:113,deployability,build,build,113,Maybe travis’ [ubuntu-systemd](https://hub.docker.com/r/travisci/ubuntu-systemd)? Then you’d need to use [travis-build](https://github.com/travis-ci/travis-build) (for which there also is a [docker image](https://hub.docker.com/r/travisci/travis-build)) to convert the .yml to a .sh and execute that on the ubuntu container. (travis-build exists to do all this but that’s maybe overkill),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:156,deployability,build,build,156,Maybe travis’ [ubuntu-systemd](https://hub.docker.com/r/travisci/ubuntu-systemd)? Then you’d need to use [travis-build](https://github.com/travis-ci/travis-build) (for which there also is a [docker image](https://hub.docker.com/r/travisci/travis-build)) to convert the .yml to a .sh and execute that on the ubuntu container. (travis-build exists to do all this but that’s maybe overkill),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:246,deployability,build,build,246,Maybe travis’ [ubuntu-systemd](https://hub.docker.com/r/travisci/ubuntu-systemd)? Then you’d need to use [travis-build](https://github.com/travis-ci/travis-build) (for which there also is a [docker image](https://hub.docker.com/r/travisci/travis-build)) to convert the .yml to a .sh and execute that on the ubuntu container. (travis-build exists to do all this but that’s maybe overkill),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:314,deployability,contain,container,314,Maybe travis’ [ubuntu-systemd](https://hub.docker.com/r/travisci/ubuntu-systemd)? Then you’d need to use [travis-build](https://github.com/travis-ci/travis-build) (for which there also is a [docker image](https://hub.docker.com/r/travisci/travis-build)) to convert the .yml to a .sh and execute that on the ubuntu container. (travis-build exists to do all this but that’s maybe overkill),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:333,deployability,build,build,333,Maybe travis’ [ubuntu-systemd](https://hub.docker.com/r/travisci/ubuntu-systemd)? Then you’d need to use [travis-build](https://github.com/travis-ci/travis-build) (for which there also is a [docker image](https://hub.docker.com/r/travisci/travis-build)) to convert the .yml to a .sh and execute that on the ubuntu container. (travis-build exists to do all this but that’s maybe overkill),MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:265,availability,state,statements,265,"In #583 I have amended this PR a bit... corrected the normalization to make more sense, made the input dict value type more malleable, and I'm playing with the Travis build there. For some reason it already stopped failing when I just changed the order of `assert` statements. I thought there might have been too many `assert` statements in a single function, so I split them up into separate testing functions. I think that's probably better coding practice anyway... but now they fail again for python 3.5... Maybe move the discussion there?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:327,availability,state,statements,327,"In #583 I have amended this PR a bit... corrected the normalization to make more sense, made the input dict value type more malleable, and I'm playing with the Travis build there. For some reason it already stopped failing when I just changed the order of `assert` statements. I thought there might have been too many `assert` statements in a single function, so I split them up into separate testing functions. I think that's probably better coding practice anyway... but now they fail again for python 3.5... Maybe move the discussion there?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:167,deployability,build,build,167,"In #583 I have amended this PR a bit... corrected the normalization to make more sense, made the input dict value type more malleable, and I'm playing with the Travis build there. For some reason it already stopped failing when I just changed the order of `assert` statements. I thought there might have been too many `assert` statements in a single function, so I split them up into separate testing functions. I think that's probably better coding practice anyway... but now they fail again for python 3.5... Maybe move the discussion there?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:215,deployability,fail,failing,215,"In #583 I have amended this PR a bit... corrected the normalization to make more sense, made the input dict value type more malleable, and I'm playing with the Travis build there. For some reason it already stopped failing when I just changed the order of `assert` statements. I thought there might have been too many `assert` statements in a single function, so I split them up into separate testing functions. I think that's probably better coding practice anyway... but now they fail again for python 3.5... Maybe move the discussion there?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:482,deployability,fail,fail,482,"In #583 I have amended this PR a bit... corrected the normalization to make more sense, made the input dict value type more malleable, and I'm playing with the Travis build there. For some reason it already stopped failing when I just changed the order of `assert` statements. I thought there might have been too many `assert` statements in a single function, so I split them up into separate testing functions. I think that's probably better coding practice anyway... but now they fail again for python 3.5... Maybe move the discussion there?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:265,integrability,state,statements,265,"In #583 I have amended this PR a bit... corrected the normalization to make more sense, made the input dict value type more malleable, and I'm playing with the Travis build there. For some reason it already stopped failing when I just changed the order of `assert` statements. I thought there might have been too many `assert` statements in a single function, so I split them up into separate testing functions. I think that's probably better coding practice anyway... but now they fail again for python 3.5... Maybe move the discussion there?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:327,integrability,state,statements,327,"In #583 I have amended this PR a bit... corrected the normalization to make more sense, made the input dict value type more malleable, and I'm playing with the Travis build there. For some reason it already stopped failing when I just changed the order of `assert` statements. I thought there might have been too many `assert` statements in a single function, so I split them up into separate testing functions. I think that's probably better coding practice anyway... but now they fail again for python 3.5... Maybe move the discussion there?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:215,reliability,fail,failing,215,"In #583 I have amended this PR a bit... corrected the normalization to make more sense, made the input dict value type more malleable, and I'm playing with the Travis build there. For some reason it already stopped failing when I just changed the order of `assert` statements. I thought there might have been too many `assert` statements in a single function, so I split them up into separate testing functions. I think that's probably better coding practice anyway... but now they fail again for python 3.5... Maybe move the discussion there?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:450,reliability,pra,practice,450,"In #583 I have amended this PR a bit... corrected the normalization to make more sense, made the input dict value type more malleable, and I'm playing with the Travis build there. For some reason it already stopped failing when I just changed the order of `assert` statements. I thought there might have been too many `assert` statements in a single function, so I split them up into separate testing functions. I think that's probably better coding practice anyway... but now they fail again for python 3.5... Maybe move the discussion there?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:482,reliability,fail,fail,482,"In #583 I have amended this PR a bit... corrected the normalization to make more sense, made the input dict value type more malleable, and I'm playing with the Travis build there. For some reason it already stopped failing when I just changed the order of `assert` statements. I thought there might have been too many `assert` statements in a single function, so I split them up into separate testing functions. I think that's probably better coding practice anyway... but now they fail again for python 3.5... Maybe move the discussion there?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:97,safety,input,input,97,"In #583 I have amended this PR a bit... corrected the normalization to make more sense, made the input dict value type more malleable, and I'm playing with the Travis build there. For some reason it already stopped failing when I just changed the order of `assert` statements. I thought there might have been too many `assert` statements in a single function, so I split them up into separate testing functions. I think that's probably better coding practice anyway... but now they fail again for python 3.5... Maybe move the discussion there?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:393,safety,test,testing,393,"In #583 I have amended this PR a bit... corrected the normalization to make more sense, made the input dict value type more malleable, and I'm playing with the Travis build there. For some reason it already stopped failing when I just changed the order of `assert` statements. I thought there might have been too many `assert` statements in a single function, so I split them up into separate testing functions. I think that's probably better coding practice anyway... but now they fail again for python 3.5... Maybe move the discussion there?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:257,testability,assert,assert,257,"In #583 I have amended this PR a bit... corrected the normalization to make more sense, made the input dict value type more malleable, and I'm playing with the Travis build there. For some reason it already stopped failing when I just changed the order of `assert` statements. I thought there might have been too many `assert` statements in a single function, so I split them up into separate testing functions. I think that's probably better coding practice anyway... but now they fail again for python 3.5... Maybe move the discussion there?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:319,testability,assert,assert,319,"In #583 I have amended this PR a bit... corrected the normalization to make more sense, made the input dict value type more malleable, and I'm playing with the Travis build there. For some reason it already stopped failing when I just changed the order of `assert` statements. I thought there might have been too many `assert` statements in a single function, so I split them up into separate testing functions. I think that's probably better coding practice anyway... but now they fail again for python 3.5... Maybe move the discussion there?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:393,testability,test,testing,393,"In #583 I have amended this PR a bit... corrected the normalization to make more sense, made the input dict value type more malleable, and I'm playing with the Travis build there. For some reason it already stopped failing when I just changed the order of `assert` statements. I thought there might have been too many `assert` statements in a single function, so I split them up into separate testing functions. I think that's probably better coding practice anyway... but now they fail again for python 3.5... Maybe move the discussion there?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:97,usability,input,input,97,"In #583 I have amended this PR a bit... corrected the normalization to make more sense, made the input dict value type more malleable, and I'm playing with the Travis build there. For some reason it already stopped failing when I just changed the order of `assert` statements. I thought there might have been too many `assert` statements in a single function, so I split them up into separate testing functions. I think that's probably better coding practice anyway... but now they fail again for python 3.5... Maybe move the discussion there?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/pull/549:207,usability,stop,stopped,207,"In #583 I have amended this PR a bit... corrected the normalization to make more sense, made the input dict value type more malleable, and I'm playing with the Travis build there. For some reason it already stopped failing when I just changed the order of `assert` statements. I thought there might have been too many `assert` statements in a single function, so I split them up into separate testing functions. I think that's probably better coding practice anyway... but now they fail again for python 3.5... Maybe move the discussion there?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/549
https://github.com/scverse/scanpy/issues/550:14,usability,behavi,behavior,14,"Hm, that is a behavior that @fidelram built in. Typically you should be able to achieve different orderings of categories by doing exactly what you did (you don't need `ordered=True`, which would mean you're looking at ordinal categories). For instance, the legends in scatter plots respect that. @fidelram, what's the reason for ignoring the `.cat.categories` order?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/550
https://github.com/scverse/scanpy/issues/550:238,modifiability,maintain,maintained,238,"@falexwolf @fidelram I wanted to use the same ordering concept for the correlation matrix from the new visualization tutorial. I tried ordering using the same strategy as @fbrundu mentioned above. This works for a UMAP where the order is maintained in the labels but for the correlation matrix the labels are getting jumbled up again. I am pasting my command below (pt_order is the ordered patient id obs I created for my adata object). ax = sc.pl.correlation_matrix(adata_cd45p, 'pt_order',dendrogram=False). Do only certain plots accept the ordering ? Thanks for your help.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/550
https://github.com/scverse/scanpy/issues/550:238,safety,maintain,maintained,238,"@falexwolf @fidelram I wanted to use the same ordering concept for the correlation matrix from the new visualization tutorial. I tried ordering using the same strategy as @fbrundu mentioned above. This works for a UMAP where the order is maintained in the labels but for the correlation matrix the labels are getting jumbled up again. I am pasting my command below (pt_order is the ordered patient id obs I created for my adata object). ax = sc.pl.correlation_matrix(adata_cd45p, 'pt_order',dendrogram=False). Do only certain plots accept the ordering ? Thanks for your help.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/550
https://github.com/scverse/scanpy/issues/550:103,usability,visual,visualization,103,"@falexwolf @fidelram I wanted to use the same ordering concept for the correlation matrix from the new visualization tutorial. I tried ordering using the same strategy as @fbrundu mentioned above. This works for a UMAP where the order is maintained in the labels but for the correlation matrix the labels are getting jumbled up again. I am pasting my command below (pt_order is the ordered patient id obs I created for my adata object). ax = sc.pl.correlation_matrix(adata_cd45p, 'pt_order',dendrogram=False). Do only certain plots accept the ordering ? Thanks for your help.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/550
https://github.com/scverse/scanpy/issues/550:351,usability,command,command,351,"@falexwolf @fidelram I wanted to use the same ordering concept for the correlation matrix from the new visualization tutorial. I tried ordering using the same strategy as @fbrundu mentioned above. This works for a UMAP where the order is maintained in the labels but for the correlation matrix the labels are getting jumbled up again. I am pasting my command below (pt_order is the ordered patient id obs I created for my adata object). ax = sc.pl.correlation_matrix(adata_cd45p, 'pt_order',dendrogram=False). Do only certain plots accept the ordering ? Thanks for your help.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/550
https://github.com/scverse/scanpy/issues/550:570,usability,help,help,570,"@falexwolf @fidelram I wanted to use the same ordering concept for the correlation matrix from the new visualization tutorial. I tried ordering using the same strategy as @fbrundu mentioned above. This works for a UMAP where the order is maintained in the labels but for the correlation matrix the labels are getting jumbled up again. I am pasting my command below (pt_order is the ordered patient id obs I created for my adata object). ax = sc.pl.correlation_matrix(adata_cd45p, 'pt_order',dendrogram=False). Do only certain plots accept the ordering ? Thanks for your help.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/550
https://github.com/scverse/scanpy/issues/550:29,energy efficiency,heat,heatmap,29,"@fbrundu the ordering of the heatmap follows the ordering of the categories. Are you sure that your categories are re-ordered? I use a dictionary instead of a list when reordering. @aditisk correlation_matrix uses the ordering given by the dendrogram, even if the dendrogram is not shown. Do you think that we should change this behaviour?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/550
https://github.com/scverse/scanpy/issues/550:329,usability,behavi,behaviour,329,"@fbrundu the ordering of the heatmap follows the ordering of the categories. Are you sure that your categories are re-ordered? I use a dictionary instead of a list when reordering. @aditisk correlation_matrix uses the ordering given by the dendrogram, even if the dendrogram is not shown. Do you think that we should change this behaviour?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/550
https://github.com/scverse/scanpy/issues/550:425,availability,cluster,cluster,425,"@fidelram I think that it would be helpful to have a way to order the list used in the correlation_matrix (and all other plots that don't already support this). This is very useful when we have the same samples under 2 conditions. As of now, the order in condition 1 and condition 2 is not the same because the dendrogram is reordering the samples in a different way each time. It is definitely useful to see how the samples cluster but in this specific case, I want to maintain the order to keep the plot easy to read.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/550
https://github.com/scverse/scanpy/issues/550:425,deployability,cluster,cluster,425,"@fidelram I think that it would be helpful to have a way to order the list used in the correlation_matrix (and all other plots that don't already support this). This is very useful when we have the same samples under 2 conditions. As of now, the order in condition 1 and condition 2 is not the same because the dendrogram is reordering the samples in a different way each time. It is definitely useful to see how the samples cluster but in this specific case, I want to maintain the order to keep the plot easy to read.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/550
https://github.com/scverse/scanpy/issues/550:445,interoperability,specif,specific,445,"@fidelram I think that it would be helpful to have a way to order the list used in the correlation_matrix (and all other plots that don't already support this). This is very useful when we have the same samples under 2 conditions. As of now, the order in condition 1 and condition 2 is not the same because the dendrogram is reordering the samples in a different way each time. It is definitely useful to see how the samples cluster but in this specific case, I want to maintain the order to keep the plot easy to read.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/550
https://github.com/scverse/scanpy/issues/550:470,modifiability,maintain,maintain,470,"@fidelram I think that it would be helpful to have a way to order the list used in the correlation_matrix (and all other plots that don't already support this). This is very useful when we have the same samples under 2 conditions. As of now, the order in condition 1 and condition 2 is not the same because the dendrogram is reordering the samples in a different way each time. It is definitely useful to see how the samples cluster but in this specific case, I want to maintain the order to keep the plot easy to read.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/550
https://github.com/scverse/scanpy/issues/550:372,performance,time,time,372,"@fidelram I think that it would be helpful to have a way to order the list used in the correlation_matrix (and all other plots that don't already support this). This is very useful when we have the same samples under 2 conditions. As of now, the order in condition 1 and condition 2 is not the same because the dendrogram is reordering the samples in a different way each time. It is definitely useful to see how the samples cluster but in this specific case, I want to maintain the order to keep the plot easy to read.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/550
https://github.com/scverse/scanpy/issues/550:470,safety,maintain,maintain,470,"@fidelram I think that it would be helpful to have a way to order the list used in the correlation_matrix (and all other plots that don't already support this). This is very useful when we have the same samples under 2 conditions. As of now, the order in condition 1 and condition 2 is not the same because the dendrogram is reordering the samples in a different way each time. It is definitely useful to see how the samples cluster but in this specific case, I want to maintain the order to keep the plot easy to read.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/550
https://github.com/scverse/scanpy/issues/550:35,usability,help,helpful,35,"@fidelram I think that it would be helpful to have a way to order the list used in the correlation_matrix (and all other plots that don't already support this). This is very useful when we have the same samples under 2 conditions. As of now, the order in condition 1 and condition 2 is not the same because the dendrogram is reordering the samples in a different way each time. It is definitely useful to see how the samples cluster but in this specific case, I want to maintain the order to keep the plot easy to read.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/550
https://github.com/scverse/scanpy/issues/550:146,usability,support,support,146,"@fidelram I think that it would be helpful to have a way to order the list used in the correlation_matrix (and all other plots that don't already support this). This is very useful when we have the same samples under 2 conditions. As of now, the order in condition 1 and condition 2 is not the same because the dendrogram is reordering the samples in a different way each time. It is definitely useful to see how the samples cluster but in this specific case, I want to maintain the order to keep the plot easy to read.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/550
https://github.com/scverse/scanpy/issues/550:613,availability,cluster,cluster,613,"That's a good reason. I will try to find some time to fix this. On Tue, Apr 9, 2019 at 7:57 PM aditisk <notifications@github.com> wrote:. > @fidelram <https://github.com/fidelram> I think that it would be helpful. > to have a way to order the list used in the correlation_matrix (and all. > other plots that don't already support this). This is very useful when we. > have the same samples under 2 conditions. As of now, the order in condition. > 1 and condition 2 is not the same because the dendrogram is reordering the. > samples in a different way each time. It is definitely useful to see how. > the samples cluster but in this specific case, I want to maintain the order. > to keep the plot easy to read. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/550#issuecomment-481364097>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1bezEF2pGPOJnvCzNDrN3VlbfBMLks5vfNRtgaJpZM4cESJ4>. > . >. -- . Fidel Ramirez.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/550
https://github.com/scverse/scanpy/issues/550:613,deployability,cluster,cluster,613,"That's a good reason. I will try to find some time to fix this. On Tue, Apr 9, 2019 at 7:57 PM aditisk <notifications@github.com> wrote:. > @fidelram <https://github.com/fidelram> I think that it would be helpful. > to have a way to order the list used in the correlation_matrix (and all. > other plots that don't already support this). This is very useful when we. > have the same samples under 2 conditions. As of now, the order in condition. > 1 and condition 2 is not the same because the dendrogram is reordering the. > samples in a different way each time. It is definitely useful to see how. > the samples cluster but in this specific case, I want to maintain the order. > to keep the plot easy to read. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/550#issuecomment-481364097>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1bezEF2pGPOJnvCzNDrN3VlbfBMLks5vfNRtgaJpZM4cESJ4>. > . >. -- . Fidel Ramirez.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/550
https://github.com/scverse/scanpy/issues/550:633,interoperability,specif,specific,633,"That's a good reason. I will try to find some time to fix this. On Tue, Apr 9, 2019 at 7:57 PM aditisk <notifications@github.com> wrote:. > @fidelram <https://github.com/fidelram> I think that it would be helpful. > to have a way to order the list used in the correlation_matrix (and all. > other plots that don't already support this). This is very useful when we. > have the same samples under 2 conditions. As of now, the order in condition. > 1 and condition 2 is not the same because the dendrogram is reordering the. > samples in a different way each time. It is definitely useful to see how. > the samples cluster but in this specific case, I want to maintain the order. > to keep the plot easy to read. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/550#issuecomment-481364097>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1bezEF2pGPOJnvCzNDrN3VlbfBMLks5vfNRtgaJpZM4cESJ4>. > . >. -- . Fidel Ramirez.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/550
https://github.com/scverse/scanpy/issues/550:658,modifiability,maintain,maintain,658,"That's a good reason. I will try to find some time to fix this. On Tue, Apr 9, 2019 at 7:57 PM aditisk <notifications@github.com> wrote:. > @fidelram <https://github.com/fidelram> I think that it would be helpful. > to have a way to order the list used in the correlation_matrix (and all. > other plots that don't already support this). This is very useful when we. > have the same samples under 2 conditions. As of now, the order in condition. > 1 and condition 2 is not the same because the dendrogram is reordering the. > samples in a different way each time. It is definitely useful to see how. > the samples cluster but in this specific case, I want to maintain the order. > to keep the plot easy to read. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/550#issuecomment-481364097>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1bezEF2pGPOJnvCzNDrN3VlbfBMLks5vfNRtgaJpZM4cESJ4>. > . >. -- . Fidel Ramirez.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/550
https://github.com/scverse/scanpy/issues/550:46,performance,time,time,46,"That's a good reason. I will try to find some time to fix this. On Tue, Apr 9, 2019 at 7:57 PM aditisk <notifications@github.com> wrote:. > @fidelram <https://github.com/fidelram> I think that it would be helpful. > to have a way to order the list used in the correlation_matrix (and all. > other plots that don't already support this). This is very useful when we. > have the same samples under 2 conditions. As of now, the order in condition. > 1 and condition 2 is not the same because the dendrogram is reordering the. > samples in a different way each time. It is definitely useful to see how. > the samples cluster but in this specific case, I want to maintain the order. > to keep the plot easy to read. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/550#issuecomment-481364097>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1bezEF2pGPOJnvCzNDrN3VlbfBMLks5vfNRtgaJpZM4cESJ4>. > . >. -- . Fidel Ramirez.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/550
https://github.com/scverse/scanpy/issues/550:557,performance,time,time,557,"That's a good reason. I will try to find some time to fix this. On Tue, Apr 9, 2019 at 7:57 PM aditisk <notifications@github.com> wrote:. > @fidelram <https://github.com/fidelram> I think that it would be helpful. > to have a way to order the list used in the correlation_matrix (and all. > other plots that don't already support this). This is very useful when we. > have the same samples under 2 conditions. As of now, the order in condition. > 1 and condition 2 is not the same because the dendrogram is reordering the. > samples in a different way each time. It is definitely useful to see how. > the samples cluster but in this specific case, I want to maintain the order. > to keep the plot easy to read. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/550#issuecomment-481364097>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1bezEF2pGPOJnvCzNDrN3VlbfBMLks5vfNRtgaJpZM4cESJ4>. > . >. -- . Fidel Ramirez.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/550
https://github.com/scverse/scanpy/issues/550:658,safety,maintain,maintain,658,"That's a good reason. I will try to find some time to fix this. On Tue, Apr 9, 2019 at 7:57 PM aditisk <notifications@github.com> wrote:. > @fidelram <https://github.com/fidelram> I think that it would be helpful. > to have a way to order the list used in the correlation_matrix (and all. > other plots that don't already support this). This is very useful when we. > have the same samples under 2 conditions. As of now, the order in condition. > 1 and condition 2 is not the same because the dendrogram is reordering the. > samples in a different way each time. It is definitely useful to see how. > the samples cluster but in this specific case, I want to maintain the order. > to keep the plot easy to read. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/550#issuecomment-481364097>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1bezEF2pGPOJnvCzNDrN3VlbfBMLks5vfNRtgaJpZM4cESJ4>. > . >. -- . Fidel Ramirez.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/550
https://github.com/scverse/scanpy/issues/550:968,security,auth,auth,968,"That's a good reason. I will try to find some time to fix this. On Tue, Apr 9, 2019 at 7:57 PM aditisk <notifications@github.com> wrote:. > @fidelram <https://github.com/fidelram> I think that it would be helpful. > to have a way to order the list used in the correlation_matrix (and all. > other plots that don't already support this). This is very useful when we. > have the same samples under 2 conditions. As of now, the order in condition. > 1 and condition 2 is not the same because the dendrogram is reordering the. > samples in a different way each time. It is definitely useful to see how. > the samples cluster but in this specific case, I want to maintain the order. > to keep the plot easy to read. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/550#issuecomment-481364097>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1bezEF2pGPOJnvCzNDrN3VlbfBMLks5vfNRtgaJpZM4cESJ4>. > . >. -- . Fidel Ramirez.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/550
https://github.com/scverse/scanpy/issues/550:205,usability,help,helpful,205,"That's a good reason. I will try to find some time to fix this. On Tue, Apr 9, 2019 at 7:57 PM aditisk <notifications@github.com> wrote:. > @fidelram <https://github.com/fidelram> I think that it would be helpful. > to have a way to order the list used in the correlation_matrix (and all. > other plots that don't already support this). This is very useful when we. > have the same samples under 2 conditions. As of now, the order in condition. > 1 and condition 2 is not the same because the dendrogram is reordering the. > samples in a different way each time. It is definitely useful to see how. > the samples cluster but in this specific case, I want to maintain the order. > to keep the plot easy to read. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/550#issuecomment-481364097>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1bezEF2pGPOJnvCzNDrN3VlbfBMLks5vfNRtgaJpZM4cESJ4>. > . >. -- . Fidel Ramirez.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/550
https://github.com/scverse/scanpy/issues/550:322,usability,support,support,322,"That's a good reason. I will try to find some time to fix this. On Tue, Apr 9, 2019 at 7:57 PM aditisk <notifications@github.com> wrote:. > @fidelram <https://github.com/fidelram> I think that it would be helpful. > to have a way to order the list used in the correlation_matrix (and all. > other plots that don't already support this). This is very useful when we. > have the same samples under 2 conditions. As of now, the order in condition. > 1 and condition 2 is not the same because the dendrogram is reordering the. > samples in a different way each time. It is definitely useful to see how. > the samples cluster but in this specific case, I want to maintain the order. > to keep the plot easy to read. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/550#issuecomment-481364097>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AEu_1bezEF2pGPOJnvCzNDrN3VlbfBMLks5vfNRtgaJpZM4cESJ4>. > . >. -- . Fidel Ramirez.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/550
https://github.com/scverse/scanpy/issues/550:22,energy efficiency,current,currently,22,"Sorry @fidelram . I'm currently busy, but I'll get back to this problem asap. Thanks",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/550
https://github.com/scverse/scanpy/pull/551:477,energy efficiency,reduc,reduce,477,"Ah sorry, I should have told you that. All of the preprocessing functions can be migrated to only work with AnnData; there is no important setting in which you want to pass an array or a sparse matrix. That's also remniscient from the early days when I thought people might not like to use AnnData. But that's of course stupid, they wouldn't use Scanpy in that case, anyway. I'm merging this for now so that we have something working for 1.4.1, but if you want to simplify and reduce this to AnnData-only, happy to merge a PR on that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/551
https://github.com/scverse/scanpy/pull/551:464,testability,simpl,simplify,464,"Ah sorry, I should have told you that. All of the preprocessing functions can be migrated to only work with AnnData; there is no important setting in which you want to pass an array or a sparse matrix. That's also remniscient from the early days when I thought people might not like to use AnnData. But that's of course stupid, they wouldn't use Scanpy in that case, anyway. I'm merging this for now so that we have something working for 1.4.1, but if you want to simplify and reduce this to AnnData-only, happy to merge a PR on that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/551
https://github.com/scverse/scanpy/pull/551:464,usability,simpl,simplify,464,"Ah sorry, I should have told you that. All of the preprocessing functions can be migrated to only work with AnnData; there is no important setting in which you want to pass an array or a sparse matrix. That's also remniscient from the early days when I thought people might not like to use AnnData. But that's of course stupid, they wouldn't use Scanpy in that case, anyway. I'm merging this for now so that we have something working for 1.4.1, but if you want to simplify and reduce this to AnnData-only, happy to merge a PR on that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/551
https://github.com/scverse/scanpy/pull/553:77,usability,prefer,prefer,77,"We’re still waiting if we can get gitter.im/scanpy, see #542. If we can, I’d prefer to not make gitter.im/scanpyhelp a thing. Let’s reopen this once we know how the gitter community will actually be called.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/553
https://github.com/scverse/scanpy/pull/555:59,deployability,fail,fails,59,"I noticed a minor bug that if the layer is sparse the plot fails with the following traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-963-f4f784156b06> in <module>. ----> 1 import sys, codecs, os, ast;__pyfile = codecs.open('''/tmp/pySnNnI3''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/pySnNnI3''');__block = ast.parse(__code, '''/tmp/pySnNnI3''', mode='exec'); __block.body = (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.Name) else __block.body if not __block.body[0].test.id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:181,deployability,modul,module,181,"I noticed a minor bug that if the layer is sparse the plot fails with the following traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-963-f4f784156b06> in <module>. ----> 1 import sys, codecs, os, ast;__pyfile = codecs.open('''/tmp/pySnNnI3''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/pySnNnI3''');__block = ast.parse(__code, '''/tmp/pySnNnI3''', mode='exec'); __block.body = (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.Name) else __block.body if not __block.body[0].test.id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:1212,deployability,modul,module,1212,"s, os, ast;__pyfile = codecs.open('''/tmp/pySnNnI3''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/pySnNnI3''');__block = ast.parse(__code, '''/tmp/pySnNnI3''', mode='exec'); __block.body = (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.Name) else __block.body if not __block.body[0].test.id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.6/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1808 ""the Matplotlib list!)"" % (label_namer, func.__name__),. 1809 RuntimeWarning, stacklevel=2). -> 1810 return func(ax, *args, **kwargs).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:2159,deployability,stack,stacklevel,2159,"else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.6/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1808 ""the Matplotlib list!)"" % (label_namer, func.__name__),. 1809 RuntimeWarning, stacklevel=2). -> 1810 return func(ax, *args, **kwargs). 1811 . 1812 inner.__doc__ = _add_data_doc(inner.__doc__,. ~/.virtualenvs/intel_default/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4203 isinstance(c, str) or. 4204 (isinstance(c, collections.Iterable) and. -> 4205 len(c) > 0 and. 4206 isinstance(cbook.safe_first_element(c), str))):. 4207 c_array = None. ~/.virtualenvs/intel_default/lib/python3.6/site-packages/scipy/sparse/base.py in __len__(self). 294 # non-zeros is more important. For now, raise an exception! 295 def __len__(self):. --> 296 raise TypeError(""sparse matrix length is ambiguous; use getnnz()"". 297 "" or shape[0]""). 298 . TypeError: sparse matrix length is ambiguous; use getnnz() or shape[0]. ```. Is this only on my end?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:1628,integrability,compon,components,1628,".id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.6/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1808 ""the Matplotlib list!)"" % (label_namer, func.__name__),. 1809 RuntimeWarning, stacklevel=2). -> 1810 return func(ax, *args, **kwargs). 1811 . 1812 inner.__doc__ = _add_data_doc(inner.__doc__,. ~/.virtualenvs/intel_default/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4203 isinstance(c, str) or. 4204 (isinstance(c, collections.Iterable) and. -> 4205 len(c) > 0 and. 4206 isinstance(cbook.safe_first_element(c), str))):. 4207 c_array =",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:1628,interoperability,compon,components,1628,".id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.6/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1808 ""the Matplotlib list!)"" % (label_namer, func.__name__),. 1809 RuntimeWarning, stacklevel=2). -> 1810 return func(ax, *args, **kwargs). 1811 . 1812 inner.__doc__ = _add_data_doc(inner.__doc__,. ~/.virtualenvs/intel_default/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4203 isinstance(c, str) or. 4204 (isinstance(c, collections.Iterable) and. -> 4205 len(c) > 0 and. 4206 isinstance(cbook.safe_first_element(c), str))):. 4207 c_array =",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:34,modifiability,layer,layer,34,"I noticed a minor bug that if the layer is sparse the plot fails with the following traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-963-f4f784156b06> in <module>. ----> 1 import sys, codecs, os, ast;__pyfile = codecs.open('''/tmp/pySnNnI3''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/pySnNnI3''');__block = ast.parse(__code, '''/tmp/pySnNnI3''', mode='exec'); __block.body = (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.Name) else __block.body if not __block.body[0].test.id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:181,modifiability,modul,module,181,"I noticed a minor bug that if the layer is sparse the plot fails with the following traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-963-f4f784156b06> in <module>. ----> 1 import sys, codecs, os, ast;__pyfile = codecs.open('''/tmp/pySnNnI3''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/pySnNnI3''');__block = ast.parse(__code, '''/tmp/pySnNnI3''', mode='exec'); __block.body = (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.Name) else __block.body if not __block.body[0].test.id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:1212,modifiability,modul,module,1212,"s, os, ast;__pyfile = codecs.open('''/tmp/pySnNnI3''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/pySnNnI3''');__block = ast.parse(__code, '''/tmp/pySnNnI3''', mode='exec'); __block.body = (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.Name) else __block.body if not __block.body[0].test.id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.6/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1808 ""the Matplotlib list!)"" % (label_namer, func.__name__),. 1809 RuntimeWarning, stacklevel=2). -> 1810 return func(ax, *args, **kwargs).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:1628,modifiability,compon,components,1628,".id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.6/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1808 ""the Matplotlib list!)"" % (label_namer, func.__name__),. 1809 RuntimeWarning, stacklevel=2). -> 1810 return func(ax, *args, **kwargs). 1811 . 1812 inner.__doc__ = _add_data_doc(inner.__doc__,. ~/.virtualenvs/intel_default/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4203 isinstance(c, str) or. 4204 (isinstance(c, collections.Iterable) and. -> 4205 len(c) > 0 and. 4206 isinstance(cbook.safe_first_element(c), str))):. 4207 c_array =",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:1640,modifiability,layer,layer,1640,"ue' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.6/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1808 ""the Matplotlib list!)"" % (label_namer, func.__name__),. 1809 RuntimeWarning, stacklevel=2). -> 1810 return func(ax, *args, **kwargs). 1811 . 1812 inner.__doc__ = _add_data_doc(inner.__doc__,. ~/.virtualenvs/intel_default/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4203 isinstance(c, str) or. 4204 (isinstance(c, collections.Iterable) and. -> 4205 len(c) > 0 and. 4206 isinstance(cbook.safe_first_element(c), str))):. 4207 c_array = None. ~/.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:2007,modifiability,pac,packages,2007,"() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.6/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1808 ""the Matplotlib list!)"" % (label_namer, func.__name__),. 1809 RuntimeWarning, stacklevel=2). -> 1810 return func(ax, *args, **kwargs). 1811 . 1812 inner.__doc__ = _add_data_doc(inner.__doc__,. ~/.virtualenvs/intel_default/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4203 isinstance(c, str) or. 4204 (isinstance(c, collections.Iterable) and. -> 4205 len(c) > 0 and. 4206 isinstance(cbook.safe_first_element(c), str))):. 4207 c_array = None. ~/.virtualenvs/intel_default/lib/python3.6/site-packages/scipy/sparse/base.py in __len__(self). 294 # non-zeros is more important. For now, raise an exception! 295 def __len__(self):. --> 296 raise TypeError(""sparse matrix length is ambiguous; use getnnz()"". 297 "" or shape[0]""). 298 . TypeError: sparse matrix length is ambiguous; use getnnz() or shape[0]. ```. Is this ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:2322,modifiability,pac,packages,2322,"else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.6/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1808 ""the Matplotlib list!)"" % (label_namer, func.__name__),. 1809 RuntimeWarning, stacklevel=2). -> 1810 return func(ax, *args, **kwargs). 1811 . 1812 inner.__doc__ = _add_data_doc(inner.__doc__,. ~/.virtualenvs/intel_default/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4203 isinstance(c, str) or. 4204 (isinstance(c, collections.Iterable) and. -> 4205 len(c) > 0 and. 4206 isinstance(cbook.safe_first_element(c), str))):. 4207 c_array = None. ~/.virtualenvs/intel_default/lib/python3.6/site-packages/scipy/sparse/base.py in __len__(self). 294 # non-zeros is more important. For now, raise an exception! 295 def __len__(self):. --> 296 raise TypeError(""sparse matrix length is ambiguous; use getnnz()"". 297 "" or shape[0]""). 298 . TypeError: sparse matrix length is ambiguous; use getnnz() or shape[0]. ```. Is this only on my end?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:2688,modifiability,pac,packages,2688,"else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.6/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1808 ""the Matplotlib list!)"" % (label_namer, func.__name__),. 1809 RuntimeWarning, stacklevel=2). -> 1810 return func(ax, *args, **kwargs). 1811 . 1812 inner.__doc__ = _add_data_doc(inner.__doc__,. ~/.virtualenvs/intel_default/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4203 isinstance(c, str) or. 4204 (isinstance(c, collections.Iterable) and. -> 4205 len(c) > 0 and. 4206 isinstance(cbook.safe_first_element(c), str))):. 4207 c_array = None. ~/.virtualenvs/intel_default/lib/python3.6/site-packages/scipy/sparse/base.py in __len__(self). 294 # non-zeros is more important. For now, raise an exception! 295 def __len__(self):. --> 296 raise TypeError(""sparse matrix length is ambiguous; use getnnz()"". 297 "" or shape[0]""). 298 . TypeError: sparse matrix length is ambiguous; use getnnz() or shape[0]. ```. Is this only on my end?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:59,reliability,fail,fails,59,"I noticed a minor bug that if the layer is sparse the plot fails with the following traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-963-f4f784156b06> in <module>. ----> 1 import sys, codecs, os, ast;__pyfile = codecs.open('''/tmp/pySnNnI3''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/pySnNnI3''');__block = ast.parse(__code, '''/tmp/pySnNnI3''', mode='exec'); __block.body = (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.Name) else __block.body if not __block.body[0].test.id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:153,safety,input,input-,153,"I noticed a minor bug that if the layer is sparse the plot fails with the following traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-963-f4f784156b06> in <module>. ----> 1 import sys, codecs, os, ast;__pyfile = codecs.open('''/tmp/pySnNnI3''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/pySnNnI3''');__block = ast.parse(__code, '''/tmp/pySnNnI3''', mode='exec'); __block.body = (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.Name) else __block.body if not __block.body[0].test.id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:181,safety,modul,module,181,"I noticed a minor bug that if the layer is sparse the plot fails with the following traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-963-f4f784156b06> in <module>. ----> 1 import sys, codecs, os, ast;__pyfile = codecs.open('''/tmp/pySnNnI3''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/pySnNnI3''');__block = ast.parse(__code, '''/tmp/pySnNnI3''', mode='exec'); __block.body = (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.Name) else __block.body if not __block.body[0].test.id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:572,safety,test,test,572,"I noticed a minor bug that if the layer is sparse the plot fails with the following traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-963-f4f784156b06> in <module>. ----> 1 import sys, codecs, os, ast;__pyfile = codecs.open('''/tmp/pySnNnI3''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/pySnNnI3''');__block = ast.parse(__code, '''/tmp/pySnNnI3''', mode='exec'); __block.body = (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.Name) else __block.body if not __block.body[0].test.id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:629,safety,test,test,629,"I noticed a minor bug that if the layer is sparse the plot fails with the following traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-963-f4f784156b06> in <module>. ----> 1 import sys, codecs, os, ast;__pyfile = codecs.open('''/tmp/pySnNnI3''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/pySnNnI3''');__block = ast.parse(__code, '''/tmp/pySnNnI3''', mode='exec'); __block.body = (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.Name) else __block.body if not __block.body[0].test.id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:815,safety,test,test,815,"I noticed a minor bug that if the layer is sparse the plot fails with the following traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-963-f4f784156b06> in <module>. ----> 1 import sys, codecs, os, ast;__pyfile = codecs.open('''/tmp/pySnNnI3''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/pySnNnI3''');__block = ast.parse(__code, '''/tmp/pySnNnI3''', mode='exec'); __block.body = (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.Name) else __block.body if not __block.body[0].test.id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:880,safety,test,test,880,"I noticed a minor bug that if the layer is sparse the plot fails with the following traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-963-f4f784156b06> in <module>. ----> 1 import sys, codecs, os, ast;__pyfile = codecs.open('''/tmp/pySnNnI3''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/pySnNnI3''');__block = ast.parse(__code, '''/tmp/pySnNnI3''', mode='exec'); __block.body = (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.Name) else __block.body if not __block.body[0].test.id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:1212,safety,modul,module,1212,"s, os, ast;__pyfile = codecs.open('''/tmp/pySnNnI3''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/pySnNnI3''');__block = ast.parse(__code, '''/tmp/pySnNnI3''', mode='exec'); __block.body = (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.Name) else __block.body if not __block.body[0].test.id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.6/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1808 ""the Matplotlib list!)"" % (label_namer, func.__name__),. 1809 RuntimeWarning, stacklevel=2). -> 1810 return func(ax, *args, **kwargs).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:2789,safety,except,exception,2789,"else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.6/site-packages/matplotlib/__init__.py in inner(ax, data, *args, **kwargs). 1808 ""the Matplotlib list!)"" % (label_namer, func.__name__),. 1809 RuntimeWarning, stacklevel=2). -> 1810 return func(ax, *args, **kwargs). 1811 . 1812 inner.__doc__ = _add_data_doc(inner.__doc__,. ~/.virtualenvs/intel_default/lib/python3.6/site-packages/matplotlib/axes/_axes.py in scatter(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs). 4203 isinstance(c, str) or. 4204 (isinstance(c, collections.Iterable) and. -> 4205 len(c) > 0 and. 4206 isinstance(cbook.safe_first_element(c), str))):. 4207 c_array = None. ~/.virtualenvs/intel_default/lib/python3.6/site-packages/scipy/sparse/base.py in __len__(self). 294 # non-zeros is more important. For now, raise an exception! 295 def __len__(self):. --> 296 raise TypeError(""sparse matrix length is ambiguous; use getnnz()"". 297 "" or shape[0]""). 298 . TypeError: sparse matrix length is ambiguous; use getnnz() or shape[0]. ```. Is this only on my end?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:84,testability,trace,traceback,84,"I noticed a minor bug that if the layer is sparse the plot fails with the following traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-963-f4f784156b06> in <module>. ----> 1 import sys, codecs, os, ast;__pyfile = codecs.open('''/tmp/pySnNnI3''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/pySnNnI3''');__block = ast.parse(__code, '''/tmp/pySnNnI3''', mode='exec'); __block.body = (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.Name) else __block.body if not __block.body[0].test.id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:572,testability,test,test,572,"I noticed a minor bug that if the layer is sparse the plot fails with the following traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-963-f4f784156b06> in <module>. ----> 1 import sys, codecs, os, ast;__pyfile = codecs.open('''/tmp/pySnNnI3''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/pySnNnI3''');__block = ast.parse(__code, '''/tmp/pySnNnI3''', mode='exec'); __block.body = (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.Name) else __block.body if not __block.body[0].test.id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:629,testability,test,test,629,"I noticed a minor bug that if the layer is sparse the plot fails with the following traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-963-f4f784156b06> in <module>. ----> 1 import sys, codecs, os, ast;__pyfile = codecs.open('''/tmp/pySnNnI3''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/pySnNnI3''');__block = ast.parse(__code, '''/tmp/pySnNnI3''', mode='exec'); __block.body = (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.Name) else __block.body if not __block.body[0].test.id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:815,testability,test,test,815,"I noticed a minor bug that if the layer is sparse the plot fails with the following traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-963-f4f784156b06> in <module>. ----> 1 import sys, codecs, os, ast;__pyfile = codecs.open('''/tmp/pySnNnI3''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/pySnNnI3''');__block = ast.parse(__code, '''/tmp/pySnNnI3''', mode='exec'); __block.body = (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.Name) else __block.body if not __block.body[0].test.id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:880,testability,test,test,880,"I noticed a minor bug that if the layer is sparse the plot fails with the following traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-963-f4f784156b06> in <module>. ----> 1 import sys, codecs, os, ast;__pyfile = codecs.open('''/tmp/pySnNnI3''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/pySnNnI3''');__block = ast.parse(__code, '''/tmp/pySnNnI3''', mode='exec'); __block.body = (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.Name) else __block.body if not __block.body[0].test.id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:153,usability,input,input-,153,"I noticed a minor bug that if the layer is sparse the plot fails with the following traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-963-f4f784156b06> in <module>. ----> 1 import sys, codecs, os, ast;__pyfile = codecs.open('''/tmp/pySnNnI3''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/pySnNnI3''');__block = ast.parse(__code, '''/tmp/pySnNnI3''', mode='exec'); __block.body = (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.Name) else __block.body if not __block.body[0].test.id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:346,usability,close,close,346,"I noticed a minor bug that if the layer is sparse the plot fails with the following traceback. ```. TypeErrorTraceback (most recent call last). <ipython-input-963-f4f784156b06> in <module>. ----> 1 import sys, codecs, os, ast;__pyfile = codecs.open('''/tmp/pySnNnI3''', encoding='''utf-8''');__code = __pyfile.read().encode('''utf-8''');__pyfile.close();os.remove('''/tmp/pySnNnI3''');__block = ast.parse(__code, '''/tmp/pySnNnI3''', mode='exec'); __block.body = (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.Name) else __block.body if not __block.body[0].test.id == 'True' else __block.body[0].body) if sys.version_info[0] < 3 else (__block.body if not isinstance(__block.body[0], ast.If) else __block.body if not isinstance(__block.body[0].test, ast.NameConstant) else __block.body if not __block.body[0].test.value is True else __block.body[0].body);__last = __block.body[-1];__isexpr = isinstance(__last,ast.Expr);_ = __block.body.pop() if __isexpr else None;exec(compile(__block, '''/tmp/pySnNnI3''', mode='exec'));eval(compile(ast.Expression(__last.value), '''/tmp/pySnNnI3''', mode='eval')) if __isexpr else None. /tmp/pySnNnI3 in <module>. ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in umap(adata, **kwargs). 285 If `show==False` a `matplotlib.Axis` or a list of it. 286 """""". --> 287 return plot_scatter(adata, 'umap', **kwargs). 288 . 289 . ~/projects/scanpy/scanpy/plotting/_tools/scatterplots.py in plot_scatter(adata, basis, color, gene_symbols, use_raw, sort_order, edges, edges_width, edges_color, arrows, arrows_kwds, groups, components, layer, projection, color_map, palette, size, frameon, legend_fontsize, legend_fontweight, legend_loc, ncols, hspace, wspace, title, show, save, ax, return_fig, **kwargs). 202 _data_points[:, 0], _data_points[:, 1],. 203 marker=""."", c=color_vector, rasterized=settings._vector_friendly,. --> 204 **kwargs,. 205 ). 206 . ~/.virtualenvs/intel_default/lib/python3.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/555:6,availability,replic,replicate,6,I can replicate the problem. I will look into it,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/555
https://github.com/scverse/scanpy/pull/557:13,availability,redund,redundant,13,That’s super redundant now. Please extract all that text from `doc_scatter_bulk` into another variable and import and use that one instead.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/557
https://github.com/scverse/scanpy/pull/557:13,deployability,redundan,redundant,13,That’s super redundant now. Please extract all that text from `doc_scatter_bulk` into another variable and import and use that one instead.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/557
https://github.com/scverse/scanpy/pull/557:94,modifiability,variab,variable,94,That’s super redundant now. Please extract all that text from `doc_scatter_bulk` into another variable and import and use that one instead.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/557
https://github.com/scverse/scanpy/pull/557:13,reliability,redundan,redundant,13,That’s super redundant now. Please extract all that text from `doc_scatter_bulk` into another variable and import and use that one instead.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/557
https://github.com/scverse/scanpy/pull/557:13,safety,redund,redundant,13,That’s super redundant now. Please extract all that text from `doc_scatter_bulk` into another variable and import and use that one instead.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/557
https://github.com/scverse/scanpy/pull/557:93,modifiability,variab,variable,93,"In #458 @fidelram suggested that this would be the way to go. If I put the text into another variable, this variable will only be used once. Does this still make sense? Anyways, I think this is just temporary until `pl.scatter` is in a better shape if I follow @falexwolf correctly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/557
https://github.com/scverse/scanpy/pull/557:108,modifiability,variab,variable,108,"In #458 @fidelram suggested that this would be the way to go. If I put the text into another variable, this variable will only be used once. Does this still make sense? Anyways, I think this is just temporary until `pl.scatter` is in a better shape if I follow @falexwolf correctly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/557
https://github.com/scverse/scanpy/pull/557:141,reliability,Doe,Does,141,"In #458 @fidelram suggested that this would be the way to go. If I put the text into another variable, this variable will only be used once. Does this still make sense? Anyways, I think this is just temporary until `pl.scatter` is in a better shape if I follow @falexwolf correctly.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/557
https://github.com/scverse/scanpy/pull/557:55,modifiability,variab,variable,55,"Deduplication always makes sense. I often use speaking variable names instead of comments to clarify what I’m doing. Here the 6 reasons why I’m convinced of the way I suggested:. 1\) If I look at your change as it is, I have no idea what parameters are missing compared to `doc_scatter_bulk`. If you used variables, we could see it at a glance. 2) You could add a comment explaining that this one is just temporary (Hard to do in-line in a docstring). If one makes changes to the parameters, 3) they only have to make them once and 4) can’t forget to make them twice. 5) Also the diff becomes much smaller and 6) git will be able to track doc changes that are made in the mean time. So do it please.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/557
https://github.com/scverse/scanpy/pull/557:238,modifiability,paramet,parameters,238,"Deduplication always makes sense. I often use speaking variable names instead of comments to clarify what I’m doing. Here the 6 reasons why I’m convinced of the way I suggested:. 1\) If I look at your change as it is, I have no idea what parameters are missing compared to `doc_scatter_bulk`. If you used variables, we could see it at a glance. 2) You could add a comment explaining that this one is just temporary (Hard to do in-line in a docstring). If one makes changes to the parameters, 3) they only have to make them once and 4) can’t forget to make them twice. 5) Also the diff becomes much smaller and 6) git will be able to track doc changes that are made in the mean time. So do it please.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/557
https://github.com/scverse/scanpy/pull/557:305,modifiability,variab,variables,305,"Deduplication always makes sense. I often use speaking variable names instead of comments to clarify what I’m doing. Here the 6 reasons why I’m convinced of the way I suggested:. 1\) If I look at your change as it is, I have no idea what parameters are missing compared to `doc_scatter_bulk`. If you used variables, we could see it at a glance. 2) You could add a comment explaining that this one is just temporary (Hard to do in-line in a docstring). If one makes changes to the parameters, 3) they only have to make them once and 4) can’t forget to make them twice. 5) Also the diff becomes much smaller and 6) git will be able to track doc changes that are made in the mean time. So do it please.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/557
https://github.com/scverse/scanpy/pull/557:480,modifiability,paramet,parameters,480,"Deduplication always makes sense. I often use speaking variable names instead of comments to clarify what I’m doing. Here the 6 reasons why I’m convinced of the way I suggested:. 1\) If I look at your change as it is, I have no idea what parameters are missing compared to `doc_scatter_bulk`. If you used variables, we could see it at a glance. 2) You could add a comment explaining that this one is just temporary (Hard to do in-line in a docstring). If one makes changes to the parameters, 3) they only have to make them once and 4) can’t forget to make them twice. 5) Also the diff becomes much smaller and 6) git will be able to track doc changes that are made in the mean time. So do it please.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/557
https://github.com/scverse/scanpy/pull/557:677,performance,time,time,677,"Deduplication always makes sense. I often use speaking variable names instead of comments to clarify what I’m doing. Here the 6 reasons why I’m convinced of the way I suggested:. 1\) If I look at your change as it is, I have no idea what parameters are missing compared to `doc_scatter_bulk`. If you used variables, we could see it at a glance. 2) You could add a comment explaining that this one is just temporary (Hard to do in-line in a docstring). If one makes changes to the parameters, 3) they only have to make them once and 4) can’t forget to make them twice. 5) Also the diff becomes much smaller and 6) git will be able to track doc changes that are made in the mean time. So do it please.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/557
https://github.com/scverse/scanpy/pull/557:61,modifiability,paramet,parameter,61,There’s still duplication. There shouldn’t be any duplicated parameter docs. I’d expect something like this:. The diff will be 8 changed lines or so as opposed to dozens of added duplicate lines. ```py. _doc_scatter_common = '''. sort_order. ... '''. _doc_scatter_panels = '''. ncol. ... '''. _doc_scatter_meta = '''. title. ... '''. doc_scatter_temp = _doc_scatter_common + _doc_scatter_meta. doc_scatter_bulk = _doc_scatter_common + _doc_scatter_panel + _doc_scatter_meta. ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/557
https://github.com/scverse/scanpy/pull/557:30,usability,help,help,30,"@flying-sheep Thanks for your help. Like this, maybe?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/557
https://github.com/scverse/scanpy/issues/558:11,deployability,instal,install,11,"The scanpy install directory is super wrong, as it’s not writable for many people. There’s exactly one correct way of determining a global place for cache* files like this: [`appdirs.user_cache_dir(...)`](https://pypi.org/project/appdirs/). Alex and me talked in the past and decided for a visible directory in the working directory. I’d be up for changing it to `user_cache_dir(…)` for the data. *the data are cache files since reexccuting their function after deleting the files will redownload them without loss of information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:149,performance,cach,cache,149,"The scanpy install directory is super wrong, as it’s not writable for many people. There’s exactly one correct way of determining a global place for cache* files like this: [`appdirs.user_cache_dir(...)`](https://pypi.org/project/appdirs/). Alex and me talked in the past and decided for a visible directory in the working directory. I’d be up for changing it to `user_cache_dir(…)` for the data. *the data are cache files since reexccuting their function after deleting the files will redownload them without loss of information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:411,performance,cach,cache,411,"The scanpy install directory is super wrong, as it’s not writable for many people. There’s exactly one correct way of determining a global place for cache* files like this: [`appdirs.user_cache_dir(...)`](https://pypi.org/project/appdirs/). Alex and me talked in the past and decided for a visible directory in the working directory. I’d be up for changing it to `user_cache_dir(…)` for the data. *the data are cache files since reexccuting their function after deleting the files will redownload them without loss of information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:510,security,loss,loss,510,"The scanpy install directory is super wrong, as it’s not writable for many people. There’s exactly one correct way of determining a global place for cache* files like this: [`appdirs.user_cache_dir(...)`](https://pypi.org/project/appdirs/). Alex and me talked in the past and decided for a visible directory in the working directory. I’d be up for changing it to `user_cache_dir(…)` for the data. *the data are cache files since reexccuting their function after deleting the files will redownload them without loss of information.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:65,availability,down,downloader,65,"Hi Isaac, I have a related question: does your expression atlas. downloader also store the coordinate and all the meta data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:91,interoperability,coordinat,coordinate,91,"Hi Isaac, I have a related question: does your expression atlas. downloader also store the coordinate and all the meta data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:37,reliability,doe,does,37,"Hi Isaac, I have a related question: does your expression atlas. downloader also store the coordinate and all the meta data?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:543,availability,cluster,clustering,543,"@flying-sheep That does look useful, though I definitely see a lot of toolkits using something like `~/.{toolkitname}` on my mac. Personally, I'd look under my home directory first. I think if things are going to move, there should be a sensible default, but the location should be user configurable (probably through an environment variable). For example, the main hpc I'm on only gives me about 1gb of space where `appdirs` would put these files. @maximilianh Currently I don't get coordinates along with some other computed values like SC3 clustering. I also believe it's only a subset of the metadata. I think there's more through the array express api, but that was more of a pain to navigate. Was there anything in particular you wanted to see included?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:543,deployability,cluster,clustering,543,"@flying-sheep That does look useful, though I definitely see a lot of toolkits using something like `~/.{toolkitname}` on my mac. Personally, I'd look under my home directory first. I think if things are going to move, there should be a sensible default, but the location should be user configurable (probably through an environment variable). For example, the main hpc I'm on only gives me about 1gb of space where `appdirs` would put these files. @maximilianh Currently I don't get coordinates along with some other computed values like SC3 clustering. I also believe it's only a subset of the metadata. I think there's more through the array express api, but that was more of a pain to navigate. Was there anything in particular you wanted to see included?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:653,deployability,api,api,653,"@flying-sheep That does look useful, though I definitely see a lot of toolkits using something like `~/.{toolkitname}` on my mac. Personally, I'd look under my home directory first. I think if things are going to move, there should be a sensible default, but the location should be user configurable (probably through an environment variable). For example, the main hpc I'm on only gives me about 1gb of space where `appdirs` would put these files. @maximilianh Currently I don't get coordinates along with some other computed values like SC3 clustering. I also believe it's only a subset of the metadata. I think there's more through the array express api, but that was more of a pain to navigate. Was there anything in particular you wanted to see included?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:462,energy efficiency,Current,Currently,462,"@flying-sheep That does look useful, though I definitely see a lot of toolkits using something like `~/.{toolkitname}` on my mac. Personally, I'd look under my home directory first. I think if things are going to move, there should be a sensible default, but the location should be user configurable (probably through an environment variable). For example, the main hpc I'm on only gives me about 1gb of space where `appdirs` would put these files. @maximilianh Currently I don't get coordinates along with some other computed values like SC3 clustering. I also believe it's only a subset of the metadata. I think there's more through the array express api, but that was more of a pain to navigate. Was there anything in particular you wanted to see included?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:287,integrability,configur,configurable,287,"@flying-sheep That does look useful, though I definitely see a lot of toolkits using something like `~/.{toolkitname}` on my mac. Personally, I'd look under my home directory first. I think if things are going to move, there should be a sensible default, but the location should be user configurable (probably through an environment variable). For example, the main hpc I'm on only gives me about 1gb of space where `appdirs` would put these files. @maximilianh Currently I don't get coordinates along with some other computed values like SC3 clustering. I also believe it's only a subset of the metadata. I think there's more through the array express api, but that was more of a pain to navigate. Was there anything in particular you wanted to see included?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:582,integrability,sub,subset,582,"@flying-sheep That does look useful, though I definitely see a lot of toolkits using something like `~/.{toolkitname}` on my mac. Personally, I'd look under my home directory first. I think if things are going to move, there should be a sensible default, but the location should be user configurable (probably through an environment variable). For example, the main hpc I'm on only gives me about 1gb of space where `appdirs` would put these files. @maximilianh Currently I don't get coordinates along with some other computed values like SC3 clustering. I also believe it's only a subset of the metadata. I think there's more through the array express api, but that was more of a pain to navigate. Was there anything in particular you wanted to see included?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:653,integrability,api,api,653,"@flying-sheep That does look useful, though I definitely see a lot of toolkits using something like `~/.{toolkitname}` on my mac. Personally, I'd look under my home directory first. I think if things are going to move, there should be a sensible default, but the location should be user configurable (probably through an environment variable). For example, the main hpc I'm on only gives me about 1gb of space where `appdirs` would put these files. @maximilianh Currently I don't get coordinates along with some other computed values like SC3 clustering. I also believe it's only a subset of the metadata. I think there's more through the array express api, but that was more of a pain to navigate. Was there anything in particular you wanted to see included?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:484,interoperability,coordinat,coordinates,484,"@flying-sheep That does look useful, though I definitely see a lot of toolkits using something like `~/.{toolkitname}` on my mac. Personally, I'd look under my home directory first. I think if things are going to move, there should be a sensible default, but the location should be user configurable (probably through an environment variable). For example, the main hpc I'm on only gives me about 1gb of space where `appdirs` would put these files. @maximilianh Currently I don't get coordinates along with some other computed values like SC3 clustering. I also believe it's only a subset of the metadata. I think there's more through the array express api, but that was more of a pain to navigate. Was there anything in particular you wanted to see included?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:653,interoperability,api,api,653,"@flying-sheep That does look useful, though I definitely see a lot of toolkits using something like `~/.{toolkitname}` on my mac. Personally, I'd look under my home directory first. I think if things are going to move, there should be a sensible default, but the location should be user configurable (probably through an environment variable). For example, the main hpc I'm on only gives me about 1gb of space where `appdirs` would put these files. @maximilianh Currently I don't get coordinates along with some other computed values like SC3 clustering. I also believe it's only a subset of the metadata. I think there's more through the array express api, but that was more of a pain to navigate. Was there anything in particular you wanted to see included?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:287,modifiability,configur,configurable,287,"@flying-sheep That does look useful, though I definitely see a lot of toolkits using something like `~/.{toolkitname}` on my mac. Personally, I'd look under my home directory first. I think if things are going to move, there should be a sensible default, but the location should be user configurable (probably through an environment variable). For example, the main hpc I'm on only gives me about 1gb of space where `appdirs` would put these files. @maximilianh Currently I don't get coordinates along with some other computed values like SC3 clustering. I also believe it's only a subset of the metadata. I think there's more through the array express api, but that was more of a pain to navigate. Was there anything in particular you wanted to see included?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:333,modifiability,variab,variable,333,"@flying-sheep That does look useful, though I definitely see a lot of toolkits using something like `~/.{toolkitname}` on my mac. Personally, I'd look under my home directory first. I think if things are going to move, there should be a sensible default, but the location should be user configurable (probably through an environment variable). For example, the main hpc I'm on only gives me about 1gb of space where `appdirs` would put these files. @maximilianh Currently I don't get coordinates along with some other computed values like SC3 clustering. I also believe it's only a subset of the metadata. I think there's more through the array express api, but that was more of a pain to navigate. Was there anything in particular you wanted to see included?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:19,reliability,doe,does,19,"@flying-sheep That does look useful, though I definitely see a lot of toolkits using something like `~/.{toolkitname}` on my mac. Personally, I'd look under my home directory first. I think if things are going to move, there should be a sensible default, but the location should be user configurable (probably through an environment variable). For example, the main hpc I'm on only gives me about 1gb of space where `appdirs` would put these files. @maximilianh Currently I don't get coordinates along with some other computed values like SC3 clustering. I also believe it's only a subset of the metadata. I think there's more through the array express api, but that was more of a pain to navigate. Was there anything in particular you wanted to see included?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:287,security,configur,configurable,287,"@flying-sheep That does look useful, though I definitely see a lot of toolkits using something like `~/.{toolkitname}` on my mac. Personally, I'd look under my home directory first. I think if things are going to move, there should be a sensible default, but the location should be user configurable (probably through an environment variable). For example, the main hpc I'm on only gives me about 1gb of space where `appdirs` would put these files. @maximilianh Currently I don't get coordinates along with some other computed values like SC3 clustering. I also believe it's only a subset of the metadata. I think there's more through the array express api, but that was more of a pain to navigate. Was there anything in particular you wanted to see included?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:70,usability,tool,toolkits,70,"@flying-sheep That does look useful, though I definitely see a lot of toolkits using something like `~/.{toolkitname}` on my mac. Personally, I'd look under my home directory first. I think if things are going to move, there should be a sensible default, but the location should be user configurable (probably through an environment variable). For example, the main hpc I'm on only gives me about 1gb of space where `appdirs` would put these files. @maximilianh Currently I don't get coordinates along with some other computed values like SC3 clustering. I also believe it's only a subset of the metadata. I think there's more through the array express api, but that was more of a pain to navigate. Was there anything in particular you wanted to see included?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:105,usability,tool,toolkitname,105,"@flying-sheep That does look useful, though I definitely see a lot of toolkits using something like `~/.{toolkitname}` on my mac. Personally, I'd look under my home directory first. I think if things are going to move, there should be a sensible default, but the location should be user configurable (probably through an environment variable). For example, the main hpc I'm on only gives me about 1gb of space where `appdirs` would put these files. @maximilianh Currently I don't get coordinates along with some other computed values like SC3 clustering. I also believe it's only a subset of the metadata. I think there's more through the array express api, but that was more of a pain to navigate. Was there anything in particular you wanted to see included?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:130,usability,Person,Personally,130,"@flying-sheep That does look useful, though I definitely see a lot of toolkits using something like `~/.{toolkitname}` on my mac. Personally, I'd look under my home directory first. I think if things are going to move, there should be a sensible default, but the location should be user configurable (probably through an environment variable). For example, the main hpc I'm on only gives me about 1gb of space where `appdirs` would put these files. @maximilianh Currently I don't get coordinates along with some other computed values like SC3 clustering. I also believe it's only a subset of the metadata. I think there's more through the array express api, but that was more of a pain to navigate. Was there anything in particular you wanted to see included?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:282,usability,user,user,282,"@flying-sheep That does look useful, though I definitely see a lot of toolkits using something like `~/.{toolkitname}` on my mac. Personally, I'd look under my home directory first. I think if things are going to move, there should be a sensible default, but the location should be user configurable (probably through an environment variable). For example, the main hpc I'm on only gives me about 1gb of space where `appdirs` would put these files. @maximilianh Currently I don't get coordinates along with some other computed values like SC3 clustering. I also believe it's only a subset of the metadata. I think there's more through the array express api, but that was more of a pain to navigate. Was there anything in particular you wanted to see included?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:689,usability,navigat,navigate,689,"@flying-sheep That does look useful, though I definitely see a lot of toolkits using something like `~/.{toolkitname}` on my mac. Personally, I'd look under my home directory first. I think if things are going to move, there should be a sensible default, but the location should be user configurable (probably through an environment variable). For example, the main hpc I'm on only gives me about 1gb of space where `appdirs` would put these files. @maximilianh Currently I don't get coordinates along with some other computed values like SC3 clustering. I also believe it's only a subset of the metadata. I think there's more through the array express api, but that was more of a pain to navigate. Was there anything in particular you wanted to see included?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:200,availability,down,downloadable,200,"Well, I know nothing, maybe you already have everything, but I could. look at an example? The advantage of the expression atlas is that they. have really good meta data. That's provided through their downloadable. files, as far as I remember. So if you got everything that is in their. downloadable meta data files, then you certainly have everything of. interest.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:286,availability,down,downloadable,286,"Well, I know nothing, maybe you already have everything, but I could. look at an example? The advantage of the expression atlas is that they. have really good meta data. That's provided through their downloadable. files, as far as I remember. So if you got everything that is in their. downloadable meta data files, then you certainly have everything of. interest.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:233,safety,reme,remember,233,"Well, I know nothing, maybe you already have everything, but I could. look at an example? The advantage of the expression atlas is that they. have really good meta data. That's provided through their downloadable. files, as far as I remember. So if you got everything that is in their. downloadable meta data files, then you certainly have everything of. interest.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:266,interoperability,standard,standards,266,"> though I definitely see a lot of toolkits using something like ~/.{toolkitname} on my mac. . There’s two possible reasons: 1.: We’re talking about something from the 80’s like SSH or BASH. They earned their right to things their way because they’re older than the standards they’re not following. Or 2.: Whoever designed this didn’t do their research and just hacked in first thing that came to mind. This is not an excuse. MacOS knows about `~/Library/Caches` and to clean it out when disk space gets scarce. The same applies to Linux’ and Windows’ respective canonical cache directories. Each OS has that place specifically to place things like those datasets there. > For example, the main hpc I'm on only gives me about 1gb of space where appdirs would put these files. Ouch. Seems like it’s time to file a bug report.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:615,interoperability,specif,specifically,615,"> though I definitely see a lot of toolkits using something like ~/.{toolkitname} on my mac. . There’s two possible reasons: 1.: We’re talking about something from the 80’s like SSH or BASH. They earned their right to things their way because they’re older than the standards they’re not following. Or 2.: Whoever designed this didn’t do their research and just hacked in first thing that came to mind. This is not an excuse. MacOS knows about `~/Library/Caches` and to clean it out when disk space gets scarce. The same applies to Linux’ and Windows’ respective canonical cache directories. Each OS has that place specifically to place things like those datasets there. > For example, the main hpc I'm on only gives me about 1gb of space where appdirs would put these files. Ouch. Seems like it’s time to file a bug report.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:455,performance,Cach,Caches,455,"> though I definitely see a lot of toolkits using something like ~/.{toolkitname} on my mac. . There’s two possible reasons: 1.: We’re talking about something from the 80’s like SSH or BASH. They earned their right to things their way because they’re older than the standards they’re not following. Or 2.: Whoever designed this didn’t do their research and just hacked in first thing that came to mind. This is not an excuse. MacOS knows about `~/Library/Caches` and to clean it out when disk space gets scarce. The same applies to Linux’ and Windows’ respective canonical cache directories. Each OS has that place specifically to place things like those datasets there. > For example, the main hpc I'm on only gives me about 1gb of space where appdirs would put these files. Ouch. Seems like it’s time to file a bug report.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:488,performance,disk,disk,488,"> though I definitely see a lot of toolkits using something like ~/.{toolkitname} on my mac. . There’s two possible reasons: 1.: We’re talking about something from the 80’s like SSH or BASH. They earned their right to things their way because they’re older than the standards they’re not following. Or 2.: Whoever designed this didn’t do their research and just hacked in first thing that came to mind. This is not an excuse. MacOS knows about `~/Library/Caches` and to clean it out when disk space gets scarce. The same applies to Linux’ and Windows’ respective canonical cache directories. Each OS has that place specifically to place things like those datasets there. > For example, the main hpc I'm on only gives me about 1gb of space where appdirs would put these files. Ouch. Seems like it’s time to file a bug report.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:573,performance,cach,cache,573,"> though I definitely see a lot of toolkits using something like ~/.{toolkitname} on my mac. . There’s two possible reasons: 1.: We’re talking about something from the 80’s like SSH or BASH. They earned their right to things their way because they’re older than the standards they’re not following. Or 2.: Whoever designed this didn’t do their research and just hacked in first thing that came to mind. This is not an excuse. MacOS knows about `~/Library/Caches` and to clean it out when disk space gets scarce. The same applies to Linux’ and Windows’ respective canonical cache directories. Each OS has that place specifically to place things like those datasets there. > For example, the main hpc I'm on only gives me about 1gb of space where appdirs would put these files. Ouch. Seems like it’s time to file a bug report.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:798,performance,time,time,798,"> though I definitely see a lot of toolkits using something like ~/.{toolkitname} on my mac. . There’s two possible reasons: 1.: We’re talking about something from the 80’s like SSH or BASH. They earned their right to things their way because they’re older than the standards they’re not following. Or 2.: Whoever designed this didn’t do their research and just hacked in first thing that came to mind. This is not an excuse. MacOS knows about `~/Library/Caches` and to clean it out when disk space gets scarce. The same applies to Linux’ and Windows’ respective canonical cache directories. Each OS has that place specifically to place things like those datasets there. > For example, the main hpc I'm on only gives me about 1gb of space where appdirs would put these files. Ouch. Seems like it’s time to file a bug report.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:178,security,SSH,SSH,178,"> though I definitely see a lot of toolkits using something like ~/.{toolkitname} on my mac. . There’s two possible reasons: 1.: We’re talking about something from the 80’s like SSH or BASH. They earned their right to things their way because they’re older than the standards they’re not following. Or 2.: Whoever designed this didn’t do their research and just hacked in first thing that came to mind. This is not an excuse. MacOS knows about `~/Library/Caches` and to clean it out when disk space gets scarce. The same applies to Linux’ and Windows’ respective canonical cache directories. Each OS has that place specifically to place things like those datasets there. > For example, the main hpc I'm on only gives me about 1gb of space where appdirs would put these files. Ouch. Seems like it’s time to file a bug report.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:362,security,hack,hacked,362,"> though I definitely see a lot of toolkits using something like ~/.{toolkitname} on my mac. . There’s two possible reasons: 1.: We’re talking about something from the 80’s like SSH or BASH. They earned their right to things their way because they’re older than the standards they’re not following. Or 2.: Whoever designed this didn’t do their research and just hacked in first thing that came to mind. This is not an excuse. MacOS knows about `~/Library/Caches` and to clean it out when disk space gets scarce. The same applies to Linux’ and Windows’ respective canonical cache directories. Each OS has that place specifically to place things like those datasets there. > For example, the main hpc I'm on only gives me about 1gb of space where appdirs would put these files. Ouch. Seems like it’s time to file a bug report.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:35,usability,tool,toolkits,35,"> though I definitely see a lot of toolkits using something like ~/.{toolkitname} on my mac. . There’s two possible reasons: 1.: We’re talking about something from the 80’s like SSH or BASH. They earned their right to things their way because they’re older than the standards they’re not following. Or 2.: Whoever designed this didn’t do their research and just hacked in first thing that came to mind. This is not an excuse. MacOS knows about `~/Library/Caches` and to clean it out when disk space gets scarce. The same applies to Linux’ and Windows’ respective canonical cache directories. Each OS has that place specifically to place things like those datasets there. > For example, the main hpc I'm on only gives me about 1gb of space where appdirs would put these files. Ouch. Seems like it’s time to file a bug report.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:69,usability,tool,toolkitname,69,"> though I definitely see a lot of toolkits using something like ~/.{toolkitname} on my mac. . There’s two possible reasons: 1.: We’re talking about something from the 80’s like SSH or BASH. They earned their right to things their way because they’re older than the standards they’re not following. Or 2.: Whoever designed this didn’t do their research and just hacked in first thing that came to mind. This is not an excuse. MacOS knows about `~/Library/Caches` and to clean it out when disk space gets scarce. The same applies to Linux’ and Windows’ respective canonical cache directories. Each OS has that place specifically to place things like those datasets there. > For example, the main hpc I'm on only gives me about 1gb of space where appdirs would put these files. Ouch. Seems like it’s time to file a bug report.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:159,deployability,instal,installation,159,"Hey! 😄 . I'd in principle happy if we move the default `scanpy.settings.cachedir` from `./cache/` to `appdirs.user_cache_dir()`. . However, if then any Scanpy installation breaks, as _the main hpc I'm on 1gb of space where appdirs would put these files_, I would probably not make this the default, but choose something like `~/cache-scanpy/`, that is, a visible directory in home (if we really want, `~/.scanpy/` is also fine). Under https://scanpy.readthedocs.io/en/latest/api/index.html#settings, we could also talk about other alternatives. I second Isaac's concern. Like many others, I'm computing on AWS these days and there, the canonical way of making data locally accessible is via EBS volumes. Hence, I'm used to setting the cachedir to that mount point with a visible name, knowing that this can hold a lot of data. I'd manually clean it if something that I don't use often takes too much space. So, I fear that `appdirs.user_cache_dir()` is not smart enough to figure out locations on a Linux system that hold the size of data that we're typically talking about. It would for sure be the right solution for laptops and work stations etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:475,deployability,api,api,475,"Hey! 😄 . I'd in principle happy if we move the default `scanpy.settings.cachedir` from `./cache/` to `appdirs.user_cache_dir()`. . However, if then any Scanpy installation breaks, as _the main hpc I'm on 1gb of space where appdirs would put these files_, I would probably not make this the default, but choose something like `~/cache-scanpy/`, that is, a visible directory in home (if we really want, `~/.scanpy/` is also fine). Under https://scanpy.readthedocs.io/en/latest/api/index.html#settings, we could also talk about other alternatives. I second Isaac's concern. Like many others, I'm computing on AWS these days and there, the canonical way of making data locally accessible is via EBS volumes. Hence, I'm used to setting the cachedir to that mount point with a visible name, knowing that this can hold a lot of data. I'd manually clean it if something that I don't use often takes too much space. So, I fear that `appdirs.user_cache_dir()` is not smart enough to figure out locations on a Linux system that hold the size of data that we're typically talking about. It would for sure be the right solution for laptops and work stations etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:475,integrability,api,api,475,"Hey! 😄 . I'd in principle happy if we move the default `scanpy.settings.cachedir` from `./cache/` to `appdirs.user_cache_dir()`. . However, if then any Scanpy installation breaks, as _the main hpc I'm on 1gb of space where appdirs would put these files_, I would probably not make this the default, but choose something like `~/cache-scanpy/`, that is, a visible directory in home (if we really want, `~/.scanpy/` is also fine). Under https://scanpy.readthedocs.io/en/latest/api/index.html#settings, we could also talk about other alternatives. I second Isaac's concern. Like many others, I'm computing on AWS these days and there, the canonical way of making data locally accessible is via EBS volumes. Hence, I'm used to setting the cachedir to that mount point with a visible name, knowing that this can hold a lot of data. I'd manually clean it if something that I don't use often takes too much space. So, I fear that `appdirs.user_cache_dir()` is not smart enough to figure out locations on a Linux system that hold the size of data that we're typically talking about. It would for sure be the right solution for laptops and work stations etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:475,interoperability,api,api,475,"Hey! 😄 . I'd in principle happy if we move the default `scanpy.settings.cachedir` from `./cache/` to `appdirs.user_cache_dir()`. . However, if then any Scanpy installation breaks, as _the main hpc I'm on 1gb of space where appdirs would put these files_, I would probably not make this the default, but choose something like `~/cache-scanpy/`, that is, a visible directory in home (if we really want, `~/.scanpy/` is also fine). Under https://scanpy.readthedocs.io/en/latest/api/index.html#settings, we could also talk about other alternatives. I second Isaac's concern. Like many others, I'm computing on AWS these days and there, the canonical way of making data locally accessible is via EBS volumes. Hence, I'm used to setting the cachedir to that mount point with a visible name, knowing that this can hold a lot of data. I'd manually clean it if something that I don't use often takes too much space. So, I fear that `appdirs.user_cache_dir()` is not smart enough to figure out locations on a Linux system that hold the size of data that we're typically talking about. It would for sure be the right solution for laptops and work stations etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:562,modifiability,concern,concern,562,"Hey! 😄 . I'd in principle happy if we move the default `scanpy.settings.cachedir` from `./cache/` to `appdirs.user_cache_dir()`. . However, if then any Scanpy installation breaks, as _the main hpc I'm on 1gb of space where appdirs would put these files_, I would probably not make this the default, but choose something like `~/cache-scanpy/`, that is, a visible directory in home (if we really want, `~/.scanpy/` is also fine). Under https://scanpy.readthedocs.io/en/latest/api/index.html#settings, we could also talk about other alternatives. I second Isaac's concern. Like many others, I'm computing on AWS these days and there, the canonical way of making data locally accessible is via EBS volumes. Hence, I'm used to setting the cachedir to that mount point with a visible name, knowing that this can hold a lot of data. I'd manually clean it if something that I don't use often takes too much space. So, I fear that `appdirs.user_cache_dir()` is not smart enough to figure out locations on a Linux system that hold the size of data that we're typically talking about. It would for sure be the right solution for laptops and work stations etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:72,performance,cach,cachedir,72,"Hey! 😄 . I'd in principle happy if we move the default `scanpy.settings.cachedir` from `./cache/` to `appdirs.user_cache_dir()`. . However, if then any Scanpy installation breaks, as _the main hpc I'm on 1gb of space where appdirs would put these files_, I would probably not make this the default, but choose something like `~/cache-scanpy/`, that is, a visible directory in home (if we really want, `~/.scanpy/` is also fine). Under https://scanpy.readthedocs.io/en/latest/api/index.html#settings, we could also talk about other alternatives. I second Isaac's concern. Like many others, I'm computing on AWS these days and there, the canonical way of making data locally accessible is via EBS volumes. Hence, I'm used to setting the cachedir to that mount point with a visible name, knowing that this can hold a lot of data. I'd manually clean it if something that I don't use often takes too much space. So, I fear that `appdirs.user_cache_dir()` is not smart enough to figure out locations on a Linux system that hold the size of data that we're typically talking about. It would for sure be the right solution for laptops and work stations etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:90,performance,cach,cache,90,"Hey! 😄 . I'd in principle happy if we move the default `scanpy.settings.cachedir` from `./cache/` to `appdirs.user_cache_dir()`. . However, if then any Scanpy installation breaks, as _the main hpc I'm on 1gb of space where appdirs would put these files_, I would probably not make this the default, but choose something like `~/cache-scanpy/`, that is, a visible directory in home (if we really want, `~/.scanpy/` is also fine). Under https://scanpy.readthedocs.io/en/latest/api/index.html#settings, we could also talk about other alternatives. I second Isaac's concern. Like many others, I'm computing on AWS these days and there, the canonical way of making data locally accessible is via EBS volumes. Hence, I'm used to setting the cachedir to that mount point with a visible name, knowing that this can hold a lot of data. I'd manually clean it if something that I don't use often takes too much space. So, I fear that `appdirs.user_cache_dir()` is not smart enough to figure out locations on a Linux system that hold the size of data that we're typically talking about. It would for sure be the right solution for laptops and work stations etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:328,performance,cach,cache-scanpy,328,"Hey! 😄 . I'd in principle happy if we move the default `scanpy.settings.cachedir` from `./cache/` to `appdirs.user_cache_dir()`. . However, if then any Scanpy installation breaks, as _the main hpc I'm on 1gb of space where appdirs would put these files_, I would probably not make this the default, but choose something like `~/cache-scanpy/`, that is, a visible directory in home (if we really want, `~/.scanpy/` is also fine). Under https://scanpy.readthedocs.io/en/latest/api/index.html#settings, we could also talk about other alternatives. I second Isaac's concern. Like many others, I'm computing on AWS these days and there, the canonical way of making data locally accessible is via EBS volumes. Hence, I'm used to setting the cachedir to that mount point with a visible name, knowing that this can hold a lot of data. I'd manually clean it if something that I don't use often takes too much space. So, I fear that `appdirs.user_cache_dir()` is not smart enough to figure out locations on a Linux system that hold the size of data that we're typically talking about. It would for sure be the right solution for laptops and work stations etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:735,performance,cach,cachedir,735,"Hey! 😄 . I'd in principle happy if we move the default `scanpy.settings.cachedir` from `./cache/` to `appdirs.user_cache_dir()`. . However, if then any Scanpy installation breaks, as _the main hpc I'm on 1gb of space where appdirs would put these files_, I would probably not make this the default, but choose something like `~/cache-scanpy/`, that is, a visible directory in home (if we really want, `~/.scanpy/` is also fine). Under https://scanpy.readthedocs.io/en/latest/api/index.html#settings, we could also talk about other alternatives. I second Isaac's concern. Like many others, I'm computing on AWS these days and there, the canonical way of making data locally accessible is via EBS volumes. Hence, I'm used to setting the cachedir to that mount point with a visible name, knowing that this can hold a lot of data. I'd manually clean it if something that I don't use often takes too much space. So, I fear that `appdirs.user_cache_dir()` is not smart enough to figure out locations on a Linux system that hold the size of data that we're typically talking about. It would for sure be the right solution for laptops and work stations etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:673,security,access,accessible,673,"Hey! 😄 . I'd in principle happy if we move the default `scanpy.settings.cachedir` from `./cache/` to `appdirs.user_cache_dir()`. . However, if then any Scanpy installation breaks, as _the main hpc I'm on 1gb of space where appdirs would put these files_, I would probably not make this the default, but choose something like `~/cache-scanpy/`, that is, a visible directory in home (if we really want, `~/.scanpy/` is also fine). Under https://scanpy.readthedocs.io/en/latest/api/index.html#settings, we could also talk about other alternatives. I second Isaac's concern. Like many others, I'm computing on AWS these days and there, the canonical way of making data locally accessible is via EBS volumes. Hence, I'm used to setting the cachedir to that mount point with a visible name, knowing that this can hold a lot of data. I'd manually clean it if something that I don't use often takes too much space. So, I fear that `appdirs.user_cache_dir()` is not smart enough to figure out locations on a Linux system that hold the size of data that we're typically talking about. It would for sure be the right solution for laptops and work stations etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:562,testability,concern,concern,562,"Hey! 😄 . I'd in principle happy if we move the default `scanpy.settings.cachedir` from `./cache/` to `appdirs.user_cache_dir()`. . However, if then any Scanpy installation breaks, as _the main hpc I'm on 1gb of space where appdirs would put these files_, I would probably not make this the default, but choose something like `~/cache-scanpy/`, that is, a visible directory in home (if we really want, `~/.scanpy/` is also fine). Under https://scanpy.readthedocs.io/en/latest/api/index.html#settings, we could also talk about other alternatives. I second Isaac's concern. Like many others, I'm computing on AWS these days and there, the canonical way of making data locally accessible is via EBS volumes. Hence, I'm used to setting the cachedir to that mount point with a visible name, knowing that this can hold a lot of data. I'd manually clean it if something that I don't use often takes too much space. So, I fear that `appdirs.user_cache_dir()` is not smart enough to figure out locations on a Linux system that hold the size of data that we're typically talking about. It would for sure be the right solution for laptops and work stations etc.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:205,availability,down,download,205,PS: `pbmc68k_reduced` and `toggleswitch` are from back in the days; they should remain the only examples that actually have the data in the repository and the PyPI distributions. All other datasets should download their data from some stable URL...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:27,deployability,toggl,toggleswitch,27,PS: `pbmc68k_reduced` and `toggleswitch` are from back in the days; they should remain the only examples that actually have the data in the repository and the PyPI distributions. All other datasets should download their data from some stable URL...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:140,integrability,repositor,repository,140,PS: `pbmc68k_reduced` and `toggleswitch` are from back in the days; they should remain the only examples that actually have the data in the repository and the PyPI distributions. All other datasets should download their data from some stable URL...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:140,interoperability,repositor,repository,140,PS: `pbmc68k_reduced` and `toggleswitch` are from back in the days; they should remain the only examples that actually have the data in the repository and the PyPI distributions. All other datasets should download their data from some stable URL...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:164,interoperability,distribut,distributions,164,PS: `pbmc68k_reduced` and `toggleswitch` are from back in the days; they should remain the only examples that actually have the data in the repository and the PyPI distributions. All other datasets should download their data from some stable URL...,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:114,availability,down,download,114,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```. python3 download_expression_atlas.py {accession}. ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:411,availability,down,download,411,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```. python3 download_expression_atlas.py {accession}. ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:501,availability,down,download,501,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```. python3 download_expression_atlas.py {accession}. ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:576,availability,down,downloads,576,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```. python3 download_expression_atlas.py {accession}. ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:676,availability,redund,redundant,676,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```. python3 download_expression_atlas.py {accession}. ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:196,deployability,instal,installed,196,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```. python3 download_expression_atlas.py {accession}. ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:642,deployability,version,version,642,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```. python3 download_expression_atlas.py {accession}. ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:676,deployability,redundan,redundant,676,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```. python3 download_expression_atlas.py {accession}. ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:642,integrability,version,version,642,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```. python3 download_expression_atlas.py {accession}. ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:642,modifiability,version,version,642,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```. python3 download_expression_atlas.py {accession}. ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:398,reliability,doe,does,398,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```. python3 download_expression_atlas.py {accession}. ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:676,reliability,redundan,redundant,676,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```. python3 download_expression_atlas.py {accession}. ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:676,safety,redund,redundant,676,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```. python3 download_expression_atlas.py {accession}. ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:299,security,access,accession,299,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```. python3 download_expression_atlas.py {accession}. ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:324,security,access,accession,324,"@maximilianh Sure! This [gist](https://gist.github.com/ivirshup/e7f0c435474d9b06b622c63d4221afe6) has a script to download a dataset and write it to a `.h5ad` file. I think having scanpy and tqdm installed should be sufficient to run it. Usage should be:. ```. python3 download_expression_atlas.py {accession}. ``` . where `accession` is something like: `E-EHCA-2` or `E-GEOD-98816`. . But what it does is just download and parse the expression `.zip` and ""Experiment design file"" from each dataset's download page ([example](https://www.ebi.ac.uk/gxa/sc/experiments/E-EHCA-2/downloads)). I think the experiment design files are a cleaned up version of the `.sdrf` file (some redundant fields are removed, field names can be less verbose).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:189,modifiability,variab,variables,189,I think @falexwolf voiced my thoughts much more eloquently. A non-hidden directory in the root folder makes a sensible default to me. Would anyone be against also having some environmental variables/ a scanpy config (I’m thinking `.cfg` or `.json`) so this (and things like verbosity) don’t have to be set manually each session?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:320,security,session,session,320,I think @falexwolf voiced my thoughts much more eloquently. A non-hidden directory in the root folder makes a sensible default to me. Would anyone be against also having some environmental variables/ a scanpy config (I’m thinking `.cfg` or `.json`) so this (and things like verbosity) don’t have to be set manually each session?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:66,availability,cluster,cluster,66,"not that it matters, but I agree with Alex and Isaac. Our compute cluster. also is extremely picky on where you put data >100MB and the directories. and their differences are completely obscure to anyone but its users. (=""big"" file systems vs ""fast fstat"" file systems vs ""archival"" file. systems). >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:66,deployability,cluster,cluster,66,"not that it matters, but I agree with Alex and Isaac. Our compute cluster. also is extremely picky on where you put data >100MB and the directories. and their differences are completely obscure to anyone but its users. (=""big"" file systems vs ""fast fstat"" file systems vs ""archival"" file. systems). >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:175,safety,compl,completely,175,"not that it matters, but I agree with Alex and Isaac. Our compute cluster. also is extremely picky on where you put data >100MB and the directories. and their differences are completely obscure to anyone but its users. (=""big"" file systems vs ""fast fstat"" file systems vs ""archival"" file. systems). >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:175,security,compl,completely,175,"not that it matters, but I agree with Alex and Isaac. Our compute cluster. also is extremely picky on where you put data >100MB and the directories. and their differences are completely obscure to anyone but its users. (=""big"" file systems vs ""fast fstat"" file systems vs ""archival"" file. systems). >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:212,usability,user,users,212,"not that it matters, but I agree with Alex and Isaac. Our compute cluster. also is extremely picky on where you put data >100MB and the directories. and their differences are completely obscure to anyone but its users. (=""big"" file systems vs ""fast fstat"" file systems vs ""archival"" file. systems). >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:214,availability,Error,Error,214,"> the main hpc I'm on 1gb of space where appdirs would put these files. That's a misconfigured server, not a normal case. We should use appdirs as default, catch a IOError on write, and send a nice message like. > Error: Cannot write to your cache directory. Please make sure there's space in {cache_dir!r} or override the cache directory by setting one of the $SCANPY_CACHE_DIR or $XDG_CACHE_DIR environment variables. All linux-based systems should set $XDG_CACHE_DIR if there's a better place than ~/.cache for such files.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:198,integrability,messag,message,198,"> the main hpc I'm on 1gb of space where appdirs would put these files. That's a misconfigured server, not a normal case. We should use appdirs as default, catch a IOError on write, and send a nice message like. > Error: Cannot write to your cache directory. Please make sure there's space in {cache_dir!r} or override the cache directory by setting one of the $SCANPY_CACHE_DIR or $XDG_CACHE_DIR environment variables. All linux-based systems should set $XDG_CACHE_DIR if there's a better place than ~/.cache for such files.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:198,interoperability,messag,message,198,"> the main hpc I'm on 1gb of space where appdirs would put these files. That's a misconfigured server, not a normal case. We should use appdirs as default, catch a IOError on write, and send a nice message like. > Error: Cannot write to your cache directory. Please make sure there's space in {cache_dir!r} or override the cache directory by setting one of the $SCANPY_CACHE_DIR or $XDG_CACHE_DIR environment variables. All linux-based systems should set $XDG_CACHE_DIR if there's a better place than ~/.cache for such files.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:409,modifiability,variab,variables,409,"> the main hpc I'm on 1gb of space where appdirs would put these files. That's a misconfigured server, not a normal case. We should use appdirs as default, catch a IOError on write, and send a nice message like. > Error: Cannot write to your cache directory. Please make sure there's space in {cache_dir!r} or override the cache directory by setting one of the $SCANPY_CACHE_DIR or $XDG_CACHE_DIR environment variables. All linux-based systems should set $XDG_CACHE_DIR if there's a better place than ~/.cache for such files.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:214,performance,Error,Error,214,"> the main hpc I'm on 1gb of space where appdirs would put these files. That's a misconfigured server, not a normal case. We should use appdirs as default, catch a IOError on write, and send a nice message like. > Error: Cannot write to your cache directory. Please make sure there's space in {cache_dir!r} or override the cache directory by setting one of the $SCANPY_CACHE_DIR or $XDG_CACHE_DIR environment variables. All linux-based systems should set $XDG_CACHE_DIR if there's a better place than ~/.cache for such files.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:242,performance,cach,cache,242,"> the main hpc I'm on 1gb of space where appdirs would put these files. That's a misconfigured server, not a normal case. We should use appdirs as default, catch a IOError on write, and send a nice message like. > Error: Cannot write to your cache directory. Please make sure there's space in {cache_dir!r} or override the cache directory by setting one of the $SCANPY_CACHE_DIR or $XDG_CACHE_DIR environment variables. All linux-based systems should set $XDG_CACHE_DIR if there's a better place than ~/.cache for such files.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:323,performance,cach,cache,323,"> the main hpc I'm on 1gb of space where appdirs would put these files. That's a misconfigured server, not a normal case. We should use appdirs as default, catch a IOError on write, and send a nice message like. > Error: Cannot write to your cache directory. Please make sure there's space in {cache_dir!r} or override the cache directory by setting one of the $SCANPY_CACHE_DIR or $XDG_CACHE_DIR environment variables. All linux-based systems should set $XDG_CACHE_DIR if there's a better place than ~/.cache for such files.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:504,performance,cach,cache,504,"> the main hpc I'm on 1gb of space where appdirs would put these files. That's a misconfigured server, not a normal case. We should use appdirs as default, catch a IOError on write, and send a nice message like. > Error: Cannot write to your cache directory. Please make sure there's space in {cache_dir!r} or override the cache directory by setting one of the $SCANPY_CACHE_DIR or $XDG_CACHE_DIR environment variables. All linux-based systems should set $XDG_CACHE_DIR if there's a better place than ~/.cache for such files.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:214,safety,Error,Error,214,"> the main hpc I'm on 1gb of space where appdirs would put these files. That's a misconfigured server, not a normal case. We should use appdirs as default, catch a IOError on write, and send a nice message like. > Error: Cannot write to your cache directory. Please make sure there's space in {cache_dir!r} or override the cache directory by setting one of the $SCANPY_CACHE_DIR or $XDG_CACHE_DIR environment variables. All linux-based systems should set $XDG_CACHE_DIR if there's a better place than ~/.cache for such files.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:214,usability,Error,Error,214,"> the main hpc I'm on 1gb of space where appdirs would put these files. That's a misconfigured server, not a normal case. We should use appdirs as default, catch a IOError on write, and send a nice message like. > Error: Cannot write to your cache directory. Please make sure there's space in {cache_dir!r} or override the cache directory by setting one of the $SCANPY_CACHE_DIR or $XDG_CACHE_DIR environment variables. All linux-based systems should set $XDG_CACHE_DIR if there's a better place than ~/.cache for such files.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:364,integrability,messag,message,364,"@flyingsheep I can assure you, that's the normal case in academic HPC. systems. On Tue, Mar 26, 2019 at 3:37 PM Philipp A. <notifications@github.com> wrote:. > the main hpc I'm on 1gb of space where appdirs would put these files. >. > That's a misconfigured server, not a normal case. We should use appdirs as. > default, catch a IOError on write, and send a nice message like. >. > Your cache directory is full. Please make sure there's space in. > {cache_dir} or override the cache directory by setting the. > $SCANPY_CACHE_DIR environment variable. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/558#issuecomment-476675808>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAS-TQPrmr3LWdmwNL5O6XPnRdSAcl_1ks5vajC0gaJpZM4cKXC7>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:364,interoperability,messag,message,364,"@flyingsheep I can assure you, that's the normal case in academic HPC. systems. On Tue, Mar 26, 2019 at 3:37 PM Philipp A. <notifications@github.com> wrote:. > the main hpc I'm on 1gb of space where appdirs would put these files. >. > That's a misconfigured server, not a normal case. We should use appdirs as. > default, catch a IOError on write, and send a nice message like. >. > Your cache directory is full. Please make sure there's space in. > {cache_dir} or override the cache directory by setting the. > $SCANPY_CACHE_DIR environment variable. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/558#issuecomment-476675808>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAS-TQPrmr3LWdmwNL5O6XPnRdSAcl_1ks5vajC0gaJpZM4cKXC7>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:542,modifiability,variab,variable,542,"@flyingsheep I can assure you, that's the normal case in academic HPC. systems. On Tue, Mar 26, 2019 at 3:37 PM Philipp A. <notifications@github.com> wrote:. > the main hpc I'm on 1gb of space where appdirs would put these files. >. > That's a misconfigured server, not a normal case. We should use appdirs as. > default, catch a IOError on write, and send a nice message like. >. > Your cache directory is full. Please make sure there's space in. > {cache_dir} or override the cache directory by setting the. > $SCANPY_CACHE_DIR environment variable. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/558#issuecomment-476675808>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAS-TQPrmr3LWdmwNL5O6XPnRdSAcl_1ks5vajC0gaJpZM4cKXC7>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:388,performance,cach,cache,388,"@flyingsheep I can assure you, that's the normal case in academic HPC. systems. On Tue, Mar 26, 2019 at 3:37 PM Philipp A. <notifications@github.com> wrote:. > the main hpc I'm on 1gb of space where appdirs would put these files. >. > That's a misconfigured server, not a normal case. We should use appdirs as. > default, catch a IOError on write, and send a nice message like. >. > Your cache directory is full. Please make sure there's space in. > {cache_dir} or override the cache directory by setting the. > $SCANPY_CACHE_DIR environment variable. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/558#issuecomment-476675808>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAS-TQPrmr3LWdmwNL5O6XPnRdSAcl_1ks5vajC0gaJpZM4cKXC7>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:478,performance,cach,cache,478,"@flyingsheep I can assure you, that's the normal case in academic HPC. systems. On Tue, Mar 26, 2019 at 3:37 PM Philipp A. <notifications@github.com> wrote:. > the main hpc I'm on 1gb of space where appdirs would put these files. >. > That's a misconfigured server, not a normal case. We should use appdirs as. > default, catch a IOError on write, and send a nice message like. >. > Your cache directory is full. Please make sure there's space in. > {cache_dir} or override the cache directory by setting the. > $SCANPY_CACHE_DIR environment variable. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/558#issuecomment-476675808>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAS-TQPrmr3LWdmwNL5O6XPnRdSAcl_1ks5vajC0gaJpZM4cKXC7>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:809,security,auth,auth,809,"@flyingsheep I can assure you, that's the normal case in academic HPC. systems. On Tue, Mar 26, 2019 at 3:37 PM Philipp A. <notifications@github.com> wrote:. > the main hpc I'm on 1gb of space where appdirs would put these files. >. > That's a misconfigured server, not a normal case. We should use appdirs as. > default, catch a IOError on write, and send a nice message like. >. > Your cache directory is full. Please make sure there's space in. > {cache_dir} or override the cache directory by setting the. > $SCANPY_CACHE_DIR environment variable. >. > —. > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/558#issuecomment-476675808>,. > or mute the thread. > <https://github.com/notifications/unsubscribe-auth/AAS-TQPrmr3LWdmwNL5O6XPnRdSAcl_1ks5vajC0gaJpZM4cKXC7>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:247,modifiability,variab,variable,247,"Sure, and I'm not against supporting special cases! Could you please explain the setup? Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? Some systems are strange. We should be nice and support those systems while still doing the correct thing by default. We shouldn't do the wrong thing by default to accommodate strange cases.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:134,performance,cach,cache,134,"Sure, and I'm not against supporting special cases! Could you please explain the setup? Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? Some systems are strange. We should be nice and support those systems while still doing the correct thing by default. We shouldn't do the wrong thing by default to accommodate strange cases.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:282,performance,cach,cache,282,"Sure, and I'm not against supporting special cases! Could you please explain the setup? Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? Some systems are strange. We should be nice and support those systems while still doing the correct thing by default. We shouldn't do the wrong thing by default to accommodate strange cases.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:194,safety,detect,detect,194,"Sure, and I'm not against supporting special cases! Could you please explain the setup? Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? Some systems are strange. We should be nice and support those systems while still doing the correct thing by default. We shouldn't do the wrong thing by default to accommodate strange cases.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:194,security,detect,detect,194,"Sure, and I'm not against supporting special cases! Could you please explain the setup? Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? Some systems are strange. We should be nice and support those systems while still doing the correct thing by default. We shouldn't do the wrong thing by default to accommodate strange cases.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:26,usability,support,supporting,26,"Sure, and I'm not against supporting special cases! Could you please explain the setup? Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? Some systems are strange. We should be nice and support those systems while still doing the correct thing by default. We shouldn't do the wrong thing by default to accommodate strange cases.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:102,usability,user,user,102,"Sure, and I'm not against supporting special cases! Could you please explain the setup? Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? Some systems are strange. We should be nice and support those systems while still doing the correct thing by default. We shouldn't do the wrong thing by default to accommodate strange cases.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:165,usability,user,user,165,"Sure, and I'm not against supporting special cases! Could you please explain the setup? Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? Some systems are strange. We should be nice and support those systems while still doing the correct thing by default. We shouldn't do the wrong thing by default to accommodate strange cases.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:347,usability,support,support,347,"Sure, and I'm not against supporting special cases! Could you please explain the setup? Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? Some systems are strange. We should be nice and support those systems while still doing the correct thing by default. We shouldn't do the wrong thing by default to accommodate strange cases.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:159,deployability,instal,install,159,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:297,deployability,instal,installing,297,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:179,modifiability,pac,packages,179,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:317,modifiability,pac,package,317,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:526,modifiability,variab,variable,526,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:798,modifiability,responsibil,responsibility,798,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:413,performance,cach,cache,413,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:561,performance,cach,cache,561,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:607,performance,cach,cache,607,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:620,performance,cach,cache,620,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:872,performance,cach,cache,872,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:913,performance,time,time,913,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:233,safety,avoid,avoid,233,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:473,safety,detect,detect,473,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:473,security,detect,detect,473,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:381,usability,user,user,381,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:444,usability,user,user,444,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:589,usability,user,user,589,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:791,usability,user,user,791,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:959,usability,user,user,959,"> @flyingsheep I can assure you, that's the normal case in academic HPC systems. I agree that this is a huge and common problem in many HPC systems. I usually install conda and R packages to non-home directories with bigger space to avoid issues on servers. One can fill up hundreds of MB by just installing a single package e.g. human genome from Bioconductor 😄 . > Do you have a user home? Is there a canonical cache directory outside of the user home? Is there a way to detect that we are on such a system or a environment variable pointing to the canonical cache directory? There is a user home and the cache is `~/.cache` and $XDG_CACHE_HOME is undefined (at least in my case). Some pip wheel files are there for example. . Although it's painful to work in such systems, I believe it's user's responsibility to fix this. One idea might be to print a warning when the cache directory is created for the first time along with the path itself to inform the user about where files are.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:218,availability,down,download,218,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download? @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`. * `seaborn` – `~/seaborn-data`. * `NLTK` – `~/nltk_data`. * `keras` and `tensorflow` – `~/.keras/datasets`. * `conda` – `~/miniconda3/`. * `intake` – `~/.intake/cache/` (specifically for caching feature). * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:272,availability,error,error,272,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download? @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`. * `seaborn` – `~/seaborn-data`. * `NLTK` – `~/nltk_data`. * `keras` and `tensorflow` – `~/.keras/datasets`. * `conda` – `~/miniconda3/`. * `intake` – `~/.intake/cache/` (specifically for caching feature). * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:985,availability,Sla,Slack,985,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download? @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`. * `seaborn` – `~/seaborn-data`. * `NLTK` – `~/nltk_data`. * `keras` and `tensorflow` – `~/.keras/datasets`. * `conda` – `~/miniconda3/`. * `intake` – `~/.intake/cache/` (specifically for caching feature). * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:1037,availability,avail,available,1037,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download? @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`. * `seaborn` – `~/seaborn-data`. * `NLTK` – `~/nltk_data`. * `keras` and `tensorflow` – `~/.keras/datasets`. * `conda` – `~/miniconda3/`. * `intake` – `~/.intake/cache/` (specifically for caching feature). * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:492,deployability,instal,installing,492,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download? @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`. * `seaborn` – `~/seaborn-data`. * `NLTK` – `~/nltk_data`. * `keras` and `tensorflow` – `~/.keras/datasets`. * `conda` – `~/miniconda3/`. * `intake` – `~/.intake/cache/` (specifically for caching feature). * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:851,deployability,log,log,851,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download? @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`. * `seaborn` – `~/seaborn-data`. * `NLTK` – `~/nltk_data`. * `keras` and `tensorflow` – `~/.keras/datasets`. * `conda` – `~/miniconda3/`. * `intake` – `~/.intake/cache/` (specifically for caching feature). * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:897,energy efficiency,model,model,897,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download? @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`. * `seaborn` – `~/seaborn-data`. * `NLTK` – `~/nltk_data`. * `keras` and `tensorflow` – `~/.keras/datasets`. * `conda` – `~/miniconda3/`. * `intake` – `~/.intake/cache/` (specifically for caching feature). * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:448,integrability,coupl,couple,448,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download? @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`. * `seaborn` – `~/seaborn-data`. * `NLTK` – `~/nltk_data`. * `keras` and `tensorflow` – `~/.keras/datasets`. * `conda` – `~/miniconda3/`. * `intake` – `~/.intake/cache/` (specifically for caching feature). * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:505,integrability,coupl,couple,505,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download? @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`. * `seaborn` – `~/seaborn-data`. * `NLTK` – `~/nltk_data`. * `keras` and `tensorflow` – `~/.keras/datasets`. * `conda` – `~/miniconda3/`. * `intake` – `~/.intake/cache/` (specifically for caching feature). * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:1310,interoperability,specif,specifically,1310,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download? @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`. * `seaborn` – `~/seaborn-data`. * `NLTK` – `~/nltk_data`. * `keras` and `tensorflow` – `~/.keras/datasets`. * `conda` – `~/miniconda3/`. * `intake` – `~/.intake/cache/` (specifically for caching feature). * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:45,modifiability,responsibil,responsibility,45,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download? @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`. * `seaborn` – `~/seaborn-data`. * `NLTK` – `~/nltk_data`. * `keras` and `tensorflow` – `~/.keras/datasets`. * `conda` – `~/miniconda3/`. * `intake` – `~/.intake/cache/` (specifically for caching feature). * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
https://github.com/scverse/scanpy/issues/558:92,modifiability,responsibil,responsibility,92,"@gokceneraslan Totally agree it's the user's responsibility. I would say that it's the devs responsibility to make it as easy as possible for the user. How about printing the absolute path of the data's destination on download? @flying-sheep Would there necessarily be an error if space ran out? I could probably fit a few datasets in 2gb. From your previous depiction, I thought the older ones would just be deleted, right? If you had space for a couple datasets, wouldn't it be likely that installing a couple things with pip would clear these datasets on a system like we're describing? I'm not sure I find this behavior intuitive for this use case. Also here's the [docs](https://opus.nci.org.au/display/Help/Filesystems+User+Guide#FilesystemsUserGuide-DiskQuotaPolicy) for my HPCs filesystem. I don't have an `XDG_CACHE_HOME` variable set when I log in. I'm also not sure scanpy fits the app model. When I look in my `~/Library/Caches/` I see things like Illustrator, VSCode, and Slack. When I think about example datasets that are available through scientific computing packages I think of:. * `scikit-learn` – `~/scikit_learn_data`. * `seaborn` – `~/seaborn-data`. * `NLTK` – `~/nltk_data`. * `keras` and `tensorflow` – `~/.keras/datasets`. * `conda` – `~/miniconda3/`. * `intake` – `~/.intake/cache/` (specifically for caching feature). * CRAN and bioconductor data packages – same place as packages I think",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/558
